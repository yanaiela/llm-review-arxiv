arxiv_id,title,abstract,classified_type,MARIA_ANNOTATION,YANAI_ANNOTATION,YANAI_COMMENT,MARIA_COMMENT
2408.01934,A Survey and Evaluation of Adversarial Attacks for Object Detection,"  Deep learning models excel in various computer vision tasks but are
susceptible to adversarial examples-subtle perturbations in input data that
lead to incorrect predictions. This vulnerability poses significant risks in
safety-critical applications such as autonomous vehicles, security
surveillance, and aircraft health monitoring. While numerous surveys focus on
adversarial attacks in image classification, the literature on such attacks in
object detection is limited. This paper offers a comprehensive taxonomy of
adversarial attacks specific to object detection, reviews existing adversarial
robustness evaluation metrics, and systematically assesses open-source attack
methods and model robustness. Key observations are provided to enhance the
understanding of attack effectiveness and corresponding countermeasures.
Additionally, we identify crucial research challenges to guide future efforts
in securing automated object detection systems.
",review,1,1,,
2109.10572,"Realism of Simulation Models in Serious Gaming: Two case studies from
  Urban Water Management Higher Education","  For games used in educational contexts, realism, i.e., the degree of
congruence between the simulation models used in the games and the real-world
systems represented, is an important characteristic for achieving learning
goals well. However, in the past, the realism of especially entertainment games
has often been identified as insufficient. Thus, this study is investigating
the degree of realism provided by current games. To this purpose, two games in
the domain urban water management, a subdomain of environmental engineering
(EE), are examined. One is ANAWAK, a web-based serious game on water management
and climate change. For ANAWAK, an analysis of the simulation model is
conducted. Second, the simulation model of the entertainment game Cities:
Skylines (CS) is analyzed. In addition, a survey among CS players (N=61) is
conducted. Thereby, different degrees of realism in various EE subdomains are
revealed. All in all, there are still considerable deficits regarding the
degree of realism in the CS simulation model. However, modding as a means of
achieving more realistic simulation models is more widely supported than in the
past.
",review,0,0,,
2308.13821,"A Survey of Imbalanced Learning on Graphs: Problems, Techniques, and
  Future Directions","  Graphs represent interconnected structures prevalent in a myriad of
real-world scenarios. Effective graph analytics, such as graph learning
methods, enables users to gain profound insights from graph data, underpinning
various tasks including node classification and link prediction. However, these
methods often suffer from data imbalance, a common issue in graph data where
certain segments possess abundant data while others are scarce, thereby leading
to biased learning outcomes. This necessitates the emerging field of imbalanced
learning on graphs, which aims to correct these data distribution skews for
more accurate and representative learning outcomes. In this survey, we embark
on a comprehensive review of the literature on imbalanced learning on graphs.
We begin by providing a definitive understanding of the concept and related
terminologies, establishing a strong foundational understanding for readers.
Following this, we propose two comprehensive taxonomies: (1) the problem
taxonomy, which describes the forms of imbalance we consider, the associated
tasks, and potential solutions; (2) the technique taxonomy, which details key
strategies for addressing these imbalances, and aids readers in their method
selection process. Finally, we suggest prospective future directions for both
problems and techniques within the sphere of imbalanced learning on graphs,
fostering further innovation in this critical area.
",review,1,1,,
2309.07689,"Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated
  Text","  While recent advancements in the capabilities and widespread accessibility of
generative language models, such as ChatGPT (OpenAI, 2022), have brought about
various benefits by generating fluent human-like text, the task of
distinguishing between human- and large language model (LLM) generated text has
emerged as a crucial problem. These models can potentially deceive by
generating artificial text that appears to be human-generated. This issue is
particularly significant in domains such as law, education, and science, where
ensuring the integrity of text is of the utmost importance. This survey
provides an overview of the current approaches employed to differentiate
between texts generated by humans and ChatGPT. We present an account of the
different datasets constructed for detecting ChatGPT-generated text, the
various methods utilized, what qualitative analyses into the characteristics of
human versus ChatGPT-generated text have been performed, and finally, summarize
our findings into general insights
",review,1,1,,
2406.10948,"Incorporating uncertainty quantification into travel mode choice
  modeling: a Bayesian neural network (BNN) approach and an uncertainty-guided
  active survey framework","  Existing deep learning approaches for travel mode choice modeling fail to
inform modelers about their prediction uncertainty. Even when facing scenarios
that are out of the distribution of training data, which implies high
prediction uncertainty, these approaches still provide deterministic answers,
potentially leading to misguidance. To address this limitation, this study
introduces the concept of uncertainty from the field of explainable artificial
intelligence into travel mode choice modeling. We propose a Bayesian neural
network-based travel mode prediction model (BTMP) that quantifies the
uncertainty of travel mode predictions, enabling the model itself to ""know"" and
""tell"" what it doesn't know. With BTMP, we further propose an
uncertainty-guided active survey framework, which dynamically formulates survey
questions representing travel mode choice scenarios with high prediction
uncertainty. Through iterative collection of responses to these dynamically
tailored survey questions, BTMP is iteratively trained to achieve the desired
accuracy faster with fewer questions, thereby reducing survey costs.
Experimental validation using synthetic datasets confirms the effectiveness of
BTMP in quantifying prediction uncertainty. Furthermore, experiments, utilizing
both synthetic and real-world data, demonstrate that the BTMP model, trained
with the uncertainty-guided active survey framework, requires 20% to 50% fewer
survey responses to match the performance of the model trained on randomly
collected survey data. Overall, the proposed BTMP model and active survey
framework innovatively incorporate uncertainty quantification into travel mode
choice modeling, providing model users with essential insights into prediction
reliability while optimizing data collection for deep learning model training
in a cost-efficient manner.
",review,0,0,,
2108.12673,"Tracing app technology: An ethical review in the COVID-19 era and
  directions for post-COVID-19","  We conducted a systematic literature review on the ethical considerations of
the use of contact tracing app technology, which was extensively implemented
during the COVID-19 pandemic. The rapid and extensive use of this technology
during the COVID-19 pandemic, while benefiting the public well-being by
providing information about people's mobility and movements to control the
spread of the virus, raised several ethical concerns for the post-COVID-19 era.
To investigate these concerns for the post-pandemic situation and provide
direction for future events, we analyzed the current ethical frameworks,
research, and case studies about the ethical usage of tracing app technology.
The results suggest there are seven essential ethical considerations, namely
privacy, security, acceptability, government surveillance, transparency,
justice, and voluntariness in the ethical use of contact tracing technology. In
this paper, we explain and discuss these considerations and how they are needed
for the ethical usage of this technology. The findings also highlight the
importance of developing integrated guidelines and frameworks for
implementation of such technology in the post-COVID-19 world.
",review,1,1,,
2404.18337,Additive Spanner Lower Bounds with Optimal Inner Graph Structure,"  We construct $n$-node graphs on which any $O(n)$-size spanner has additive
error at least $+\Omega(n^{3/17})$, improving on the previous best lower bound
of $\Omega(n^{1/7})$ [Bodwin-Hoppenworth FOCS '22]. Our construction completes
the first two steps of a particular three-step research program, introduced in
prior work and overviewed here, aimed at producing tight bounds for the problem
by aligning aspects of the upper and lower bound constructions. More
specifically, we develop techniques that enable the use of inner graphs in the
lower bound framework whose technical properties are provably tight with the
corresponding assumptions made in the upper bounds. As an additional
application of our techniques, we improve the corresponding lower bound for
$O(n)$-size additive emulators to $+\Omega(n^{1/14})$.
",review,0,0,,
2302.10856,Overview of the TREC 2021 Fair Ranking Track,"  The TREC Fair Ranking Track aims to provide a platform for participants to
develop and evaluate novel retrieval algorithms that can provide a fair
exposure to a mixture of demographics or attributes, such as ethnicity, that
are represented by relevant documents in response to a search query. For
example, particular demographics or attributes can be represented by the
documents' topical content or authors. The 2021 Fair Ranking Track adopted a
resource allocation task. The task focused on supporting Wikipedia editors who
are looking to improve the encyclopedia's coverage of topics under the purview
of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for
Wikipedia documents that are in need of editing to improve the quality of the
article. The 2021 Fair Ranking track aimed to ensure that documents that are
about, or somehow represent, certain protected characteristics receive a fair
exposure to the Wikipedia editors, so that the documents have an fair
opportunity of being improved and, therefore, be well-represented in Wikipedia.
The under-representation of particular protected characteristics in Wikipedia
can result in systematic biases that can have a negative human, social, and
economic impact, particularly for disadvantaged or protected societal groups.
",review,1,1,I classified this one mostly from the title. the abstract is non sensible for classification,
2112.06522,Anatomizing Bias in Facial Analysis,"  Existing facial analysis systems have been shown to yield biased results
against certain demographic subgroups. Due to its impact on society, it has
become imperative to ensure that these systems do not discriminate based on
gender, identity, or skin tone of individuals. This has led to research in the
identification and mitigation of bias in AI systems. In this paper, we
encapsulate bias detection/estimation and mitigation algorithms for facial
analysis. Our main contributions include a systematic review of algorithms
proposed for understanding bias, along with a taxonomy and extensive overview
of existing bias mitigation algorithms. We also discuss open challenges in the
field of biased facial analysis.
",review,1,1,,
2405.11817,Systematic Review on Healthcare Systems Engineering utilizing ChatGPT,"  This paper presents an analytical framework for conducting academic reviews
in the field of Healthcare Systems Engineering, employing ChatGPT, a
state-of-the-art tool among recent language models. We utilized 9,809 abstract
paragraphs from conference presentations to systematically review the field.
The framework comprises distinct analytical processes, each employing tailored
prompts and the systematic use of the ChatGPT API. Through this framework, we
organized the target field into 11 topic categories and conducted a
comprehensive analysis covering quantitative yearly trends and detailed
sub-categories. This effort explores the potential for leveraging ChatGPT to
alleviate the burden of academic reviews. Furthermore, it provides valuable
insights into the dynamic landscape of Healthcare Systems Engineering research.
",review,1,1,,
2202.08187,"Differential Privacy and Fairness in Decisions and Learning Tasks: A
  Survey","  This paper surveys recent work in the intersection of differential privacy
(DP) and fairness. It reviews the conditions under which privacy and fairness
may have aligned or contrasting goals, analyzes how and why DP may exacerbate
bias and unfairness in decision problems and learning tasks, and describes
available mitigation measures for the fairness issues arising in DP systems.
The survey provides a unified understanding of the main challenges and
potential risks arising when deploying privacy-preserving machine-learning or
decisions-making tasks under a fairness lens.
",review,1,,,
2307.02332,"Co-creating a Transdisciplinary Map of Technology-mediated Harms, Risks
  and Vulnerabilities: Challenges, Ambivalences and Opportunities","  The phrase ""online harms"" has emerged in recent years out of a growing
political willingness to address the ethical and social issues associated with
the use of the Internet and digital technology at large. The broad landscape
that surrounds online harms gathers a multitude of disciplinary, sectoral and
organizational efforts while raising myriad challenges and opportunities for
the crossing entrenched boundaries. In this paper we draw lessons from a
journey of co-creating a transdisciplinary knowledge infrastructure within a
large research initiative animated by the online harms agenda. We begin with a
reflection of the implications of mapping, taxonomizing and constructing
knowledge infrastructures and a brief review of how online harm and adjacent
themes have been theorized and classified in the literature to date. Grounded
on our own experience of co-creating a map of online harms, we then argue that
the map -- and the process of mapping -- perform three mutually constitutive
functions, acting simultaneously as method, medium and provocation. We draw
lessons from how an open-ended approach to mapping, despite not guaranteeing
consensus, can foster productive debate and collaboration in ethically and
politically fraught areas of research. We end with a call for CSCW research to
surface and engage with the multiple temporalities, social lives and political
sensibilities of knowledge infrastructures.
",review,1,1,,
2408.06304,"Control-Flow Attestation: Concepts, Solutions, and Open Challenges","  Control-flow attestation unifies the worlds of control-flow integrity and
platform attestation by measuring and reporting a target's run-time behaviour
to a verifier. Trust assurances in the target are provided by testing whether
its execution follows an authorised control-flow path. The problem has been
explored in various settings, such as assessing the trustworthiness of
cyber-physical systems, Internet of Things devices, cloud platforms, and many
others. Despite a significant number of proposals being made in recent years,
the area remains fragmented, addressing different adversarial behaviours,
verification paradigms, and deployment challenges. In this paper, we present
the first survey of control-flow attestation, examining the core ideas and
solutions in state-of-the-art schemes. In total, we survey over 30 papers
published between 2016-2024, consolidate and compare their key features, and
pose several challenges and recommendations for future research in the area.
",review,1,,,
2204.02921,A survey on recently proposed activation functions for Deep Learning,"  Artificial neural networks (ANN), typically referred to as neural networks,
are a class of Machine Learning algorithms and have achieved widespread
success, having been inspired by the biological structure of the human brain.
Neural networks are inherently powerful due to their ability to learn complex
function approximations from data. This generalization ability has been able to
impact multidisciplinary areas involving image recognition, speech recognition,
natural language processing, and others. Activation functions are a crucial
sub-component of neural networks. They define the output of a node in the
network given a set of inputs. This survey discusses the main concepts of
activation functions in neural networks, including; a brief introduction to
deep neural networks, a summary of what are activation functions and how they
are used in neural networks, their most common properties, the different types
of activation functions, some of the challenges, limitations, and alternative
solutions faced by activation functions, concluding with the final remarks.
",review,1,,,
2310.19687,Sentiment Analysis in Digital Spaces: An Overview of Reviews,"  Sentiment analysis (SA) is commonly applied to digital textual data,
revealing insight into opinions and feelings. Many systematic reviews have
summarized existing work, but often overlook discussions of validity and
scientific practices. Here, we present an overview of reviews, synthesizing 38
systematic reviews, containing 2,275 primary studies. We devise a bespoke
quality assessment framework designed to assess the rigor and quality of
systematic review methodologies and reporting standards. Our findings show
diverse applications and methods, limited reporting rigor, and challenges over
time. We discuss how future research and practitioners can address these issues
and highlight their importance across numerous applications.
",review,1,,,
2407.18597,Reinforcement Learning for Sustainable Energy: A Survey,"  The transition to sustainable energy is a key challenge of our time,
requiring modifications in the entire pipeline of energy production, storage,
transmission, and consumption. At every stage, new sequential decision-making
challenges emerge, ranging from the operation of wind farms to the management
of electrical grids or the scheduling of electric vehicle charging stations.
All such problems are well suited for reinforcement learning, the branch of
machine learning that learns behavior from data. Therefore, numerous studies
have explored the use of reinforcement learning for sustainable energy. This
paper surveys this literature with the intention of bridging both the
underlying research communities: energy and machine learning. After a brief
introduction of both fields, we systematically list relevant sustainability
challenges, how they can be modeled as a reinforcement learning problem, and
what solution approaches currently exist in the literature. Afterwards, we zoom
out and identify overarching reinforcement learning themes that appear
throughout sustainability, such as multi-agent, offline, and safe reinforcement
learning. Lastly, we also cover standardization of environments, which will be
crucial for connecting both research fields, and highlight potential directions
for future work. In summary, this survey provides an extensive overview of
reinforcement learning methods for sustainable energy, which may play a vital
role in the energy transition.
",review,1,,,
2104.11906,"A Review on C3I Systems' Security: Vulnerabilities, Attacks, and
  Countermeasures","  Command, Control, Communication, and Intelligence (C3I) systems are
increasingly used in critical civil and military domains for achieving
information superiority, operational efficacy, and greater situational
awareness. Unlike traditional systems facing widespread cyber-attacks, the
sensitive nature of C3I tactical operations make their cybersecurity a critical
concern. For instance, tampering or intercepting confidential information in
military battlefields not only damages C3I operations, but also causes
irreversible consequences such as loss of human lives and mission failures.
Therefore, C3I systems have become a focal point for cyber adversaries.
Moreover, technological advancements and modernization of C3I systems have
significantly increased the potential risk of cyber-attacks on C3I systems.
Consequently, cyber adversaries leverage highly sophisticated attack vectors to
exploit security vulnerabilities in C3I systems. Despite the burgeoning
significance of cybersecurity for C3I systems, the existing literature lacks a
comprehensive review to systematize the body of knowledge on C3I systems'
security. Therefore, in this paper, we have gathered, analyzed, and synthesized
the state-of-the-art on the cybersecurity of C3I systems. In particular, this
paper has identified security vulnerabilities, attack vectors, and
countermeasures/defenses for C3I systems. Furthermore, our survey has enabled
us to: (i) propose a taxonomy for security vulnerabilities, attack vectors and
countermeasures; (ii) interrelate attack vectors with security vulnerabilities
and countermeasures; and (iii) propose future research directions for advancing
the state-of-the-art on the cybersecurity of C3I systems.
",review,1,,,
2203.00483,"A Survey on How Test Flakiness Affects Developers and What Support They
  Need To Address It","  Non-deterministically passing and failing test cases, so-called flaky tests,
have recently become a focus area of software engineering research. While this
research focus has been met with some enthusiastic endorsement from industry,
prior work nevertheless mostly studied flakiness using a code-centric approach
by mining software repositories. What data extracted from software repositories
cannot tell us, however, is how developers perceive flakiness: How prevalent is
test flakiness in developers' daily routine, how does it affect them, and most
importantly: What do they want us researchers to do about it? To answer these
questions, we surveyed 335 professional software developers and testers in
different domains. The survey respondents confirm that flaky tests are a common
and serious problem, thus reinforcing ongoing research on flaky test detection.
Developers are less worried about the computational costs caused by re-running
tests and more about the loss of trust in the test outcomes. Therefore, they
would like to have IDE plugins to detect flaky code as well as better
visualizations of the problem, particularly dashboards showing test outcomes
over time; they also wish for more training and information on flakiness. These
important aspects will require the attention of researchers as well as tool
developers.
",review,0,,,
2307.12874,"SoK: Design, Vulnerabilities, and Security Measures of Cryptocurrency
  Wallets","  The rapid growth of decentralized digital currencies, enabled by blockchain
technology, has ushered in a new era of peer-to-peer transactions,
revolutionizing the global economy. Cryptocurrency wallets, serving as crucial
endpoints for these transactions, have become increasingly prevalent. However,
the escalating value and usage of these wallets also expose them to significant
security risks and challenges. This research aims to comprehensively explore
the security aspects of cryptocurrency wallets. It provides a taxonomy of
wallet types, analyzes their design and implementation, identifies common
vulnerabilities and attacks, and discusses defense mechanisms and mitigation
strategies. The taxonomy covers custodial, non-custodial, hot, and cold
wallets, highlighting their unique characteristics and associated security
considerations. The security analysis scrutinizes the theoretical and practical
aspects of wallet design, while assessing the efficacy of existing security
measures and protocols. Notable wallet attacks, such as Binance, Mt. Gox are
examined to understand their causes and consequences. Furthermore, the paper
surveys defense mechanisms, transaction monitoring, evaluating their
effectiveness in mitigating threats.
",review,1,1,"If the main contribution is a taxonomy, I'd say it's a review paper",
2206.0269,A Survey on Sentence Embedding Models Performance for Patent Analysis,"  Patent data is an important source of knowledge for innovation research,
while the technological similarity between pairs of patents is a key enabling
indicator for patent analysis. Recently researchers have been using patent
vector space models based on different NLP embeddings models to calculate the
technological similarity between pairs of patents to help better understand
innovations, patent landscaping, technology mapping, and patent quality
evaluation. More often than not, Text Embedding is a vital precursor to patent
analysis tasks. A pertinent question then arises: How should we measure and
evaluate the accuracy of these embeddings? To the best of our knowledge, there
is no comprehensive survey that builds a clear delineation of embedding models'
performance for calculating patent similarity indicators. Therefore, in this
study, we provide an overview of the accuracy of these algorithms based on
patent classification performance and propose a standard library and dataset
for assessing the accuracy of embeddings models based on PatentSBERTa approach.
In a detailed discussion, we report the performance of the top 3 algorithms at
section, class, and subclass levels. The results based on the first claim of
patents show that PatentSBERTa, Bert-for-patents, and TF-IDF Weighted Word
Embeddings have the best accuracy for computing sentence embeddings at the
subclass level. According to the first results, the performance of the models
in different classes varies, which shows researchers in patent analysis can
utilize the results of this study to choose the best proper model based on the
specific section of patent data they used.
",review,1,,,
2211.13546,"Number Theoretic Transform and Its Applications in Lattice-based
  Cryptosystems: A Survey","  Number theoretic transform (NTT) is the most efficient method for multiplying
two polynomials of high degree with integer coefficients, due to its series of
advantages in terms of algorithm and implementation, and is consequently
widely-used and particularly fundamental in the practical implementations of
lattice-based cryptographic schemes. Especially, recent works have shown that
NTT can be utilized in those schemes without NTT-friendly rings, and can
outperform other multiplication algorithms. In this paper, we first review the
basic concepts of polynomial multiplication, convolution and NTT. Subsequently,
we systematically introduce basic radix-2 fast NTT algorithms in an algebraic
way via Chinese Remainder Theorem. And then, we elaborate recent advances about
the methods to weaken restrictions on parameter conditions of NTT. Furthermore,
we systematically introduce how to choose appropriate strategy of NTT
algorithms for the various given rings. Later, we introduce the applications of
NTT in the lattice-based cryptographic schemes of NIST post-quantum
cryptography standardization competition. Finally, we try to present some
possible future research directions.
",review,1,,,
2405.19265,"AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight
  Tuning on Multi-source Data","  Open-source Large Language Models (LLMs) and their specialized variants,
particularly Code LLMs, have recently delivered impressive performance.
However, previous Code LLMs are typically fine-tuned on single-source data with
limited quality and diversity, which may insufficiently elicit the potential of
pre-trained Code LLMs. In this paper, we present AlchemistCoder, a series of
Code LLMs with enhanced code generation and generalization capabilities
fine-tuned on multi-source data. To achieve this, we pioneer to unveil inherent
conflicts among the various styles and qualities in multi-source code corpora
and introduce data-specific prompts with hindsight relabeling, termed
AlchemistPrompts, to harmonize different data sources and instruction-response
pairs. Additionally, we propose incorporating the data construction process
into the fine-tuning data as code comprehension tasks, including instruction
evolution, data filtering, and code review. Extensive experiments demonstrate
that AlchemistCoder holds a clear lead among all models of the same size
(6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B), showcasing
the efficacy of our method in refining instruction-following capabilities and
advancing the boundaries of code intelligence.
",review,0,,,
2101.11775,Moral and Social Ramifications of Autonomous Vehicles,"  Autonomous Vehicles (AVs) raise important social and ethical concerns,
especially about accountability, dignity, and justice. We focus on the specific
concerns arising from how AV technology will affect the lives and livelihoods
of professional and semi-professional drivers. Whereas previous studies of such
concerns have focused on the opinions of experts, we seek to understand these
ethical and societal challenges from the perspectives of the drivers
themselves.
  To this end, we adopted a qualitative research methodology based on
semi-structured interviews. This is an established social science methodology
that helps understand the core concerns of stakeholders in depth by avoiding
the biases of superficial methods such as surveys.
  We find that whereas drivers agree with the experts that AVs will
significantly impact transportation systems, they are apprehensive about the
prospects for their livelihoods and dismiss the suggestions that driving jobs
are unsatisfying and their profession does not merit protection.
  By showing how drivers differ from the experts, our study has ramifications
beyond AVs to AI and other advanced technologies. Our findings suggest that
qualitative research applied to the relevant, especially disempowered,
stakeholders is essential to ensuring that new technologies are introduced
ethically.
",review,0,,,
2212.07902,Five Facets of 6G: Research Challenges and Opportunities,"  Whilst the fifth-generation (5G) systems are being rolled out across the
globe, researchers have turned their attention to the exploration of radical
next-generation solutions. At this early evolutionary stage we survey five main
research facets of this field, namely {\em Facet~1: next-generation
architectures, spectrum and services, Facet~2: next-generation networking,
Facet~3: Internet of Things (IoT), Facet~4: wireless positioning and sensing,
as well as Facet~5: applications of deep learning in 6G networks.} In this
paper, we have provided a critical appraisal of the literature of promising
techniques ranging from the associated architectures, networking, applications
as well as designs. We have portrayed a plethora of heterogeneous architectures
relying on cooperative hybrid networks supported by diverse access and
transmission mechanisms. The vulnerabilities of these techniques are also
addressed and carefully considered for highlighting the most of promising
future research directions. Additionally, we have listed a rich suite of
learning-driven optimization techniques. We conclude by observing the
evolutionary paradigm-shift that has taken place from pure single-component
bandwidth-efficiency, power-efficiency or delay-optimization towards
multi-component designs, as exemplified by the twin-component ultra-reliable
low-latency mode of the 5G system. We advocate a further evolutionary step
towards multi-component Pareto optimization, which requires the exploration of
the entire Pareto front of all optiomal solutions, where none of the components
of the objective function may be improved without degrading at least one of the
other components.
",review,1,,,
2401.14656,"Scientific Large Language Models: A Survey on Biological & Chemical
  Domains","  Large Language Models (LLMs) have emerged as a transformative power in
enhancing natural language comprehension, representing a significant stride
toward artificial general intelligence. The application of LLMs extends beyond
conventional linguistic boundaries, encompassing specialized linguistic systems
developed within various scientific disciplines. This growing interest has led
to the advent of scientific LLMs, a novel subclass specifically engineered for
facilitating scientific discovery. As a burgeoning area in the community of AI
for Science, scientific LLMs warrant comprehensive exploration. However, a
systematic and up-to-date survey introducing them is currently lacking. In this
paper, we endeavor to methodically delineate the concept of ""scientific
language"", whilst providing a thorough review of the latest advancements in
scientific LLMs. Given the expansive realm of scientific disciplines, our
analysis adopts a focused lens, concentrating on the biological and chemical
domains. This includes an in-depth examination of LLMs for textual knowledge,
small molecules, macromolecular proteins, genomic sequences, and their
combinations, analyzing them in terms of model architectures, capabilities,
datasets, and evaluation. Finally, we critically examine the prevailing
challenges and point out promising research directions along with the advances
of LLMs. By offering a comprehensive overview of technical developments in this
field, this survey aspires to be an invaluable resource for researchers
navigating the intricate landscape of scientific LLMs.
",review,1,,,
2108.13176,"Maximum Expected Delay: A New Metric to Analyse the Performance of
  Asynchronous Quorum-based Protocols in Wireless Sensor Networks","  Energy management is a crucial challenge in wireless sensor networks. To
date, many techniques have been proposed to reduce energy consumption. Duty
cycle methods reduce the energy consumption of wireless sensor networks since
energy consumption declines in the sleep mode. Using quorum-based methods,
sensors can stay in the sleep mode and be awaken periodically to send and
receive data from adjacent nodes. In this paper, we review a subset of these
methods called asynchronous quorum-based methods, independent of
synchronization between nodes, and investigate their performances in different
metrics. Then, we propose a new metric to investigate the latency of adjacent
nodes in wireless sensor networks. Next, we study the performances of all
discussed methods using the proposed metric. Finally, we introduce the best and
worst methods based on different metrics.
",review,0,,,
2205.06719,dewolf: Improving Decompilation by leveraging User Surveys,"  Analyzing third-party software such as malware or firmware is a crucial task
for security analysts. Although various approaches for automatic analysis exist
and are the subject of ongoing research, analysts often have to resort to
manual static analysis to get a deep understanding of a given binary sample.
Since the source code of encountered samples is rarely available, analysts
regularly employ decompilers for easier and faster comprehension than analyzing
a binary's disassembly.
  In this paper, we introduce our decompilation approach dewolf. We developed a
variety of improvements over the previous academic state-of-the-art decompiler
and some novel algorithms to enhance readability and comprehension, focusing on
manual analysis. To evaluate our approach and to obtain a better insight into
the analysts' needs, we conducted three user surveys. The results indicate that
dewolf is suitable for malware comprehension and that its output quality
noticeably exceeds Ghidra and Hex-Rays in certain aspects. Furthermore, our
results imply that decompilers aiming at manual analysis should be highly
configurable to respect individual user preferences. Additionally, future
decompilers should not necessarily follow the unwritten rule to stick to the
code-structure dictated by the assembly in order to produce readable output. In
fact, the few cases where dewolf already cracks this rule lead to its results
considerably exceeding other decompilers. We publish a prototype implementation
of dewolf and all survey results on GitHub.
",review,0,,,
2212.03283,"Status Quo Bias in Users Information Systems (IS) Adoption and
  Continuance Intentions: A Literature Review and Framework","  Information systems (IS) adoption and continuance intentions of users have a
dominant effect on digital transformation in organisations. However,
organisations undergoing digital transformation face substantial barriers due
to user resistance to IS implementations. Status quo bias (SQB) plays a vital
role in users decision-making regarding adopting new IS or continuing to use
existing IS. Despite recent research to validate the effects of SQB on user
resistance to IS implementations, how SQB affects the IS adoption and
continuance intentions of users remains poorly understood, making it harder to
develop ways of successfully dealing with it. To address the gap, we performed
a systematic literature review on SQB in IS research. Our proposed framework
incorporates the psychological phenomena promoting the status quo, SQB theory
constructs, levels of SQB influence, and factors reducing the user resistance
to IS implementations to enhance the understanding of IS adoption and
continuance intentions.
",review,1,,,
2209.04376,Challenges of Implementing Agile Processes in Remote-First Companies,"  The trend of remote work, especially in the IT sector, has been on the rise
in recent years, and its popularity has especially increased since the COVID-19
pandemic. In addition to adopting remote work, companies also have been
migrating toward managing their projects using agile processes. Agile processes
promote small and continuous feedback loops powered by effective communication.
In this survey, we look to discover the challenges of implementing these
processes in a remote setting, specifically focusing on the impact on
communication. We examine the role communication plays in an agile setting and
look for ways to mitigate the risk remote environments impose on it. Lastly, we
present other miscellaneous challenges companies could experience that still
carry dangers but are less impactful overall to agile implementation.
",review,1,,,
2406.09722,Cross-view geo-localization: a survey,"  Cross-view geo-localization has garnered notable attention in the realm of
computer vision, spurred by the widespread availability of copious geotagged
datasets and the advancements in machine learning techniques. This paper
provides a thorough survey of cutting-edge methodologies, techniques, and
associated challenges that are integral to this domain, with a focus on
feature-based and deep learning strategies. Feature-based methods capitalize on
unique features to establish correspondences across disparate viewpoints,
whereas deep learning-based methodologies deploy convolutional neural networks
to embed view-invariant attributes. This work also delineates the multifaceted
challenges encountered in cross-view geo-localization, such as variations in
viewpoints and illumination, the occurrence of occlusions, and it elucidates
innovative solutions that have been formulated to tackle these issues.
Furthermore, we delineate benchmark datasets and relevant evaluation metrics,
and also perform a comparative analysis of state-of-the-art techniques.
Finally, we conclude the paper with a discussion on prospective avenues for
future research and the burgeoning applications of cross-view geo-localization
in an intricately interconnected global landscape.
",review,1,,,
2401.08081,"Predicting Next Useful Location With Context-Awareness: The
  State-Of-The-Art","  Predicting the future location of mobile objects reinforces location-aware
services with proactive intelligence and helps businesses and decision-makers
with better planning and near real-time scheduling in different applications
such as traffic congestion control, location-aware advertisements, and
monitoring public health and well-being. The recent developments in the
smartphone and location sensors technology and the prevalence of using
location-based social networks alongside the improvements in artificial
intelligence and machine learning techniques provide an excellent opportunity
to exploit massive amounts of historical and real-time contextual information
to recognise mobility patterns and achieve more accurate and intelligent
predictions. This survey provides a comprehensive overview of the next useful
location prediction problem with context-awareness. First, we explain the
concepts of context and context-awareness and define the next location
prediction problem. Then we analyse nearly thirty studies in this field
concerning the prediction method, the challenges addressed, the datasets and
metrics used for training and evaluating the model, and the types of context
incorporated. Finally, we discuss the advantages and disadvantages of different
approaches, focusing on the usefulness of the predicted location and
identifying the open challenges and future work on this subject by introducing
two potential use cases of next location prediction in the automotive industry.
",review,1,,,
2109.06808,"What are the attackers doing now? Automating cyber threat intelligence
  extraction from text on pace with the changing threat landscape: A survey","  Cybersecurity researchers have contributed to the automated extraction of CTI
from textual sources, such as threat reports and online articles, where
cyberattack strategies, procedures, and tools are described. The goal of this
article is to aid cybersecurity researchers understand the current techniques
used for cyberthreat intelligence extraction from text through a survey of
relevant studies in the literature. We systematically collect ""CTI extraction
from text""-related studies from the literature and categorize the CTI
extraction purposes. We propose a CTI extraction pipeline abstracted from these
studies. We identify the data sources, techniques, and CTI sharing formats
utilized in the context of the proposed pipeline. Our work finds ten types of
extraction purposes, such as extraction indicators of compromise extraction,
TTPs (tactics, techniques, procedures of attack), and cybersecurity keywords.
We also identify seven types of textual sources for CTI extraction, and textual
data obtained from hacker forums, threat reports, social media posts, and
online news articles have been used by almost 90% of the studies. Natural
language processing along with both supervised and unsupervised machine
learning techniques such as named entity recognition, topic modelling,
dependency parsing, supervised classification, and clustering are used for CTI
extraction. We observe the technical challenges associated with these studies
related to obtaining available clean, labelled data which could assure
replication, validation, and further extension of the studies. As we find the
studies focusing on CTI information extraction from text, we advocate for
building upon the current CTI extraction work to help cybersecurity
practitioners with proactive decision making such as threat prioritization,
automated threat modelling to utilize knowledge from past cybersecurity
incidents.
",review,1,,,
2404.05429,"Re-Ranking News Comments by Constructiveness and Curiosity Significantly
  Increases Perceived Respect, Trustworthiness, and Interest","  Online commenting platforms have commonly developed systems to address online
harms by removing and down-ranking content. An alternative, under-explored
approach is to focus on up-ranking content to proactively prioritize prosocial
commentary and set better conversational norms. We present a study with 460
English-speaking US-based news readers to understand the effects of re-ranking
comments by constructiveness, curiosity, and personal stories on a variety of
outcomes related to willingness to participate and engage, as well as perceived
credibility and polarization in a comment section. In our rich-media survey
experiment, participants across these four ranking conditions and a control
group reviewed prototypes of comment sections of a Politics op-ed and Dining
article. We found that outcomes varied significantly by article type.
Up-ranking curiosity and constructiveness improved a number of measures for the
Politics article, including perceived Respect, Trustworthiness, and
Interestingness of the comment section. Constructiveness also increased
perceptions that the comments were favorable to Republicans, with no condition
worsening perceptions of partisans. Additionally, in the Dining article,
personal stories and constructiveness rankings significantly improved the
perceived informativeness of the comments. Overall, these findings indicate
that incorporating prosocial qualities of speech into ranking could be a
promising approach to promote healthier, less polarized dialogue in online
comment sections.
",review,0,,,
2211.0478,"On the Robustness of Explanations of Deep Neural Network Models: A
  Survey","  Explainability has been widely stated as a cornerstone of the responsible and
trustworthy use of machine learning models. With the ubiquitous use of Deep
Neural Network (DNN) models expanding to risk-sensitive and safety-critical
domains, many methods have been proposed to explain the decisions of these
models. Recent years have also seen concerted efforts that have shown how such
explanations can be distorted (attacked) by minor input perturbations. While
there have been many surveys that review explainability methods themselves,
there has been no effort hitherto to assimilate the different methods and
metrics proposed to study the robustness of explanations of DNN models. In this
work, we present a comprehensive survey of methods that study, understand,
attack, and defend explanations of DNN models. We also present a detailed
review of different metrics used to evaluate explanation methods, as well as
describe attributional attack and defense methods. We conclude with lessons and
take-aways for the community towards ensuring robust explanations of DNN model
predictions.
",review,1,,,
2103.01888,DM algorithms in health industry,"  This survey reviews several approaches of data mining (DM) in healthindustry
from many research groups world wide. The focus is on modern multi-core
processors built into today's commodity computers, which are typically found at
university institutes both as small server and workstation computers. So they
are deliberately not high-performance computers. Modern multi-core processors
consist of several (2 to over 100) computer cores, which work independently of
each other according to the principle of ""multiple instruction multiple data""
(MIMD). They have a common main memory (shared memory). Each of these computer
cores has several (2-16) arithmetic-logic units, which can simultaneously carry
out the same arithmetic operation on several data in a vector-like manner
(single instruction multiple data, SIMD). DM algorithms must use both types of
parallelism (SIMD and MIMD), with access to the main memory (centralized
component) being the main barrier to increased efficiency. This is important
for DM in healthindustry applications like ECG, EEG, CT, SPECT, fMRI, DTI,
ultrasound, microscopy, dermascopy, etc.
",review,1,,,
2302.08244,"Beyond 5G Domainless Network Operation enabled by Multiband: Toward
  Optical Continuum Architectures","  Both public and private innovation projects are targeting the design,
prototyping and demonstration of a novel end-to-end integrated packet-optical
transport architecture based on Multi-Band (MB) optical transmission and
switching networks. Essentially, MB is expected to be the next technological
evolution to deal with the traffic demand and service requirements of 5G mobile
networks, and beyond, in the most cost-effective manner. Thanks to MB
transmission, classical telco architectures segmented into hierarchical levels
and domains can move forward toward an optical network continuum, where edge
access nodes are all-optically interconnected with top-hierarchical nodes,
interfacing Content Delivery Networks (CDN) and Internet Exchange Points (IXP).
This article overviews the technological challenges and innovation requirements
to enable such an architectural shift of telco networks both from a data and
control and management planes.
",review,1,,,
2407.11203,The Life Cycle of Large Language Models: A Review of Biases in Education,"  Large Language Models (LLMs) are increasingly adopted in educational contexts
to provide personalized support to students and teachers. The unprecedented
capacity of LLM-based applications to understand and generate natural language
can potentially improve instructional effectiveness and learning outcomes, but
the integration of LLMs in education technology has renewed concerns over
algorithmic bias which may exacerbate educational inequities. In this review,
building on prior work on mapping the traditional machine learning life cycle,
we provide a holistic map of the LLM life cycle from the initial development of
LLMs to customizing pre-trained models for various applications in educational
settings. We explain each step in the LLM life cycle and identify potential
sources of bias that may arise in the context of education. We discuss why
current measures of bias from traditional machine learning fail to transfer to
LLM-generated content in education, such as tutoring conversations because the
text is high-dimensional, there can be multiple correct responses, and
tailoring responses may be pedagogically desirable rather than unfair. This
review aims to clarify the complex nature of bias in LLM applications and
provide practical guidance for their evaluation to promote educational equity.
",review,1,,,
2103.00097,"A Brief Survey of Current Software Engineering Practices in Continuous
  Integration and Automated Accessibility Testing","  It's long been accepted that continuous integration (CI) in software
engineering increases the code quality of enterprise projects when adhered to
by it's practitioners. But is any of that effort to increase code quality and
velocity directed towards improving software accessibility accommodations? What
are the potential benefits quoted in literature? Does it fit with the modern
agile way that teams operate in most enterprises? This paper attempts to map
the current scene of the software engineering effort spent on improving
accessibility via continuous integration and it's hurdles to adoption as quoted
by researchers. We also try to explore steps that agile teams may take to train
members on how to implement accessibility testing and introduce key diagrams to
visualize processes to implement CI based accessibility testing procedures in
the software development lifecycle.
",review,1,,,
2102.13364,"Building Blocks of Sharding Blockchain Systems: Concepts, Approaches,
  and Open Problems","  Sharding is the prevalent approach to breaking the trilemma of simultaneously
achieving decentralization, security, and scalability in traditional blockchain
systems, which are implemented as replicated state machines relying on atomic
broadcast for consensus on an immutable chain of valid transactions. Sharding
is to be understood broadly as techniques for dynamically partitioning nodes in
a blockchain system into subsets (shards) that perform storage, communication,
and computation tasks without fine-grained synchronization with each other.
Despite much recent research on sharding blockchains, much remains to be
explored in the design space of these systems. Towards that aim, we conduct a
systematic analysis of existing sharding blockchain systems and derive a
conceptual decomposition of their architecture into functional components and
the underlying assumptions about system models and attackers they are built on.
The functional components identified are node selection, epoch randomness, node
assignment, intra-shard consensus, cross-shard transaction processing, shard
reconfiguration, and motivation mechanism. We describe interfaces,
functionality, and properties of each component and show how they compose into
a sharding blockchain system. For each component, we systematically review
existing approaches, identify potential and open problems, and propose future
research directions. We focus on potential security attacks and performance
problems, including system throughput and latency concerns such as confirmation
delays. We believe our modular architectural decomposition and in-depth
analysis of each component, based on a comprehensive literature study, provides
a systematic basis for conceptualizing state-of-the-art sharding blockchain
systems, proving or improving security and performance properties of
components, and developing new sharding blockchain system designs.
",review,1,,,
2307.15838,Holistic Survey of Privacy and Fairness in Machine Learning,"  Privacy and fairness are two crucial pillars of responsible Artificial
Intelligence (AI) and trustworthy Machine Learning (ML). Each objective has
been independently studied in the literature with the aim of reducing utility
loss in achieving them. Despite the significant interest attracted from both
academia and industry, there remains an immediate demand for more in-depth
research to unravel how these two objectives can be simultaneously integrated
into ML models. As opposed to well-accepted trade-offs, i.e., privacy-utility
and fairness-utility, the interrelation between privacy and fairness is not
well-understood. While some works suggest a trade-off between the two objective
functions, there are others that demonstrate the alignment of these functions
in certain scenarios. To fill this research gap, we provide a thorough review
of privacy and fairness in ML, including supervised, unsupervised,
semi-supervised, and reinforcement learning. After examining and consolidating
the literature on both objectives, we present a holistic survey on the impact
of privacy on fairness, the impact of fairness on privacy, existing
architectures, their interaction in application domains, and algorithms that
aim to achieve both objectives while minimizing the utility sacrificed.
Finally, we identify research challenges in achieving privacy and fairness
concurrently in ML, particularly focusing on large language models.
",review,1,,,
2206.1265,"Machine Learning-based Biological Ageing Estimation Technologies: A
  Survey","  In recent years, there are various methods of estimating Biological Age (BA)
have been developed. Especially with the development of machine learning (ML),
there are more and more types of BA predictions, and the accuracy has been
greatly improved. The models for the estimation of BA play an important role in
monitoring healthy aging, and could provide new tools to detect health status
in the general population and give warnings to sub-healthy people. We will
mainly review three age prediction methods by using ML. They are based on blood
biomarkers, facial images, and structural neuroimaging features. For now, the
model using blood biomarkers is the simplest, most direct, and most accurate
method. The face image method is affected by various aspects such as race,
environment, etc., the prediction accuracy is not very good, which cannot make
a great contribution to the medical field. In summary, we are here to track the
way forward in the era of big data for us and other potential general
populations and show ways to leverage the vast amounts of data available today.
",review,1,,,
2108.04087,"Reinforcement Learning for Intelligent Healthcare Systems: A
  Comprehensive Survey","  The rapid increase in the percentage of chronic disease patients along with
the recent pandemic pose immediate threats on healthcare expenditure and
elevate causes of death. This calls for transforming healthcare systems away
from one-on-one patient treatment into intelligent health systems, to improve
services, access and scalability, while reducing costs. Reinforcement Learning
(RL) has witnessed an intrinsic breakthrough in solving a variety of complex
problems for diverse applications and services. Thus, we conduct in this paper
a comprehensive survey of the recent models and techniques of RL that have been
developed/used for supporting Intelligent-healthcare (I-health) systems. This
paper can guide the readers to deeply understand the state-of-the-art regarding
the use of RL in the context of I-health. Specifically, we first present an
overview for the I-health systems challenges, architecture, and how RL can
benefit these systems. We then review the background and mathematical modeling
of different RL, Deep RL (DRL), and multi-agent RL models. After that, we
provide a deep literature review for the applications of RL in I-health
systems. In particular, three main areas have been tackled, i.e., edge
intelligence, smart core network, and dynamic treatment regimes. Finally, we
highlight emerging challenges and outline future research directions in driving
the future success of RL in I-health systems, which opens the door for
exploring some interesting and unsolved problems.
",review,1,,,
2407.0379,Assessing Consensus of Developers' Views on Code Readability,"  The rapid rise of Large Language Models (LLMs) has changed software
development, with tools like Copilot, JetBrains AI Assistant, and others
boosting developers' productivity. However, developers now spend more time
reviewing code than writing it, highlighting the importance of Code Readability
for code comprehension. Our previous research found that existing Code
Readability models were inaccurate in representing developers' notions and
revealed a low consensus among developers, highlighting a need for further
investigations in this field.
  Building on this, we surveyed 10 Java developers with similar coding
experience to evaluate their consensus on Code Readability assessments and
related aspects. We found significant agreement among developers on Code
Readability evaluations and identified specific code aspects strongly
correlated with Code Readability. Overall, our study sheds light on Code
Readability within LLM contexts, offering insights into how these models can
align with developers' perceptions of Code Readability, enhancing software
development in the AI era.
",review,0,,,
2303.05453,"Personalisation within bounds: A risk taxonomy and policy framework for
  the alignment of large language models with personalised feedback","  Large language models (LLMs) are used to generate content for a wide range of
tasks, and are set to reach a growing audience in coming years due to
integration in product interfaces like ChatGPT or search engines like Bing.
This intensifies the need to ensure that models are aligned with human
preferences and do not produce unsafe, inaccurate or toxic outputs. While
alignment techniques like reinforcement learning with human feedback (RLHF) and
red-teaming can mitigate some safety concerns and improve model capabilities,
it is unlikely that an aggregate fine-tuning process can adequately represent
the full range of users' preferences and values. Different people may
legitimately disagree on their preferences for language and conversational
norms, as well as on values or ideologies which guide their communication.
Personalising LLMs through micro-level preference learning processes may result
in models that are better aligned with each user. However, there are several
normative challenges in defining the bounds of a societally-acceptable and safe
degree of personalisation. In this paper, we ask how, and in what ways, LLMs
should be personalised. First, we review literature on current paradigms for
aligning LLMs with human feedback, and identify issues including (i) a lack of
clarity regarding what alignment means; (ii) a tendency of technology providers
to prescribe definitions of inherently subjective preferences and values; and
(iii) a 'tyranny of the crowdworker', exacerbated by a lack of documentation in
who we are really aligning to. Second, we present a taxonomy of benefits and
risks associated with personalised LLMs, for individuals and society at large.
Finally, we propose a three-tiered policy framework that allows users to
experience the benefits of personalised alignment, while restraining unsafe and
undesirable LLM-behaviours within (supra-)national and organisational bounds.
",review,1,,,
2105.05804,"Bridging the user equilibrium and the system optimum in static traffic
  assignment: how the cooperation among drivers can solve the congestion
  problem in city networks","  Solving the road congestion problem is one of the most pressing issues in
moderncities since it causes time wasting, pollution, higher industrial costs
and huge roadmaintenance costs. Advances in ITS technologies and the advent of
autonomousvehicles are changing mobility dramatically. They enable the
implementation of acoordination mechanism, called coordinated traffic
assignment, among the sat-navdevices aiming at assigning paths to drivers to
eliminate congestion and to re-duce the total travel time in traffic networks.
Among possible congestion avoidance methods, coordinated traffic assignment is
a valuable choice since it does not involvehuge investments to expand the road
network. Traffic assignments are traditionally devoted to two main perspectives
on which the well-known Wardropian principlesare inspired: the user equilibrium
and the system optimum. User equilibrium is a user-driven traffic assignment in
which each user chooses the most convenientpath selfishly. It guarantees that
fairness among users is respected since, whenthe equilibrium is reached, all
users sharing the same origin and destination willexperience the same travel
time. The main drawback in a user equilibrium is thatthe system total travel
time is not minimized and, hence, the so-called Price ofAnarchy is paid. On the
other hand, the system optimum is an efficient system-wide traffic assignment
in which drivers are routed on the network in such a waythe total travel time
is minimized but users might experience travel times that arehigher than the
other users travelling from the same origin to the same destina-tion affecting
the compliance. Thus, drawbacks in implementing one of the two assignments can
be overcome by hybridizing the two approaches aiming at bridging users'
fairness to system-wide efficiency. The survey reviews the state-of-the-art of
these trade-off approaches
",review,1,,,
2311.06311,"Game Theory Solutions in Sensor-Based Human Activity Recognition: A
  Review","  The Human Activity Recognition (HAR) tasks automatically identify human
activities using the sensor data, which has numerous applications in
healthcare, sports, security, and human-computer interaction. Despite
significant advances in HAR, critical challenges still exist. Game theory has
emerged as a promising solution to address these challenges in machine learning
problems including HAR. However, there is a lack of research work on applying
game theory solutions to the HAR problems. This review paper explores the
potential of game theory as a solution for HAR tasks, and bridges the gap
between game theory and HAR research work by suggesting novel game-theoretic
approaches for HAR problems. The contributions of this work include exploring
how game theory can improve the accuracy and robustness of HAR models,
investigating how game-theoretic concepts can optimize recognition algorithms,
and discussing the game-theoretic approaches against the existing HAR methods.
The objective is to provide insights into the potential of game theory as a
solution for sensor-based HAR, and contribute to develop a more accurate and
efficient recognition system in the future research directions.
",review,1,,,
2311.02608,"Deep Learning-based 3D Point Cloud Classification: A Systematic Survey
  and Outlook","  In recent years, point cloud representation has become one of the research
hotspots in the field of computer vision, and has been widely used in many
fields, such as autonomous driving, virtual reality, robotics, etc. Although
deep learning techniques have achieved great success in processing regular
structured 2D grid image data, there are still great challenges in processing
irregular, unstructured point cloud data. Point cloud classification is the
basis of point cloud analysis, and many deep learning-based methods have been
widely used in this task. Therefore, the purpose of this paper is to provide
researchers in this field with the latest research progress and future trends.
First, we introduce point cloud acquisition, characteristics, and challenges.
Second, we review 3D data representations, storage formats, and commonly used
datasets for point cloud classification. We then summarize deep learning-based
methods for point cloud classification and complement recent research work.
Next, we compare and analyze the performance of the main methods. Finally, we
discuss some challenges and future directions for point cloud classification.
",review,1,,,
2108.13732,Deep Learning on Edge TPUs,"  Computing at the edge is important in remote settings, however, conventional
hardware is not optimized for utilizing deep neural networks. The Google Edge
TPU is an emerging hardware accelerator that is cost, power and speed
efficient, and is available for prototyping and production purposes. Here, I
review the Edge TPU platform, the tasks that have been accomplished using the
Edge TPU, and which steps are necessary to deploy a model to the Edge TPU
hardware. The Edge TPU is not only capable of tackling common computer vision
tasks, but also surpasses other hardware accelerators, especially when the
entire model can be deployed to the Edge TPU. Co-embedding the Edge TPU in
cameras allows a seamless analysis of primary data. In summary, the Edge TPU is
a maturing system that has proven its usability across multiple tasks.
",review,1,,,
2101.10261,Discrete Choice Analysis with Machine Learning Capabilities,"  This paper discusses capabilities that are essential to models applied in
policy analysis settings and the limitations of direct applications of
off-the-shelf machine learning methodologies to such settings. Traditional
econometric methodologies for building discrete choice models for policy
analysis involve combining data with modeling assumptions guided by
subject-matter considerations. Such considerations are typically most useful in
specifying the systematic component of random utility discrete choice models
but are typically of limited aid in determining the form of the random
component. We identify an area where machine learning paradigms can be
leveraged, namely in specifying and systematically selecting the best
specification of the random component of the utility equations. We review two
recent novel applications where mixed-integer optimization and cross-validation
are used to algorithmically select optimal specifications for the random
utility components of nested logit and logit mixture models subject to
interpretability constraints.
",review,1,,,
2307.0066,Minimum Levels of Interpretability for Artificial Moral Agents,"  As artificial intelligence (AI) models continue to scale up, they are
becoming more capable and integrated into various forms of decision-making
systems. For models involved in moral decision-making, also known as artificial
moral agents (AMA), interpretability provides a way to trust and understand the
agent's internal reasoning mechanisms for effective use and error correction.
In this paper, we provide an overview of this rapidly-evolving sub-field of AI
interpretability, introduce the concept of the Minimum Level of
Interpretability (MLI) and recommend an MLI for various types of agents, to aid
their safe deployment in real-world settings.
",review,1,,,
2207.06415,"The Free Energy Principle for Perception and Action: A Deep Learning
  Perspective","  The free energy principle, and its corollary active inference, constitute a
bio-inspired theory that assumes biological agents act to remain in a
restricted set of preferred states of the world, i.e., they minimize their free
energy. Under this principle, biological agents learn a generative model of the
world and plan actions in the future that will maintain the agent in an
homeostatic state that satisfies its preferences. This framework lends itself
to being realized in silico, as it comprehends important aspects that make it
computationally affordable, such as variational inference and amortized
planning. In this work, we investigate the tool of deep learning to design and
realize artificial agents based on active inference, presenting a deep-learning
oriented presentation of the free energy principle, surveying works that are
relevant in both machine learning and active inference areas, and discussing
the design choices that are involved in the implementation process. This
manuscript probes newer perspectives for the active inference framework,
grounding its theoretical aspects into more pragmatic affairs, offering a
practical guide to active inference newcomers and a starting point for deep
learning practitioners that would like to investigate implementations of the
free energy principle.
",review,1,,,
2109.0184,"A review of Quantum Neural Networks: Methods, Models, Dilemma","  The rapid development of quantum computer hardware has laid the hardware
foundation for the realization of QNN. Due to quantum properties, QNN shows
higher storage capacity and computational efficiency compared to its classical
counterparts. This article will review the development of QNN in the past six
years from three parts: implementation methods, quantum circuit models, and
difficulties faced. Among them, the first part, the implementation method,
mainly refers to some underlying algorithms and theoretical frameworks for
constructing QNN models, such as VQA. The second part introduces several
quantum circuit models of QNN, including QBM, QCVNN and so on. The third part
describes some of the main difficult problems currently encountered. In short,
this field is still in the exploratory stage, full of magic and practical
significance.
",review,1,,,
2107.02975,"Neural Natural Language Processing for Unstructured Data in Electronic
  Health Records: a Review","  Electronic health records (EHRs), digital collections of patient healthcare
events and observations, are ubiquitous in medicine and critical to healthcare
delivery, operations, and research. Despite this central role, EHRs are
notoriously difficult to process automatically. Well over half of the
information stored within EHRs is in the form of unstructured text (e.g.
provider notes, operation reports) and remains largely untapped for secondary
use. Recently, however, newer neural network and deep learning approaches to
Natural Language Processing (NLP) have made considerable advances,
outperforming traditional statistical and rule-based systems on a variety of
tasks. In this survey paper, we summarize current neural NLP methods for EHR
applications. We focus on a broad scope of tasks, namely, classification and
prediction, word embeddings, extraction, generation, and other topics such as
question answering, phenotyping, knowledge graphs, medical dialogue,
multilinguality, interpretability, etc.
",review,1,,,
2104.04842,"Designing Effective Interview Chatbots: Automatic Chatbot Profiling and
  Design Suggestion Generation for Chatbot Debugging","  Recent studies show the effectiveness of interview chatbots for information
elicitation. However, designing an effective interview chatbot is non-trivial.
Few tools exist to help designers design, evaluate, and improve an interview
chatbot iteratively. Based on a formative study and literature reviews, we
propose a computational framework for quantifying the performance of interview
chatbots. Incorporating the framework, we have developed iChatProfile, an
assistive chatbot design tool that can automatically generate a profile of an
interview chatbot with quantified performance metrics and offer design
suggestions for improving the chatbot based on such metrics. To validate the
effectiveness of iChatProfile, we designed and conducted a between-subject
study that compared the performance of 10 interview chatbots designed with or
without using iChatProfile. Based on the live chats between the 10 chatbots and
1349 users, our results show that iChatProfile helped the designers build
significantly more effective interview chatbots, improving both interview
quality and user experience.
",review,0,,,
2301.12687,Understanding Visual Arts Experiences of Blind People,"  Visual arts play an important role in cultural life and provide access to
social heritage and self-enrichment, but most visual arts are inaccessible to
blind people. Researchers have explored different ways to enhance blind
people's access to visual arts (e.g., audio descriptions, tactile graphics).
However, how blind people adopt these methods remains unknown. We conducted
semi-structured interviews with 15 blind visual arts patrons to understand how
they engage with visual artwork and the factors that influence their adoption
of visual arts access methods. We further examined interview insights in a
follow-up survey (N=220). We present: 1) current practices and challenges of
accessing visual artwork in-person and online (e.g., Zoom tour), 2) motivation
and cognition of perceiving visual arts (e.g., imagination), and 3)
implications for designing visual arts access methods. Overall, our findings
provide a roadmap for technology-based support for blind people's visual arts
experiences.
",review,0,,,
2404.0457,"A Map of Exploring Human Interaction patterns with LLM: Insights into
  Collaboration and Creativity","  The outstanding performance capabilities of large language model have driven
the evolution of current AI system interaction patterns. This has led to
considerable discussion within the Human-AI Interaction (HAII) community.
Numerous studies explore this interaction from technical, design, and empirical
perspectives. However, the majority of current literature reviews concentrate
on interactions across the wider spectrum of AI, with limited attention given
to the specific realm of interaction with LLM. We searched for articles on
human interaction with LLM, selecting 110 relevant publications meeting
consensus definition of Human-AI interaction. Subsequently, we developed a
comprehensive Mapping Procedure, structured in five distinct stages, to
systematically analyze and categorize the collected publications. Applying this
methodical approach, we meticulously mapped the chosen studies, culminating in
a detailed and insightful representation of the research landscape. Overall,
our review presents an novel approach, introducing a distinctive mapping
method, specifically tailored to evaluate human-LLM interaction patterns. We
conducted a comprehensive analysis of the current research in related fields,
employing clustering techniques for categorization, which enabled us to clearly
delineate the status and challenges prevalent in each identified area.
",review,1,,,
2202.01428,Multi-Criteria Assessment of Shape Quality in CAD Systems of the Future,"  Unlike many other works, where authors are usually focused on one or two
quality criteria, the current manuscript, which is a generalization of the
article [35] published in Russian, offers a multi-criteria approach to the
assessment of the shape quality of curves that constitute component parts of
the surfaces used for the computer modelling of object shapes in various types
of design. Based on the analysis of point particle motion along a curved path,
requirements for the quality of functional curves are proposed: a high order of
smoothness, a minimum number of curvature extrema, minimization of the maximum
value of curvature and its variation rate, minimization of the potential energy
of the curve, and aesthetic analysis from the standpoint of the laws of
technical aesthetics. The authors do not set themselves the task of giving a
simple and precise mathematical definition of such curves. On the contrary,
this category can include various curves that meet certain quality criteria,
the refinement and addition of which is possible in the near future.
Engineering practice shows that quality criteria can change over time, which
does not diminish the need to develop multi-criteria methods for assessing the
quality of geometric shapes. Technical issues faced during edge rounding in 3D
models that affect the quality of industrial design product shape have been
reviewed as an example of the imperfection of existing CAD systems.
",review,0,,,
2202.0251,A Survey on Poisoning Attacks Against Supervised Machine Learning,"  With the rise of artificial intelligence and machine learning in modern
computing, one of the major concerns regarding such techniques is to provide
privacy and security against adversaries. We present this survey paper to cover
the most representative papers in poisoning attacks against supervised machine
learning models. We first provide a taxonomy to categorize existing studies and
then present detailed summaries for selected papers. We summarize and compare
the methodology and limitations of existing literature. We conclude this paper
with potential improvements and future directions to further exploit and
prevent poisoning attacks on supervised models. We propose several unanswered
research questions to encourage and inspire researchers for future work.
",review,1,,,
2103.04112,"Applying Machine Learning in Self-Adaptive Systems: A Systematic
  Literature Review","  Recently, we witness a rapid increase in the use of machine learning in
self-adaptive systems. Machine learning has been used for a variety of reasons,
ranging from learning a model of the environment of a system during operation
to filtering large sets of possible configurations before analysing them. While
a body of work on the use of machine learning in self-adaptive systems exists,
there is currently no systematic overview of this area. Such overview is
important for researchers to understand the state of the art and direct future
research efforts. This paper reports the results of a systematic literature
review that aims at providing such an overview. We focus on self-adaptive
systems that are based on a traditional Monitor-Analyze-Plan-Execute feedback
loop (MAPE). The research questions are centred on the problems that motivate
the use of machine learning in self-adaptive systems, the key engineering
aspects of learning in self-adaptation, and open challenges. The search
resulted in 6709 papers, of which 109 were retained for data collection.
Analysis of the collected data shows that machine learning is mostly used for
updating adaptation rules and policies to improve system qualities, and
managing resources to better balance qualities and resources. These problems
are primarily solved using supervised and interactive learning with
classification, regression and reinforcement learning as the dominant methods.
Surprisingly, unsupervised learning that naturally fits automation is only
applied in a small number of studies. Key open challenges in this area include
the performance of learning, managing the effects of learning, and dealing with
more complex types of goals. From the insights derived from this systematic
literature review we outline an initial design process for applying machine
learning in self-adaptive systems that are based on MAPE feedback loops.
",review,1,,,
2403.0466,"Exploring the Design Space of Optical See-through AR Head-Mounted
  Displays to Support First Responders in the Field","  First responders (FRs) navigate hazardous, unfamiliar environments in the
field (e.g., mass-casualty incidents), making life-changing decisions in a
split second. AR head-mounted displays (HMDs) have shown promise in supporting
them due to its capability of recognizing and augmenting the challenging
environments in a hands-free manner. However, the design space have not been
thoroughly explored by involving various FRs who serve different roles (e.g.,
firefighters, law enforcement) but collaborate closely in the field. We
interviewed 26 first responders in the field who experienced a state-of-the-art
optical-see-through AR HMD, as well as its interaction techniques and four
types of AR cues (i.e., overview cues, directional cues, highlighting cues, and
labeling cues), soliciting their first-hand experiences, design ideas, and
concerns. Our study revealed both generic and role-specific preferences and
needs for AR hardware, interactions, and feedback, as well as identifying
desired AR designs tailored to urgent, risky scenarios (e.g., affordance
augmentation to facilitate fast and safe action). While acknowledging the value
of AR HMDs, concerns were also raised around trust, privacy, and proper
integration with other equipment. Finally, we derived comprehensive and
actionable design guidelines to inform future AR systems for in-field FRs.
",review,0,,,
2208.08876,Survey on Teleoperation Concepts for Automated Vehicles,"  In parallel with the advancement of Automated Driving (AD) functions,
teleoperation has grown in popularity over recent years. By enabling remote
operation of automated vehicles, teleoperation can be established as a reliable
fallback solution for operational design domain limits and edge cases of AD
functions. Over the years, a variety of different teleoperation concepts as to
how a human operator can remotely support or substitute an AD function have
been proposed in the literature. This paper presents the results of a
literature survey on teleoperation concepts for road vehicles. Furthermore, due
to the increasing interest within the industry, insights on patents and overall
company activities in the field of teleoperation are presented.
",review,1,,,
2304.10891,"Transformer-based models and hardware acceleration analysis in
  autonomous driving: A survey","  Transformer architectures have exhibited promising performance in various
autonomous driving applications in recent years. On the other hand, its
dedicated hardware acceleration on portable computational platforms has become
the next critical step for practical deployment in real autonomous vehicles.
This survey paper provides a comprehensive overview, benchmark, and analysis of
Transformer-based models specifically tailored for autonomous driving tasks
such as lane detection, segmentation, tracking, planning, and decision-making.
We review different architectures for organizing Transformer inputs and
outputs, such as encoder-decoder and encoder-only structures, and explore their
respective advantages and disadvantages. Furthermore, we discuss
Transformer-related operators and their hardware acceleration schemes in depth,
taking into account key factors such as quantization and runtime. We
specifically illustrate the operator level comparison between layers from
convolutional neural network, Swin-Transformer, and Transformer with 4D
encoder. The paper also highlights the challenges, trends, and current insights
in Transformer-based models, addressing their hardware deployment and
acceleration issues within the context of long-term autonomous driving
applications.
",review,1,,,
2207.04914,"Team CERBERUS Wins the DARPA Subterranean Challenge: Technical Overview
  and Lessons Learned","  This article presents the CERBERUS robotic system-of-systems, which won the
DARPA Subterranean Challenge Final Event in 2021. The Subterranean Challenge
was organized by DARPA with the vision to facilitate the novel technologies
necessary to reliably explore diverse underground environments despite the
grueling challenges they present for robotic autonomy. Due to their geometric
complexity, degraded perceptual conditions combined with lack of GPS support,
austere navigation conditions, and denied communications, subterranean settings
render autonomous operations particularly demanding. In response to this
challenge, we developed the CERBERUS system which exploits the synergy of
legged and flying robots, coupled with robust control especially for overcoming
perilous terrain, multi-modal and multi-robot perception for localization and
mapping in conditions of sensor degradation, and resilient autonomy through
unified exploration path planning and local motion planning that reflects
robot-specific limitations. Based on its ability to explore diverse underground
environments and its high-level command and control by a single human
supervisor, CERBERUS demonstrated efficient exploration, reliable detection of
objects of interest, and accurate mapping. In this article, we report results
from both the preliminary runs and the final Prize Round of the DARPA
Subterranean Challenge, and discuss highlights and challenges faced, alongside
lessons learned for the benefit of the community.
",review,0,,,
2301.10398,"A Survey of Process-Oriented Data Science and Analytics for supporting
  Business Process Management","  Process analytics approaches allow organizations to support the practice of
Business Process Management and continuous improvement by leveraging all
process-related data to extract knowledge, improve process performance and
support decision-making across the organization. Process execution data once
collected will contain hidden insights and actionable knowledge that are of
considerable business value enabling firms to take a data-driven approach for
identifying performance bottlenecks, reducing costs, extracting insights and
optimizing the utilization of available resources. Understanding the properties
of 'current deployed process' (whose execution trace is often available in
these logs), is critical to understanding the variation across the process
instances, root-causes of inefficiencies and determining the areas for
investing improvement efforts. In this survey, we discuss various methods that
allow organizations to understand the behaviour of their processes, monitor
currently running process instances, predict the future behavior of those
instances and provide better support for operational decision-making across the
organization.
",review,1,,,
2404.16244,The Ethics of Advanced AI Assistants,"  This paper focuses on the opportunities and the ethical and societal risks
posed by advanced AI assistants. We define advanced AI assistants as artificial
agents with natural language interfaces, whose function is to plan and execute
sequences of actions on behalf of a user, across one or more domains, in line
with the user's expectations. The paper starts by considering the technology
itself, providing an overview of AI assistants, their technical foundations and
potential range of applications. It then explores questions around AI value
alignment, well-being, safety and malicious uses. Extending the circle of
inquiry further, we next consider the relationship between advanced AI
assistants and individual users in more detail, exploring topics such as
manipulation and persuasion, anthropomorphism, appropriate relationships, trust
and privacy. With this analysis in place, we consider the deployment of
advanced assistants at a societal scale, focusing on cooperation, equity and
access, misinformation, economic impact, the environment and how best to
evaluate advanced AI assistants. Finally, we conclude by providing a range of
recommendations for researchers, developers, policymakers and public
stakeholders.
",review,1,,,
2102.09368,How do students test software units?,"  We gained insight into ideas and beliefs on testing of students who finished
an introductory course on programming without any formal education on testing.
We asked students to fill in a small survey, to do four exercises and to fill
in a second survey. We interviewed eleven of these students in semi-structured
interviews, to obtain more in-depth insight. The main outcome is that students
do not test systematically, while most of them think they do test
systematically. One of the misconceptions we found is that most students can
only think of test cases based on programming code. Even if no code was
provided (black-box testing), students try to come up with code to base their
test cases on.
",review,0,,,
2408.17222,"How Could Generative AI Support Compliance with the EU AI Act? A Review
  for Safe Automated Driving Perception","  Deep Neural Networks (DNNs) have become central for the perception functions
of autonomous vehicles, substantially enhancing their ability to understand and
interpret the environment. However, these systems exhibit inherent limitations
such as brittleness, opacity, and unpredictable behavior in out-of-distribution
scenarios. The European Union (EU) Artificial Intelligence (AI) Act, as a
pioneering legislative framework, aims to address these challenges by
establishing stringent norms and standards for AI systems, including those used
in autonomous driving (AD), which are categorized as high-risk AI. In this
work, we explore how the newly available generative AI models can potentially
support addressing upcoming regulatory requirements in AD perception,
particularly with respect to safety. This short review paper summarizes the
requirements arising from the EU AI Act regarding DNN-based perception systems
and systematically categorizes existing generative AI applications in AD. While
generative AI models show promise in addressing some of the EU AI Acts
requirements, such as transparency and robustness, this review examines their
potential benefits and discusses how developers could leverage these methods to
enhance compliance with the Act. The paper also highlights areas where further
research is needed to ensure reliable and safe integration of these
technologies.
",review,1,,,
2301.05339,A Comprehensive Review of Data-Driven Co-Speech Gesture Generation,"  Gestures that accompany speech are an essential part of natural and efficient
embodied human communication. The automatic generation of such co-speech
gestures is a long-standing problem in computer animation and is considered an
enabling technology in film, games, virtual social spaces, and for interaction
with social robots. The problem is made challenging by the idiosyncratic and
non-periodic nature of human co-speech gesture motion, and by the great
diversity of communicative functions that gestures encompass. Gesture
generation has seen surging interest recently, owing to the emergence of more
and larger datasets of human gesture motion, combined with strides in
deep-learning-based generative models, that benefit from the growing
availability of data. This review article summarizes co-speech gesture
generation research, with a particular focus on deep generative models. First,
we articulate the theory describing human gesticulation and how it complements
speech. Next, we briefly discuss rule-based and classical statistical gesture
synthesis, before delving into deep learning approaches. We employ the choice
of input modalities as an organizing principle, examining systems that generate
gestures from audio, text, and non-linguistic input. We also chronicle the
evolution of the related training data sets in terms of size, diversity, motion
quality, and collection method. Finally, we identify key research challenges in
gesture generation, including data availability and quality; producing
human-like motion; grounding the gesture in the co-occurring speech in
interaction with other speakers, and in the environment; performing gesture
evaluation; and integration of gesture synthesis into applications. We
highlight recent approaches to tackling the various key challenges, as well as
the limitations of these approaches, and point toward areas of future
development.
",review,1,,,
2110.09313,"Impact of review valence and perceived uncertainty on purchase of
  time-constrained and discounted search goods","  Increasing online shoppers have generated enormous amount of data in form of
reviews (text) and sales data. Aggregate reviews in form of rating (stars) have
become noticeable indicators of product quality and vendor performance to
prospective consumers at first sight. Consumers subjected to product discount
deadlines search for ways in which they could evaluate product and vendor
service using a comprehensible benchmark. Considering the effect of time
pressure on consumers, aggregate reviews, known as review valence, become a
viable indicator of product quality. This study investigates how purchase
decisions for new products are affected by past customer aggregate ratings when
a soon-to-expire discount is being offered. We examine the role that a
consumer's attitude towards review valence (RV) plays as an antecedent to that
consumer's reliance on RV in a purchase decision for time-discounted search
goods. Considering review credibility, diagnosticity, and effectiveness as
determinants of consumer attitude in a time-constrained search and purchase
environment, we follow the approach-avoidance conflict theory to examine the
role of review valence and perceived uncertainty in a time-constrained
environment. The data was collected through an online survey and analyzed using
structural equation modelling. This study provides significant implications for
practitioners as they can better understand how review valence can influence a
purchase decision. Empirical analysis includes two contributions: 1. It helps
to understand how consumer attitude toward review valence, when positively
influenced by the determinants, can lead to reliance on review valence, further
influencing purchase decision; 2. Time constrained purchase-related perceived
uncertainty negatively moderates the relationship between consumer attitude and
reliance on review valence.
",review,0,,,
2303.14779,"The Application of Driver Models in the Safety Assessment of Autonomous
  Vehicles: A Survey","  Driver models play a vital role in developing and verifying autonomous
vehicles (AVs). Previously, they are mainly applied in traffic flow simulation
to model driver behavior. With the development of AVs, driver models attract
much attention again due to their potential contributions to AV safety
assessment. The simulation-based testing method is an effective measure to
accelerate AV testing due to its safe and efficient characteristics.
Nonetheless, realistic driver models are prerequisites for valid simulation
results. Additionally, an AV is assumed to be at least as safe as a careful and
competent driver, which is modeled by driver models as well. Therefore, driver
models are essential for AV safety assessment from the current perspective.
However, no comparison or discussion of driver models is available regarding
their utility to AVs in the last five years despite their necessities in the
release of AVs. This motivates us to present a comprehensive survey of driver
models in the paper and compare their applicability. Requirements for driver
models as applied to AV safety assessment are discussed. A summary of driver
models for simulation-based testing and AV benchmarks is provided. Evaluation
metrics are defined to compare their strength and weakness. Finally, potential
gaps in existing driver models are identified, which provide direction for
future work. This study gives related researchers especially regulators an
overview and helps them to define appropriate driver models for AVs.
",review,1,,,
2101.05869,"Technical Report: Rapid Reviews on Engineering of Internet of Things
  Software Systems","  We conducted a set of Rapid Reviews to characterize Internet of Things
facets. We formatted a generic meta-protocol that was instantiated for each of
the six facets presented (Connectivity, Things, Behavior, Smartness,
Interactivity, and Environment)and considering the issue of Security, one of
the most important and frequent challenges in the context of IoT. The
meta-protocol is detailed and the results of each review are presented.
",review,?,1,,
2307.05035,Number Systems for Deep Neural Network Architectures: A Survey,"  Deep neural networks (DNNs) have become an enabling component for a myriad of
artificial intelligence applications. DNNs have shown sometimes superior
performance, even compared to humans, in cases such as self-driving, health
applications, etc. Because of their computational complexity, deploying DNNs in
resource-constrained devices still faces many challenges related to computing
complexity, energy efficiency, latency, and cost. To this end, several research
directions are being pursued by both academia and industry to accelerate and
efficiently implement DNNs. One important direction is determining the
appropriate data representation for the massive amount of data involved in DNN
processing. Using conventional number systems has been found to be sub-optimal
for DNNs. Alternatively, a great body of research focuses on exploring suitable
number systems. This article aims to provide a comprehensive survey and
discussion about alternative number systems for more efficient representations
of DNN data. Various number systems (conventional/unconventional) exploited for
DNNs are discussed. The impact of these number systems on the performance and
hardware design of DNNs is considered. In addition, this paper highlights the
challenges associated with each number system and various solutions that are
proposed for addressing them. The reader will be able to understand the
importance of an efficient number system for DNN, learn about the widely used
number systems for DNN, understand the trade-offs between various number
systems, and consider various design aspects that affect the impact of number
systems on DNN performance. In addition, the recent trends and related research
opportunities will be highlighted
",review,1,,,
2111.13756,"Demystifying Ten Big Ideas and Rules Every Fire Scientist & Engineer
  Should Know About Blackbox, Whitebox & Causal Artificial Intelligence","  Artificial intelligence (AI) is paving the way towards the fourth industrial
revolution with the fire domain (Fire 4.0). As a matter of fact, the next few
years will be elemental to how this technology will shape our academia,
practice, and entrepreneurship. Despite the growing interest between fire
research groups, AI remains absent of our curriculum, and we continue to lack a
methodical framework to adopt, apply and create AI solutions suitable for our
problems. The above is also true for parallel engineering domains (i.e.,
civil/mechanical engineering), and in order to negate the notion of history
repeats itself (e.g., look at the continued debate with regard to modernizing
standardized fire testing, etc.), it is the motivation behind this letter to
the Editor to demystify some of the big ideas behind AI to jump-start prolific
and strategic discussions on the front of AI & Fire. In addition, this letter
intends to explain some of the most fundamental concepts and clear common
misconceptions specific to the adoption of AI in fire engineering. This short
letter is a companion to the Smart Systems in Fire Engineering special issue
sponsored by Fire Technology. An in-depth review of AI algorithms [1] and
success stories to the proper implementations of such algorithms can be found
in the aforenoted special issue and collection of papers. This letter comprises
two sections. The first section outlines big ideas pertaining to AI, and
answers some of the burning questions with regard to the merit of adopting AI
in our domain. The second section presents a set of rules or technical
recommendations an AI user may deem helpful to practice whenever AI is used as
an investigation methodology. The presented set of rules are complementary to
the big ideas.
",review,1,,,
2408.00716,"A Natural Language Processing Framework for Hotel Recommendation Based
  on Users' Text Reviews","  Recently, the application of Artificial Intelligence algorithms in hotel
recommendation systems has become an increasingly popular topic. One such
method that has proven to be effective in this field is Deep Learning,
especially Natural Language processing models, which are able to extract
semantic knowledge from user's text reviews to create more efficient
recommendation systems. This can lead to the development of intelligent models
that can classify a user's preferences and emotions based on their feedback in
the form of text reviews about their hotel stay experience. In this study, we
propose a Natural Language Processing framework that utilizes customer text
reviews to provide personalized recommendations for the most appropriate hotel
based on their preferences. The framework is based on Bidirectional Encoder
Representations from Transformers (BERT) and a fine-tuning/validation pipeline
that categorizes customer hotel review texts into ""Bad,"" ""Good,"" or ""Excellent""
recommended hotels. Our findings indicate that the hotel recommendation system
we propose can significantly enhance the user experience of booking
accommodations by providing personalized recommendations based on user
preferences and previous booking history.
",review,0,,,
2404.01335,Generative AI for Architectural Design: A Literature Review,"  Generative Artificial Intelligence (AI) has pioneered new methodological
paradigms in architectural design, significantly expanding the innovative
potential and efficiency of the design process. This paper explores the
extensive applications of generative AI technologies in architectural design, a
trend that has benefited from the rapid development of deep generative models.
This article provides a comprehensive review of the basic principles of
generative AI and large-scale models and highlights the applications in the
generation of 2D images, videos, and 3D models. In addition, by reviewing the
latest literature from 2020, this paper scrutinizes the impact of generative AI
technologies at different stages of architectural design, from generating
initial architectural 3D forms to producing final architectural imagery. The
marked trend of research growth indicates an increasing inclination within the
architectural design community towards embracing generative AI, thereby
catalyzing a shared enthusiasm for research. These research cases and
methodologies have not only proven to enhance efficiency and innovation
significantly but have also posed challenges to the conventional boundaries of
architectural creativity. Finally, we point out new directions for design
innovation and articulate fresh trajectories for applying generative AI in the
architectural domain. This article provides the first comprehensive literature
review about generative AI for architectural design, and we believe this work
can facilitate more research work on this significant topic in architecture.
",review,1,,,
2409.05033,A Survey on Diffusion Models for Recommender Systems,"  While traditional recommendation techniques have made significant strides in
the past decades, they still suffer from limited generalization performance
caused by factors like inadequate collaborative signals, weak latent
representations, and noisy data. In response, diffusion models (DMs) have
emerged as promising solutions for recommender systems due to their robust
generative capabilities, solid theoretical foundations, and improved training
stability. To this end, in this paper, we present the first comprehensive
survey on diffusion models for recommendation, and draw a bird's-eye view from
the perspective of the whole pipeline in real-world recommender systems. We
systematically categorize existing research works into three primary domains:
(1) diffusion for data engineering & encoding, focusing on data augmentation
and representation enhancement; (2) diffusion as recommender models, employing
diffusion models to directly estimate user preferences and rank items; and (3)
diffusion for content presentation, utilizing diffusion models to generate
personalized content such as fashion and advertisement creatives. Our taxonomy
highlights the unique strengths of diffusion models in capturing complex data
distributions and generating high-quality, diverse samples that closely align
with user preferences. We also summarize the core characteristics of the
adapting diffusion models for recommendation, and further identify key areas
for future exploration, which helps establish a roadmap for researchers and
practitioners seeking to advance recommender systems through the innovative
application of diffusion models. To further facilitate the research community
of recommender systems based on diffusion models, we actively maintain a GitHub
repository for papers and other related resources in this rising direction
https://github.com/CHIANGEL/Awesome-Diffusion-for-RecSys.
",review,1,,,
2210.0556,"Comparison of encrypted control approaches and tutorial on dynamic
  systems using LWE-based homomorphic encryption","  Encrypted control has been introduced to protect controller data by
encryption at the stage of computation and communication, by performing the
computation directly on encrypted data. In this article, we first review and
categorize recent relevant studies on encrypted control. Approaches based on
homomorphic encryption, multi-party computation, and secret sharing are
introduced, compared, and then discussed with respect to computational
complexity, communication load, enabled operations, security, and research
directions. We proceed to discuss a current challenge in the application of
homomorphic encryption to dynamic systems, where arithmetic operations other
than integer addition and multiplication are limited. We also introduce a
homomorphic cryptosystem called ``GSW-LWE'' and discuss its benefits that allow
for recursive multiplication of encrypted dynamic systems, without use of
computationally expensive bootstrapping techniques.
",review,0,,,
2208.14685,Accessible Interactive Maps for Visually Impaired Users,"  Tactile maps are commonly used to give visually impaired users access to
geographical representations. Although those relief maps are efficient tools
for acquisition of spatial knowledge, they present several limitations and
issues such as the need to read braille. Several research projects have been
led during the past three decades in order to improve access to maps using
interactive technologies. In this chapter, we present an exhaustive review of
interactive map prototypes. We classified existing interactive maps into two
categories: Digital Interactive Maps (DIMs) that are displayed on a flat
surface such as a screen; and Hybrid Interactive Maps (HIMs) that include both
a digital and a physical representation. In each family, we identified several
subcategories depending on the technology being used. We compared the
categories and subcategories according to cost, availability and technological
limitations, but also in terms of content, comprehension and interactivity.
Then we reviewed a number of studies showing that those maps can support
spatial learning for visually impaired users. Finally, we identified new
technologies and methods that could improve the accessibility of graphics for
visually impaired users in the future.
",review,1,,,
2408.03817,Interactive Visual Analysis of Spatial Sensitivities,"  Sensitivity analyses of simulation ensembles determine how simulation
parameters influence the simulation's outcome. Commonly, one global numerical
sensitivity value is computed per simulation parameter. However, when
considering 3D spatial simulations, the analysis of localized sensitivities in
different spatial regions is of importance in many applications. For analyzing
the spatial variation of parameter sensitivity, one needs to compute a spatial
sensitivity scalar field per simulation parameter. Given $n$ simulation
parameters, we obtain multi-field data consisting of $n$ scalar fields when
considering all simulation parameters. We propose an interactive visual
analytics solution to analyze the multi-field sensitivity data. It supports the
investigation of how strongly and in what way individual parameters influence
the simulation outcome, in which spatial regions this is happening, and what
the interplay of the simulation parameters is. Its central component is an
overview visualization of all sensitivity fields that avoids 3D occlusions by
linearizing the data using an adapted scheme of data-driven space-filling
curves. The spatial sensitivity values are visualized in a combination of a
Horizon Graph and a line chart. We validate our approach by applying it to
synthetic and real-world ensemble data.
",review,1,,,
2401.1631,Security Code Review by LLMs: A Deep Dive into Responses,"  Security code review aims to combine automated tools and manual efforts to
detect security defects during development. The rapid development of Large
Language Models (LLMs) has shown promising potential in software development,
as well as opening up new possibilities in automated security code review. To
explore the challenges of applying LLMs in practical code review for security
defect detection, this study compared the detection performance of three
state-of-the-art LLMs (Gemini Pro, GPT-4, and GPT-3.5) under five prompts on
549 code files that contain security defects from real-world code reviews.
Through analyzing 82 responses generated by the best-performing LLM-prompt
combination based on 100 randomly selected code files, we extracted and
categorized quality problems present in these responses into 5 themes and 16
categories. Our results indicate that the responses produced by LLMs often
suffer from verbosity, vagueness, and incompleteness, highlighting the
necessity to enhance their conciseness, understandability, and compliance to
security defect detection. This work reveals the deficiencies of LLM-generated
responses in security code review and paves the way for future optimization of
LLMs towards this task.
",review,0,,,
2203.03847,Trust in AI and Implications for the AEC Research: A Literature Analysis,"  Engendering trust in technically acceptable and psychologically embraceable
systems requires domain-specific research to capture unique characteristics of
the field of application. The architecture, engineering, and construction (AEC)
research community has been recently harnessing advanced solutions offered by
artificial intelligence (AI) to improve project workflows. Despite the unique
characteristics of work, workers, and workplaces in the AEC industry, the
concept of trust in AI has received very little attention in the literature.
This paper presents a comprehensive analysis of the academic literature in two
main areas of trust in AI and AI in the AEC, to explore the interplay between
AEC projects unique aspects and the sociotechnical concepts that lead to trust
in AI. A total of 490 peer-reviewed scholarly articles are analyzed in this
study. The main constituents of human trust in AI are identified from the
literature and are characterized within the AEC project types, processes, and
technologies.
",review,1,,,
2109.04256,Cataloging Dependency Injection Anti-Patterns in Software Systems,"  Context: Dependency Injection (DI) is a commonly applied mechanism to
decouple classes from their dependencies in order to provide higher
modularization. However, bad DI practices often lead to negative consequences,
such as increasing coupling. Although white literature conjectures about the
existence of DI anti-patterns, there is no evidence on their practical
relevance, usefulness, and generality. Objective: The objective of this study
is to propose and evaluate a catalog of Java DI anti-patterns and associated
refactorings. Methodology: We reviewed existing reported DI anti-patterns in
order to analyze their completeness. The limitations found in literature
motivated proposing a novel catalog of 12 DI anti-patterns. We developed a tool
to statically analyze the occurrence level of the candidate DI anti-patterns in
both open-source and industry projects. Next, we survey practitioners to assess
their perception on the relevance, usefulness, and their willingness on
refactoring anti-pattern instances of the catalog. Results: Our static code
analyzer tool showed a relative recall of 92.19% and high average precision. It
revealed that at least 9 different DI anti-patterns appeared frequently in the
analyzed projects. Besides, our survey confirmed the perceived relevance of the
catalog and developers expressed their willingness to refactor instances of
anti-patterns from source code. Conclusion: The catalog contains Java DI
anti-patterns that occur in practice and that are perceived as useful. Sharing
it with practitioners may help them to avoid such anti-patterns, thus improving
source-code quality.
",review,0,,,
2106.04897,Unsupervised Automatic Speech Recognition: A Review,"  Automatic Speech Recognition (ASR) systems can be trained to achieve
remarkable performance given large amounts of manually transcribed speech, but
large labeled data sets can be difficult or expensive to acquire for all
languages of interest. In this paper, we review the research literature to
identify models and ideas that could lead to fully unsupervised ASR, including
unsupervised segmentation of the speech signal, unsupervised mapping from
speech segments to text, and semi-supervised models with nominal amounts of
labeled examples. The objective of the study is to identify the limitations of
what can be learned from speech data alone and to understand the minimum
requirements for speech recognition. Identifying these limitations would help
optimize the resources and efforts in ASR development for low-resource
languages.
",review,1,,,
2303.14725,"Natural Language Reasoning, A Survey","  This survey paper proposes a clearer view of natural language reasoning in
the field of Natural Language Processing (NLP), both conceptually and
practically. Conceptually, we provide a distinct definition for natural
language reasoning in NLP, based on both philosophy and NLP scenarios, discuss
what types of tasks require reasoning, and introduce a taxonomy of reasoning.
Practically, we conduct a comprehensive literature review on natural language
reasoning in NLP, mainly covering classical logical reasoning, natural language
inference, multi-hop question answering, and commonsense reasoning. The paper
also identifies and views backward reasoning, a powerful paradigm for
multi-step reasoning, and introduces defeasible reasoning as one of the most
important future directions in natural language reasoning research. We focus on
single-modality unstructured natural language text, excluding neuro-symbolic
techniques and mathematical reasoning.
",review,1,,,
2202.03188,Knowledge-Integrated Informed AI for National Security,"  The state of artificial intelligence technology has a rich history that dates
back decades and includes two fall-outs before the explosive resurgence of
today, which is credited largely to data-driven techniques. While AI technology
has and continues to become increasingly mainstream with impact across domains
and industries, it's not without several drawbacks, weaknesses, and potential
to cause undesired effects. AI techniques are numerous with many approaches and
variants, but they can be classified simply based on the degree of knowledge
they capture and how much data they require; two broad categories emerge as
prominent across AI to date: (1) techniques that are primarily, and often
solely, data-driven while leveraging little to no knowledge and (2) techniques
that primarily leverage knowledge and depend less on data. Now, a third
category is starting to emerge that leverages both data and knowledge, that
some refer to as ""informed AI."" This third category can be a game changer
within the national security domain where there is ample scientific and
domain-specific knowledge that stands ready to be leveraged, and where purely
data-driven AI can lead to serious unwanted consequences.
  This report shares findings from a thorough exploration of AI approaches that
exploit data as well as principled and/or practical knowledge, which we refer
to as ""knowledge-integrated informed AI."" Specifically, we review illuminating
examples of knowledge integrated in deep learning and reinforcement learning
pipelines, taking note of the performance gains they provide. We also discuss
an apparent trade space across variants of knowledge-integrated informed AI,
along with observed and prominent issues that suggest worthwhile future
research directions. Most importantly, this report suggests how the advantages
of knowledge-integrated informed AI stand to benefit the national security
domain.
",review,?,0,,
2212.06495,Inherent Limitations of AI Fairness,"  As the real-world impact of Artificial Intelligence (AI) systems has been
steadily growing, so too have these systems come under increasing scrutiny. In
response, the study of AI fairness has rapidly developed into a rich field of
research with links to computer science, social science, law, and philosophy.
Many technical solutions for measuring and achieving AI fairness have been
proposed, yet their approach has been criticized in recent years for being
misleading, unrealistic and harmful.
  In our paper, we survey these criticisms of AI fairness and identify key
limitations that are inherent to the prototypical paradigm of AI fairness. By
carefully outlining the extent to which technical solutions can realistically
help in achieving AI fairness, we aim to provide the background necessary to
form a nuanced opinion on developments in fair AI. This delineation also
provides research opportunities for non-AI solutions peripheral to AI systems
in supporting fair decision processes.
",review,1,,,
2309.16459,Augmenting LLMs with Knowledge: A survey on hallucination prevention,"  Large pre-trained language models have demonstrated their proficiency in
storing factual knowledge within their parameters and achieving remarkable
results when fine-tuned for downstream natural language processing tasks.
Nonetheless, their capacity to access and manipulate knowledge with precision
remains constrained, resulting in performance disparities on
knowledge-intensive tasks when compared to task-specific architectures.
Additionally, the challenges of providing provenance for model decisions and
maintaining up-to-date world knowledge persist as open research frontiers. To
address these limitations, the integration of pre-trained models with
differentiable access mechanisms to explicit non-parametric memory emerges as a
promising solution. This survey delves into the realm of language models (LMs)
augmented with the ability to tap into external knowledge sources, including
external knowledge bases and search engines. While adhering to the standard
objective of predicting missing tokens, these augmented LMs leverage diverse,
possibly non-parametric external modules to augment their contextual processing
capabilities, departing from the conventional language modeling paradigm.
Through an exploration of current advancements in augmenting large language
models with knowledge, this work concludes that this emerging research
direction holds the potential to address prevalent issues in traditional LMs,
such as hallucinations, un-grounded responses, and scalability challenges.
",review,1,,,
2310.09485,"Applying Bayesian Ridge Regression AI Modeling in Virus Severity
  Prediction","  Artificial intelligence (AI) is a powerful tool for reshaping healthcare
systems. In healthcare, AI is invaluable for its capacity to manage vast
amounts of data, which can lead to more accurate and speedy diagnoses,
ultimately easing the workload on healthcare professionals. As a result, AI has
proven itself to be a power tool across various industries, simplifying complex
tasks and pattern recognition that would otherwise be overwhelming for humans
or traditional computer algorithms. In this paper, we review the strengths and
weaknesses of Bayesian Ridge Regression, an AI model that can be used to bring
cutting edge virus analysis to healthcare professionals around the world. The
model's accuracy assessment revealed promising results, with room for
improvement primarily related to data organization. In addition, the severity
index serves as a valuable tool to gain a broad overview of patient care needs,
aligning with healthcare professionals' preference for broader categorizations.
",review,0,,,
2404.01363,"AIOps Solutions for Incident Management: Technical Guidelines and A
  Comprehensive Literature Review","  The management of modern IT systems poses unique challenges, necessitating
scalability, reliability, and efficiency in handling extensive data streams.
Traditional methods, reliant on manual tasks and rule-based approaches, prove
inefficient for the substantial data volumes and alerts generated by IT
systems. Artificial Intelligence for Operating Systems (AIOps) has emerged as a
solution, leveraging advanced analytics like machine learning and big data to
enhance incident management. AIOps detects and predicts incidents, identifies
root causes, and automates healing actions, improving quality and reducing
operational costs. However, despite its potential, the AIOps domain is still in
its early stages, decentralized across multiple sectors, and lacking
standardized conventions. Research and industrial contributions are distributed
without consistent frameworks for data management, target problems,
implementation details, requirements, and capabilities. This study proposes an
AIOps terminology and taxonomy, establishing a structured incident management
procedure and providing guidelines for constructing an AIOps framework. The
research also categorizes contributions based on criteria such as incident
management tasks, application areas, data sources, and technical approaches.
The goal is to provide a comprehensive review of technical and research aspects
in AIOps for incident management, aiming to structure knowledge, identify gaps,
and establish a foundation for future developments in the field.
",review,1,,,
2402.09781,A Comprehensive Review on Computer Vision Analysis of Aerial Data,"  With the emergence of new technologies in the field of airborne platforms and
imaging sensors, aerial data analysis is becoming very popular, capitalizing on
its advantages over land data. This paper presents a comprehensive review of
the computer vision tasks within the domain of aerial data analysis. While
addressing fundamental aspects such as object detection and tracking, the
primary focus is on pivotal tasks like change detection, object segmentation,
and scene-level analysis. The paper provides the comparison of various hyper
parameters employed across diverse architectures and tasks. A substantial
section is dedicated to an in-depth discussion on libraries, their
categorization, and their relevance to different domain expertise. The paper
encompasses aerial datasets, the architectural nuances adopted, and the
evaluation metrics associated with all the tasks in aerial data analysis.
Applications of computer vision tasks in aerial data across different domains
are explored, with case studies providing further insights. The paper
thoroughly examines the challenges inherent in aerial data analysis, offering
practical solutions. Additionally, unresolved issues of significance are
identified, paving the way for future research directions in the field of
aerial data analysis.
",review,1,,,
2404.12901,"Large Language Models for Networking: Workflow, Advances and Challenges","  The networking field is characterized by its high complexity and rapid
iteration, requiring extensive expertise to accomplish network tasks, ranging
from network design, configuration, diagnosis and security. The inherent
complexity of these tasks, coupled with the ever-changing landscape of
networking technologies and protocols, poses significant hurdles for
traditional machine learning-based methods. These methods often struggle to
generalize and automate complex tasks in networking, as they require extensive
labeled data, domain-specific feature engineering, and frequent retraining to
adapt to new scenarios. However, the recent emergence of large language models
(LLMs) has sparked a new wave of possibilities in addressing these challenges.
LLMs have demonstrated remarkable capabilities in natural language
understanding, generation, and reasoning. These models, trained on extensive
data, can benefit the networking domain. Some efforts have already explored the
application of LLMs in the networking domain and revealed promising results. By
reviewing recent advances, we present an abstract workflow to describe the
fundamental process involved in applying LLM for Networking. We introduce the
highlights of existing works by category and explain in detail how they operate
at different stages of the workflow. Furthermore, we delve into the challenges
encountered, discuss potential solutions, and outline future research
prospects. We hope that this survey will provide insight for researchers and
practitioners, promoting the development of this interdisciplinary research
field.
",review,1,,,
2306.12276,Wildfire Detection Via Transfer Learning: A Survey,"  This paper surveys different publicly available neural network models used
for detecting wildfires using regular visible-range cameras which are placed on
hilltops or forest lookout towers. The neural network models are pre-trained on
ImageNet-1K and fine-tuned on a custom wildfire dataset. The performance of
these models is evaluated on a diverse set of wildfire images, and the survey
provides useful information for those interested in using transfer learning for
wildfire detection. Swin Transformer-tiny has the highest AUC value but
ConvNext-tiny detects all the wildfire events and has the lowest false alarm
rate in our dataset.
",review,0,,,it's a survey but it's experimental
2404.0848,Decoding AI: The inside story of data analysis in ChatGPT,"  As a result of recent advancements in generative AI, the field of Data
Science is prone to various changes. This review critically examines the Data
Analysis (DA) capabilities of ChatGPT assessing its performance across a wide
range of tasks. While DA provides researchers and practitioners with
unprecedented analytical capabilities, it is far from being perfect, and it is
important to recognize and address its limitations.
",review,1,,,
2107.01381,Recent Advancements In Distributed System Communications,"  Overheads in Operating System kernel network stacks and sockets have been
hindering OSes from managing networking operations efficiently for years.
Moreover, when building Remote Procedure Calls over TCP, certain TCP features
do not match the needs of RPCs, imposing additional overheads. These issues
degrade the performance of distributed systems, which rely on fast
communications between machines to be able to serve a large number of client
requests with low latency and high throughput. The purpose of this literature
survey is to look into recent proposals in research literature that aim to
overcome these issues. The survey investigates research literature published
between 2010-2020, in order to include important advancements during the most
recent decade at the time of writing. The proposals found in papers have been
categorized into hardware-based and software-based approaches. The former
require specialized hardware to offer high communications performance. The
latter are implemented in software and don't rely on specialized hardware or
require only certain hardware features. Furthermore, the proposals where also
classified according to whether they implement kernel bypass, to avoid using
the Operating System kernel network stack, or not. The hardware-based
approaches examined here are RDMA, programmable Network Interface Controllers
(NIC) and System-on-a-Chip (SoC), while the software-based approaches include
optimized socket implementations and RPC frameworks, as well as user space
networking.
",review,1,,,
2103.15698,A Systematic Survey on Multi-relational Community Detection,"  Complex networks contain various interactions among similar or different
entities. These kinds of networks are called multi-relational networks, in
which each layer corresponds to a special type of interaction. Multi-relational
networks are a particular type of multilayer networks in which nodes are
similar entities; however, edges or communications demonstrate different types
of interactions among similar entities. In this survey, we study community
detection methods for multi-relational networks. The considered models are
divided into two main groups, namely, direct methods and indirect methods. We
put indirect methods in two classes: flattening and ensembling, and the direct
methods are further divided into four groups which are: probabilistic methods,
algebraic methods, modular-based methods, and graph feature-based methods. For
each approach and each method, we explain their pros and cons. Additionally,
all the used datasets in the multilayer community detection studies are
categorized into synthetic and real data. We elaborate on the most important
datasets. Afterward, the utilized evaluation metrics by the papers are
described. Finally, the current models' challenges and shortcomings are
discussed. Finally, some suggestions for future research are developed. Putting
all this together, this study, to the best of our knowledge, is the most
comprehensive survey dedicated to multi-relational networks community
detection.
",review,1,,,
2303.02715,Deep Learning in the Field of Biometric Template Protection: An Overview,"  Today, deep learning represents the most popular and successful form of
machine learning. Deep learning has revolutionised the field of pattern
recognition, including biometric recognition. Biometric systems utilising deep
learning have been shown to achieve auspicious recognition accuracy, surpassing
human performance. Apart from said breakthrough advances in terms of biometric
performance, the use of deep learning was reported to impact different
covariates of biometrics such as algorithmic fairness, vulnerability to
attacks, or template protection. Technologies of biometric template protection
are designed to enable a secure and privacy-preserving deployment of
biometrics. In the recent past, deep learning techniques have been frequently
applied in biometric template protection systems for various purposes. This
work provides an overview of how advances in deep learning take influence on
the field of biometric template protection. The interrelation between improved
biometric performance rates and security in biometric template protection is
elaborated. Further, the use of deep learning for obtaining feature
representations that are suitable for biometric template protection is
discussed. Novel methods that apply deep learning to achieve various goals of
biometric template protection are surveyed along with deep learning-based
attacks.
",review,1,,,
2301.0689,"AI-Based Affective Music Generation Systems: A Review of Methods, and
  Challenges","  Music is a powerful medium for altering the emotional state of the listener.
In recent years, with significant advancement in computing capabilities,
artificial intelligence-based (AI-based) approaches have become popular for
creating affective music generation (AMG) systems that are empowered with the
ability to generate affective music. Entertainment, healthcare, and
sensor-integrated interactive system design are a few of the areas in which
AI-based affective music generation (AI-AMG) systems may have a significant
impact. Given the surge of interest in this topic, this article aims to provide
a comprehensive review of AI-AMG systems. The main building blocks of an AI-AMG
system are discussed, and existing systems are formally categorized based on
the core algorithm used for music generation. In addition, this article
discusses the main musical features employed to compose affective music, along
with the respective AI-based approaches used for tailoring them. Lastly, the
main challenges and open questions in this field, as well as their potential
solutions, are presented to guide future research. We hope that this review
will be useful for readers seeking to understand the state-of-the-art in AI-AMG
systems, and gain an overview of the methods used for developing them, thereby
helping them explore this field in the future.
",review,1,,,
2407.17503,"Challenges and Considerations in Annotating Legal Data: A Comprehensive
  Overview","  The process of annotating data within the legal sector is filled with
distinct challenges that differ from other fields, primarily due to the
inherent complexities of legal language and documentation. The initial task
usually involves selecting an appropriate raw dataset that captures the
intricate aspects of legal texts. Following this, extracting text becomes a
complicated task, as legal documents often have complex structures, footnotes,
references, and unique terminology. The importance of data cleaning is
magnified in this context, ensuring that redundant information is eliminated
while maintaining crucial legal details and context. Creating comprehensive yet
straightforward annotation guidelines is imperative, as these guidelines serve
as the road map for maintaining uniformity and addressing the subtle nuances of
legal terminology. Another critical aspect is the involvement of legal
professionals in the annotation process. Their expertise is valuable in
ensuring that the data not only remains contextually accurate but also adheres
to prevailing legal standards and interpretations. This paper provides an
expanded view of these challenges and aims to offer a foundational
understanding and guidance for researchers and professionals engaged in legal
data annotation projects. In addition, we provide links to our created and
fine-tuned datasets and language models. These resources are outcomes of our
discussed projects and solutions to challenges faced while working on them.
",review,1,,,
2107.00906,"Using Machine Learning to Generate Test Oracles: A Systematic Literature
  Review","  Machine learning may enable the automated generation of test oracles. We have
characterized emerging research in this area through a systematic literature
review examining oracle types, researcher goals, the ML techniques applied, how
the generation process was assessed, and the open research challenges in this
emerging field.
  Based on a sample of 22 relevant studies, we observed that ML algorithms
generated test verdict, metamorphic relation, and - most commonly - expected
output oracles. Almost all studies employ a supervised or semi-supervised
approach, trained on labeled system executions or code metadata - including
neural networks, support vector machines, adaptive boosting, and decision
trees. Oracles are evaluated using the mutation score, correct classifications,
accuracy, and ROC. Work-to-date show great promise, but there are significant
open challenges regarding the requirements imposed on training data, the
complexity of modeled functions, the ML algorithms employed - and how they are
applied - the benchmarks used by researchers, and replicability of the studies.
We hope that our findings will serve as a roadmap and inspiration for
researchers in this field.
",review,1,,,
2305.14525,"The State of the Art in Creating Visualization Corpora for Automated
  Chart Analysis","  We present a state-of-the-art report on visualization corpora in automated
chart analysis research. We survey 56 papers that created or used a
visualization corpus as the input of their research techniques or systems.
Based on a multi-level task taxonomy that identifies the goal, method, and
outputs of automated chart analysis, we examine the property space of existing
chart corpora along five dimensions: format, scope, collection method,
annotations, and diversity. Through the survey, we summarize common patterns
and practices of creating chart corpora, identify research gaps and
opportunities, and discuss the desired properties of future benchmark corpora
and the required tools to create them.
",review,1,,,
2303.05205,"Real-time scheduling of renewable power systems through planning-based
  reinforcement learning","  The growing renewable energy sources have posed significant challenges to
traditional power scheduling. It is difficult for operators to obtain accurate
day-ahead forecasts of renewable generation, thereby requiring the future
scheduling system to make real-time scheduling decisions aligning with
ultra-short-term forecasts. Restricted by the computation speed, traditional
optimization-based methods can not solve this problem. Recent developments in
reinforcement learning (RL) have demonstrated the potential to solve this
challenge. However, the existing RL methods are inadequate in terms of
constraint complexity, algorithm performance, and environment fidelity. We are
the first to propose a systematic solution based on the state-of-the-art
reinforcement learning algorithm and the real power grid environment. The
proposed approach enables planning and finer time resolution adjustments of
power generators, including unit commitment and economic dispatch, thus
increasing the grid's ability to admit more renewable energy. The well-trained
scheduling agent significantly reduces renewable curtailment and load shedding,
which are issues arising from traditional scheduling's reliance on inaccurate
day-ahead forecasts. High-frequency control decisions exploit the existing
units' flexibility, reducing the power grid's dependence on hardware
transformations and saving investment and operating costs, as demonstrated in
experimental results. This research exhibits the potential of reinforcement
learning in promoting low-carbon and intelligent power systems and represents a
solid step toward sustainable electricity generation.
",regular,0,,,
2305.04154,Score: A Rule Engine for the Scone Knowledge Base System,"  We present Score, a rule engine designed and implemented for the Scone
knowledge base system. Scone is a knowledge base system designed for storing
and manipulating rich representations of general knowledge in symbolic form. It
represents knowledge in the form of nodes and links in a network structure, and
it can perform basic inference about the relationships between different
elements efficiently. On its own, Scone acts as a sort of ""smart memory"" that
can interface with other software systems. One area of improvement for Scone is
how useful it can be in supplying knowledge to an intelligent agent that can
use the knowledge to perform actions and update the knowledge base with its
observations.
  We augment the Scone system with a production rule engine that automatically
performs simple inference based on existing and newly-added structures in
Scone's knowledge base, potentially improving the capabilities of any planning
systems built on top of Scone. Production rule systems consist of ""if-then""
production rules that try to match their predicates to existing knowledge and
fire their actions when their predicates are satisfied. We propose two kinds of
production rules, if-added and if-needed rules, that differ in how they are
checked and fired to cover multiple use cases. We then implement methods to
efficiently check and fire these rules in a large knowledge base. The new rule
engine is not meant to be a complex stand-alone planner, so we discuss how it
fits into the context of Scone and future work on planning systems.
",regular,0,,,
2307.03059,"Explorations in Subexponential non-associative non-commutative Linear
  Logic (extended version)","  In a previous work we introduced a non-associative non-commutative logic
extended by multimodalities, called subexponentials, licensing local
application of structural rules. Here, we further explore this system,
considering a classical one-sided multi-succedent classical version of the
system, following the exponential-free calculi of Buszkowski's and de Groote
and Lamarche's works, where the intuitionistic calculus is shown to embed
faithfully into the classical fragment.
",regular,0,,,
2409.02383,"Reinforcement Learning for Wheeled Mobility on Vertically Challenging
  Terrain","  Off-road navigation on vertically challenging terrain, involving steep slopes
and rugged boulders, presents significant challenges for wheeled robots both at
the planning level to achieve smooth collision-free trajectories and at the
control level to avoid rolling over or getting stuck. Considering the complex
model of wheel-terrain interactions, we develop an end-to-end Reinforcement
Learning (RL) system for an autonomous vehicle to learn wheeled mobility
through simulated trial-and-error experiences. Using a custom-designed
simulator built on the Chrono multi-physics engine, our approach leverages
Proximal Policy Optimization (PPO) and a terrain difficulty curriculum to
refine a policy based on a reward function to encourage progress towards the
goal and penalize excessive roll and pitch angles, which circumvents the need
of complex and expensive kinodynamic modeling, planning, and control.
Additionally, we present experimental results in the simulator and deploy our
approach on a physical Verti-4-Wheeler (V4W) platform, demonstrating that RL
can equip conventional wheeled robots with previously unrealized potential of
navigating vertically challenging terrain.
",regular,0,,,
2110.0584,"A bridge between features and evidence for binary attribute-driven
  perfect privacy","  Attribute-driven privacy aims to conceal a single user's attribute, contrary
to anonymisation that tries to hide the full identity of the user in some data.
When the attribute to protect from malicious inferences is binary, perfect
privacy requires the log-likelihood-ratio to be zero resulting in no
strength-of-evidence. This work presents an approach based on normalizing flow
that maps a feature vector into a latent space where the evidence, related to
the binary attribute, and an independent residual are disentangled. It can be
seen as a non-linear discriminant analysis where the mapping is invertible
allowing generation by mapping the latent variable back to the original space.
This framework allows to manipulate the log-likelihood-ratio of the data and
therefore allows to set it to zero for privacy. We show the applicability of
the approach on an attribute-driven privacy task where the sex information is
removed from speaker embeddings. Results on VoxCeleb2 dataset show the
efficiency of the method that outperforms in terms of privacy and utility our
previous experiments based on adversarial disentanglement.
",regular,0,,,
2203.1519,3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow,"  Reconstructing 3D shape from a single 2D image is a challenging task, which
needs to estimate the detailed 3D structures based on the semantic attributes
from 2D image. So far, most of the previous methods still struggle to extract
semantic attributes for 3D reconstruction task. Since the semantic attributes
of a single image are usually implicit and entangled with each other, it is
still challenging to reconstruct 3D shape with detailed semantic structures
represented by the input image. To address this problem, we propose 3DAttriFlow
to disentangle and extract semantic attributes through different semantic
levels in the input images. These disentangled semantic attributes will be
integrated into the 3D shape reconstruction process, which can provide definite
guidance to the reconstruction of specific attribute on 3D shape. As a result,
the 3D decoder can explicitly capture high-level semantic features at the
bottom of the network, and utilize low-level features at the top of the
network, which allows to reconstruct more accurate 3D shapes. Note that the
explicit disentangling is learned without extra labels, where the only
supervision used in our training is the input image and its corresponding 3D
shape. Our comprehensive experiments on ShapeNet dataset demonstrate that
3DAttriFlow outperforms the state-of-the-art shape reconstruction methods, and
we also validate its generalization ability on shape completion task.
",regular,0,,,
2110.06525,"Automatic DJ Transitions with Differentiable Audio Effects and
  Generative Adversarial Networks","  A central task of a Disc Jockey (DJ) is to create a mixset of mu-sic with
seamless transitions between adjacent tracks. In this paper, we explore a
data-driven approach that uses a generative adversarial network to create the
song transition by learning from real-world DJ mixes. In particular, the
generator of the model uses two differentiable digital signal processing
components, an equalizer (EQ) and a fader, to mix two tracks selected by a data
generation pipeline. The generator has to set the parameters of the EQs and
fader in such away that the resulting mix resembles real mixes created by
humanDJ, as judged by the discriminator counterpart. Result of a listening test
shows that the model can achieve competitive results compared with a number of
baselines.
",regular,0,,,
2308.03333,"Heterogeneous Knowledge Fusion: A Novel Approach for Personalized
  Recommendation via LLM","  The analysis and mining of user heterogeneous behavior are of paramount
importance in recommendation systems. However, the conventional approach of
incorporating various types of heterogeneous behavior into recommendation
models leads to feature sparsity and knowledge fragmentation issues. To address
this challenge, we propose a novel approach for personalized recommendation via
Large Language Model (LLM), by extracting and fusing heterogeneous knowledge
from user heterogeneous behavior information. In addition, by combining
heterogeneous knowledge and recommendation tasks, instruction tuning is
performed on LLM for personalized recommendations. The experimental results
demonstrate that our method can effectively integrate user heterogeneous
behavior and significantly improve recommendation performance.
",regular,0,,,
2209.01434,"Reinforcement Learning with Prior Policy Guidance for Motion Planning of
  Dual-Arm Free-Floating Space Robot","  Reinforcement learning methods as a promising technique have achieved
superior results in the motion planning of free-floating space robots. However,
due to the increase in planning dimension and the intensification of system
dynamics coupling, the motion planning of dual-arm free-floating space robots
remains an open challenge. In particular, the current study cannot handle the
task of capturing a non-cooperative object due to the lack of the pose
constraint of the end-effectors. To address the problem, we propose a novel
algorithm, EfficientLPT, to facilitate RL-based methods to improve planning
accuracy efficiently. Our core contributions are constructing a mixed policy
with prior knowledge guidance and introducing infinite norm to build a more
reasonable reward function. Furthermore, our method successfully captures a
rotating object with different spinning speeds.
",regular,0,,,
2303.04414,"Next-Generation URLLC with Massive Devices: A Unified Semi-Blind
  Detection Framework for Sourced and Unsourced Random Access","  This paper proposes a unified semi-blind detection framework for sourced and
unsourced random access (RA), which enables next-generation ultra-reliable
low-latency communications (URLLC) with massive devices. Specifically, the
active devices transmit their uplink access signals in a grant-free manner to
realize ultra-low access latency. Meanwhile, the base station aims to achieve
ultra-reliable data detection under severe inter-device interference without
exploiting explicit channel state information (CSI). We first propose an
efficient transmitter design, where a small amount of reference information
(RI) is embedded in the access signal to resolve the inherent ambiguities
incurred by the unknown CSI. At the receiver, we further develop a successive
interference cancellation-based semi-blind detection scheme, where a bilinear
generalized approximate message passing algorithm is utilized for joint channel
and signal estimation (JCSE), while the embedded RI is exploited for ambiguity
elimination. Particularly, a rank selection approach and a RI-aided
initialization strategy are incorporated to reduce the algorithmic
computational complexity and to enhance the JCSE reliability, respectively.
Besides, four enabling techniques are integrated to satisfy the stringent
latency and reliability requirements of massive URLLC. Numerical results
demonstrate that the proposed semi-blind detection framework offers a better
scalability-latency-reliability tradeoff than the state-of-the-art detection
schemes dedicated to sourced or unsourced RA.
",regular,0,,,
2304.08493,"Coordinated Multi-Agent Reinforcement Learning for Unmanned Aerial
  Vehicle Swarms in Autonomous Mobile Access Applications","  This paper proposes a novel centralized training and distributed execution
(CTDE)-based multi-agent deep reinforcement learning (MADRL) method for
multiple unmanned aerial vehicles (UAVs) control in autonomous mobile access
applications. For the purpose, a single neural network is utilized in
centralized training for cooperation among multiple agents while maximizing the
total quality of service (QoS) in mobile access applications.
",regular,0,,,
2405.1769,Data Makes Better Data Scientists,"  With the goal of identifying common practices in data science projects, this
paper proposes a framework for logging and understanding incremental code
executions in Jupyter notebooks. This framework aims to allow reasoning about
how insights are generated in data science and extract key observations into
best data science practices in the wild. In this paper, we show an early
prototype of this framework and ran an experiment to log a machine learning
project for 25 undergraduate students.
",regular,0,,,"seems like the key differentiator is ""experiments or no experiments"""
2204.13237,Spatio-Temporal Graph Localization Networks for Image-based Navigation,"  Localization in topological maps is essential for image-based navigation
using an RGB camera. Localization using only one camera can be challenging in
medium-to-large-sized environments because similar-looking images are often
observed repeatedly, especially in indoor environments. To overcome this issue,
we propose a learning-based localization method that simultaneously utilizes
the spatial consistency from topological maps and the temporal consistency from
time-series images captured by the robot. Our method combines a convolutional
neural network (CNN) to embed image features and a recurrent-type graph neural
network to perform accurate localization. When training our model, it is
difficult to obtain the ground truth pose of the robot when capturing images in
real-world environments. Hence, we propose a sim2real transfer approach with
semi-supervised learning that leverages simulator images with the ground truth
pose in addition to real images. We evaluated our method quantitatively and
qualitatively and compared it with several state-of-the-art baselines. The
proposed method outperformed the baselines in environments where the map
contained similar images. Moreover, we evaluated an image-based navigation
system incorporating our localization method and confirmed that navigation
accuracy significantly improved in the simulator and real environments when
compared with the other baseline methods.
",regular,0,,,
2301.08606,Data Augmentation for Modeling Human Personality: The Dexter Machine,"  Modeling human personality is important for several AI challenges, from the
engineering of artificial psychotherapists to the design of persona bots.
However, the field of computational personality analysis heavily relies on
labeled data, which may be expensive, difficult or impossible to get. This
problem is amplified when dealing with rare personality types or disorders
(e.g., the anti-social psychopathic personality disorder). In this context, we
developed a text-based data augmentation approach for human personality
(PEDANT). PEDANT doesn't rely on the common type of labeled data but on the
generative pre-trained model (GPT) combined with domain expertise. Testing the
methodology on three different datasets, provides results that support the
quality of the generated data.
",regular,0,,,
2305.0514,"Linguistic More: Taking a Further Step toward Efficient and Accurate
  Scene Text Recognition","  Vision model have gained increasing attention due to their simplicity and
efficiency in Scene Text Recognition (STR) task. However, due to lacking the
perception of linguistic knowledge and information, recent vision models suffer
from two problems: (1) the pure vision-based query results in attention drift,
which usually causes poor recognition and is summarized as linguistic
insensitive drift (LID) problem in this paper. (2) the visual feature is
suboptimal for the recognition in some vision-missing cases (e.g. occlusion,
etc.). To address these issues, we propose a $\textbf{L}$inguistic
$\textbf{P}$erception $\textbf{V}$ision model (LPV), which explores the
linguistic capability of vision model for accurate text recognition. To
alleviate the LID problem, we introduce a Cascade Position Attention (CPA)
mechanism that obtains high-quality and accurate attention maps through
step-wise optimization and linguistic information mining. Furthermore, a Global
Linguistic Reconstruction Module (GLRM) is proposed to improve the
representation of visual features by perceiving the linguistic information in
the visual space, which gradually converts visual features into semantically
rich ones during the cascade process. Different from previous methods, our
method obtains SOTA results while keeping low complexity (92.4% accuracy with
only 8.11M parameters). Code is available at
https://github.com/CyrilSterling/LPV.
",regular,0,,,
2406.18853,Decoding-Time Language Model Alignment with Multiple Objectives,"  Aligning language models (LMs) to human preferences has emerged as a critical
pursuit, enabling these models to better serve diverse user needs. Existing
methods primarily focus on optimizing LMs for a single reward function,
limiting their adaptability to varied objectives. Here, we propose
$\textbf{multi-objective decoding (MOD)}$, a decoding-time algorithm that
outputs the next token from a linear combination of predictions of all base
models, for any given weightings over different objectives. We exploit a common
form among a family of $f$-divergence regularized alignment approaches (such as
PPO, DPO, and their variants) to identify a closed-form solution by Legendre
transform, and derive an efficient decoding strategy. Theoretically, we show
why existing approaches can be sub-optimal even in natural settings and obtain
optimality guarantees for our method. Empirical results demonstrate the
effectiveness of the algorithm. For example, compared to a parameter-merging
baseline, MOD achieves 12.8% overall reward improvement when equally optimizing
towards $3$ objectives. Moreover, we experiment with MOD on combining three
fully-finetuned LLMs of different model sizes, each aimed at different
objectives such as safety, coding, and general user preference. Unlike
traditional methods that require careful curation of a mixture of datasets to
achieve comprehensive improvement, we can quickly experiment with preference
weightings using MOD to find the best combination of models. Our best
combination reduces toxicity on Toxigen to nearly 0% and achieves 7.9--33.3%
improvement across other three metrics ($\textit{i.e.}$, Codex@1, GSM-COT,
BBH-COT).
",regular,0,,,
2305.10332,"Extracting a functional representation from a dictionary for non-rigid
  shape matching","  Shape matching is a fundamental problem in computer graphics with many
applications. Functional maps translate the point-wise shape-matching problem
into its functional counterpart and have inspired numerous solutions over the
last decade. Nearly all the solutions based on functional maps rely on the
eigenfunctions of the Laplace-Beltrami Operator (LB) to describe the functional
spaces defined on the surfaces and then convert the functional correspondences
into point-wise correspondences. However, this final step is often error-prone
and inaccurate in tiny regions and protrusions, where the energy of LB does not
uniformly cover the surface. We propose a new functional basis Principal
Components of a Dictionary (PCD) to address such intrinsic limitation. PCD
constructs an orthonormal basis from the Principal Component Analysis (PCA) of
a dictionary of functions defined over the shape. These dictionaries can target
specific properties of the final basis, such as achieving an even spreading of
energy. Our experimental evaluation compares seven different dictionaries on
established benchmarks, showing that PCD is suited to target different
shape-matching scenarios, resulting in more accurate point-wise maps than the
LB basis when used in the same pipeline. This evidence provides a promising
alternative for improving correspondence estimation, confirming the power and
flexibility of functional maps.
",regular,0,,,
2302.14803,Learned Risk Metric Maps for Kinodynamic Systems,"  We present Learned Risk Metric Maps (LRMM) for real-time estimation of
coherent risk metrics of high dimensional dynamical systems operating in
unstructured, partially observed environments. LRMM models are simple to design
and train -- requiring only procedural generation of obstacle sets, state and
control sampling, and supervised training of a function approximator -- which
makes them broadly applicable to arbitrary system dynamics and obstacle sets.
In a parallel autonomy setting, we demonstrate the model's ability to rapidly
infer collision probabilities of a fast-moving car-like robot driving
recklessly in an obstructed environment; allowing the LRMM agent to intervene,
take control of the vehicle, and avoid collisions. In this time-critical
scenario, we show that LRMMs can evaluate risk metrics 20-100x times faster
than alternative safety algorithms based on control barrier functions (CBFs)
and Hamilton-Jacobi reachability (HJ-reach), leading to 5-15\% fewer obstacle
collisions by the LRMM agent than CBFs and HJ-reach. This performance
improvement comes in spite of the fact that the LRMM model only has access to
local/partial observation of obstacles, whereas the CBF and HJ-reach agents are
granted privileged/global information. We also show that our model can be
equally well trained on a 12-dimensional quadrotor system operating in an
obstructed indoor environment. The LRMM codebase is provided at
https://github.com/mit-drl/pyrmm.
",regular,0,,,
2204.07615,"TabNAS: Rejection Sampling for Neural Architecture Search on Tabular
  Datasets","  The best neural architecture for a given machine learning problem depends on
many factors: not only the complexity and structure of the dataset, but also on
resource constraints including latency, compute, energy consumption, etc.
Neural architecture search (NAS) for tabular datasets is an important but
under-explored problem. Previous NAS algorithms designed for image search
spaces incorporate resource constraints directly into the reinforcement
learning (RL) rewards. However, for NAS on tabular datasets, this protocol
often discovers suboptimal architectures. This paper develops TabNAS, a new and
more effective approach to handle resource constraints in tabular NAS using an
RL controller motivated by the idea of rejection sampling. TabNAS immediately
discards any architecture that violates the resource constraints without
training or learning from that architecture. TabNAS uses a Monte-Carlo-based
correction to the RL policy gradient update to account for this extra filtering
step. Results on several tabular datasets demonstrate the superiority of TabNAS
over previous reward-shaping methods: it finds better models that obey the
constraints.
",regular,0,,,
2106.00992,NVC-Net: End-to-End Adversarial Voice Conversion,"  Voice conversion has gained increasing popularity in many applications of
speech synthesis. The idea is to change the voice identity from one speaker
into another while keeping the linguistic content unchanged. Many voice
conversion approaches rely on the use of a vocoder to reconstruct the speech
from acoustic features, and as a consequence, the speech quality heavily
depends on such a vocoder. In this paper, we propose NVC-Net, an end-to-end
adversarial network, which performs voice conversion directly on the raw audio
waveform of arbitrary length. By disentangling the speaker identity from the
speech content, NVC-Net is able to perform non-parallel traditional
many-to-many voice conversion as well as zero-shot voice conversion from a
short utterance of an unseen target speaker. Importantly, NVC-Net is
non-autoregressive and fully convolutional, achieving fast inference. Our model
is capable of producing samples at a rate of more than 3600 kHz on an NVIDIA
V100 GPU, being orders of magnitude faster than state-of-the-art methods under
the same hardware configurations. Objective and subjective evaluations on
non-parallel many-to-many voice conversion tasks show that NVC-Net obtains
competitive results with significantly fewer parameters.
",regular,0,,,
2302.06827,"B-BACN: Bayesian Boundary-Aware Convolutional Network for Crack
  Characterization","  Accurately detecting crack boundaries is crucial for reliability assessment
and risk management of structures and materials, such as structural health
monitoring, diagnostics, prognostics, and maintenance scheduling. Uncertainty
quantification of crack detection is challenging due to various stochastic
factors, such as measurement noises, signal processing, and model
simplifications. A machine learning-based approach is proposed to quantify both
epistemic and aleatoric uncertainties concurrently. We introduce a Bayesian
Boundary-Aware Convolutional Network (B-BACN) that emphasizes uncertainty-aware
boundary refinement to generate precise and reliable crack boundary detections.
The proposed method employs a multi-task learning approach, where we use Monte
Carlo Dropout to learn the epistemic uncertainty and a Gaussian sampling
function to predict each sample's aleatoric uncertainty. Moreover, we include a
boundary refinement loss to B-BACN to enhance the determination of defect
boundaries. The proposed method is demonstrated with benchmark experimental
results and compared with several existing methods. The experimental results
illustrate the effectiveness of our proposed approach in uncertainty-aware
crack boundary detection, minimizing misclassification rate, and improving
model calibration capabilities.
",regular,0,,,
2304.09741,"A Multi-robot Coverage Path Planning Algorithm Based on Improved DARP
  Algorithm","  The research on multi-robot coverage path planning (CPP) has been attracting
more and more attention. In order to achieve efficient coverage, this paper
proposes an improved DARP coverage algorithm. The improved DARP algorithm based
on A* algorithm is used to assign tasks to robots and then combined with STC
algorithm based on Up-First algorithm to achieve full coverage of the task
area. Compared with the initial DARP algorithm, this algorithm has higher
efficiency and higher coverage rate.
",regular,0,,,
2105.04965,Succinct Euler-Tour Trees,"  We show how a collection of Euler-tour trees for a forest on $n$ vertices can
be stored in $2 n + o (n)$ bits such that simple queries take constant time,
more complex queries take logarithmic time and updates take polylogarithmic
amortized time.
",regular,0,,,
2104.10013,Parallel Physics-Informed Neural Networks via Domain Decomposition,"  We develop a distributed framework for the physics-informed neural networks
(PINNs) based on two recent extensions, namely conservative PINNs (cPINNs) and
extended PINNs (XPINNs), which employ domain decomposition in space and in
time-space, respectively. This domain decomposition endows cPINNs and XPINNs
with several advantages over the vanilla PINNs, such as parallelization
capacity, large representation capacity, efficient hyperparameter tuning, and
is particularly effective for multi-scale and multi-physics problems. Here, we
present a parallel algorithm for cPINNs and XPINNs constructed with a hybrid
programming model described by MPI $+$ X, where X $\in
\{\text{CPUs},~\text{GPUs}\}$. The main advantage of cPINN and XPINN over the
more classical data and model parallel approaches is the flexibility of
optimizing all hyperparameters of each neural network separately in each
subdomain. We compare the performance of distributed cPINNs and XPINNs for
various forward problems, using both weak and strong scalings. Our results
indicate that for space domain decomposition, cPINNs are more efficient in
terms of communication cost but XPINNs provide greater flexibility as they can
also handle time-domain decomposition for any differential equations, and can
deal with any arbitrarily shaped complex subdomains. To this end, we also
present an application of the parallel XPINN method for solving an inverse
diffusion problem with variable conductivity on the United States map, using
ten regions as subdomains.
",regular,0,,,
2211.09322,Targeted Attention for Generalized- and Zero-Shot Learning,"  The Zero-Shot Learning (ZSL) task attempts to learn concepts without any
labeled data. Unlike traditional classification/detection tasks, the evaluation
environment is provided unseen classes never encountered during training. As
such, it remains both challenging, and promising on a variety of fronts,
including unsupervised concept learning, domain adaptation, and dataset drift
detection. Recently, there have been a variety of approaches towards solving
ZSL, including improved metric learning methods, transfer learning,
combinations of semantic and image domains using, e.g. word vectors, and
generative models to model the latent space of known classes to classify unseen
classes. We find many approaches require intensive training augmentation with
attributes or features that may be commonly unavailable (attribute-based
learning) or susceptible to adversarial attacks (generative learning). We
propose combining approaches from the related person re-identification task for
ZSL, with key modifications to ensure sufficiently improved performance in the
ZSL setting without the need for feature or training dataset augmentation. We
are able to achieve state-of-the-art performance on the CUB200 and Cars196
datasets in the ZSL setting compared to recent works, with NMI (normalized
mutual inference) of 63.27 and top-1 of 61.04 for CUB200, and NMI 66.03 with
top-1 82.75% in Cars196. We also show state-of-the-art results in the
Generalized Zero-Shot Learning (GZSL) setting, with Harmonic Mean R-1 of 66.14%
on the CUB200 dataset.
",regular,0,,,
2401.12491,Assessing and Understanding Creativity in Large Language Models,"  In the field of natural language processing, the rapid development of large
language model (LLM) has attracted more and more attention. LLMs have shown a
high level of creativity in various tasks, but the methods for assessing such
creativity are inadequate. The assessment of LLM creativity needs to consider
differences from humans, requiring multi-dimensional measurement while
balancing accuracy and efficiency. This paper aims to establish an efficient
framework for assessing the level of creativity in LLMs. By adapting the
modified Torrance Tests of Creative Thinking, the research evaluates the
creative performance of various LLMs across 7 tasks, emphasizing 4 criteria
including Fluency, Flexibility, Originality, and Elaboration. In this context,
we develop a comprehensive dataset of 700 questions for testing and an
LLM-based evaluation method. In addition, this study presents a novel analysis
of LLMs' responses to diverse prompts and role-play situations. We found that
the creativity of LLMs primarily falls short in originality, while excelling in
elaboration. Besides, the use of prompts and the role-play settings of the
model significantly influence creativity. Additionally, the experimental
results also indicate that collaboration among multiple LLMs can enhance
originality. Notably, our findings reveal a consensus between human evaluations
and LLMs regarding the personality traits that influence creativity. The
findings underscore the significant impact of LLM design on creativity and
bridges artificial intelligence and human creativity, offering insights into
LLMs' creativity and potential applications.
",regular,0,,,
2112.07174,"Practical Distributed Reception for Wireless Body Area Networks Using
  Supervised Learning","  Medical applications have driven many areas of engineering to optimize
diagnostic capabilities and convenience. In the near future, wireless body area
networks (WBANs) are expected to have widespread impact in medicine. To achieve
this impact, however, significant advances in research are needed to cope with
the changes of the human body's state, which make coherent communications
difficult or even impossible. In this paper, we consider a realistic
noncoherent WBAN system model where transmissions and receptions are conducted
without any channel state information due to the fast-varying channels of the
human body. Using distributed reception, we propose several symbol detection
approaches where on-off keying (OOK) modulation is exploited, among which a
supervised-learning-based approach is developed to overcome the noncoherent
system issue. Through simulation results, we compare and verify the performance
of the proposed techniques for noncoherent WBANs with OOK transmissions. We
show that the well-defined detection techniques with a
supervised-learning-based approach enable robust communications for noncoherent
WBAN systems.
",regular,0,,,
2105.08709,Learning and Certification under Instance-targeted Poisoning,"  In this paper, we study PAC learnability and certification of predictions
under instance-targeted poisoning attacks, where the adversary who knows the
test instance may change a fraction of the training set with the goal of
fooling the learner at the test instance. Our first contribution is to
formalize the problem in various settings and to explicitly model subtle
aspects such as the proper or improper nature of the learning, learner's
randomness, and whether (or not) adversary's attack can depend on it. Our main
result shows that when the budget of the adversary scales sublinearly with the
sample complexity, (improper) PAC learnability and certification are
achievable; in contrast, when the adversary's budget grows linearly with the
sample complexity, the adversary can potentially drive up the expected 0-1 loss
to one. We also study distribution-specific PAC learning in the same attack
model and show that proper learning with certification is possible for learning
half spaces under natural distributions. Finally, we empirically study the
robustness of K nearest neighbour, logistic regression, multi-layer perceptron,
and convolutional neural network on real data sets against targeted-poisoning
attacks. Our experimental results show that many models, especially
state-of-the-art neural networks, are indeed vulnerable to these strong
attacks. Interestingly, we observe that methods with high standard accuracy
might be more vulnerable to instance-targeted poisoning attacks.
",regular,0,,,
2404.07814,"MultiLS-SP/CA: Lexical Complexity Prediction and Lexical Simplification
  Resources for Catalan and Spanish","  Automatic lexical simplification is a task to substitute lexical items that
may be unfamiliar and difficult to understand with easier and more common
words. This paper presents MultiLS-SP/CA, a novel dataset for lexical
simplification in Spanish and Catalan. This dataset represents the first of its
kind in Catalan and a substantial addition to the sparse data on automatic
lexical simplification which is available for Spanish. Specifically, MultiLS-SP
is the first dataset for Spanish which includes scalar ratings of the
understanding difficulty of lexical items. In addition, we describe experiments
with this dataset, which can serve as a baseline for future work on the same
data.
",regular,0,,,
2405.11677,"Advancing 6-DoF Instrument Pose Estimation in Variable X-Ray Imaging
  Geometries","  Accurate 6-DoF pose estimation of surgical instruments during minimally
invasive surgeries can substantially improve treatment strategies and eventual
surgical outcome. Existing deep learning methods have achieved accurate
results, but they require custom approaches for each object and laborious setup
and training environments often stretching to extensive simulations, whilst
lacking real-time computation. We propose a general-purpose approach of data
acquisition for 6-DoF pose estimation tasks in X-ray systems, a novel and
general purpose YOLOv5-6D pose architecture for accurate and fast object pose
estimation and a complete method for surgical screw pose estimation under
acquisition geometry consideration from a monocular cone-beam X-ray image. The
proposed YOLOv5-6D pose model achieves competitive results on public benchmarks
whilst being considerably faster at 42 FPS on GPU. In addition, the method
generalizes across varying X-ray acquisition geometry and semantic image
complexity to enable accurate pose estimation over different domains. Finally,
the proposed approach is tested for bone-screw pose estimation for
computer-aided guidance during spine surgeries. The model achieves a 92.41% by
the 0.1 ADD-S metric, demonstrating a promising approach for enhancing surgical
precision and patient outcomes. The code for YOLOv5-6D is publicly available at
https://github.com/cviviers/YOLOv5-6D-Pose
",regular,0,,,
2105.05714,Representation in Dynamical Systems,"  The brain is often called a computer and likened to a Turing machine, in part
because the mind can manipulate discrete symbols such as numbers. But the brain
is a dynamical system, more like a Watt governor than a Turing machine. Can a
dynamical system be said to operate using ""representations""? This paper argues
that it can, although not in the way a digital computer does. Instead, it uses
phenomena best described using mathematic concepts such as chaotic attractors
to stand in for aspects of the world.
",regular,?,0,,
2107.07404,Two-Sided Matching Meets Fair Division,"  We introduce a new model for two-sided matching which allows us to borrow
popular fairness notions from the fair division literature such as
envy-freeness up to one good and maximin share guarantee. In our model, each
agent is matched to multiple agents on the other side over whom she has
additive preferences. We demand fairness for each side separately, giving rise
to notions such as double envy-freeness up to one match (DEF1) and double
maximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1
cannot always be achieved, but in the special case where both sides have
identical preferences, the round-robin algorithm with a carefully designed
agent ordering achieves it. In contrast, DMMS cannot be achieved even when both
sides have identical preferences.
",regular,0,,,
2105.08179,Learning Disentangled Representations for Time Series,"  Time-series representation learning is a fundamental task for time-series
analysis. While significant progress has been made to achieve accurate
representations for downstream applications, the learned representations often
lack interpretability and do not expose semantic meanings. Different from
previous efforts on the entangled feature space, we aim to extract the
semantic-rich temporal correlations in the latent interpretable factorized
representation of the data. Motivated by the success of disentangled
representation learning in computer vision, we study the possibility of
learning semantic-rich time-series representations, which remains unexplored
due to three main challenges: 1) sequential data structure introduces complex
temporal correlations and makes the latent representations hard to interpret,
2) sequential models suffer from KL vanishing problem, and 3) interpretable
semantic concepts for time-series often rely on multiple factors instead of
individuals. To bridge the gap, we propose Disentangle Time Series (DTS), a
novel disentanglement enhancement framework for sequential data. Specifically,
to generate hierarchical semantic concepts as the interpretable and
disentangled representation of time-series, DTS introduces multi-level
disentanglement strategies by covering both individual latent factors and group
semantic segments. We further theoretically show how to alleviate the KL
vanishing problem: DTS introduces a mutual information maximization term, while
preserving a heavier penalty on the total correlation and the dimension-wise KL
to keep the disentanglement property. Experimental results on various
real-world benchmark datasets demonstrate that the representations learned by
DTS achieve superior performance in downstream applications, with high
interpretability of semantic concepts.
",regular,0,,,
2109.14208,"A Communication Security Game on Switched Systems for Autonomous Vehicle
  Platoons","  Vehicle-to-vehicle communication enables autonomous platoons to boost traffic
efficiency and safety, while ensuring string stability with a constant spacing
policy. However, communication-based controllers are susceptible to a range of
cyber-attacks. In this paper, we propose a distributed attack mitigation
defense framework with a dual-mode control system reconfiguration scheme to
prevent a compromised platoon member from causing collisions via message
falsification attacks. In particular, we model it as a switched system
consisting of a communication-based cooperative controller and a sensor-based
local controller and derive conditions to achieve global uniform exponential
stability (GUES) as well as string stability in the sense of platoon operation.
The switching decision comes from game-theoretic analysis of the attacker and
the defender's interactions. In this framework, the attacker acts as a leader
that chooses whether to engage in malicious activities and the defender decides
which control system to deploy with the help of an anomaly detector. Imperfect
detection reports associate the game with imperfect information. A dedicated
state constraint further enhances safety against bounded but aggressive message
modifications in which a bounded solution may still violate practical
constraint e.g. vehicles nearly crashing. Our formulation uniquely combines
switched systems with security games to strategically improve the safety of
such autonomous vehicle systems.
",regular,0,,,
2103.08634,"Competitive Equilibria with Unequal Budgets: Supporting Arbitrary Pareto
  Optimal Allocations","  We consider a market setting of agents with additive valuations over
heterogeneous divisible resources. Agents are assigned a budget of tokens
(possibly unequal budgets) they can use to obtain resources; leftover tokens
are worthless. We show how to support any Pareto efficient allocation in
equilibrium, using anonymous resource prices and agent specific budgets. We
also give computationally efficient algorithms for those tasks. In particular,
this allows us to support the Rawlsian max-min allocation.
",regular,0,,,
2101.01842,Confluence up to Garbage in Graph Transformation,"  The transformation of graphs and graph-like structures is ubiquitous in
computer science. When a system is described by graph-transformation rules, it
is often desirable that the rules are both terminating and confluent so that
rule applications in an arbitrary order produce unique resulting graphs.
However, there are application scenarios where the rules are not globally
confluent but confluent on a subclass of graphs that are of interest. In other
words, non-resolvable conflicts can only occur on graphs that are considered as
""garbage"". In this paper, we introduce the notion of confluence up to garbage
and generalise Plump's critical pair lemma for double-pushout graph
transformation, providing a sufficient condition for confluence up to garbage
by non-garbage critical pair analysis. We apply our results in two case studies
about efficient language recognition: we present backtracking-free graph
reduction systems which recognise a class of flow diagrams and a class of
labelled series-parallel graphs, respectively. Both systems are non-confluent
but confluent up to garbage. We also give a critical pair condition for
subcommutativity up to garbage which, together with closedness, implies
confluence up to garbage even in non-terminating systems.
",regular,0,,,
2106.07353,Posthoc Verification and the Fallibility of the Ground Truth,"  Classifiers commonly make use of pre-annotated datasets, wherein a model is
evaluated by pre-defined metrics on a held-out test set typically made of
human-annotated labels. Metrics used in these evaluations are tied to the
availability of well-defined ground truth labels, and these metrics typically
do not allow for inexact matches. These noisy ground truth labels and strict
evaluation metrics may compromise the validity and realism of evaluation
results. In the present work, we discuss these concerns and conduct a
systematic posthoc verification experiment on the entity linking (EL) task.
Unlike traditional methodologies, which asks annotators to provide free-form
annotations, we ask annotators to verify the correctness of annotations after
the fact (i.e., posthoc). Compared to pre-annotation evaluation,
state-of-the-art EL models performed extremely well according to the posthoc
evaluation methodology. Posthoc validation also permits the validation of the
ground truth dataset. Surprisingly, we find predictions from EL models had a
similar or higher verification rate than the ground truth. We conclude with a
discussion on these findings and recommendations for future evaluations.
",regular,0,,,
2306.13055,Deep Metric Learning with Soft Orthogonal Proxies,"  Deep Metric Learning (DML) models rely on strong representations and
similarity-based measures with specific loss functions. Proxy-based losses have
shown great performance compared to pair-based losses in terms of convergence
speed. However, proxies that are assigned to different classes may end up being
closely located in the embedding space and hence having a hard time to
distinguish between positive and negative items. Alternatively, they may become
highly correlated and hence provide redundant information with the model. To
address these issues, we propose a novel approach that introduces Soft
Orthogonality (SO) constraint on proxies. The constraint ensures the proxies to
be as orthogonal as possible and hence control their positions in the embedding
space. Our approach leverages Data-Efficient Image Transformer (DeiT) as an
encoder to extract contextual features from images along with a DML objective.
The objective is made of the Proxy Anchor loss along with the SO
regularization. We evaluate our method on four public benchmarks for
category-level image retrieval and demonstrate its effectiveness with
comprehensive experimental results and ablation studies. Our evaluations
demonstrate the superiority of our proposed approach over state-of-the-art
methods by a significant margin.
",regular,0,,,
2312.10961,Aspect-Based Sentiment Analysis with Explicit Sentiment Augmentations,"  Aspect-based sentiment analysis (ABSA), a fine-grained sentiment
classification task, has received much attention recently. Many works
investigate sentiment information through opinion words, such as ''good'' and
''bad''. However, implicit sentiment widely exists in the ABSA dataset, which
refers to the sentence containing no distinct opinion words but still expresses
sentiment to the aspect term. To deal with implicit sentiment, this paper
proposes an ABSA method that integrates explicit sentiment augmentations. And
we propose an ABSA-specific augmentation method to create such augmentations.
Specifically, we post-trains T5 by rule-based data. We employ Syntax Distance
Weighting and Unlikelihood Contrastive Regularization in the training procedure
to guide the model to generate an explicit sentiment. Meanwhile, we utilize the
Constrained Beam Search to ensure the augmentation sentence contains the aspect
terms. We test ABSA-ESA on two of the most popular benchmarks of ABSA. The
results show that ABSA-ESA outperforms the SOTA baselines on implicit and
explicit sentiment accuracy.
",regular,0,,,
2203.0451,ReVar: Strengthening Policy Evaluation via Reduced Variance Sampling,"  This paper studies the problem of data collection for policy evaluation in
Markov decision processes (MDPs). In policy evaluation, we are given a target
policy and asked to estimate the expected cumulative reward it will obtain in
an environment formalized as an MDP. We develop theory for optimal data
collection within the class of tree-structured MDPs by first deriving an oracle
data collection strategy that uses knowledge of the variance of the reward
distributions. We then introduce the Reduced Variance Sampling (ReVar)
algorithm that approximates the oracle strategy when the reward variances are
unknown a priori and bound its sub-optimality compared to the oracle strategy.
Finally, we empirically validate that ReVar leads to policy evaluation with
mean squared error comparable to the oracle strategy and significantly lower
than simply running the target policy.
",regular,0,,,
2307.08283,Complexity Matters: Rethinking the Latent Space for Generative Modeling,"  In generative modeling, numerous successful approaches leverage a
low-dimensional latent space, e.g., Stable Diffusion models the latent space
induced by an encoder and generates images through a paired decoder. Although
the selection of the latent space is empirically pivotal, determining the
optimal choice and the process of identifying it remain unclear. In this study,
we aim to shed light on this under-explored topic by rethinking the latent
space from the perspective of model complexity. Our investigation starts with
the classic generative adversarial networks (GANs). Inspired by the GAN
training objective, we propose a novel ""distance"" between the latent and data
distributions, whose minimization coincides with that of the generator
complexity. The minimizer of this distance is characterized as the optimal
data-dependent latent that most effectively capitalizes on the generator's
capacity. Then, we consider parameterizing such a latent distribution by an
encoder network and propose a two-stage training strategy called Decoupled
Autoencoder (DAE), where the encoder is only updated in the first stage with an
auxiliary decoder and then frozen in the second stage while the actual decoder
is being trained. DAE can improve the latent distribution and as a result,
improve the generative performance. Our theoretical analyses are corroborated
by comprehensive experiments on various models such as VQGAN and Diffusion
Transformer, where our modifications yield significant improvements in sample
quality with decreased model complexity.
",regular,0,,,
2304.09626,StyleDEM: a Versatile Model for Authoring Terrains,"  Many terrain modelling methods have been proposed for the past decades,
providing efficient and often interactive authoring tools. However, they
generally do not include any notion of style, which is a critical aspect for
designers in the entertainment industry. We introduce StyleDEM, a new
generative adversarial network method for terrain synthesis and authoring, with
a versatile toolbox of authoring methods with style. This method starts from an
input sketch or an existing terrain. It outputs a terrain with features that
can be authored using interactive brushes and enhanced with additional tools
such as style manipulation or super-resolution. The strength of our approach
resides in the versatility and interoperability of the toolbox.
",regular,0,,,
2202.07499,"Texture Aware Autoencoder Pre-training And Pairwise Learning Refinement
  For Improved Iris Recognition","  This paper presents a texture aware end-to-end trainable iris recognition
system, specifically designed for datasets like iris having limited training
data. We build upon our previous stagewise learning framework with certain key
optimization and architectural innovations. First, we pretrain a Stage-1
encoder network with an unsupervised autoencoder learning optimized with an
additional data relation loss on top of usual reconstruction loss. The data
relation loss enables learning better texture representation which is pivotal
for a texture rich dataset such as iris. Robustness of Stage-1 feature
representation is further enhanced with an auxiliary denoising task. Such
pre-training proves beneficial for effectively training deep networks on data
constrained iris datasets. Next, in Stage-2 supervised refinement, we design a
pairwise learning architecture for an end-to-end trainable iris recognition
system. The pairwise learning includes the task of iris matching inside the
training pipeline itself and results in significant improvement in recognition
performance compared to usual offline matching. We validate our model across
three publicly available iris datasets and the proposed model consistently
outperforms both traditional and deep learning baselines for both
Within-Dataset and Cross-Dataset configurations
",regular,0,,,
2307.02132,"Going Retro: Astonishingly Simple Yet Effective Rule-based Prosody
  Modelling for Speech Synthesis Simulating Emotion Dimensions","  We introduce two rule-based models to modify the prosody of speech synthesis
in order to modulate the emotion to be expressed. The prosody modulation is
based on speech synthesis markup language (SSML) and can be used with any
commercial speech synthesizer. The models as well as the optimization result
are evaluated against human emotion annotations. Results indicate that with a
very simple method both dimensions arousal (.76 UAR) and valence (.43 UAR) can
be simulated.
",regular,0,,,
2406.11867,"Not as Simple as It Looked: Are We Concluding for Biased Arrest
  Practices?","  This study examines racial disparities in violent arrest outcomes,
challenging conventional methods through a nuanced analysis of Cincinnati
Police Department data. Acknowledging the intricate nature of racial disparity,
the study categorizes explanations into types of place, types of person, and a
combination of both, emphasizing the impact of neighborhood characteristics on
crime distribution and police deployment. By introducing alternative scenarios,
such as spuriousness, directed policing, and the geo-concentration of racial
groups, the study underscores the complexity of racial disparity calculations.
Employing a case study approach, the analysis of violent arrest outcomes
reveals approximately 40 percent of the observed variation attributed to
neighborhood-level characteristics, with concentrated disadvantage neutralizing
the influence of race on arrest rates. Contrary to expectations, the study
challenges the notion of unintentional racism, suggesting that neighborhood
factors play a more significant role than the racial composition in explaining
arrests. Policymakers are urged to focus on comprehensive community development
initiatives addressing socioeconomic inequalities and support the development
of robust racial disparity indices. The study calls for nuanced explorations of
unintentional racism and future research addressing potential limitations,
aiming to enhance understanding of the complexities surrounding racial
disparities in arrests.
",regular,0,,,
2203.15988,"Does Configuration Encoding Matter in Learning Software Performance? An
  Empirical Study on Encoding Schemes","  Learning and predicting the performance of a configurable software system
helps to provide better quality assurance. One important engineering decision
therein is how to encode the configuration into the model built. Despite the
presence of different encoding schemes, there is still little understanding of
which is better and under what circumstances, as the community often relies on
some general beliefs that inform the decision in an ad-hoc manner. To bridge
this gap, in this paper, we empirically compared the widely used encoding
schemes for software performance learning, namely label, scaled label, and
one-hot encoding. The study covers five systems, seven models, and three
encoding schemes, leading to 105 cases of investigation.
  Our key findings reveal that: (1) conducting trial-and-error to find the best
encoding scheme in a case by case manner can be rather expensive, requiring up
to 400+ hours on some models and systems; (2) the one-hot encoding often leads
to the most accurate results while the scaled label encoding is generally weak
on accuracy over different models; (3) conversely, the scaled label encoding
tends to result in the fastest training time across the models/systems while
the one-hot encoding is the slowest; (4) for all models studied, label and
scaled label encoding often lead to relatively less biased outcomes between
accuracy and training time, but the paired model varies according to the
system.
  We discuss the actionable suggestions derived from our findings, hoping to
provide a better understanding of this topic for the community. To promote open
science, the data and code of this work can be publicly accessed at
https://github.com/ideas-labo/MSR2022-encoding-study.
",regular,0,,,
2107.13298,Generalized Nash Equilibrium Problems with Mixed-Integer Variables,"  We consider generalized Nash equilibrium problems (GNEPs) with non-convex
strategy spaces and non-convex cost functions. This general class of games
includes the important case of games with mixed-integer variables for which
only a few results are known in the literature. We present a new approach to
characterize equilibria via a convexification technique using the Nikaido-Isoda
function. To any given instance of the GNEP, we construct a set of convexified
instances and show that a feasible strategy profile is an equilibrium for the
original instance if and only if it is an equilibrium for any convexified
instance and the convexified cost functions coincide with the initial ones. We
further develop this approach along three dimensions. We first show that for
quasi-linear models, where a convexified instance exists in which for fixed
strategies of the opponent players, the cost function of every player is linear
and the respective strategy space is polyhedral, the convexification reduces
the GNEP to a standard (non-linear) optimization problem. Secondly, we derive
two complete characterizations of those GNEPs for which the convexification
leads to a jointly constrained or a jointly convex GNEP, respectively. These
characterizations require new concepts related to the interplay of the convex
hull operator applied to restricted subsets of feasible strategies and may be
interesting on their own. Finally, we demonstrate the applicability of our
results by presenting a numerical study regarding the computation of equilibria
for a class of integral network flow GNEPs.
",regular,0,,,
2105.10148,On Instrumental Variable Regression for Deep Offline Policy Evaluation,"  We show that the popular reinforcement learning (RL) strategy of estimating
the state-action value (Q-function) by minimizing the mean squared Bellman
error leads to a regression problem with confounding, the inputs and output
noise being correlated. Hence, direct minimization of the Bellman error can
result in significantly biased Q-function estimates. We explain why fixing the
target Q-network in Deep Q-Networks and Fitted Q Evaluation provides a way of
overcoming this confounding, thus shedding new light on this popular but not
well understood trick in the deep RL literature. An alternative approach to
address confounding is to leverage techniques developed in the causality
literature, notably instrumental variables (IV). We bring together here the
literature on IV and RL by investigating whether IV approaches can lead to
improved Q-function estimates. This paper analyzes and compares a wide range of
recent IV methods in the context of offline policy evaluation (OPE), where the
goal is to estimate the value of a policy using logged data only. By applying
different IV techniques to OPE, we are not only able to recover previously
proposed OPE methods such as model-based techniques but also to obtain
competitive new techniques. We find empirically that state-of-the-art OPE
methods are closely matched in performance by some IV methods such as AGMM,
which were not developed for OPE. We open-source all our code and datasets at
https://github.com/liyuan9988/IVOPEwithACME.
",regular,0,,,
2103.12498,Stereo Object Matching Network,"  This paper presents a stereo object matching method that exploits both 2D
contextual information from images as well as 3D object-level information.
Unlike existing stereo matching methods that exclusively focus on the
pixel-level correspondence between stereo images within a volumetric space
(i.e., cost volume), we exploit this volumetric structure in a different
manner. The cost volume explicitly encompasses 3D information along its
disparity axis, therefore it is a privileged structure that can encapsulate the
3D contextual information from objects. However, it is not straightforward
since the disparity values map the 3D metric space in a non-linear fashion.
Thus, we present two novel strategies to handle 3D objectness in the cost
volume space: selective sampling (RoISelect) and 2D-3D fusion
(fusion-by-occupancy), which allow us to seamlessly incorporate 3D object-level
information and achieve accurate depth performance near the object boundary
regions. Our depth estimation achieves competitive performance in the KITTI
dataset and the Virtual-KITTI 2.0 dataset.
",regular,0,,,
2303.10452,"Confidence Attention and Generalization Enhanced Distillation for
  Continuous Video Domain Adaptation","  Continuous Video Domain Adaptation (CVDA) is a scenario where a source model
is required to adapt to a series of individually available changing target
domains continuously without source data or target supervision. It has wide
applications, such as robotic vision and autonomous driving. The main
underlying challenge of CVDA is to learn helpful information only from the
unsupervised target data while avoiding forgetting previously learned knowledge
catastrophically, which is out of the capability of previous Video-based
Unsupervised Domain Adaptation methods. Therefore, we propose a
Confidence-Attentive network with geneRalization enhanced self-knowledge
disTillation (CART) to address the challenge in CVDA. Firstly, to learn from
unsupervised domains, we propose to learn from pseudo labels. However, in
continuous adaptation, prediction errors can accumulate rapidly in pseudo
labels, and CART effectively tackles this problem with two key modules.
Specifically, The first module generates refined pseudo labels using model
predictions and deploys a novel attentive learning strategy. The second module
compares the outputs of augmented data from the current model to the outputs of
weakly augmented data from the source model, forming a novel consistency
regularization on the model to alleviate the accumulation of prediction errors.
Extensive experiments suggest that the CVDA performance of CART outperforms
existing methods by a considerable margin.
",regular,0,,,
2204.09222,K-LITE: Learning Transferable Visual Models with External Knowledge,"  The new generation of state-of-the-art computer vision systems are trained
from natural language supervision, ranging from simple object category names to
descriptive captions. This form of supervision ensures high generality and
usability of the learned visual models, due to the broad concept coverage
achieved via large-scale data collection process. Alternatively, we argue that
learning with external knowledge is a promising way which leverages a much more
structured source of supervision and offers sample efficiency. We propose
K-LITE, a simple strategy to leverage external knowledge for building
transferable visual systems: In training, it enriches entities in text with
WordNet and Wiktionary knowledge, leading to an efficient and scalable approach
to learning image representations that uses knowledge about the visual
concepts. In evaluation, the text is also augmented with external knowledge and
then used to reference learned visual concepts (or describe new ones) to enable
zero-shot and few-shot transfer of the pre-trained models. We study the
performance of K-LITE on two important computer vision problems, image
classification and object detection, benchmarking on 20 and 13 different
existing datasets, respectively. The proposed knowledge-augmented models show
significant improvement in transfer learning performance over existing methods.
Our code is available at https://github.com/microsoft/klite.
",regular,0,,,
2401.06379,"Vehicle: Bridging the Embedding Gap in the Verification of
  Neuro-Symbolic Programs","  Neuro-symbolic programs -- programs containing both machine learning
components and traditional symbolic code -- are becoming increasingly
widespread. However, we believe that there is still a lack of a general
methodology for verifying these programs whose correctness depends on the
behaviour of the machine learning components. In this paper, we identify the
``embedding gap'' -- the lack of techniques for linking semantically-meaningful
``problem-space'' properties to equivalent ``embedding-space'' properties -- as
one of the key issues, and describe Vehicle, a tool designed to facilitate the
end-to-end verification of neural-symbolic programs in a modular fashion.
Vehicle provides a convenient language for specifying ``problem-space''
properties of neural networks and declaring their relationship to the
``embedding-space"", and a powerful compiler that automates interpretation of
these properties in the language of a chosen machine-learning training
environment, neural network verifier, and interactive theorem prover. We
demonstrate Vehicle's utility by using it to formally verify the safety of a
simple autonomous car equipped with a neural network controller.
",regular,0,,,
2108.09372,InBiodiv-O: An Ontology for Indian Biodiversity Knowledge Management,"  To present the biodiversity information, a semantic model is required that
connects all kinds of data about living creatures and their habitats. The model
must be able to encode human knowledge for machines to be understood. Ontology
offers the richest machine-interpretable (rather than just machine-processable)
and explicit semantics that are being extensively used in the biodiversity
domain. Various ontologies are developed for the biodiversity domain however a
review of the current landscape shows that these ontologies are not capable to
define the Indian biodiversity information though India is one of the
megadiverse countries. To semantically analyze the Indian biodiversity
information, it is crucial to build an ontology that describes all the
essential terms of this domain from the unstructured format of the data
available on the web. Since, the curation of the ontologies heavily depends on
the domain where these are implemented hence there is no ideal methodology is
defined yet to be ready for universal use. The aim of this article is to
develop an ontology that semantically encodes all the terms of Indian
biodiversity information in all its dimensions based on the proposed
methodology. The comprehensive evaluation of the proposed ontology depicts that
ontology is well built in the specified domain.
",regular,1,,,good example of how hard it is to differentiate
2104.04205,"Alignment of Stakeholder Expectations about User Involvement in Agile
  Software Development","  Context: User involvement is generally considered to contributing to user
satisfaction and project success and is central to Agile software development.
In theory, the expectations about user involvement, such as the PO's, are quite
demanding in this Agile way of working. But what are the expectations seen in
practice, and are the expectations of user involvement aligned among the
development team and users? Any misalignment could contribute to conflict and
miscommunication among stakeholders that may result in ineffective user
involvement. Objective: Our aim is to compare and contrast the expectations of
two stakeholder groups (software development team, and software users) about
user involvement in order to understand the expectations and assess their
alignment. Method: We have conducted an exploratory case study of expectations
about user involvement in an Agile software development. Qualitative data was
collected through interviews to design a novel method for the assessing the
alignment of expectations about user involvement by applying Repertory Grids
(RG). Results: By aggregating the results from the interviews and RGs, varying
degrees of expectation alignments were observed between the development team
and user representatives. Conclusion: Alignment of expectations can be assessed
in practice using the proposed RG instrument and can reveal misalignment
between user roles and activities they participate in Agile software
development projects. Although we used RG instrument retrospectively in this
study, we posit that it could also be applied from the start of a project, or
proactively as a diagnostic tool throughout a project to assess and ensure that
expectations are aligned.
",regular,0,,,
2308.106,Fixed-Parameter Algorithms for Computing RAC Drawings of Graphs,"  In a right-angle crossing (RAC) drawing of a graph, each edge is represented
as a polyline and edge crossings must occur at an angle of exactly $90^\circ$,
where the number of bends on such polylines is typically restricted in some
way. While structural and topological properties of RAC drawings have been the
focus of extensive research, little was known about the boundaries of
tractability for computing such drawings. In this paper, we initiate the study
of RAC drawings from the viewpoint of parameterized complexity. In particular,
we establish that computing a RAC drawing of an input graph $G$ with at most
$b$ bends (or determining that none exists) is fixed-parameter tractable
parameterized by either the feedback edge number of $G$, or $b$ plus the vertex
cover number of $G$.
",regular,0,,,
2407.1241,Proximity-based Self-Federated Learning,"  In recent advancements in machine learning, federated learning allows a
network of distributed clients to collaboratively develop a global model
without needing to share their local data. This technique aims to safeguard
privacy, countering the vulnerabilities of conventional centralized learning
methods. Traditional federated learning approaches often rely on a central
server to coordinate model training across clients, aiming to replicate the
same model uniformly across all nodes. However, these methods overlook the
significance of geographical and local data variances in vast networks,
potentially affecting model effectiveness and applicability. Moreover, relying
on a central server might become a bottleneck in large networks, such as the
ones promoted by edge computing. Our paper introduces a novel,
fully-distributed federated learning strategy called proximity-based
self-federated learning that enables the self-organised creation of multiple
federations of clients based on their geographic proximity and data
distribution without exchanging raw data. Indeed, unlike traditional
algorithms, our approach encourages clients to share and adjust their models
with neighbouring nodes based on geographic proximity and model accuracy. This
method not only addresses the limitations posed by diverse data distributions
but also enhances the model's adaptability to different regional
characteristics creating specialized models for each federation. We demonstrate
the efficacy of our approach through simulations on well-known datasets,
showcasing its effectiveness over the conventional centralized federated
learning framework.
",regular,0,,,
2407.11882,"Enhancing Covert Communication in Relay Systems Using Multi-Antenna
  Technique","  This paper exploits the multi-antenna technique to enhance the covert
communication performance in a relay system, where a source S conducts covert
communication with a destination D via a relay R, subjecting to the detections
of transmissions in the two hops from a single-antenna warden W. To demonstrate
the performance gain from adopting the multi-antenna technique, we first
consider the scenario when S, R and D all adopt single antenna, and apply
hypothesis testing and statistics theories to develop a theoretical framework
for the covert performance modeling in terms of detection error probability
(DEP) and covert throughput. We then consider the scenario when S, R and D all
adopt multiple antennas, and apply the hypothesis testing, statistics and
matrix theories to develop corresponding theoretical framework for performance
modeling. We further explore the optimal designs of the target rate and
transmit power for covert throughput maximization under above both scenarios,
subjecting to the constraints of covertness, reliability and transmit power. To
solve the optimization problems, we employ Karushi-Kuhn-Tucker (KKT) conditions
method in the single antenna scenario and a search algorithm in the
multi-antenna scenario. Finally, we provide extensive numerical results to
illustrate how the multi-antenna technique can enhance the covert performance
in two-hop relay systems.
",regular,0,,,
2112.05416,Optimizing Edge Detection for Image Segmentation with Multicut Penalties,"  The Minimum Cost Multicut Problem (MP) is a popular way for obtaining a graph
decomposition by optimizing binary edge labels over edge costs. While the
formulation of a MP from independently estimated costs per edge is highly
flexible and intuitive, solving the MP is NP-hard and time-expensive. As a
remedy, recent work proposed to predict edge probabilities with awareness to
potential conflicts by incorporating cycle constraints in the prediction
process. We argue that such formulation, while providing a first step towards
end-to-end learnable edge weights, is suboptimal, since it is built upon a
loose relaxation of the MP. We therefore propose an adaptive CRF that allows to
progressively consider more violated constraints and, in consequence, to issue
solutions with higher validity. Experiments on the BSDS500 benchmark for
natural image segmentation as well as on electron microscopic recordings show
that our approach yields more precise edge detection and image segmentation.
",regular,0,,,
2212.0228,GARF:Geometry-Aware Generalized Neural Radiance Field,"  Neural Radiance Field (NeRF) has revolutionized free viewpoint rendering
tasks and achieved impressive results. However, the efficiency and accuracy
problems hinder its wide applications. To address these issues, we propose
Geometry-Aware Generalized Neural Radiance Field (GARF) with a geometry-aware
dynamic sampling (GADS) strategy to perform real-time novel view rendering and
unsupervised depth estimation on unseen scenes without per-scene optimization.
Distinct from most existing generalized NeRFs, our framework infers the unseen
scenes on both pixel-scale and geometry-scale with only a few input images.
More specifically, our method learns common attributes of novel-view synthesis
by an encoder-decoder structure and a point-level learnable multi-view feature
fusion module which helps avoid occlusion. To preserve scene characteristics in
the generalized model, we introduce an unsupervised depth estimation module to
derive the coarse geometry, narrow down the ray sampling interval to proximity
space of the estimated surface and sample in expectation maximum position,
constituting Geometry-Aware Dynamic Sampling strategy (GADS). Moreover, we
introduce a Multi-level Semantic Consistency loss (MSC) to assist more
informative representation learning. Extensive experiments on indoor and
outdoor datasets show that comparing with state-of-the-art generalized NeRF
methods, GARF reduces samples by more than 25\%, while improving rendering
quality and 3D geometry estimation.
",regular,0,,,
2111.01726,"Instructive artificial intelligence (AI) for human training, assistance,
  and explainability","  We propose a novel approach to explainable AI (XAI) based on the concept of
""instruction"" from neural networks. In this case study, we demonstrate how a
superhuman neural network might instruct human trainees as an alternative to
traditional approaches to XAI. Specifically, an AI examines human actions and
calculates variations on the human strategy that lead to better performance.
Experiments with a JHU/APL-developed AI player for the cooperative card game
Hanabi suggest this technique makes unique contributions to explainability
while improving human performance. One area of focus for Instructive AI is in
the significant discrepancies that can arise between a human's actual strategy
and the strategy they profess to use. This inaccurate self-assessment presents
a barrier for XAI, since explanations of an AI's strategy may not be properly
understood or implemented by human recipients. We have developed and are
testing a novel, Instructive AI approach that estimates human strategy by
observing human actions. With neural networks, this allows a direct calculation
of the changes in weights needed to improve the human strategy to better
emulate a more successful AI. Subjected to constraints (e.g. sparsity) these
weight changes can be interpreted as recommended changes to human strategy
(e.g. ""value A more, and value B less""). Instruction from AI such as this
functions both to help humans perform better at tasks, but also to better
understand, anticipate, and correct the actions of an AI. Results will be
presented on AI instruction's ability to improve human decision-making and
human-AI teaming in Hanabi.
",regular,0,,,
2407.03949,Establishing Provenance Before Coding: Traditional and Next-Gen Signing,"  Software engineers integrate third-party components into their applications.
The resulting software supply chain is vulnerable. To reduce the attack
surface, we can verify the origin of components (provenance) before adding
them. Cryptographic signatures enable this. This article describes traditional
signing, its challenges, and changes introduced by next generation signing
platforms
",regular,1,,,
2306.09124,DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks,"  Adversarial attacks, particularly patch attacks, pose significant threats to
the robustness and reliability of deep learning models. Developing reliable
defenses against patch attacks is crucial for real-world applications, yet
current research in this area is unsatisfactory. In this paper, we propose
DIFFender, a novel defense method that leverages a text-guided diffusion model
to defend against adversarial patches. DIFFender includes two main stages:
patch localization and patch restoration. In the localization stage, we find
and exploit an intriguing property of the diffusion model to precisely identify
the locations of adversarial patches. In the restoration stage, we employ the
diffusion model to reconstruct the adversarial regions in the images while
preserving the integrity of the visual content. Thanks to the former finding,
these two stages can be simultaneously guided by a unified diffusion model.
Thus, we can utilize the close interaction between them to improve the whole
defense performance. Moreover, we propose a few-shot prompt-tuning algorithm to
fine-tune the diffusion model, enabling the pre-trained diffusion model to
adapt to the defense task easily. We conduct extensive experiments on image
classification, face recognition, and further in the physical world,
demonstrating that our proposed method exhibits superior robustness under
strong adaptive attacks and generalizes well across various scenarios, diverse
classifiers, and multiple patch attack methods.
",regular,0,,,
2102.05301,Parallel Minimum Cuts in $O(m \log^2(n))$ Work and Low Depth,"  We present a randomized $O(m \log^2 n)$ work, $O(\text{polylog } n)$ depth
parallel algorithm for minimum cut. This algorithm matches the work bounds of a
recent sequential algorithm by Gawrychowski, Mozes, and Weimann [ICALP'20], and
improves on the previously best parallel algorithm by Geissmann and Gianinazzi
[SPAA'18], which performs $O(m \log^4 n)$ work in $O(\text{polylog } n)$ depth.
  Our algorithm makes use of three components that might be of independent
interest. Firstly, we design a parallel data structure that efficiently
supports batched mixed queries and updates on trees. It generalizes and
improves the work bounds of a previous data structure of Geissmann and
Gianinazzi and is work efficient with respect to the best sequential algorithm.
Secondly, we design a parallel algorithm for approximate minimum cut that
improves on previous results by Karger and Motwani. We use this algorithm to
give a work-efficient procedure to produce a tree packing, as in Karger's
sequential algorithm for minimum cuts. Lastly, we design an efficient parallel
algorithm for solving the minimum $2$-respecting cut problem.
",regular,0,,,
2311.16104,Data Analytics with Differential Privacy,"  Differential privacy is the state-of-the-art definition for privacy,
guaranteeing that any analysis performed on a sensitive dataset leaks no
information about the individuals whose data are contained therein. In this
thesis, we develop differentially private algorithms to analyze distributed and
streaming data. In the distributed model, we consider the particular problem of
learning -- in a distributed fashion -- a global model of the data, that can
subsequently be used for arbitrary analyses. We build upon PrivBayes, a
differentially private method that approximates the high-dimensional
distribution of a centralized dataset as a product of low-order distributions,
utilizing a Bayesian Network model. We examine three novel approaches to
learning a global Bayesian Network from distributed data, while offering the
differential privacy guarantee to all local datasets. Our work includes a
detailed theoretical analysis of the distributed, differentially private
entropy estimator which we use in one of our algorithms, as well as a detailed
experimental evaluation, using both synthetic and real-world data. In the
streaming model, we focus on the problem of estimating the density of a stream
of users, which expresses the fraction of all users that actually appear in the
stream. We offer one of the strongest privacy guarantees for the streaming
model, user-level pan-privacy, which ensures that the privacy of any user is
protected, even against an adversary that observes the internal state of the
algorithm. We provide a detailed analysis of an existing, sampling-based
algorithm for the problem and propose two novel modifications that
significantly improve it, both theoretically and experimentally, by optimally
using all the allocated ""privacy budget.""
",regular,0,,,
2204.03418,"Continual Inference: A Library for Efficient Online Inference with Deep
  Neural Networks in PyTorch","  We present Continual Inference, a Python library for implementing Continual
Inference Networks (CINs) in PyTorch, a class of Neural Networks designed
specifically for efficient inference in both online and batch processing
scenarios. We offer a comprehensive introduction and guide to CINs and their
implementation in practice, and provide best-practices and code examples for
composing complex modules for modern Deep Learning. Continual Inference is
readily downloadable via the Python Package Index and at
\url{www.github.com/lukashedegaard/continual-inference}.
",regular,0,,,
2312.10423,"Stochastic Bayesian Optimization with Unknown Continuous Context
  Distribution via Kernel Density Estimation","  Bayesian optimization (BO) is a sample-efficient method and has been widely
used for optimizing expensive black-box functions. Recently, there has been a
considerable interest in BO literature in optimizing functions that are
affected by context variable in the environment, which is uncontrollable by
decision makers. In this paper, we focus on the optimization of functions'
expectations over continuous context variable, subject to an unknown
distribution. To address this problem, we propose two algorithms that employ
kernel density estimation to learn the probability density function (PDF) of
continuous context variable online. The first algorithm is simpler, which
directly optimizes the expectation under the estimated PDF. Considering that
the estimated PDF may have high estimation error when the true distribution is
complicated, we further propose the second algorithm that optimizes the
distributionally robust objective. Theoretical results demonstrate that both
algorithms have sub-linear Bayesian cumulative regret on the expectation
objective. Furthermore, we conduct numerical experiments to empirically
demonstrate the effectiveness of our algorithms.
",regular,0,,,
2404.01413,"Is Model Collapse Inevitable? Breaking the Curse of Recursion by
  Accumulating Real and Synthetic Data","  The proliferation of generative models, combined with pretraining on
web-scale data, raises a timely question: what happens when these models are
trained on their own generated outputs? Recent investigations into model-data
feedback loops proposed that such loops would lead to a phenomenon termed model
collapse, under which performance progressively degrades with each model-data
feedback iteration until fitted models become useless. However, those studies
largely assumed that new data replace old data over time, where an arguably
more realistic assumption is that data accumulate over time. In this paper, we
ask: what effect does accumulating data have on model collapse? We empirically
study this question by pretraining sequences of language models on text
corpora. We confirm that replacing the original real data by each generation's
synthetic data does indeed tend towards model collapse, then demonstrate that
accumulating the successive generations of synthetic data alongside the
original real data avoids model collapse; these results hold across a range of
model sizes, architectures, and hyperparameters. We obtain similar results for
deep generative models on other types of real data: diffusion models for
molecule conformation generation and variational autoencoders for image
generation. To understand why accumulating data can avoid model collapse, we
use an analytically tractable framework introduced by prior work in which a
sequence of linear models are fit to the previous models' outputs. Previous
work used this framework to show that if data are replaced, the test error
increases with the number of model-fitting iterations; we extend this argument
to prove that if data instead accumulate, the test error has a finite upper
bound independent of the number of iterations, meaning model collapse no longer
occurs.
",regular,0,,,
2102.10024,A Tb/s Indoor MIMO Optical Wireless Backhaul System Using VCSEL Arrays,"  In this paper, the design of a multiple-input multiple-output (MIMO) optical
wireless communication (OWC) link based on vertical cavity surface emitting
laser (VCSEL) arrays is systematically carried out with the aim to support data
rates in excess of 1 Tb/s for the backhaul of sixth generation (6G) indoor
wireless networks. The proposed design combines direct current optical
orthogonal frequency division multiplexing (DCO-OFDM) and a spatial
multiplexing MIMO architecture. For such an ultra-high-speed line-of-sight
(LOS) OWC link with low divergence laser beams, maintaining alignment is of
high importance. In this paper, two types of misalignment error between the
transmitter and receiver are distinguished, namely, radial displacement error
and orientation angle error, and they are thoroughly modeled in a unified
analytical framework assuming Gaussian laser beams, resulting in a generalized
misalignment model (GMM). The derived GMM is then extended to MIMO arrays and
the performance of the MIMO-OFDM OWC system is analyzed in terms of the
aggregate data rate. Novel insights are provided into the system performance
based on computer simulations by studying various influential factors such as
beam waist, array configuration and different misalignment errors, which can be
used as guidelines for designing short range Tb/s MIMO OWC systems.
",regular,0,,,
2112.04352,"Efficient Data Race Detection of Async-Finish Programs Using Vector
  Clocks","  Existing data race detectors for task-based programs incur significant run
time and space overheads. The overheads arise because of frequent lookups in
fine-grained tree data structures to check whether two accesses can happen in
parallel.
  This work shows how to efficiently apply vector clocks for dynamic data race
detection of async-finish programs with locks. Our proposed technique,
FastRacer, builds on the FastTrack algorithm with per-task and per-variable
optimizations to reduce the size of vector clocks. FastRacer exploits the
structured parallelism of async-finish programs to use a coarse-grained
encoding of the dynamic task inheritance relations to limit the metadata in the
presence of many concurrent readers. Our evaluation shows that FastRacer
substantially improves time and space overheads over FastTrack, and is
competitive with the state-of-the-art data race detectors for async-finish
programs with locks.
",regular,0,,,
2204.08609,"""Flux+Mutability"": A Conditional Generative Approach to One-Class
  Classification and Anomaly Detection","  Anomaly Detection is becoming increasingly popular within the experimental
physics community. At experiments such as the Large Hadron Collider, anomaly
detection is at the forefront of finding new physics beyond the Standard Model.
This paper details the implementation of a novel Machine Learning architecture,
called Flux+Mutability, which combines cutting-edge conditional generative
models with clustering algorithms. In the `flux' stage we learn the
distribution of a reference class. The `mutability' stage at inference
addresses if data significantly deviates from the reference class. We
demonstrate the validity of our approach and its connection to multiple
problems spanning from one-class classification to anomaly detection. In
particular, we apply our method to the isolation of neutral showers in an
electromagnetic calorimeter and show its performance in detecting anomalous
dijets events from standard QCD background. This approach limits assumptions on
the reference sample and remains agnostic to the complementary class of objects
of a given problem. We describe the possibility of dynamically generating a
reference population and defining selection criteria via quantile cuts.
Remarkably this flexible architecture can be deployed for a wide range of
problems, and applications like multi-class classification or data quality
control are left for further exploration.
",regular,0,,,
2309.15572,"HPL-ViT: A Unified Perception Framework for Heterogeneous Parallel
  LiDARs in V2V","  To develop the next generation of intelligent LiDARs, we propose a novel
framework of parallel LiDARs and construct a hardware prototype in our
experimental platform, DAWN (Digital Artificial World for Natural). It
emphasizes the tight integration of physical and digital space in LiDAR
systems, with networking being one of its supported core features. In the
context of autonomous driving, V2V (Vehicle-to-Vehicle) technology enables
efficient information sharing between different agents which significantly
promotes the development of LiDAR networks. However, current research operates
under an ideal situation where all vehicles are equipped with identical LiDAR,
ignoring the diversity of LiDAR categories and operating frequencies. In this
paper, we first utilize OpenCDA and RLS (Realistic LiDAR Simulation) to
construct a novel heterogeneous LiDAR dataset named OPV2V-HPL. Additionally, we
present HPL-ViT, a pioneering architecture designed for robust feature fusion
in heterogeneous and dynamic scenarios. It uses a graph-attention Transformer
to extract domain-specific features for each agent, coupled with a
cross-attention mechanism for the final fusion. Extensive experiments on
OPV2V-HPL demonstrate that HPL-ViT achieves SOTA (state-of-the-art) performance
in all settings and exhibits outstanding generalization capabilities.
",regular,0,,,
2203.16123,"An I/O-Efficient Disk-based Graph System for Scalable Second-Order
  Random Walk of Large Graphs","  Random walk is widely used in many graph analysis tasks, especially the
first-order random walk. However, as a simplification of real-world problems,
the first-order random walk is poor at modeling higher-order structures in the
data. Recently, second-order random walk-based applications (e.g., Node2vec,
Second-order PageRank) have become attractive. Due to the complexity of the
second-order random walk models and memory limitations, it is not scalable to
run second-order random walk-based applications on a single machine. Existing
disk-based graph systems are only friendly to the first-order random walk
models and suffer from expensive disk I/Os when executing the second-order
random walks. This paper introduces an I/O-efficient disk-based graph system
for the scalable second-order random walk of large graphs, called GraSorw.
First, to eliminate massive light vertex I/Os, we develop a bi-block execution
engine that converts random I/Os into sequential I/Os by applying a new
triangular bi-block scheduling strategy, the bucket-based walk management, and
the skewed walk storage. Second, to improve the I/O utilization, we design a
learning-based block loading model to leverage the advantages of the full-load
and on-demand load methods. Finally, we conducted extensive experiments on six
large real datasets as well as several synthetic datasets. The empirical
results demonstrate that the end-to-end time cost of popular tasks in GraSorw
is reduced by more than one order of magnitude compared to the existing
disk-based graph systems.
",regular,0,,,
2112.14478,Semantic Feature Extraction for Generalized Zero-shot Learning,"  Generalized zero-shot learning (GZSL) is a technique to train a deep learning
model to identify unseen classes using the attribute. In this paper, we put
forth a new GZSL technique that improves the GZSL classification performance
greatly. Key idea of the proposed approach, henceforth referred to as semantic
feature extraction-based GZSL (SE-GZSL), is to use the semantic feature
containing only attribute-related information in learning the relationship
between the image and the attribute. In doing so, we can remove the
interference, if any, caused by the attribute-irrelevant information contained
in the image feature. To train a network extracting the semantic feature, we
present two novel loss functions, 1) mutual information-based loss to capture
all the attribute-related information in the image feature and 2)
similarity-based loss to remove unwanted attribute-irrelevant information. From
extensive experiments using various datasets, we show that the proposed SE-GZSL
technique outperforms conventional GZSL approaches by a large margin.
",regular,0,,,
2110.13535,"An in-depth Analysis of Occasional and Recurring Collaborations in
  Online Music Co-creation","  The success of online creative communities depends on the will of
participants to create and derive content in a collaborative environment.
Despite their growing popularity, the factors that lead to remixing existing
content in online creative communities are not entirely understood. In this
paper, we focus on overdubbing, that is, a dyadic collaboration where one
author mixes one new track with an audio recording previously uploaded by
another. We study musicians who collaborate regularly, that is, frequently
overdub each other's songs. Building on frequent pattern mining techniques, we
develop an approach to seek instances of such recurring collaborations in the
Songtree community. We identify 43 instances involving two or three members
with a similar reputation in the community. Our findings highlight common and
different remix factors in occasional and recurring collaborations.
Specifically, fresh and less mature songs are generally overdubbed more;
instead, exchanging messages and invitations to collaborate are significant
factors only for songs generated through recurring collaborations whereas
author reputation (ranking) and applying metadata tags to songs have a positive
effect only in occasional collaborations.
",regular,0,,,
2104.12124,On Measure Quantifiers in First-Order Arithmetic (Long Version),"  We study the logic obtained by endowing the language of first-order
arithmetic with second-order measure quantifiers. This new kind of
quantification allows us to express that the argument formula is true in a
certain portion of all possible interpretations of the quantified variable. We
show that first-order arithmetic with measure quantifiers is capable of
formalizing simple results from probability theory and, most importantly, of
representing every recursive random function. Moreover, we introduce a
realizability interpretation of this logic in which programs have access to an
oracle from the Cantor space.
",regular,0,,,
2105.08114,Weakly Private Information Retrieval Under R\'enyi Divergence,"  Private information retrieval (PIR) is a protocol that guarantees the privacy
of a user who is in communication with databases. The user wants to download
one of the messages stored in the databases while hiding the identity of the
desired message. Recently, the benefits that can be obtained by weakening the
privacy requirement have been studied, but the definition of weak privacy needs
to be elaborated upon. In this paper, we attempt to quantify the weak privacy
(i.e., information leakage) in PIR problems by using the R\'enyi divergence
that generalizes the Kullback-Leibler divergence. By introducing R\'enyi
divergence into the existing PIR problem, the tradeoff relationship between
privacy (information leakage) and PIR performance (download cost) is
characterized via convex optimization. Furthermore, we propose an alternative
PIR scheme with smaller message sizes than the Tian-Sun-Chen (TSC) scheme. The
proposed scheme cannot achieve the PIR capacity of perfect privacy since the
message size of the TSC scheme is the minimum to achieve the PIR capacity.
However, we show that the proposed scheme can be better than the TSC scheme in
the weakly PIR setting, especially under a low download cost regime.
",regular,0,,,
2205.10386,A Dynamic Weighted Tabular Method for Convolutional Neural Networks,"  Traditional Machine Learning (ML) models like Support Vector Machine, Random
Forest, and Logistic Regression are generally preferred for classification
tasks on tabular datasets. Tabular data consists of rows and columns
corresponding to instances and features, respectively. Past studies indicate
that traditional classifiers often produce unsatisfactory results in complex
tabular datasets. Hence, researchers attempt to use the powerful Convolutional
Neural Networks (CNN) for tabular datasets. Recent studies propose several
techniques like SuperTML, Conditional GAN (CTGAN), and Tabular Convolution
(TAC) for applying Convolutional Neural Networks (CNN) on tabular data. These
models outperform the traditional classifiers and substantially improve the
performance on tabular data. This study introduces a novel technique, namely,
Dynamic Weighted Tabular Method (DWTM), that uses feature weights dynamically
based on statistical techniques to apply CNNs on tabular datasets. The method
assigns weights dynamically to each feature based on their strength of
associativity to the class labels. Each data point is converted into images and
fed to a CNN model. The features are allocated image canvas space based on
their weights. The DWTM is an improvement on the previously mentioned methods
as it dynamically implements the entire experimental setting rather than using
the static configuration provided in the previous methods. Furthermore, it uses
the novel idea of using feature weights to create image canvas space. In this
paper, the DWTM is applied to six benchmarked tabular datasets and it achieves
outstanding performance (i.e., average accuracy = 95%) on all of them.
",regular,0,,,
2103.14021,Orthogonal Projection Loss,"  Deep neural networks have achieved remarkable performance on a range of
classification tasks, with softmax cross-entropy (CE) loss emerging as the
de-facto objective function. The CE loss encourages features of a class to have
a higher projection score on the true class-vector compared to the negative
classes. However, this is a relative constraint and does not explicitly force
different class features to be well-separated. Motivated by the observation
that ground-truth class representations in CE loss are orthogonal (one-hot
encoded vectors), we develop a novel loss function termed `Orthogonal
Projection Loss' (OPL) which imposes orthogonality in the feature space. OPL
augments the properties of CE loss and directly enforces inter-class separation
alongside intra-class clustering in the feature space through orthogonality
constraints on the mini-batch level. As compared to other alternatives of CE,
OPL offers unique advantages e.g., no additional learnable parameters, does not
require careful negative mining and is not sensitive to the batch size. Given
the plug-and-play nature of OPL, we evaluate it on a diverse range of tasks
including image recognition (CIFAR-100), large-scale classification (ImageNet),
domain generalization (PACS) and few-shot learning (miniImageNet, CIFAR-FS,
tiered-ImageNet and Meta-dataset) and demonstrate its effectiveness across the
board. Furthermore, OPL offers better robustness against practical nuisances
such as adversarial attacks and label noise. Code is available at:
https://github.com/kahnchana/opl.
",regular,0,,,
2207.0157,Goal-Conditioned Generators of Deep Policies,"  Goal-conditioned Reinforcement Learning (RL) aims at learning optimal
policies, given goals encoded in special command inputs. Here we study
goal-conditioned neural nets (NNs) that learn to generate deep NN policies in
form of context-specific weight matrices, similar to Fast Weight Programmers
and other methods from the 1990s. Using context commands of the form ""generate
a policy that achieves a desired expected return,"" our NN generators combine
powerful exploration of parameter space with generalization across commands to
iteratively find better and better policies. A form of weight-sharing
HyperNetworks and policy embeddings scales our method to generate deep NNs.
Experiments show how a single learned policy generator can produce policies
that achieve any return seen during training. Finally, we evaluate our
algorithm on a set of continuous control tasks where it exhibits competitive
performance. Our code is public.
",regular,0,,,
2304.13502,"How Semantic Information G Measure Relates to Distortion, Freshness,
  Purposiveness, and Efficiency","  To improve communication efficiency and provide more useful information, we
need to measure semantic information by combining inaccuracy or distortion,
freshness, purposiveness, and efficiency. The author proposed the semantic
information G measure before. This measure is more compatible with Shannon
information theory than other semantic or generalized information measures and
has been applied to machine learning. This paper focuses on semantic predictive
information (including observation information) and purposive (or goal-related)
information (involving semantic communication and constraint control). The GPS
pointer is used as an example to discuss the change of semantic predictive
information with inaccuracy and time (age of the information). An example of
constraint control (controlling probability distributions) is provided for
measuring purposive information and maximizing this information and the
information efficiency. The information rate fidelity function (a
generalization of the information rate distortion function) is introduced for
the optimization. Two computing examples demonstrate how to measure predictive
and goal-related information and optimizing information efficiency. The results
accord with theoretical conclusions well. The G measure is related to deep
learning; its application to machine learning is worth exploring. Communication
efficiency also involves utilities or information values; semantic
communication optimization combining utilities needs further research.
",regular,1,,,
2208.02578,"N-best Response-based Analysis of Contradiction-awareness in Neural
  Response Generation Models","  Avoiding the generation of responses that contradict the preceding context is
a significant challenge in dialogue response generation. One feasible method is
post-processing, such as filtering out contradicting responses from a resulting
n-best response list. In this scenario, the quality of the n-best list
considerably affects the occurrence of contradictions because the final
response is chosen from this n-best list. This study quantitatively analyzes
the contextual contradiction-awareness of neural response generation models
using the consistency of the n-best lists. Particularly, we used polar
questions as stimulus inputs for concise and quantitative analyses. Our tests
illustrate the contradiction-awareness of recent neural response generation
models and methodologies, followed by a discussion of their properties and
limitations.
",regular,0,,,
2101.06545,VideoClick: Video Object Segmentation with a Single Click,"  Annotating videos with object segmentation masks typically involves a two
stage procedure of drawing polygons per object instance for all the frames and
then linking them through time. While simple, this is a very tedious, time
consuming and expensive process, making the creation of accurate annotations at
scale only possible for well-funded labs. What if we were able to segment an
object in the full video with only a single click? This will enable video
segmentation at scale with a very low budget opening the door to many
applications. Towards this goal, in this paper we propose a bottom up approach
where given a single click for each object in a video, we obtain the
segmentation masks of these objects in the full video. In particular, we
construct a correlation volume that assigns each pixel in a target frame to
either one of the objects in the reference frame or the background. We then
refine this correlation volume via a recurrent attention module and decode the
final segmentation. To evaluate the performance, we label the popular and
challenging Cityscapes dataset with video object segmentations. Results on this
new CityscapesVideo dataset show that our approach outperforms all the
baselines in this challenging setting.
",regular,0,,,
2201.02065,"ASL-Skeleton3D and ASL-Phono: Two Novel Datasets for the American Sign
  Language","  Sign language is an essential resource enabling access to communication and
proper socioemotional development for individuals suffering from disabling
hearing loss. As this population is expected to reach 700 million by 2050, the
importance of the language becomes even more essential as it plays a critical
role to ensure the inclusion of such individuals in society. The Sign Language
Recognition field aims to bridge the gap between users and non-users of sign
languages. However, the scarcity in quantity and quality of datasets is one of
the main challenges limiting the exploration of novel approaches that could
lead to significant advancements in this research area. Thus, this paper
contributes by introducing two new datasets for the American Sign Language: the
first is composed of the three-dimensional representation of the signers and,
the second, by an unprecedented linguistics-based representation containing a
set of phonological attributes of the signs.
",regular,0,,,
2109.03891,"SORNet: Spatial Object-Centric Representations for Sequential
  Manipulation","  Sequential manipulation tasks require a robot to perceive the state of an
environment and plan a sequence of actions leading to a desired goal state. In
such tasks, the ability to reason about spatial relations among object entities
from raw sensor inputs is crucial in order to determine when a task has been
completed and which actions can be executed. In this work, we propose SORNet
(Spatial Object-Centric Representation Network), a framework for learning
object-centric representations from RGB images conditioned on a set of object
queries, represented as image patches called canonical object views. With only
a single canonical view per object and no annotation, SORNet generalizes
zero-shot to object entities whose shape and texture are both unseen during
training. We evaluate SORNet on various spatial reasoning tasks such as spatial
relation classification and relative direction regression in complex tabletop
manipulation scenarios and show that SORNet significantly outperforms baselines
including state-of-the-art representation learning techniques. We also
demonstrate the application of the representation learned by SORNet on
visual-servoing and task planning for sequential manipulation on a real robot.
",regular,0,,,
2101.09528,"Hard satisfiable formulas for DPLL algorithms using heuristics with
  small memory","  DPLL algorithm for solving the Boolean satisfiability problem (SAT) can be
represented in the form of a procedure that, using heuristics $A$ and $B$,
select the variable $x$ from the input formula $\varphi$ and the value $b$ and
runs recursively on the formulas $\varphi[x := b]$ and $\varphi[x := 1 - b]$.
Exponential lower bounds on the running time of DPLL algorithms on
unsatisfiable formulas follow from the lower bounds for tree-like resolution
proofs. Lower bounds on satisfiable formulas are also known for some classes of
DPLL algorithms such as ""myopic"" and ""drunken"" algorithms.
  All lower bounds are made for the classes of DPLL algorithms that limit
heuristics access to the formula. In this paper we consider DPLL algorithms
with heuristics that have unlimited access to the formula but use small memory.
We show that for any pair of heuristics with small memory there exists a family
of satisfiable formulas $\Phi_n$ such that a DPLL algorithm that uses these
heuristics runs in exponential time on the formulas $\Phi_n$.
",regular,0,,,
2110.03276,"Inferring Substitutable and Complementary Products with Knowledge-Aware
  Path Reasoning based on Dynamic Policy Network","  Inferring the substitutable and complementary products for a given product is
an essential and fundamental concern for the recommender system. To achieve
this, existing approaches take advantage of the knowledge graphs to learn more
evidences for inference, whereas they often suffer from invalid reasoning for
lack of elegant decision making strategies. Therefore, we propose a novel
Knowledge-Aware Path Reasoning (KAPR) model which leverages the dynamic policy
network to make explicit reasoning over knowledge graphs, for inferring the
substitutable and complementary relationships. Our contributions can be
highlighted as three aspects. Firstly, we model this inference scenario as a
Markov Decision Process in order to accomplish a knowledge-aware path reasoning
over knowledge graphs. Secondly,we integrate both structured and unstructured
knowledge to provide adequate evidences for making accurate decision-making.
Thirdly, we evaluate our model on a series of real-world datasets, achieving
competitive performance compared with state-of-the-art approaches. Our code is
released on https://gitee.com/yangzijing flower/kapr/tree/master.
",regular,0,,,
2409.1151,Unidirectional Human-Robot-Human Physical Interaction for Gait Training,"  This work presents a novel rehabilitation framework designed for a therapist,
wearing an inertial measurement unit (IMU) suit, to virtually interact with a
lower-limb exoskeleton worn by a patient with motor impairments. This framework
aims to harmonize the skills and knowledge of the therapist with the
capabilities of the exoskeleton. The therapist can guide the patient's
movements by moving their own joints and making real-time adjustments to meet
the patient's needs, while reducing the physical effort of the therapist. This
eliminates the need for a predefined trajectory for the patient to follow, as
in conventional robotic gait training. For the virtual interaction medium
between the therapist and patient, we propose an impedance profile that is
stiff at low frequencies and less stiff at high frequencies, that can be
tailored to individual patient needs and different stages of rehabilitation.
The desired interaction torque from this medium is commanded to a
whole-exoskeleton closed-loop compensation controller. The proposed virtual
interaction framework was evaluated with a pair of unimpaired individuals in
different teacher-student gait training exercises. Results show the proposed
interaction control effectively transmits haptic cues, informing future
applications in rehabilitation scenarios.
",regular,0,,,
2206.02796,Mixed Graph Contrastive Network for Semi-Supervised Node Classification,"  Graph Neural Networks (GNNs) have achieved promising performance in
semi-supervised node classification in recent years. However, the problem of
insufficient supervision, together with representation collapse, largely limits
the performance of the GNNs in this field. To alleviate the collapse of node
representations in semi-supervised scenario, we propose a novel graph
contrastive learning method, termed Mixed Graph Contrastive Network (MGCN). In
our method, we improve the discriminative capability of the latent feature by
enlarging the margin of decision boundaries and improving the cross-view
consistency of the latent representation. Specifically, we first adopt an
interpolation-based strategy to conduct data augmentation in the latent space
and then force the prediction model to change linearly between samples. Second,
we enable the learned network to tell apart samples across two
interpolation-perturbed views through forcing the correlation matrix across
views to approximate an identity matrix. By combining the two settings, we
extract rich supervision information from both the abundant unlabeled nodes and
the rare yet valuable labeled nodes for discriminative representation learning.
Extensive experimental results on six datasets demonstrate the effectiveness
and the generality of MGCN compared to the existing state-of-the-art methods.
",regular,0,,,
2207.07212,"Attention, Filling in The Gaps for Generalization in Routing Problems","  Machine Learning (ML) methods have become a useful tool for tackling vehicle
routing problems, either in combination with popular heuristics or as
standalone models. However, current methods suffer from poor generalization
when tackling problems of different sizes or different distributions. As a
result, ML in vehicle routing has witnessed an expansion phase with new
methodologies being created for particular problem instances that become
infeasible at larger problem sizes.
  This paper aims at encouraging the consolidation of the field through
understanding and improving current existing models, namely the attention model
by Kool et al. We identify two discrepancy categories for VRP generalization.
The first is based on the differences that are inherent to the problems
themselves, and the second relates to architectural weaknesses that limit the
model's ability to generalize. Our contribution becomes threefold: We first
target model discrepancies by adapting the Kool et al. method and its loss
function for Sparse Dynamic Attention based on the alpha-entmax activation. We
then target inherent differences through the use of a mixed instance training
method that has been shown to outperform single instance training in certain
scenarios. Finally, we introduce a framework for inference level data
augmentation that improves performance by leveraging the model's lack of
invariance to rotation and dilation changes.
",regular,0,,,
2109.08569,"Mitigating Data Scarceness through Data Synthesis, Augmentation and
  Curriculum for Abstractive Summarization","  This paper explores three simple data manipulation techniques (synthesis,
augmentation, curriculum) for improving abstractive summarization models
without the need for any additional data. We introduce a method of data
synthesis with paraphrasing, a data augmentation technique with sample mixing,
and curriculum learning with two new difficulty metrics based on specificity
and abstractiveness. We conduct experiments to show that these three techniques
can help improve abstractive summarization across two summarization models and
two different small datasets. Furthermore, we show that these techniques can
improve performance when applied in isolation and when combined.
",regular,0,,,
2305.08116,"The Structure and Dynamics of Knowledge Graphs, with Superficiality","  Large knowledge graphs combine human knowledge garnered from projects ranging
from academia and institutions to enterprises and crowdsourcing. Within such
graphs, each relationship between two nodes represents a basic fact involving
these two entities. The diversity of the semantics of relationships constitutes
the richness of knowledge graphs, leading to the emergence of singular
topologies, sometimes chaotic in appearance. However, this complex
characteristic can be modeled in a simple way by introducing the concept of
superficiality, which controls the overlap between relationships whose facts
are generated independently. Superficiality also regulates the balance of the
global distribution of knowledge by determining the proportion of misdescribed
entities. This is the first model for the structure and dynamics of knowledge
graphs. It leads to a better understanding of formal knowledge acquisition and
organization.
",regular,0,,,
2305.03859,"Open problems in causal structure learning: A case study of COVID-19 in
  the UK","  Causal machine learning (ML) algorithms recover graphical structures that
tell us something about cause-and-effect relationships. The causal
representation praovided by these algorithms enables transparency and
explainability, which is necessary for decision making in critical real-world
problems. Yet, causal ML has had limited impact in practice compared to
associational ML. This paper investigates the challenges of causal ML with
application to COVID-19 UK pandemic data. We collate data from various public
sources and investigate what the various structure learning algorithms learn
from these data. We explore the impact of different data formats on algorithms
spanning different classes of learning, and assess the results produced by each
algorithm, and groups of algorithms, in terms of graphical structure, model
dimensionality, sensitivity analysis, confounding variables, predictive and
interventional inference. We use these results to highlight open problems in
causal structure learning and directions for future research. To facilitate
future work, we make all graphs, models, data sets, and source code publicly
available online.
",regular,0,,,
2402.10639,"Generalizability of Mixture of Domain-Specific Adapters from the Lens of
  Signed Weight Directions and its Application to Effective Model Pruning","  Several parameter-efficient fine-tuning methods based on adapters have been
proposed as a streamlined approach to incorporate not only a single specialized
knowledge into existing Pre-Trained Language Models (PLMs) but also multiple of
them at once. Recent works such as AdapterSoup propose to mix not all but only
a selective sub-set of domain-specific adapters during inference via model
weight averaging to optimize performance on novel, unseen domains with
excellent computational efficiency. However, the essential generalizability of
this emerging weight-space adapter mixing mechanism on unseen, in-domain
examples remains unexplored. Thus, in this study, we conduct a comprehensive
analysis to elucidate the generalizability of domain-specific adapter mixtures
in in-domain evaluation. We also provide investigations into the inner workings
of the mixture of domain-specific adapters by analyzing their weight signs,
yielding critical analysis on the negative correlation between their fraction
of weight sign difference and their mixtures' generalizability. All source code
will be published.
",regular,0,,,
2204.08584,A Region-Based Deep Learning Approach to Automated Retail Checkout,"  Automating the product checkout process at conventional retail stores is a
task poised to have large impacts on society generally speaking. Towards this
end, reliable deep learning models that enable automated product counting for
fast customer checkout can make this goal a reality. In this work, we propose a
novel, region-based deep learning approach to automate product counting using a
customized YOLOv5 object detection pipeline and the DeepSORT algorithm. Our
results on challenging, real-world test videos demonstrate that our method can
generalize its predictions to a sufficient level of accuracy and with a fast
enough runtime to warrant deployment to real-world commercial settings. Our
proposed method won 4th place in the 2022 AI City Challenge, Track 4, with an
F1 score of 0.4400 on experimental validation data.
",regular,0,,,
2404.05563,"Predefined Software Environment Runtimes As A Measure For
  Reproducibility","  As part of Mathematical Research Data Initiative (MaRDI), we have developed a
way to preserve a software package into an easy to deploy and use sandbox
environment we call a ""runtime"", via a program we developed called MaPS : MaRDI
Packaging System. The program relies on Linux user namespaces to isolate a
library environment from the host system, making the sandboxed software
reproducible on other systems, with minimal effort. Moreover an overlay
filesystem makes local edits persistent. This project will aid reproducibility
efforts of research papers: both mathematical and from other disciplines. As a
proof of concept, we provide runtimes for the OSCAR Computer Algebra System,
polymake software for research in polyhedral geometry, and VIBRANT Virus
Identification By iteRative ANnoTation. The software is in a prerelease state:
the interface for creating, deploying, and executing runtimes is final, and an
interface for easily publishing runtimes is under active development. We thus
propose publishing predefined, distributable software environment runtimes
along with research papers in an effort to make research with software based
results reproducible.
",regular,0,,,
2206.03879,Reconfiguration of Non-crossing Spanning Trees,"  For a set $P$ of $n$ points in the plane in general position, a non-crossing
spanning tree is a spanning tree of the points where every edge is a
straight-line segment between a pair of points and no two edges intersect
except at a common endpoint. We study the problem of reconfiguring one
non-crossing spanning tree of $P$ to another using a sequence of flips where
each flip removes one edge and adds one new edge so that the result is again a
non-crossing spanning tree of $P$. There is a known upper bound of $2n-4$ flips
[Avis and Fukuda, 1996] and a lower bound of $1.5n - 5$ flips. We give a
reconfiguration algorithm that uses at most $2n-3$ flips but reduces that to
$1.5n-2$ flips when one tree is a path and either: the points are in convex
position; or the path is monotone in some direction. For points in convex
position, we prove an upper bound of $2d - \Omega(\log d)$ where $d$ is half
the size of the symmetric difference between the trees. We also examine whether
the happy edges (those common to the initial and final trees) need to flip, and
we find exact minimum flip distances for small point sets using exhaustive
search.
",regular,0,,,
2201.00301,"Investigating Cargo Loss in Logistics Systems using Low-Cost Impact
  Sensors","  Cargo loss/damage is a very common problem faced by almost any business with
a supply chain arm, leading to major problems like revenue loss and reputation
tarnishing. This problem can be solved by employing an asset and impact
tracking solution. This would be more practical and effective for high-cost
cargo in comparison to low-cost cargo due to the high costs associated with the
sensors and overall solution. In this study, we propose a low-cost solution
architecture that is scalable, user-friendly, easy to adopt and is viable for a
large range of cargo and logistics systems. Taking inspiration from a real-life
use case we solved for a client, we also provide insights into the architecture
as well as the design decisions that make this a reality.
",regular,0,,,
2303.02449,"Exploit CAM by itself: Complementary Learning System for Weakly
  Supervised Semantic Segmentation","  Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has
long been suffering from fragmentary object regions led by Class Activation Map
(CAM), which is incapable of generating fine-grained masks for semantic
segmentation. To guide CAM to find more non-discriminating object patterns,
this paper turns to an interesting working mechanism in agent learning named
Complementary Learning System (CLS). CLS holds that the neocortex builds a
sensation of general knowledge, while the hippocampus specially learns specific
details, completing the learned patterns. Motivated by this simple but
effective learning pattern, we propose a General-Specific Learning Mechanism
(GSLM) to explicitly drive a coarse-grained CAM to a fine-grained pseudo mask.
Specifically, GSLM develops a General Learning Module (GLM) and a Specific
Learning Module (SLM). The GLM is trained with image-level supervision to
extract coarse and general localization representations from CAM. Based on the
general knowledge in the GLM, the SLM progressively exploits the specific
spatial knowledge from the localization representations, expanding the CAM in
an explicit way. To this end, we propose the Seed Reactivation to help SLM
reactivate non-discriminating regions by setting a boundary for activation
values, which successively identifies more regions of CAM. Without extra
refinement processes, our method is able to achieve breakthrough improvements
for CAM of over 20.0% mIoU on PASCAL VOC 2012 and 10.0% mIoU on MS COCO 2014
datasets, representing a new state-of-the-art among existing WSSS methods.
",regular,0,,,
2404.19542,"One-Stage Open-Vocabulary Temporal Action Detection Leveraging Temporal
  Multi-scale and Action Label Features","  Open-vocabulary Temporal Action Detection (Open-vocab TAD) is an advanced
video analysis approach that expands Closed-vocabulary Temporal Action
Detection (Closed-vocab TAD) capabilities. Closed-vocab TAD is typically
confined to localizing and classifying actions based on a predefined set of
categories. In contrast, Open-vocab TAD goes further and is not limited to
these predefined categories. This is particularly useful in real-world
scenarios where the variety of actions in videos can be vast and not always
predictable. The prevalent methods in Open-vocab TAD typically employ a 2-stage
approach, which involves generating action proposals and then identifying those
actions. However, errors made during the first stage can adversely affect the
subsequent action identification accuracy. Additionally, existing studies face
challenges in handling actions of different durations owing to the use of fixed
temporal processing methods. Therefore, we propose a 1-stage approach
consisting of two primary modules: Multi-scale Video Analysis (MVA) and
Video-Text Alignment (VTA). The MVA module captures actions at varying temporal
resolutions, overcoming the challenge of detecting actions with diverse
durations. The VTA module leverages the synergy between visual and textual
modalities to precisely align video segments with corresponding action labels,
a critical step for accurate action identification in Open-vocab scenarios.
Evaluations on widely recognized datasets THUMOS14 and ActivityNet-1.3, showed
that the proposed method achieved superior results compared to the other
methods in both Open-vocab and Closed-vocab settings. This serves as a strong
demonstration of the effectiveness of the proposed method in the TAD task.
",regular,0,,,
2110.0517,"Domain Adaptive Semantic Segmentation via Regional Contrastive
  Consistency Regularization","  Unsupervised domain adaptation (UDA) for semantic segmentation has been
well-studied in recent years. However, most existing works largely neglect the
local regional consistency across different domains and are less robust to
changes in outdoor environments. In this paper, we propose a novel and fully
end-to-end trainable approach, called regional contrastive consistency
regularization (RCCR) for domain adaptive semantic segmentation. Our core idea
is to pull the similar regional features extracted from the same location of
different images, i.e., the original image and augmented image, to be closer,
and meanwhile push the features from the different locations of the two images
to be separated. We innovatively propose a region-wise contrastive loss with
two sampling strategies to realize effective regional consistency. Besides, we
present momentum projection heads, where the teacher projection head is the
exponential moving average of the student. Finally, a memory bank mechanism is
designed to learn more robust and stable region-wise features under varying
environments. Extensive experiments on two common UDA benchmarks, i.e., GTAV to
Cityscapes and SYNTHIA to Cityscapes, demonstrate that our approach outperforms
the state-of-the-art methods.
",regular,0,,,