arxiv_id,title,abstract,classified_type,MARIA_ANNOTATION
2408.01934,A Survey and Evaluation of Adversarial Attacks for Object Detection,"  Deep learning models excel in various computer vision tasks but are
susceptible to adversarial examples-subtle perturbations in input data that
lead to incorrect predictions. This vulnerability poses significant risks in
safety-critical applications such as autonomous vehicles, security
surveillance, and aircraft health monitoring. While numerous surveys focus on
adversarial attacks in image classification, the literature on such attacks in
object detection is limited. This paper offers a comprehensive taxonomy of
adversarial attacks specific to object detection, reviews existing adversarial
robustness evaluation metrics, and systematically assesses open-source attack
methods and model robustness. Key observations are provided to enhance the
understanding of attack effectiveness and corresponding countermeasures.
Additionally, we identify crucial research challenges to guide future efforts
in securing automated object detection systems.
",review,1
2109.10572,"Realism of Simulation Models in Serious Gaming: Two case studies from
  Urban Water Management Higher Education","  For games used in educational contexts, realism, i.e., the degree of
congruence between the simulation models used in the games and the real-world
systems represented, is an important characteristic for achieving learning
goals well. However, in the past, the realism of especially entertainment games
has often been identified as insufficient. Thus, this study is investigating
the degree of realism provided by current games. To this purpose, two games in
the domain urban water management, a subdomain of environmental engineering
(EE), are examined. One is ANAWAK, a web-based serious game on water management
and climate change. For ANAWAK, an analysis of the simulation model is
conducted. Second, the simulation model of the entertainment game Cities:
Skylines (CS) is analyzed. In addition, a survey among CS players (N=61) is
conducted. Thereby, different degrees of realism in various EE subdomains are
revealed. All in all, there are still considerable deficits regarding the
degree of realism in the CS simulation model. However, modding as a means of
achieving more realistic simulation models is more widely supported than in the
past.
",review,0
2308.13821,"A Survey of Imbalanced Learning on Graphs: Problems, Techniques, and
  Future Directions","  Graphs represent interconnected structures prevalent in a myriad of
real-world scenarios. Effective graph analytics, such as graph learning
methods, enables users to gain profound insights from graph data, underpinning
various tasks including node classification and link prediction. However, these
methods often suffer from data imbalance, a common issue in graph data where
certain segments possess abundant data while others are scarce, thereby leading
to biased learning outcomes. This necessitates the emerging field of imbalanced
learning on graphs, which aims to correct these data distribution skews for
more accurate and representative learning outcomes. In this survey, we embark
on a comprehensive review of the literature on imbalanced learning on graphs.
We begin by providing a definitive understanding of the concept and related
terminologies, establishing a strong foundational understanding for readers.
Following this, we propose two comprehensive taxonomies: (1) the problem
taxonomy, which describes the forms of imbalance we consider, the associated
tasks, and potential solutions; (2) the technique taxonomy, which details key
strategies for addressing these imbalances, and aids readers in their method
selection process. Finally, we suggest prospective future directions for both
problems and techniques within the sphere of imbalanced learning on graphs,
fostering further innovation in this critical area.
",review,1
2309.07689,"Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated
  Text","  While recent advancements in the capabilities and widespread accessibility of
generative language models, such as ChatGPT (OpenAI, 2022), have brought about
various benefits by generating fluent human-like text, the task of
distinguishing between human- and large language model (LLM) generated text has
emerged as a crucial problem. These models can potentially deceive by
generating artificial text that appears to be human-generated. This issue is
particularly significant in domains such as law, education, and science, where
ensuring the integrity of text is of the utmost importance. This survey
provides an overview of the current approaches employed to differentiate
between texts generated by humans and ChatGPT. We present an account of the
different datasets constructed for detecting ChatGPT-generated text, the
various methods utilized, what qualitative analyses into the characteristics of
human versus ChatGPT-generated text have been performed, and finally, summarize
our findings into general insights
",review,1
2406.10948,"Incorporating uncertainty quantification into travel mode choice
  modeling: a Bayesian neural network (BNN) approach and an uncertainty-guided
  active survey framework","  Existing deep learning approaches for travel mode choice modeling fail to
inform modelers about their prediction uncertainty. Even when facing scenarios
that are out of the distribution of training data, which implies high
prediction uncertainty, these approaches still provide deterministic answers,
potentially leading to misguidance. To address this limitation, this study
introduces the concept of uncertainty from the field of explainable artificial
intelligence into travel mode choice modeling. We propose a Bayesian neural
network-based travel mode prediction model (BTMP) that quantifies the
uncertainty of travel mode predictions, enabling the model itself to ""know"" and
""tell"" what it doesn't know. With BTMP, we further propose an
uncertainty-guided active survey framework, which dynamically formulates survey
questions representing travel mode choice scenarios with high prediction
uncertainty. Through iterative collection of responses to these dynamically
tailored survey questions, BTMP is iteratively trained to achieve the desired
accuracy faster with fewer questions, thereby reducing survey costs.
Experimental validation using synthetic datasets confirms the effectiveness of
BTMP in quantifying prediction uncertainty. Furthermore, experiments, utilizing
both synthetic and real-world data, demonstrate that the BTMP model, trained
with the uncertainty-guided active survey framework, requires 20% to 50% fewer
survey responses to match the performance of the model trained on randomly
collected survey data. Overall, the proposed BTMP model and active survey
framework innovatively incorporate uncertainty quantification into travel mode
choice modeling, providing model users with essential insights into prediction
reliability while optimizing data collection for deep learning model training
in a cost-efficient manner.
",review,0
2108.12673,"Tracing app technology: An ethical review in the COVID-19 era and
  directions for post-COVID-19","  We conducted a systematic literature review on the ethical considerations of
the use of contact tracing app technology, which was extensively implemented
during the COVID-19 pandemic. The rapid and extensive use of this technology
during the COVID-19 pandemic, while benefiting the public well-being by
providing information about people's mobility and movements to control the
spread of the virus, raised several ethical concerns for the post-COVID-19 era.
To investigate these concerns for the post-pandemic situation and provide
direction for future events, we analyzed the current ethical frameworks,
research, and case studies about the ethical usage of tracing app technology.
The results suggest there are seven essential ethical considerations, namely
privacy, security, acceptability, government surveillance, transparency,
justice, and voluntariness in the ethical use of contact tracing technology. In
this paper, we explain and discuss these considerations and how they are needed
for the ethical usage of this technology. The findings also highlight the
importance of developing integrated guidelines and frameworks for
implementation of such technology in the post-COVID-19 world.
",review,1
2404.1833699999997,Additive Spanner Lower Bounds with Optimal Inner Graph Structure,"  We construct $n$-node graphs on which any $O(n)$-size spanner has additive
error at least $+\Omega(n^{3/17})$, improving on the previous best lower bound
of $\Omega(n^{1/7})$ [Bodwin-Hoppenworth FOCS '22]. Our construction completes
the first two steps of a particular three-step research program, introduced in
prior work and overviewed here, aimed at producing tight bounds for the problem
by aligning aspects of the upper and lower bound constructions. More
specifically, we develop techniques that enable the use of inner graphs in the
lower bound framework whose technical properties are provably tight with the
corresponding assumptions made in the upper bounds. As an additional
application of our techniques, we improve the corresponding lower bound for
$O(n)$-size additive emulators to $+\Omega(n^{1/14})$.
",review,0
2302.10856,Overview of the TREC 2021 Fair Ranking Track,"  The TREC Fair Ranking Track aims to provide a platform for participants to
develop and evaluate novel retrieval algorithms that can provide a fair
exposure to a mixture of demographics or attributes, such as ethnicity, that
are represented by relevant documents in response to a search query. For
example, particular demographics or attributes can be represented by the
documents' topical content or authors. The 2021 Fair Ranking Track adopted a
resource allocation task. The task focused on supporting Wikipedia editors who
are looking to improve the encyclopedia's coverage of topics under the purview
of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for
Wikipedia documents that are in need of editing to improve the quality of the
article. The 2021 Fair Ranking track aimed to ensure that documents that are
about, or somehow represent, certain protected characteristics receive a fair
exposure to the Wikipedia editors, so that the documents have an fair
opportunity of being improved and, therefore, be well-represented in Wikipedia.
The under-representation of particular protected characteristics in Wikipedia
can result in systematic biases that can have a negative human, social, and
economic impact, particularly for disadvantaged or protected societal groups.
",review,1
2112.06522,Anatomizing Bias in Facial Analysis,"  Existing facial analysis systems have been shown to yield biased results
against certain demographic subgroups. Due to its impact on society, it has
become imperative to ensure that these systems do not discriminate based on
gender, identity, or skin tone of individuals. This has led to research in the
identification and mitigation of bias in AI systems. In this paper, we
encapsulate bias detection/estimation and mitigation algorithms for facial
analysis. Our main contributions include a systematic review of algorithms
proposed for understanding bias, along with a taxonomy and extensive overview
of existing bias mitigation algorithms. We also discuss open challenges in the
field of biased facial analysis.
",review,1
2405.1181699999997,Systematic Review on Healthcare Systems Engineering utilizing ChatGPT,"  This paper presents an analytical framework for conducting academic reviews
in the field of Healthcare Systems Engineering, employing ChatGPT, a
state-of-the-art tool among recent language models. We utilized 9,809 abstract
paragraphs from conference presentations to systematically review the field.
The framework comprises distinct analytical processes, each employing tailored
prompts and the systematic use of the ChatGPT API. Through this framework, we
organized the target field into 11 topic categories and conducted a
comprehensive analysis covering quantitative yearly trends and detailed
sub-categories. This effort explores the potential for leveraging ChatGPT to
alleviate the burden of academic reviews. Furthermore, it provides valuable
insights into the dynamic landscape of Healthcare Systems Engineering research.
",review,1
2202.08187,"Differential Privacy and Fairness in Decisions and Learning Tasks: A
  Survey","  This paper surveys recent work in the intersection of differential privacy
(DP) and fairness. It reviews the conditions under which privacy and fairness
may have aligned or contrasting goals, analyzes how and why DP may exacerbate
bias and unfairness in decision problems and learning tasks, and describes
available mitigation measures for the fairness issues arising in DP systems.
The survey provides a unified understanding of the main challenges and
potential risks arising when deploying privacy-preserving machine-learning or
decisions-making tasks under a fairness lens.
",review,1
2307.02332,"Co-creating a Transdisciplinary Map of Technology-mediated Harms, Risks
  and Vulnerabilities: Challenges, Ambivalences and Opportunities","  The phrase ""online harms"" has emerged in recent years out of a growing
political willingness to address the ethical and social issues associated with
the use of the Internet and digital technology at large. The broad landscape
that surrounds online harms gathers a multitude of disciplinary, sectoral and
organizational efforts while raising myriad challenges and opportunities for
the crossing entrenched boundaries. In this paper we draw lessons from a
journey of co-creating a transdisciplinary knowledge infrastructure within a
large research initiative animated by the online harms agenda. We begin with a
reflection of the implications of mapping, taxonomizing and constructing
knowledge infrastructures and a brief review of how online harm and adjacent
themes have been theorized and classified in the literature to date. Grounded
on our own experience of co-creating a map of online harms, we then argue that
the map -- and the process of mapping -- perform three mutually constitutive
functions, acting simultaneously as method, medium and provocation. We draw
lessons from how an open-ended approach to mapping, despite not guaranteeing
consensus, can foster productive debate and collaboration in ethically and
politically fraught areas of research. We end with a call for CSCW research to
surface and engage with the multiple temporalities, social lives and political
sensibilities of knowledge infrastructures.
",review,1
2408.06304,"Control-Flow Attestation: Concepts, Solutions, and Open Challenges","  Control-flow attestation unifies the worlds of control-flow integrity and
platform attestation by measuring and reporting a target's run-time behaviour
to a verifier. Trust assurances in the target are provided by testing whether
its execution follows an authorised control-flow path. The problem has been
explored in various settings, such as assessing the trustworthiness of
cyber-physical systems, Internet of Things devices, cloud platforms, and many
others. Despite a significant number of proposals being made in recent years,
the area remains fragmented, addressing different adversarial behaviours,
verification paradigms, and deployment challenges. In this paper, we present
the first survey of control-flow attestation, examining the core ideas and
solutions in state-of-the-art schemes. In total, we survey over 30 papers
published between 2016-2024, consolidate and compare their key features, and
pose several challenges and recommendations for future research in the area.
",review,1
2204.02921,A survey on recently proposed activation functions for Deep Learning,"  Artificial neural networks (ANN), typically referred to as neural networks,
are a class of Machine Learning algorithms and have achieved widespread
success, having been inspired by the biological structure of the human brain.
Neural networks are inherently powerful due to their ability to learn complex
function approximations from data. This generalization ability has been able to
impact multidisciplinary areas involving image recognition, speech recognition,
natural language processing, and others. Activation functions are a crucial
sub-component of neural networks. They define the output of a node in the
network given a set of inputs. This survey discusses the main concepts of
activation functions in neural networks, including; a brief introduction to
deep neural networks, a summary of what are activation functions and how they
are used in neural networks, their most common properties, the different types
of activation functions, some of the challenges, limitations, and alternative
solutions faced by activation functions, concluding with the final remarks.
",review,1
2310.1968699999998,Sentiment Analysis in Digital Spaces: An Overview of Reviews,"  Sentiment analysis (SA) is commonly applied to digital textual data,
revealing insight into opinions and feelings. Many systematic reviews have
summarized existing work, but often overlook discussions of validity and
scientific practices. Here, we present an overview of reviews, synthesizing 38
systematic reviews, containing 2,275 primary studies. We devise a bespoke
quality assessment framework designed to assess the rigor and quality of
systematic review methodologies and reporting standards. Our findings show
diverse applications and methods, limited reporting rigor, and challenges over
time. We discuss how future research and practitioners can address these issues
and highlight their importance across numerous applications.
",review,1
2407.18597,Reinforcement Learning for Sustainable Energy: A Survey,"  The transition to sustainable energy is a key challenge of our time,
requiring modifications in the entire pipeline of energy production, storage,
transmission, and consumption. At every stage, new sequential decision-making
challenges emerge, ranging from the operation of wind farms to the management
of electrical grids or the scheduling of electric vehicle charging stations.
All such problems are well suited for reinforcement learning, the branch of
machine learning that learns behavior from data. Therefore, numerous studies
have explored the use of reinforcement learning for sustainable energy. This
paper surveys this literature with the intention of bridging both the
underlying research communities: energy and machine learning. After a brief
introduction of both fields, we systematically list relevant sustainability
challenges, how they can be modeled as a reinforcement learning problem, and
what solution approaches currently exist in the literature. Afterwards, we zoom
out and identify overarching reinforcement learning themes that appear
throughout sustainability, such as multi-agent, offline, and safe reinforcement
learning. Lastly, we also cover standardization of environments, which will be
crucial for connecting both research fields, and highlight potential directions
for future work. In summary, this survey provides an extensive overview of
reinforcement learning methods for sustainable energy, which may play a vital
role in the energy transition.
",review,1
2104.11906,"A Review on C3I Systems' Security: Vulnerabilities, Attacks, and
  Countermeasures","  Command, Control, Communication, and Intelligence (C3I) systems are
increasingly used in critical civil and military domains for achieving
information superiority, operational efficacy, and greater situational
awareness. Unlike traditional systems facing widespread cyber-attacks, the
sensitive nature of C3I tactical operations make their cybersecurity a critical
concern. For instance, tampering or intercepting confidential information in
military battlefields not only damages C3I operations, but also causes
irreversible consequences such as loss of human lives and mission failures.
Therefore, C3I systems have become a focal point for cyber adversaries.
Moreover, technological advancements and modernization of C3I systems have
significantly increased the potential risk of cyber-attacks on C3I systems.
Consequently, cyber adversaries leverage highly sophisticated attack vectors to
exploit security vulnerabilities in C3I systems. Despite the burgeoning
significance of cybersecurity for C3I systems, the existing literature lacks a
comprehensive review to systematize the body of knowledge on C3I systems'
security. Therefore, in this paper, we have gathered, analyzed, and synthesized
the state-of-the-art on the cybersecurity of C3I systems. In particular, this
paper has identified security vulnerabilities, attack vectors, and
countermeasures/defenses for C3I systems. Furthermore, our survey has enabled
us to: (i) propose a taxonomy for security vulnerabilities, attack vectors and
countermeasures; (ii) interrelate attack vectors with security vulnerabilities
and countermeasures; and (iii) propose future research directions for advancing
the state-of-the-art on the cybersecurity of C3I systems.
",review,1
2203.00483,"A Survey on How Test Flakiness Affects Developers and What Support They
  Need To Address It","  Non-deterministically passing and failing test cases, so-called flaky tests,
have recently become a focus area of software engineering research. While this
research focus has been met with some enthusiastic endorsement from industry,
prior work nevertheless mostly studied flakiness using a code-centric approach
by mining software repositories. What data extracted from software repositories
cannot tell us, however, is how developers perceive flakiness: How prevalent is
test flakiness in developers' daily routine, how does it affect them, and most
importantly: What do they want us researchers to do about it? To answer these
questions, we surveyed 335 professional software developers and testers in
different domains. The survey respondents confirm that flaky tests are a common
and serious problem, thus reinforcing ongoing research on flaky test detection.
Developers are less worried about the computational costs caused by re-running
tests and more about the loss of trust in the test outcomes. Therefore, they
would like to have IDE plugins to detect flaky code as well as better
visualizations of the problem, particularly dashboards showing test outcomes
over time; they also wish for more training and information on flakiness. These
important aspects will require the attention of researchers as well as tool
developers.
",review,0
2307.1287399999997,"SoK: Design, Vulnerabilities, and Security Measures of Cryptocurrency
  Wallets","  The rapid growth of decentralized digital currencies, enabled by blockchain
technology, has ushered in a new era of peer-to-peer transactions,
revolutionizing the global economy. Cryptocurrency wallets, serving as crucial
endpoints for these transactions, have become increasingly prevalent. However,
the escalating value and usage of these wallets also expose them to significant
security risks and challenges. This research aims to comprehensively explore
the security aspects of cryptocurrency wallets. It provides a taxonomy of
wallet types, analyzes their design and implementation, identifies common
vulnerabilities and attacks, and discusses defense mechanisms and mitigation
strategies. The taxonomy covers custodial, non-custodial, hot, and cold
wallets, highlighting their unique characteristics and associated security
considerations. The security analysis scrutinizes the theoretical and practical
aspects of wallet design, while assessing the efficacy of existing security
measures and protocols. Notable wallet attacks, such as Binance, Mt. Gox are
examined to understand their causes and consequences. Furthermore, the paper
surveys defense mechanisms, transaction monitoring, evaluating their
effectiveness in mitigating threats.
",review,1
2206.0269,A Survey on Sentence Embedding Models Performance for Patent Analysis,"  Patent data is an important source of knowledge for innovation research,
while the technological similarity between pairs of patents is a key enabling
indicator for patent analysis. Recently researchers have been using patent
vector space models based on different NLP embeddings models to calculate the
technological similarity between pairs of patents to help better understand
innovations, patent landscaping, technology mapping, and patent quality
evaluation. More often than not, Text Embedding is a vital precursor to patent
analysis tasks. A pertinent question then arises: How should we measure and
evaluate the accuracy of these embeddings? To the best of our knowledge, there
is no comprehensive survey that builds a clear delineation of embedding models'
performance for calculating patent similarity indicators. Therefore, in this
study, we provide an overview of the accuracy of these algorithms based on
patent classification performance and propose a standard library and dataset
for assessing the accuracy of embeddings models based on PatentSBERTa approach.
In a detailed discussion, we report the performance of the top 3 algorithms at
section, class, and subclass levels. The results based on the first claim of
patents show that PatentSBERTa, Bert-for-patents, and TF-IDF Weighted Word
Embeddings have the best accuracy for computing sentence embeddings at the
subclass level. According to the first results, the performance of the models
in different classes varies, which shows researchers in patent analysis can
utilize the results of this study to choose the best proper model based on the
specific section of patent data they used.
",review,1
2211.13546,"Number Theoretic Transform and Its Applications in Lattice-based
  Cryptosystems: A Survey","  Number theoretic transform (NTT) is the most efficient method for multiplying
two polynomials of high degree with integer coefficients, due to its series of
advantages in terms of algorithm and implementation, and is consequently
widely-used and particularly fundamental in the practical implementations of
lattice-based cryptographic schemes. Especially, recent works have shown that
NTT can be utilized in those schemes without NTT-friendly rings, and can
outperform other multiplication algorithms. In this paper, we first review the
basic concepts of polynomial multiplication, convolution and NTT. Subsequently,
we systematically introduce basic radix-2 fast NTT algorithms in an algebraic
way via Chinese Remainder Theorem. And then, we elaborate recent advances about
the methods to weaken restrictions on parameter conditions of NTT. Furthermore,
we systematically introduce how to choose appropriate strategy of NTT
algorithms for the various given rings. Later, we introduce the applications of
NTT in the lattice-based cryptographic schemes of NIST post-quantum
cryptography standardization competition. Finally, we try to present some
possible future research directions.
",review,1
2405.19265,"AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight
  Tuning on Multi-source Data","  Open-source Large Language Models (LLMs) and their specialized variants,
particularly Code LLMs, have recently delivered impressive performance.
However, previous Code LLMs are typically fine-tuned on single-source data with
limited quality and diversity, which may insufficiently elicit the potential of
pre-trained Code LLMs. In this paper, we present AlchemistCoder, a series of
Code LLMs with enhanced code generation and generalization capabilities
fine-tuned on multi-source data. To achieve this, we pioneer to unveil inherent
conflicts among the various styles and qualities in multi-source code corpora
and introduce data-specific prompts with hindsight relabeling, termed
AlchemistPrompts, to harmonize different data sources and instruction-response
pairs. Additionally, we propose incorporating the data construction process
into the fine-tuning data as code comprehension tasks, including instruction
evolution, data filtering, and code review. Extensive experiments demonstrate
that AlchemistCoder holds a clear lead among all models of the same size
(6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B), showcasing
the efficacy of our method in refining instruction-following capabilities and
advancing the boundaries of code intelligence.
",review,0
2101.11775,Moral and Social Ramifications of Autonomous Vehicles,"  Autonomous Vehicles (AVs) raise important social and ethical concerns,
especially about accountability, dignity, and justice. We focus on the specific
concerns arising from how AV technology will affect the lives and livelihoods
of professional and semi-professional drivers. Whereas previous studies of such
concerns have focused on the opinions of experts, we seek to understand these
ethical and societal challenges from the perspectives of the drivers
themselves.
  To this end, we adopted a qualitative research methodology based on
semi-structured interviews. This is an established social science methodology
that helps understand the core concerns of stakeholders in depth by avoiding
the biases of superficial methods such as surveys.
  We find that whereas drivers agree with the experts that AVs will
significantly impact transportation systems, they are apprehensive about the
prospects for their livelihoods and dismiss the suggestions that driving jobs
are unsatisfying and their profession does not merit protection.
  By showing how drivers differ from the experts, our study has ramifications
beyond AVs to AI and other advanced technologies. Our findings suggest that
qualitative research applied to the relevant, especially disempowered,
stakeholders is essential to ensuring that new technologies are introduced
ethically.
",review,0
2212.07902,Five Facets of 6G: Research Challenges and Opportunities,"  Whilst the fifth-generation (5G) systems are being rolled out across the
globe, researchers have turned their attention to the exploration of radical
next-generation solutions. At this early evolutionary stage we survey five main
research facets of this field, namely {\em Facet~1: next-generation
architectures, spectrum and services, Facet~2: next-generation networking,
Facet~3: Internet of Things (IoT), Facet~4: wireless positioning and sensing,
as well as Facet~5: applications of deep learning in 6G networks.} In this
paper, we have provided a critical appraisal of the literature of promising
techniques ranging from the associated architectures, networking, applications
as well as designs. We have portrayed a plethora of heterogeneous architectures
relying on cooperative hybrid networks supported by diverse access and
transmission mechanisms. The vulnerabilities of these techniques are also
addressed and carefully considered for highlighting the most of promising
future research directions. Additionally, we have listed a rich suite of
learning-driven optimization techniques. We conclude by observing the
evolutionary paradigm-shift that has taken place from pure single-component
bandwidth-efficiency, power-efficiency or delay-optimization towards
multi-component designs, as exemplified by the twin-component ultra-reliable
low-latency mode of the 5G system. We advocate a further evolutionary step
towards multi-component Pareto optimization, which requires the exploration of
the entire Pareto front of all optiomal solutions, where none of the components
of the objective function may be improved without degrading at least one of the
other components.
",review,1
2401.14656,"Scientific Large Language Models: A Survey on Biological & Chemical
  Domains","  Large Language Models (LLMs) have emerged as a transformative power in
enhancing natural language comprehension, representing a significant stride
toward artificial general intelligence. The application of LLMs extends beyond
conventional linguistic boundaries, encompassing specialized linguistic systems
developed within various scientific disciplines. This growing interest has led
to the advent of scientific LLMs, a novel subclass specifically engineered for
facilitating scientific discovery. As a burgeoning area in the community of AI
for Science, scientific LLMs warrant comprehensive exploration. However, a
systematic and up-to-date survey introducing them is currently lacking. In this
paper, we endeavor to methodically delineate the concept of ""scientific
language"", whilst providing a thorough review of the latest advancements in
scientific LLMs. Given the expansive realm of scientific disciplines, our
analysis adopts a focused lens, concentrating on the biological and chemical
domains. This includes an in-depth examination of LLMs for textual knowledge,
small molecules, macromolecular proteins, genomic sequences, and their
combinations, analyzing them in terms of model architectures, capabilities,
datasets, and evaluation. Finally, we critically examine the prevailing
challenges and point out promising research directions along with the advances
of LLMs. By offering a comprehensive overview of technical developments in this
field, this survey aspires to be an invaluable resource for researchers
navigating the intricate landscape of scientific LLMs.
",review,1
2108.13176,"Maximum Expected Delay: A New Metric to Analyse the Performance of
  Asynchronous Quorum-based Protocols in Wireless Sensor Networks","  Energy management is a crucial challenge in wireless sensor networks. To
date, many techniques have been proposed to reduce energy consumption. Duty
cycle methods reduce the energy consumption of wireless sensor networks since
energy consumption declines in the sleep mode. Using quorum-based methods,
sensors can stay in the sleep mode and be awaken periodically to send and
receive data from adjacent nodes. In this paper, we review a subset of these
methods called asynchronous quorum-based methods, independent of
synchronization between nodes, and investigate their performances in different
metrics. Then, we propose a new metric to investigate the latency of adjacent
nodes in wireless sensor networks. Next, we study the performances of all
discussed methods using the proposed metric. Finally, we introduce the best and
worst methods based on different metrics.
",review,0
2205.0671899999998,dewolf: Improving Decompilation by leveraging User Surveys,"  Analyzing third-party software such as malware or firmware is a crucial task
for security analysts. Although various approaches for automatic analysis exist
and are the subject of ongoing research, analysts often have to resort to
manual static analysis to get a deep understanding of a given binary sample.
Since the source code of encountered samples is rarely available, analysts
regularly employ decompilers for easier and faster comprehension than analyzing
a binary's disassembly.
  In this paper, we introduce our decompilation approach dewolf. We developed a
variety of improvements over the previous academic state-of-the-art decompiler
and some novel algorithms to enhance readability and comprehension, focusing on
manual analysis. To evaluate our approach and to obtain a better insight into
the analysts' needs, we conducted three user surveys. The results indicate that
dewolf is suitable for malware comprehension and that its output quality
noticeably exceeds Ghidra and Hex-Rays in certain aspects. Furthermore, our
results imply that decompilers aiming at manual analysis should be highly
configurable to respect individual user preferences. Additionally, future
decompilers should not necessarily follow the unwritten rule to stick to the
code-structure dictated by the assembly in order to produce readable output. In
fact, the few cases where dewolf already cracks this rule lead to its results
considerably exceeding other decompilers. We publish a prototype implementation
of dewolf and all survey results on GitHub.
",review,0
2212.03283,"Status Quo Bias in Users Information Systems (IS) Adoption and
  Continuance Intentions: A Literature Review and Framework","  Information systems (IS) adoption and continuance intentions of users have a
dominant effect on digital transformation in organisations. However,
organisations undergoing digital transformation face substantial barriers due
to user resistance to IS implementations. Status quo bias (SQB) plays a vital
role in users decision-making regarding adopting new IS or continuing to use
existing IS. Despite recent research to validate the effects of SQB on user
resistance to IS implementations, how SQB affects the IS adoption and
continuance intentions of users remains poorly understood, making it harder to
develop ways of successfully dealing with it. To address the gap, we performed
a systematic literature review on SQB in IS research. Our proposed framework
incorporates the psychological phenomena promoting the status quo, SQB theory
constructs, levels of SQB influence, and factors reducing the user resistance
to IS implementations to enhance the understanding of IS adoption and
continuance intentions.
",review,1
2209.04376,Challenges of Implementing Agile Processes in Remote-First Companies,"  The trend of remote work, especially in the IT sector, has been on the rise
in recent years, and its popularity has especially increased since the COVID-19
pandemic. In addition to adopting remote work, companies also have been
migrating toward managing their projects using agile processes. Agile processes
promote small and continuous feedback loops powered by effective communication.
In this survey, we look to discover the challenges of implementing these
processes in a remote setting, specifically focusing on the impact on
communication. We examine the role communication plays in an agile setting and
look for ways to mitigate the risk remote environments impose on it. Lastly, we
present other miscellaneous challenges companies could experience that still
carry dangers but are less impactful overall to agile implementation.
",review,1
2406.09722,Cross-view geo-localization: a survey,"  Cross-view geo-localization has garnered notable attention in the realm of
computer vision, spurred by the widespread availability of copious geotagged
datasets and the advancements in machine learning techniques. This paper
provides a thorough survey of cutting-edge methodologies, techniques, and
associated challenges that are integral to this domain, with a focus on
feature-based and deep learning strategies. Feature-based methods capitalize on
unique features to establish correspondences across disparate viewpoints,
whereas deep learning-based methodologies deploy convolutional neural networks
to embed view-invariant attributes. This work also delineates the multifaceted
challenges encountered in cross-view geo-localization, such as variations in
viewpoints and illumination, the occurrence of occlusions, and it elucidates
innovative solutions that have been formulated to tackle these issues.
Furthermore, we delineate benchmark datasets and relevant evaluation metrics,
and also perform a comparative analysis of state-of-the-art techniques.
Finally, we conclude the paper with a discussion on prospective avenues for
future research and the burgeoning applications of cross-view geo-localization
in an intricately interconnected global landscape.
",review,1
2303.05205,"Real-time scheduling of renewable power systems through planning-based
  reinforcement learning","  The growing renewable energy sources have posed significant challenges to
traditional power scheduling. It is difficult for operators to obtain accurate
day-ahead forecasts of renewable generation, thereby requiring the future
scheduling system to make real-time scheduling decisions aligning with
ultra-short-term forecasts. Restricted by the computation speed, traditional
optimization-based methods can not solve this problem. Recent developments in
reinforcement learning (RL) have demonstrated the potential to solve this
challenge. However, the existing RL methods are inadequate in terms of
constraint complexity, algorithm performance, and environment fidelity. We are
the first to propose a systematic solution based on the state-of-the-art
reinforcement learning algorithm and the real power grid environment. The
proposed approach enables planning and finer time resolution adjustments of
power generators, including unit commitment and economic dispatch, thus
increasing the grid's ability to admit more renewable energy. The well-trained
scheduling agent significantly reduces renewable curtailment and load shedding,
which are issues arising from traditional scheduling's reliance on inaccurate
day-ahead forecasts. High-frequency control decisions exploit the existing
units' flexibility, reducing the power grid's dependence on hardware
transformations and saving investment and operating costs, as demonstrated in
experimental results. This research exhibits the potential of reinforcement
learning in promoting low-carbon and intelligent power systems and represents a
solid step toward sustainable electricity generation.
",regular,0
2305.0415399999997,Score: A Rule Engine for the Scone Knowledge Base System,"  We present Score, a rule engine designed and implemented for the Scone
knowledge base system. Scone is a knowledge base system designed for storing
and manipulating rich representations of general knowledge in symbolic form. It
represents knowledge in the form of nodes and links in a network structure, and
it can perform basic inference about the relationships between different
elements efficiently. On its own, Scone acts as a sort of ""smart memory"" that
can interface with other software systems. One area of improvement for Scone is
how useful it can be in supplying knowledge to an intelligent agent that can
use the knowledge to perform actions and update the knowledge base with its
observations.
  We augment the Scone system with a production rule engine that automatically
performs simple inference based on existing and newly-added structures in
Scone's knowledge base, potentially improving the capabilities of any planning
systems built on top of Scone. Production rule systems consist of ""if-then""
production rules that try to match their predicates to existing knowledge and
fire their actions when their predicates are satisfied. We propose two kinds of
production rules, if-added and if-needed rules, that differ in how they are
checked and fired to cover multiple use cases. We then implement methods to
efficiently check and fire these rules in a large knowledge base. The new rule
engine is not meant to be a complex stand-alone planner, so we discuss how it
fits into the context of Scone and future work on planning systems.
",regular,0
2307.03059,"Explorations in Subexponential non-associative non-commutative Linear
  Logic (extended version)","  In a previous work we introduced a non-associative non-commutative logic
extended by multimodalities, called subexponentials, licensing local
application of structural rules. Here, we further explore this system,
considering a classical one-sided multi-succedent classical version of the
system, following the exponential-free calculi of Buszkowski's and de Groote
and Lamarche's works, where the intuitionistic calculus is shown to embed
faithfully into the classical fragment.
",regular,0
2409.02383,"Reinforcement Learning for Wheeled Mobility on Vertically Challenging
  Terrain","  Off-road navigation on vertically challenging terrain, involving steep slopes
and rugged boulders, presents significant challenges for wheeled robots both at
the planning level to achieve smooth collision-free trajectories and at the
control level to avoid rolling over or getting stuck. Considering the complex
model of wheel-terrain interactions, we develop an end-to-end Reinforcement
Learning (RL) system for an autonomous vehicle to learn wheeled mobility
through simulated trial-and-error experiences. Using a custom-designed
simulator built on the Chrono multi-physics engine, our approach leverages
Proximal Policy Optimization (PPO) and a terrain difficulty curriculum to
refine a policy based on a reward function to encourage progress towards the
goal and penalize excessive roll and pitch angles, which circumvents the need
of complex and expensive kinodynamic modeling, planning, and control.
Additionally, we present experimental results in the simulator and deploy our
approach on a physical Verti-4-Wheeler (V4W) platform, demonstrating that RL
can equip conventional wheeled robots with previously unrealized potential of
navigating vertically challenging terrain.
",regular,0
2110.0584,"A bridge between features and evidence for binary attribute-driven
  perfect privacy","  Attribute-driven privacy aims to conceal a single user's attribute, contrary
to anonymisation that tries to hide the full identity of the user in some data.
When the attribute to protect from malicious inferences is binary, perfect
privacy requires the log-likelihood-ratio to be zero resulting in no
strength-of-evidence. This work presents an approach based on normalizing flow
that maps a feature vector into a latent space where the evidence, related to
the binary attribute, and an independent residual are disentangled. It can be
seen as a non-linear discriminant analysis where the mapping is invertible
allowing generation by mapping the latent variable back to the original space.
This framework allows to manipulate the log-likelihood-ratio of the data and
therefore allows to set it to zero for privacy. We show the applicability of
the approach on an attribute-driven privacy task where the sex information is
removed from speaker embeddings. Results on VoxCeleb2 dataset show the
efficiency of the method that outperforms in terms of privacy and utility our
previous experiments based on adversarial disentanglement.
",regular,0
2203.1519,3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow,"  Reconstructing 3D shape from a single 2D image is a challenging task, which
needs to estimate the detailed 3D structures based on the semantic attributes
from 2D image. So far, most of the previous methods still struggle to extract
semantic attributes for 3D reconstruction task. Since the semantic attributes
of a single image are usually implicit and entangled with each other, it is
still challenging to reconstruct 3D shape with detailed semantic structures
represented by the input image. To address this problem, we propose 3DAttriFlow
to disentangle and extract semantic attributes through different semantic
levels in the input images. These disentangled semantic attributes will be
integrated into the 3D shape reconstruction process, which can provide definite
guidance to the reconstruction of specific attribute on 3D shape. As a result,
the 3D decoder can explicitly capture high-level semantic features at the
bottom of the network, and utilize low-level features at the top of the
network, which allows to reconstruct more accurate 3D shapes. Note that the
explicit disentangling is learned without extra labels, where the only
supervision used in our training is the input image and its corresponding 3D
shape. Our comprehensive experiments on ShapeNet dataset demonstrate that
3DAttriFlow outperforms the state-of-the-art shape reconstruction methods, and
we also validate its generalization ability on shape completion task.
",regular,0
2110.06525,"Automatic DJ Transitions with Differentiable Audio Effects and
  Generative Adversarial Networks","  A central task of a Disc Jockey (DJ) is to create a mixset of mu-sic with
seamless transitions between adjacent tracks. In this paper, we explore a
data-driven approach that uses a generative adversarial network to create the
song transition by learning from real-world DJ mixes. In particular, the
generator of the model uses two differentiable digital signal processing
components, an equalizer (EQ) and a fader, to mix two tracks selected by a data
generation pipeline. The generator has to set the parameters of the EQs and
fader in such away that the resulting mix resembles real mixes created by
humanDJ, as judged by the discriminator counterpart. Result of a listening test
shows that the model can achieve competitive results compared with a number of
baselines.
",regular,0
2308.03333,"Heterogeneous Knowledge Fusion: A Novel Approach for Personalized
  Recommendation via LLM","  The analysis and mining of user heterogeneous behavior are of paramount
importance in recommendation systems. However, the conventional approach of
incorporating various types of heterogeneous behavior into recommendation
models leads to feature sparsity and knowledge fragmentation issues. To address
this challenge, we propose a novel approach for personalized recommendation via
Large Language Model (LLM), by extracting and fusing heterogeneous knowledge
from user heterogeneous behavior information. In addition, by combining
heterogeneous knowledge and recommendation tasks, instruction tuning is
performed on LLM for personalized recommendations. The experimental results
demonstrate that our method can effectively integrate user heterogeneous
behavior and significantly improve recommendation performance.
",regular,0
2209.0143399999997,"Reinforcement Learning with Prior Policy Guidance for Motion Planning of
  Dual-Arm Free-Floating Space Robot","  Reinforcement learning methods as a promising technique have achieved
superior results in the motion planning of free-floating space robots. However,
due to the increase in planning dimension and the intensification of system
dynamics coupling, the motion planning of dual-arm free-floating space robots
remains an open challenge. In particular, the current study cannot handle the
task of capturing a non-cooperative object due to the lack of the pose
constraint of the end-effectors. To address the problem, we propose a novel
algorithm, EfficientLPT, to facilitate RL-based methods to improve planning
accuracy efficiently. Our core contributions are constructing a mixed policy
with prior knowledge guidance and introducing infinite norm to build a more
reasonable reward function. Furthermore, our method successfully captures a
rotating object with different spinning speeds.
",regular,0
2303.04414,"Next-Generation URLLC with Massive Devices: A Unified Semi-Blind
  Detection Framework for Sourced and Unsourced Random Access","  This paper proposes a unified semi-blind detection framework for sourced and
unsourced random access (RA), which enables next-generation ultra-reliable
low-latency communications (URLLC) with massive devices. Specifically, the
active devices transmit their uplink access signals in a grant-free manner to
realize ultra-low access latency. Meanwhile, the base station aims to achieve
ultra-reliable data detection under severe inter-device interference without
exploiting explicit channel state information (CSI). We first propose an
efficient transmitter design, where a small amount of reference information
(RI) is embedded in the access signal to resolve the inherent ambiguities
incurred by the unknown CSI. At the receiver, we further develop a successive
interference cancellation-based semi-blind detection scheme, where a bilinear
generalized approximate message passing algorithm is utilized for joint channel
and signal estimation (JCSE), while the embedded RI is exploited for ambiguity
elimination. Particularly, a rank selection approach and a RI-aided
initialization strategy are incorporated to reduce the algorithmic
computational complexity and to enhance the JCSE reliability, respectively.
Besides, four enabling techniques are integrated to satisfy the stringent
latency and reliability requirements of massive URLLC. Numerical results
demonstrate that the proposed semi-blind detection framework offers a better
scalability-latency-reliability tradeoff than the state-of-the-art detection
schemes dedicated to sourced or unsourced RA.
",regular,0
2304.08493,"Coordinated Multi-Agent Reinforcement Learning for Unmanned Aerial
  Vehicle Swarms in Autonomous Mobile Access Applications","  This paper proposes a novel centralized training and distributed execution
(CTDE)-based multi-agent deep reinforcement learning (MADRL) method for
multiple unmanned aerial vehicles (UAVs) control in autonomous mobile access
applications. For the purpose, a single neural network is utilized in
centralized training for cooperation among multiple agents while maximizing the
total quality of service (QoS) in mobile access applications.
",regular,0
2405.1769,Data Makes Better Data Scientists,"  With the goal of identifying common practices in data science projects, this
paper proposes a framework for logging and understanding incremental code
executions in Jupyter notebooks. This framework aims to allow reasoning about
how insights are generated in data science and extract key observations into
best data science practices in the wild. In this paper, we show an early
prototype of this framework and ran an experiment to log a machine learning
project for 25 undergraduate students.
",regular,0
2204.13237,Spatio-Temporal Graph Localization Networks for Image-based Navigation,"  Localization in topological maps is essential for image-based navigation
using an RGB camera. Localization using only one camera can be challenging in
medium-to-large-sized environments because similar-looking images are often
observed repeatedly, especially in indoor environments. To overcome this issue,
we propose a learning-based localization method that simultaneously utilizes
the spatial consistency from topological maps and the temporal consistency from
time-series images captured by the robot. Our method combines a convolutional
neural network (CNN) to embed image features and a recurrent-type graph neural
network to perform accurate localization. When training our model, it is
difficult to obtain the ground truth pose of the robot when capturing images in
real-world environments. Hence, we propose a sim2real transfer approach with
semi-supervised learning that leverages simulator images with the ground truth
pose in addition to real images. We evaluated our method quantitatively and
qualitatively and compared it with several state-of-the-art baselines. The
proposed method outperformed the baselines in environments where the map
contained similar images. Moreover, we evaluated an image-based navigation
system incorporating our localization method and confirmed that navigation
accuracy significantly improved in the simulator and real environments when
compared with the other baseline methods.
",regular,0
2301.08606,Data Augmentation for Modeling Human Personality: The Dexter Machine,"  Modeling human personality is important for several AI challenges, from the
engineering of artificial psychotherapists to the design of persona bots.
However, the field of computational personality analysis heavily relies on
labeled data, which may be expensive, difficult or impossible to get. This
problem is amplified when dealing with rare personality types or disorders
(e.g., the anti-social psychopathic personality disorder). In this context, we
developed a text-based data augmentation approach for human personality
(PEDANT). PEDANT doesn't rely on the common type of labeled data but on the
generative pre-trained model (GPT) combined with domain expertise. Testing the
methodology on three different datasets, provides results that support the
quality of the generated data.
",regular,0
2305.0514,"Linguistic More: Taking a Further Step toward Efficient and Accurate
  Scene Text Recognition","  Vision model have gained increasing attention due to their simplicity and
efficiency in Scene Text Recognition (STR) task. However, due to lacking the
perception of linguistic knowledge and information, recent vision models suffer
from two problems: (1) the pure vision-based query results in attention drift,
which usually causes poor recognition and is summarized as linguistic
insensitive drift (LID) problem in this paper. (2) the visual feature is
suboptimal for the recognition in some vision-missing cases (e.g. occlusion,
etc.). To address these issues, we propose a $\textbf{L}$inguistic
$\textbf{P}$erception $\textbf{V}$ision model (LPV), which explores the
linguistic capability of vision model for accurate text recognition. To
alleviate the LID problem, we introduce a Cascade Position Attention (CPA)
mechanism that obtains high-quality and accurate attention maps through
step-wise optimization and linguistic information mining. Furthermore, a Global
Linguistic Reconstruction Module (GLRM) is proposed to improve the
representation of visual features by perceiving the linguistic information in
the visual space, which gradually converts visual features into semantically
rich ones during the cascade process. Different from previous methods, our
method obtains SOTA results while keeping low complexity (92.4% accuracy with
only 8.11M parameters). Code is available at
https://github.com/CyrilSterling/LPV.
",regular,0
2406.18853,Decoding-Time Language Model Alignment with Multiple Objectives,"  Aligning language models (LMs) to human preferences has emerged as a critical
pursuit, enabling these models to better serve diverse user needs. Existing
methods primarily focus on optimizing LMs for a single reward function,
limiting their adaptability to varied objectives. Here, we propose
$\textbf{multi-objective decoding (MOD)}$, a decoding-time algorithm that
outputs the next token from a linear combination of predictions of all base
models, for any given weightings over different objectives. We exploit a common
form among a family of $f$-divergence regularized alignment approaches (such as
PPO, DPO, and their variants) to identify a closed-form solution by Legendre
transform, and derive an efficient decoding strategy. Theoretically, we show
why existing approaches can be sub-optimal even in natural settings and obtain
optimality guarantees for our method. Empirical results demonstrate the
effectiveness of the algorithm. For example, compared to a parameter-merging
baseline, MOD achieves 12.8% overall reward improvement when equally optimizing
towards $3$ objectives. Moreover, we experiment with MOD on combining three
fully-finetuned LLMs of different model sizes, each aimed at different
objectives such as safety, coding, and general user preference. Unlike
traditional methods that require careful curation of a mixture of datasets to
achieve comprehensive improvement, we can quickly experiment with preference
weightings using MOD to find the best combination of models. Our best
combination reduces toxicity on Toxigen to nearly 0% and achieves 7.9--33.3%
improvement across other three metrics ($\textit{i.e.}$, Codex@1, GSM-COT,
BBH-COT).
",regular,0
2305.1033199999997,"Extracting a functional representation from a dictionary for non-rigid
  shape matching","  Shape matching is a fundamental problem in computer graphics with many
applications. Functional maps translate the point-wise shape-matching problem
into its functional counterpart and have inspired numerous solutions over the
last decade. Nearly all the solutions based on functional maps rely on the
eigenfunctions of the Laplace-Beltrami Operator (LB) to describe the functional
spaces defined on the surfaces and then convert the functional correspondences
into point-wise correspondences. However, this final step is often error-prone
and inaccurate in tiny regions and protrusions, where the energy of LB does not
uniformly cover the surface. We propose a new functional basis Principal
Components of a Dictionary (PCD) to address such intrinsic limitation. PCD
constructs an orthonormal basis from the Principal Component Analysis (PCA) of
a dictionary of functions defined over the shape. These dictionaries can target
specific properties of the final basis, such as achieving an even spreading of
energy. Our experimental evaluation compares seven different dictionaries on
established benchmarks, showing that PCD is suited to target different
shape-matching scenarios, resulting in more accurate point-wise maps than the
LB basis when used in the same pipeline. This evidence provides a promising
alternative for improving correspondence estimation, confirming the power and
flexibility of functional maps.
",regular,0
2302.1480300000003,Learned Risk Metric Maps for Kinodynamic Systems,"  We present Learned Risk Metric Maps (LRMM) for real-time estimation of
coherent risk metrics of high dimensional dynamical systems operating in
unstructured, partially observed environments. LRMM models are simple to design
and train -- requiring only procedural generation of obstacle sets, state and
control sampling, and supervised training of a function approximator -- which
makes them broadly applicable to arbitrary system dynamics and obstacle sets.
In a parallel autonomy setting, we demonstrate the model's ability to rapidly
infer collision probabilities of a fast-moving car-like robot driving
recklessly in an obstructed environment; allowing the LRMM agent to intervene,
take control of the vehicle, and avoid collisions. In this time-critical
scenario, we show that LRMMs can evaluate risk metrics 20-100x times faster
than alternative safety algorithms based on control barrier functions (CBFs)
and Hamilton-Jacobi reachability (HJ-reach), leading to 5-15\% fewer obstacle
collisions by the LRMM agent than CBFs and HJ-reach. This performance
improvement comes in spite of the fact that the LRMM model only has access to
local/partial observation of obstacles, whereas the CBF and HJ-reach agents are
granted privileged/global information. We also show that our model can be
equally well trained on a 12-dimensional quadrotor system operating in an
obstructed indoor environment. The LRMM codebase is provided at
https://github.com/mit-drl/pyrmm.
",regular,0
2204.07615,"TabNAS: Rejection Sampling for Neural Architecture Search on Tabular
  Datasets","  The best neural architecture for a given machine learning problem depends on
many factors: not only the complexity and structure of the dataset, but also on
resource constraints including latency, compute, energy consumption, etc.
Neural architecture search (NAS) for tabular datasets is an important but
under-explored problem. Previous NAS algorithms designed for image search
spaces incorporate resource constraints directly into the reinforcement
learning (RL) rewards. However, for NAS on tabular datasets, this protocol
often discovers suboptimal architectures. This paper develops TabNAS, a new and
more effective approach to handle resource constraints in tabular NAS using an
RL controller motivated by the idea of rejection sampling. TabNAS immediately
discards any architecture that violates the resource constraints without
training or learning from that architecture. TabNAS uses a Monte-Carlo-based
correction to the RL policy gradient update to account for this extra filtering
step. Results on several tabular datasets demonstrate the superiority of TabNAS
over previous reward-shaping methods: it finds better models that obey the
constraints.
",regular,0
2106.00992,NVC-Net: End-to-End Adversarial Voice Conversion,"  Voice conversion has gained increasing popularity in many applications of
speech synthesis. The idea is to change the voice identity from one speaker
into another while keeping the linguistic content unchanged. Many voice
conversion approaches rely on the use of a vocoder to reconstruct the speech
from acoustic features, and as a consequence, the speech quality heavily
depends on such a vocoder. In this paper, we propose NVC-Net, an end-to-end
adversarial network, which performs voice conversion directly on the raw audio
waveform of arbitrary length. By disentangling the speaker identity from the
speech content, NVC-Net is able to perform non-parallel traditional
many-to-many voice conversion as well as zero-shot voice conversion from a
short utterance of an unseen target speaker. Importantly, NVC-Net is
non-autoregressive and fully convolutional, achieving fast inference. Our model
is capable of producing samples at a rate of more than 3600 kHz on an NVIDIA
V100 GPU, being orders of magnitude faster than state-of-the-art methods under
the same hardware configurations. Objective and subjective evaluations on
non-parallel many-to-many voice conversion tasks show that NVC-Net obtains
competitive results with significantly fewer parameters.
",regular,0
2302.0682699999998,"B-BACN: Bayesian Boundary-Aware Convolutional Network for Crack
  Characterization","  Accurately detecting crack boundaries is crucial for reliability assessment
and risk management of structures and materials, such as structural health
monitoring, diagnostics, prognostics, and maintenance scheduling. Uncertainty
quantification of crack detection is challenging due to various stochastic
factors, such as measurement noises, signal processing, and model
simplifications. A machine learning-based approach is proposed to quantify both
epistemic and aleatoric uncertainties concurrently. We introduce a Bayesian
Boundary-Aware Convolutional Network (B-BACN) that emphasizes uncertainty-aware
boundary refinement to generate precise and reliable crack boundary detections.
The proposed method employs a multi-task learning approach, where we use Monte
Carlo Dropout to learn the epistemic uncertainty and a Gaussian sampling
function to predict each sample's aleatoric uncertainty. Moreover, we include a
boundary refinement loss to B-BACN to enhance the determination of defect
boundaries. The proposed method is demonstrated with benchmark experimental
results and compared with several existing methods. The experimental results
illustrate the effectiveness of our proposed approach in uncertainty-aware
crack boundary detection, minimizing misclassification rate, and improving
model calibration capabilities.
",regular,0
2304.0974100000003,"A Multi-robot Coverage Path Planning Algorithm Based on Improved DARP
  Algorithm","  The research on multi-robot coverage path planning (CPP) has been attracting
more and more attention. In order to achieve efficient coverage, this paper
proposes an improved DARP coverage algorithm. The improved DARP algorithm based
on A* algorithm is used to assign tasks to robots and then combined with STC
algorithm based on Up-First algorithm to achieve full coverage of the task
area. Compared with the initial DARP algorithm, this algorithm has higher
efficiency and higher coverage rate.
",regular,0
2105.04965,Succinct Euler-Tour Trees,"  We show how a collection of Euler-tour trees for a forest on $n$ vertices can
be stored in $2 n + o (n)$ bits such that simple queries take constant time,
more complex queries take logarithmic time and updates take polylogarithmic
amortized time.
",regular,0
2104.1001300000003,Parallel Physics-Informed Neural Networks via Domain Decomposition,"  We develop a distributed framework for the physics-informed neural networks
(PINNs) based on two recent extensions, namely conservative PINNs (cPINNs) and
extended PINNs (XPINNs), which employ domain decomposition in space and in
time-space, respectively. This domain decomposition endows cPINNs and XPINNs
with several advantages over the vanilla PINNs, such as parallelization
capacity, large representation capacity, efficient hyperparameter tuning, and
is particularly effective for multi-scale and multi-physics problems. Here, we
present a parallel algorithm for cPINNs and XPINNs constructed with a hybrid
programming model described by MPI $+$ X, where X $\in
\{\text{CPUs},~\text{GPUs}\}$. The main advantage of cPINN and XPINN over the
more classical data and model parallel approaches is the flexibility of
optimizing all hyperparameters of each neural network separately in each
subdomain. We compare the performance of distributed cPINNs and XPINNs for
various forward problems, using both weak and strong scalings. Our results
indicate that for space domain decomposition, cPINNs are more efficient in
terms of communication cost but XPINNs provide greater flexibility as they can
also handle time-domain decomposition for any differential equations, and can
deal with any arbitrarily shaped complex subdomains. To this end, we also
present an application of the parallel XPINN method for solving an inverse
diffusion problem with variable conductivity on the United States map, using
ten regions as subdomains.
",regular,0
2211.0932199999997,Targeted Attention for Generalized- and Zero-Shot Learning,"  The Zero-Shot Learning (ZSL) task attempts to learn concepts without any
labeled data. Unlike traditional classification/detection tasks, the evaluation
environment is provided unseen classes never encountered during training. As
such, it remains both challenging, and promising on a variety of fronts,
including unsupervised concept learning, domain adaptation, and dataset drift
detection. Recently, there have been a variety of approaches towards solving
ZSL, including improved metric learning methods, transfer learning,
combinations of semantic and image domains using, e.g. word vectors, and
generative models to model the latent space of known classes to classify unseen
classes. We find many approaches require intensive training augmentation with
attributes or features that may be commonly unavailable (attribute-based
learning) or susceptible to adversarial attacks (generative learning). We
propose combining approaches from the related person re-identification task for
ZSL, with key modifications to ensure sufficiently improved performance in the
ZSL setting without the need for feature or training dataset augmentation. We
are able to achieve state-of-the-art performance on the CUB200 and Cars196
datasets in the ZSL setting compared to recent works, with NMI (normalized
mutual inference) of 63.27 and top-1 of 61.04 for CUB200, and NMI 66.03 with
top-1 82.75% in Cars196. We also show state-of-the-art results in the
Generalized Zero-Shot Learning (GZSL) setting, with Harmonic Mean R-1 of 66.14%
on the CUB200 dataset.
",regular,0
2401.12491,Assessing and Understanding Creativity in Large Language Models,"  In the field of natural language processing, the rapid development of large
language model (LLM) has attracted more and more attention. LLMs have shown a
high level of creativity in various tasks, but the methods for assessing such
creativity are inadequate. The assessment of LLM creativity needs to consider
differences from humans, requiring multi-dimensional measurement while
balancing accuracy and efficiency. This paper aims to establish an efficient
framework for assessing the level of creativity in LLMs. By adapting the
modified Torrance Tests of Creative Thinking, the research evaluates the
creative performance of various LLMs across 7 tasks, emphasizing 4 criteria
including Fluency, Flexibility, Originality, and Elaboration. In this context,
we develop a comprehensive dataset of 700 questions for testing and an
LLM-based evaluation method. In addition, this study presents a novel analysis
of LLMs' responses to diverse prompts and role-play situations. We found that
the creativity of LLMs primarily falls short in originality, while excelling in
elaboration. Besides, the use of prompts and the role-play settings of the
model significantly influence creativity. Additionally, the experimental
results also indicate that collaboration among multiple LLMs can enhance
originality. Notably, our findings reveal a consensus between human evaluations
and LLMs regarding the personality traits that influence creativity. The
findings underscore the significant impact of LLM design on creativity and
bridges artificial intelligence and human creativity, offering insights into
LLMs' creativity and potential applications.
",regular,0
2112.07174,"Practical Distributed Reception for Wireless Body Area Networks Using
  Supervised Learning","  Medical applications have driven many areas of engineering to optimize
diagnostic capabilities and convenience. In the near future, wireless body area
networks (WBANs) are expected to have widespread impact in medicine. To achieve
this impact, however, significant advances in research are needed to cope with
the changes of the human body's state, which make coherent communications
difficult or even impossible. In this paper, we consider a realistic
noncoherent WBAN system model where transmissions and receptions are conducted
without any channel state information due to the fast-varying channels of the
human body. Using distributed reception, we propose several symbol detection
approaches where on-off keying (OOK) modulation is exploited, among which a
supervised-learning-based approach is developed to overcome the noncoherent
system issue. Through simulation results, we compare and verify the performance
of the proposed techniques for noncoherent WBANs with OOK transmissions. We
show that the well-defined detection techniques with a
supervised-learning-based approach enable robust communications for noncoherent
WBAN systems.
",regular,0
2105.08709,Learning and Certification under Instance-targeted Poisoning,"  In this paper, we study PAC learnability and certification of predictions
under instance-targeted poisoning attacks, where the adversary who knows the
test instance may change a fraction of the training set with the goal of
fooling the learner at the test instance. Our first contribution is to
formalize the problem in various settings and to explicitly model subtle
aspects such as the proper or improper nature of the learning, learner's
randomness, and whether (or not) adversary's attack can depend on it. Our main
result shows that when the budget of the adversary scales sublinearly with the
sample complexity, (improper) PAC learnability and certification are
achievable; in contrast, when the adversary's budget grows linearly with the
sample complexity, the adversary can potentially drive up the expected 0-1 loss
to one. We also study distribution-specific PAC learning in the same attack
model and show that proper learning with certification is possible for learning
half spaces under natural distributions. Finally, we empirically study the
robustness of K nearest neighbour, logistic regression, multi-layer perceptron,
and convolutional neural network on real data sets against targeted-poisoning
attacks. Our experimental results show that many models, especially
state-of-the-art neural networks, are indeed vulnerable to these strong
attacks. Interestingly, we observe that methods with high standard accuracy
might be more vulnerable to instance-targeted poisoning attacks.
",regular,0
2404.07814,"MultiLS-SP/CA: Lexical Complexity Prediction and Lexical Simplification
  Resources for Catalan and Spanish","  Automatic lexical simplification is a task to substitute lexical items that
may be unfamiliar and difficult to understand with easier and more common
words. This paper presents MultiLS-SP/CA, a novel dataset for lexical
simplification in Spanish and Catalan. This dataset represents the first of its
kind in Catalan and a substantial addition to the sparse data on automatic
lexical simplification which is available for Spanish. Specifically, MultiLS-SP
is the first dataset for Spanish which includes scalar ratings of the
understanding difficulty of lexical items. In addition, we describe experiments
with this dataset, which can serve as a baseline for future work on the same
data.
",regular,0
2405.11677,"Advancing 6-DoF Instrument Pose Estimation in Variable X-Ray Imaging
  Geometries","  Accurate 6-DoF pose estimation of surgical instruments during minimally
invasive surgeries can substantially improve treatment strategies and eventual
surgical outcome. Existing deep learning methods have achieved accurate
results, but they require custom approaches for each object and laborious setup
and training environments often stretching to extensive simulations, whilst
lacking real-time computation. We propose a general-purpose approach of data
acquisition for 6-DoF pose estimation tasks in X-ray systems, a novel and
general purpose YOLOv5-6D pose architecture for accurate and fast object pose
estimation and a complete method for surgical screw pose estimation under
acquisition geometry consideration from a monocular cone-beam X-ray image. The
proposed YOLOv5-6D pose model achieves competitive results on public benchmarks
whilst being considerably faster at 42 FPS on GPU. In addition, the method
generalizes across varying X-ray acquisition geometry and semantic image
complexity to enable accurate pose estimation over different domains. Finally,
the proposed approach is tested for bone-screw pose estimation for
computer-aided guidance during spine surgeries. The model achieves a 92.41% by
the 0.1 ADD-S metric, demonstrating a promising approach for enhancing surgical
precision and patient outcomes. The code for YOLOv5-6D is publicly available at
https://github.com/cviviers/YOLOv5-6D-Pose
",regular,0
