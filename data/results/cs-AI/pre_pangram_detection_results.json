[
  {
    "arxiv_id":2001.06921,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"A Survey of Reinforcement Learning Techniques: Strategies, Recent\n  Development, and Future Directions\n\n  Reinforcement learning is one of the core components in designing an\nartificial intelligent system emphasizing real-time response. Reinforcement\nlearning influences the system to take actions within an arbitrary environment\neither having previous knowledge about the environment model or not. In this\npaper, we present a comprehensive study on Reinforcement Learning focusing on\nvarious dimensions including challenges, the recent development of different\nstate-of-the-art techniques, and future directions. The fundamental objective\nof this paper is to provide a framework for the presentation of available\nmethods of reinforcement learning that is informative enough and simple to\nfollow for the new researchers and academics in this domain considering the\nlatest concerns. First, we illustrated the core techniques of reinforcement\nlearning in an easily understandable and comparable way. Finally, we analyzed\nand depicted the recent developments in reinforcement learning approaches. My\nanalysis pointed out that most of the models focused on tuning policy values\nrather than tuning other things in a particular state of reasoning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.04566,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Monte Carlo Anti-Differentiation for Approximate Weighted Model\n  Integration\n\n  Probabilistic inference in the hybrid domain, i.e. inference over\ndiscrete-continuous domains, requires tackling two well known #P-hard problems\n1)~weighted model counting (WMC) over discrete variables and 2)~integration\nover continuous variables. For both of these problems inference techniques have\nbeen developed separately in order to manage their #P-hardness, such as\nknowledge compilation for WMC and Monte Carlo (MC) methods for (approximate)\nintegration in the continuous domain. Weighted model integration (WMI), the\nextension of WMC to the hybrid domain, has been proposed as a formalism to\nstudy probabilistic inference over discrete and continuous variables alike.\nRecently developed WMI solvers have focused on exploiting structure in WMI\nproblems, for which they rely on symbolic integration to find the primitive of\nan integrand, i.e. to perform anti-differentiation. To combine these advances\nwith state-of-the-art Monte Carlo integration techniques, we introduce\n\\textit{Monte Carlo anti-differentiation} (MCAD), which computes MC\napproximations of anti-derivatives. In our empirical evaluation we substitute\nthe exact symbolic integration backend in an existing WMI solver with an MCAD\nbackend. Our experiments show that that equipping existing WMI solvers with\nMCAD yields a fast yet reliable approximate inference scheme.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.10922,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Stochastic L-system Inference from Multiple String Sequence Inputs\n\n  Lindenmayer systems (L-systems) are a grammar system that consist of string\nrewriting rules. The rules replace every symbol in a string in parallel with a\nsuccessor to produce the next string, and this procedure iterates. In a\nstochastic context-free L-system (S0L-system), every symbol may have one or\nmore rewriting rule, each with an associated probability of selection. Properly\nconstructed rewriting rules have been found to be useful for modeling and\nsimulating some natural and human engineered processes where each derived\nstring describes a step in the simulation. Typically, processes are modeled by\nexperts who meticulously construct the rules based on measurements or domain\nknowledge of the process. This paper presents an automated approach to finding\nstochastic L-systems, given a set of string sequences as input. The implemented\ntool is called the Plant Model Inference Tool for S0L-systems (PMIT-S0L).\nPMIT-S0L is evaluated using 960 procedurally generated S0L-systems in a test\nsuite, which are each used to generate input strings, and PMIT-S0L is then used\nto infer the system from only the sequences. The evaluation shows that PMIT-S0L\ninfers S0L-systems with up to 9 rewriting rules each in under 12 hours.\nAdditionally, it is found that 3 sequences of strings is sufficient to find the\ncorrect original rewriting rules in 100% of the cases in the test suite, and 6\nsequences of strings reduces the difference in the associated probabilities to\napproximately 1% or less.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.07578,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Adequate and fair explanations\n\n  Explaining sophisticated machine-learning based systems is an important issue\nat the foundations of AI. Recent efforts have shown various methods for\nproviding explanations. These approaches can be broadly divided into two\nschools: those that provide a local and human interpreatable approximation of a\nmachine learning algorithm, and logical approaches that exactly characterise\none aspect of the decision. In this paper we focus upon the second school of\nexact explanations with a rigorous logical foundation. There is an\nepistemological problem with these exact methods. While they can furnish\ncomplete explanations, such explanations may be too complex for humans to\nunderstand or even to write down in human readable form. Interpretability\nrequires epistemically accessible explanations, explanations humans can grasp.\nYet what is a sufficiently complete epistemically accessible explanation still\nneeds clarification. We do this here in terms of counterfactuals, following\n[Wachter et al., 2017]. With counterfactual explanations, many of the\nassumptions needed to provide a complete explanation are left implicit. To do\nso, counterfactual explanations exploit the properties of a particular data\npoint or sample, and as such are also local as well as partial explanations. We\nexplore how to move from local partial explanations to what we call complete\nlocal explanations and then to global ones. But to preserve accessibility we\nargue for the need for partiality. This partiality makes it possible to hide\nexplicit biases present in the algorithm that may be injurious or unfair.We\ninvestigate how easy it is to uncover these biases in providing complete and\nfair explanations by exploiting the structure of the set of counterfactuals\nproviding a complete local explanation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.02619,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000023511,
      "text":"D3BA: A Tool for Optimizing Business Processes Using Non-Deterministic\n  Planning\n\n  This paper builds upon recent work in the declarative design of dialogue\nagents and proposes an exciting new tool -- D3BA -- Declarative Design for\nDigital Business Automation, built to optimize business processes using the\npower of AI planning. The tool provides a powerful framework to build,\noptimize, and maintain complex business processes and optimize them by\ncomposing with services that automate one or more subtasks. We illustrate\nsalient features of this composition technique, compare with other philosophies\nof composition, and highlight exciting opportunities for research in this\nemerging field of business process automation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.04238,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000018875,
      "text":"Nmbr9 as a Constraint Programming Challenge\n\n  Modern board games are a rich source of interesting and new challenges for\ncombinatorial problems. The game Nmbr9 is a solitaire style puzzle game using\npolyominoes. The rules of the game are simple to explain, but modelling the\ngame effectively using constraint programming is hard. This abstract presents\nthe game, contributes new generalized variants of the game suitable for\nbenchmarking and testing, and describes a model for the presented variants. The\nquestion of the top possible score in the standard game is an open challenge.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.04186,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"Towards Evaluating Plan Generation Approaches with Instructional Texts\n\n  Recent research in behaviour understanding through language grounding has\nshown it is possible to automatically generate behaviour models from textual\ninstructions. These models usually have goal-oriented structure and are\nmodelled with different formalisms from the planning domain such as the\nPlanning Domain Definition Language. One major problem that still remains is\nthat there are no benchmark datasets for comparing the different model\ngeneration approaches, as each approach is usually evaluated on domain-specific\napplication. To allow the objective comparison of different methods for model\ngeneration from textual instructions, in this report we introduce a dataset\nconsisting of 83 textual instructions in English language, their refinement in\na more structured form as well as manually developed plans for each of the\ninstructions. The dataset is publicly available to the community.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.05087,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000006126,
      "text":"Monte Carlo Game Solver\n\n  We present a general algorithm to order moves so as to speedup exact game\nsolvers. It uses online learning of playout policies and Monte Carlo Tree\nSearch. The learned policy and the information in the Monte Carlo tree are used\nto order moves in game solvers. They improve greatly the solving time for\nmultiple games.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.10905,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Interventions and Counterfactuals in Tractable Probabilistic Models:\n  Limitations of Contemporary Transformations\n\n  In recent years, there has been an increasing interest in studying\ncausality-related properties in machine learning models generally, and in\ngenerative models in particular. While that is well motivated, it inherits the\nfundamental computational hardness of probabilistic inference, making exact\nreasoning intractable. Probabilistic tractable models have also recently\nemerged, which guarantee that conditional marginals can be computed in time\nlinear in the size of the model, where the model is usually learned from data.\nAlthough initially limited to low tree-width models, recent tractable models\nsuch as sum product networks (SPNs) and probabilistic sentential decision\ndiagrams (PSDDs) exploit efficient function representations and also capture\nhigh tree-width models.\n  In this paper, we ask the following technical question: can we use the\ndistributions represented or learned by these models to perform causal queries,\nsuch as reasoning about interventions and counterfactuals? By appealing to some\nexisting ideas on transforming such models to Bayesian networks, we answer\nmostly in the negative. We show that when transforming SPNs to a causal graph\ninterventional reasoning reduces to computing marginal distributions; in other\nwords, only trivial causal reasoning is possible. For PSDDs the situation is\nonly slightly better. We first provide an algorithm for constructing a causal\ngraph from a PSDD, which introduces augmented variables. Intervening on the\noriginal variables, once again, reduces to marginal distributions, but when\nintervening on the augmented variables, a deterministic but nonetheless\ncausal-semantics can be provided for PSDDs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.07573,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000085764,
      "text":"Implementations in Machine Ethics: A Survey\n\n  Increasingly complex and autonomous systems require machine ethics to\nmaximize the benefits and minimize the risks to society arising from the new\ntechnology. It is challenging to decide which type of ethical theory to employ\nand how to implement it effectively. This survey provides a threefold\ncontribution. First, it introduces a trimorphic taxonomy to analyze machine\nethics implementations with respect to their object (ethical theories), as well\nas their nontechnical and technical aspects. Second, an exhaustive selection\nand description of relevant works is presented. Third, applying the new\ntaxonomy to the selected works, dominant research patterns, and lessons for the\nfield are identified, and future directions for research are suggested.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.0573,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Broadening Label-based Argumentation Semantics with May-Must Scales\n  (May-Must Argumentation)\n\n  The semantics as to which set of arguments in a given argumentation graph may\nbe acceptable (acceptability semantics) can be characterised in a few different\nways. Among them, labelling-based approach allows for concise and flexible\ndetermination of acceptability statuses of arguments through assignment of a\nlabel indicating acceptance, rejection, or undecided to each argument. In this\nwork, we contemplate a way of broadening it by accommodating may- and must-\nconditions for an argument to be accepted or rejected, as determined by the\nnumber(s) of rejected and accepted attacking arguments. We show that the\nbroadened label-based semantics can be used to express more mild indeterminacy\nthan inconsistency for acceptability judgement when, for example, it may be the\ncase that an argument is accepted and when it may also be the case that it is\nrejected. We identify that finding which conditions a labelling satisfies for\nevery argument can be an undecidable problem, which has an unfavourable\nimplication to existence of a semantics. We propose to address this problem by\nenforcing a labelling to maximally respect the conditions, while keeping the\nrest that would necessarily cause non-termination labelled undecided. Several\nsemantics will be presented and the relation among them will be noted. Towards\nthe end, we will touch upon possible research directions that can be pursued\nfurther.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.02094,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000052982,
      "text":"An adaptive data-driven approach to solve real-world vehicle routing\n  problems in logistics\n\n  Transportation occupies one-third of the amount in the logistics costs, and\naccordingly transportation systems largely influence the performance of the\nlogistics system. This work presents an adaptive data-driven innovative modular\napproach for solving the real-world Vehicle Routing Problems (VRP) in the field\nof logistics. The work consists of two basic units: (i) an innovative\nmulti-step algorithm for successful and entirely feasible solving of the VRP\nproblems in logistics, (ii) an adaptive approach for adjusting and setting up\nparameters and constants of the proposed algorithm. The proposed algorithm\ncombines several data transformation approaches, heuristics and Tabu search.\nMoreover, as the performance of the algorithm depends on the set of control\nparameters and constants, a predictive model that adaptively adjusts these\nparameters and constants according to historical data is proposed. A comparison\nof the acquired results has been made using the Decision Support System with\npredictive models: Generalized Linear Models (GLM) and Support Vector Machine\n(SVM). The algorithm, along with the control parameters, which using the\nprediction method were acquired, was incorporated into a web-based enterprise\nsystem, which is in use in several big distribution companies in Bosnia and\nHerzegovina. The results of the proposed algorithm were compared with a set of\nbenchmark instances and validated over real benchmark instances as well. The\nsuccessful feasibility of the given routes, in a real environment, is also\npresented.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.10828,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"A New Arc-Routing Algorithm Applied to Winter Road Maintenance\n\n  This paper studies large scale instances of a fairly general arc-routing\nproblem as well as incorporate practical constraints in particular coming from\nthe scheduling problem of the winter road maintenance (e.g. different\npriorities for and methods of road maintenance). We develop a new algorithm\nbased on a bin-packing heuristic which is well-scalable and able to solve road\nnetworks on thousands of crossroads and road segments in few minutes. Since it\nis impossible to find an optimal solution for such a large instances to compare\nit with a result of our algorithm, we also develop techniques to compute lower\nbounds which are based on Integer Linear Programming and Lazy Constraints.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.04233,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000012583,
      "text":"State Representation and Polyomino Placement for the Game Patchwork\n\n  Modern board games are a rich source of entertainment for many people, but\nalso contain interesting and challenging structures for game playing research\nand implementing game playing agents. This paper studies the game Patchwork, a\ntwo player strategy game using polyomino tile drafting and placement. The core\npolyomino placement mechanic is implemented in a constraint model using regular\nconstraints, extending and improving the model in (Lagerkvist, Pesant, 2008)\nwith: explicit rotation handling; optional placements; and new constraints for\nresource usage. Crucial for implementing good game playing agents is to have\ngreat heuristics for guiding the search when faced with large branching\nfactors. This paper divides placing tiles into two parts: a policy used for\nplacing parts and an evaluation used to select among different placements.\nPolicies are designed based on classical packing literature as well as common\nstandard constraint programming heuristics. For evaluation, global propagation\nguided regret is introduced, choosing placements based on not ruling out later\nplacements. Extensive evaluations are performed, showing the importance of\nusing a good evaluation and that the proposed global propagation guided regret\nis a very effective guide.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.03766,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000017219,
      "text":"Testing Unsatisfiability of Constraint Satisfaction Problems via Tensor\n  Products\n\n  We study the design of stochastic local search methods to prove\nunsatisfiability of a constraint satisfaction problem (CSP). For a binary CSP,\nsuch methods have been designed using the microstructure of the CSP. Here, we\ndevelop a method to decompose the microstructure into graph tensors. We show\nhow to use the tensor decomposition to compute a proof of unsatisfiability\nefficiently and in parallel. We also offer substantial empirical evidence that\nour approach improves the praxis. For instance, one decomposition yields proofs\nof unsatisfiability in half the time without sacrificing the quality. Another\ndecomposition is twenty times faster and effective three-tenths of the times\ncompared to the prior method. Our method is applicable to arbitrary CSPs using\nthe well known dual and hidden variable transformations from an arbitrary CSP\nto a binary CSP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.04418,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000022848,
      "text":"Exploiting Language Instructions for Interpretable and Compositional\n  Reinforcement Learning\n\n  In this work, we present an alternative approach to making an agent\ncompositional through the use of a diagnostic classifier. Because of the need\nfor explainable agents in automated decision processes, we attempt to interpret\nthe latent space from an RL agent to identify its current objective in a\ncomplex language instruction. Results show that the classification process\ncauses changes in the hidden states which makes them more easily interpretable,\nbut also causes a shift in zero-shot performance to novel instructions. Lastly,\nwe limit the supervisory signal on the classification, and observe a similar\nbut less notable effect.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.04861,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000027153,
      "text":"Fairness in Learning-Based Sequential Decision Algorithms: A Survey\n\n  Algorithmic fairness in decision-making has been studied extensively in\nstatic settings where one-shot decisions are made on tasks such as\nclassification. However, in practice most decision-making processes are of a\nsequential nature, where decisions made in the past may have an impact on\nfuture data. This is particularly the case when decisions affect the\nindividuals or users generating the data used for future decisions. In this\nsurvey, we review existing literature on the fairness of data-driven sequential\ndecision-making. We will focus on two types of sequential decisions: (1) past\ndecisions have no impact on the underlying user population and thus no impact\non future data; (2) past decisions have an impact on the underlying user\npopulation and therefore the future data, which can then impact future\ndecisions. In each case the impact of various fairness interventions on the\nunderlying population is examined.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.07537,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0,
      "text":"AI Trust in business processes: The need for process-aware explanations\n\n  Business processes underpin a large number of enterprise operations including\nprocessing loan applications, managing invoices, and insurance claims. There is\na large opportunity for infusing AI to reduce cost or provide better customer\nexperience, and the business process management (BPM) literature is rich in\nmachine learning solutions including unsupervised learning to gain insights on\nclusters of process traces, classification models to predict the outcomes,\nduration, or paths of partial process traces, extracting business process from\ndocuments, and models to recommend how to optimize a business process or\nnavigate decision points. More recently, deep learning models including those\nfrom the NLP domain have been applied to process predictions.\n  Unfortunately, very little of these innovations have been applied and adopted\nby enterprise companies. We assert that a large reason for the lack of adoption\nof AI models in BPM is that business users are risk-averse and do not\nimplicitly trust AI models. There has, unfortunately, been little attention\npaid to explaining model predictions to business users with process context. We\nchallenge the BPM community to build on the AI interpretability literature, and\nthe AI Trust community to understand\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.0619,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000019537,
      "text":"Visual Simplified Characters' Emotion Emulator Implementing OCC Model\n\n  In this paper, we present a visual emulator of the emotions seen in\ncharacters in stories. This system is based on a simplified view of the\ncognitive structure of emotions proposed by Ortony, Clore and Collins (OCC\nModel). The goal of this paper is to provide a visual platform that allows us\nto observe changes in the characters' different emotions, and the intricate\ninterrelationships between: 1) each character's emotions, 2) their affective\nrelationships and actions, 3) The events that take place in the development of\na plot, and 4) the objects of desire that make up the emotional map of any\nstory. This tool was tested on stories with a contrasting variety of emotional\nand affective environments: Othello, Twilight, and Harry Potter, behaving\nsensibly and in keeping with the atmosphere in which the characters were\nimmersed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2001.0321,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000099672,
      "text":"A Probabilistic Simulator of Spatial Demand for Product Allocation\n\n  Connecting consumers with relevant products is a very important problem in\nboth online and offline commerce. In physical retail, product placement is an\neffective way to connect consumers with products. However, selecting product\nlocations within a store can be a tedious process. Moreover, learning important\nspatial patterns in offline retail is challenging due to the scarcity of data\nand the high cost of exploration and experimentation in the physical world. To\naddress these challenges, we propose a stochastic model of spatial demand in\nphysical retail. We show that the proposed model is more predictive of demand\nthan existing baselines. We also perform a preliminary study into different\nautomation techniques and show that an optimal product allocation policy can be\nlearned through Deep Q-Learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.10373,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000039736,
      "text":"Symbolic Learning and Reasoning with Noisy Data for Probabilistic\n  Anchoring\n\n  Robotic agents should be able to learn from sub-symbolic sensor data, and at\nthe same time, be able to reason about objects and communicate with humans on a\nsymbolic level. This raises the question of how to overcome the gap between\nsymbolic and sub-symbolic artificial intelligence. We propose a semantic world\nmodeling approach based on bottom-up object anchoring using an object-centered\nrepresentation of the world. Perceptual anchoring processes continuous\nperceptual sensor data and maintains a correspondence to a symbolic\nrepresentation. We extend the definitions of anchoring to handle multi-modal\nprobability distributions and we couple the resulting symbol anchoring system\nto a probabilistic logic reasoner for performing inference. Furthermore, we use\nstatistical relational learning to enable the anchoring framework to learn\nsymbolic knowledge in the form of a set of probabilistic logic rules of the\nworld from noisy and sub-symbolic sensor input. The resulting framework, which\ncombines perceptual anchoring and statistical relational learning, is able to\nmaintain a semantic world model of all the objects that have been perceived\nover time, while still exploiting the expressiveness of logical rules to reason\nabout the state of objects which are not directly observed through sensory\ninput data. To validate our approach we demonstrate, on the one hand, the\nability of our system to perform probabilistic reasoning over multi-modal\nprobability distributions, and on the other hand, the learning of probabilistic\nlogical rules from anchored objects produced by perceptual observations. The\nlearned logical rules are, subsequently, used to assess our proposed\nprobabilistic anchoring procedure. We demonstrate our system in a setting\ninvolving object interactions where object occlusions arise and where\nprobabilistic inference is needed to correctly anchor objects.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.0108,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.000000298,
      "text":"Bridging the Gap: Providing Post-Hoc Symbolic Explanations for\n  Sequential Decision-Making Problems with Inscrutable Representations\n\n  As increasingly complex AI systems are introduced into our daily lives, it\nbecomes important for such systems to be capable of explaining the rationale\nfor their decisions and allowing users to contest these decisions. A\nsignificant hurdle to allowing for such explanatory dialogue could be the\nvocabulary mismatch between the user and the AI system. This paper introduces\nmethods for providing contrastive explanations in terms of user-specified\nconcepts for sequential decision-making settings where the system's model of\nthe task may be best represented as an inscrutable model. We do this by\nbuilding partial symbolic models of a local approximation of the task that can\nbe leveraged to answer the user queries. We test these methods on a popular\nAtari game (Montezuma's Revenge) and variants of Sokoban (a well-known planning\nbenchmark) and report the results of user studies to evaluate whether people\nfind explanations generated in this form useful.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.11508,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000016557,
      "text":"A binarized-domains arc-consistency algorithm for TCSPs: its\n  computational analysis and its use as a filtering procedure in solution\n  search algorithms\n\n  TCSPs (Temporal Constraint Satisfaction Problems), as defined in [Dechter et\nal., 1991], get rid of unary constraints by binarizing them after having added\nan \"origin of the world\" variable. In this work, we look at the constraints\nbetween the \"origin of the world\" variable and the other variables, as the\n(binarized) domains of these other variables. With this in mind, we define a\nnotion of arc-consistency for TCSPs, which we will refer to as\nbinarized-domains Arc-Consistency, or bdArc-Consistency for short. We provide\nan algorithm achieving bdArc-Consistency for a TCSP, which we will refer to as\nbdAC-3, for it is an adaptation of Mackworth's [1977] well-known\narc-consistency algorithm AC-3. We show that if a convex TCSP, referred to in\n[Dechter et al., 1991] as an STP (Simple Temporal Problem), is\nbdArc-Consistent, and its \"origin of the world\" variable disconnected from none\nof the other variables, its binarized domains are minimal. We provide two\npolynomial backtrack-free procedures: one for the task of getting, from a\nbdArc-Consistent STP, either that it is inconsistent or, in case of\nconsistency, a bdArc-Consistent STP refinement whose \"origin of the world\"\nvariable is disconnected from none of the other variables; the other for the\ntask of getting a solution from a bdArc-Consistent STP whose \"origin of the\nworld\" variable is disconnected from none of the other variables. We then show\nhow to use our results both in a general TCSP solver and in a TCSP-based job\nshop scheduler. From our work can be extracted a one-to-all all-to-one shortest\npaths algorithm of an IR-labelled directed graph. Finally, we show that an\nexisting adaptation to TCSPs of Mackworth's [1977] path-consistency algorithm\nPC-2 is not guaranteed to always terminate, and correct it.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.12445,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"Multi-tier Automated Planning for Adaptive Behavior (Extended Version)\n\n  A planning domain, as any model, is never complete and inevitably makes\nassumptions on the environment's dynamic. By allowing the specification of just\none domain model, the knowledge engineer is only able to make one set of\nassumptions, and to specify a single objective-goal. Borrowing from work in\nSoftware Engineering, we propose a multi-tier framework for planning that\nallows the specification of different sets of assumptions, and of different\ncorresponding objectives. The framework aims to support the synthesis of\nadaptive behavior so as to mitigate the intrinsic risk in any planning modeling\ntask. After defining the multi-tier planning task and its solution concept, we\nshow how to solve problem instances by a succinct compilation to a form of\nnon-deterministic planning. In doing so, our technique justifies the\napplicability of planning with both fair and unfair actions, and the need for\nmore efforts in developing planning systems supporting dual fairness\nassumptions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.00429,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000009934,
      "text":"Uncertainty Weighted Causal Graphs\n\n  Causality has traditionally been a scientific way to generate knowledge by\nrelating causes to effects. From an imaginery point of view, causal graphs are\na helpful tool for representing and infering new causal information. In\nprevious works, we have generated automatically causal graphs associated to a\ngiven concept by analyzing sets of documents and extracting and representing\nthe found causal information in that visual way. The retrieved information\nshows that causality is frequently imperfect rather than exact, feature\ngathered by the graph. In this work we will attempt to go a step further\nmodelling the uncertainty in the graph through probabilistic improving the\nmanagement of the imprecision in the quoted graph.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.0003,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000121196,
      "text":"Policy-Aware Model Learning for Policy Gradient Methods\n\n  This paper considers the problem of learning a model in model-based\nreinforcement learning (MBRL). We examine how the planning module of an MBRL\nalgorithm uses the model, and propose that the model learning module should\nincorporate the way the planner is going to use the model. This is in contrast\nto conventional model learning approaches, such as those based on maximum\nlikelihood estimate, that learn a predictive model of the environment without\nexplicitly considering the interaction of the model and the planner. We focus\non policy gradient type of planning algorithms and derive new loss functions\nfor model learning that incorporate how the planner uses the model. We call\nthis approach Policy-Aware Model Learning (PAML). We theoretically analyze a\ngeneric model-based policy gradient algorithm and provide a convergence\nguarantee for the optimized policy. We also empirically evaluate PAML on some\nbenchmark problems, showing promising results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.04369,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000022517,
      "text":"Belief Base Revision for Further Improvement of Unified Answer Set\n  Programming\n\n  A belief base revision is developed. The belief base is represented using\nUnified Answer Set Programs which is capable of representing imprecise and\nuncertain information and perform nonomonotonic reasoning with them. The base\nrevision operator is developed using Removed Set Revision strategy. The\noperator is characterized with respect to the postulates for base revisions\noperator satisfies.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.03256,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000016557,
      "text":"Diversity and Inclusion Metrics in Subset Selection\n\n  The ethical concept of fairness has recently been applied in machine learning\n(ML) settings to describe a wide range of constraints and objectives. When\nconsidering the relevance of ethical concepts to subset selection problems, the\nconcepts of diversity and inclusion are additionally applicable in order to\ncreate outputs that account for social power and access differentials. We\nintroduce metrics based on these concepts, which can be applied together,\nseparately, and in tandem with additional fairness constraints. Results from\nhuman subject experiments lend support to the proposed criteria. Social choice\nmethods can additionally be leveraged to aggregate and choose preferable sets,\nand we detail how these may be applied.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.11485,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000012252,
      "text":"A machine-learning software-systems approach to capture social,\n  regulatory, governance, and climate problems\n\n  This paper will discuss the role of an artificially-intelligent computer\nsystem as critique-based, implicit-organizational, and an inherently necessary\ndevice, deployed in synchrony with parallel governmental policy, as a genuine\nmeans of capturing nation-population complexity in quantitative form, public\ncontentment in societal-cooperative economic groups, regulatory proposition,\nand governance-effectiveness domains. It will discuss a solution involving a\nwell-known algorithm and proffer an improved mechanism for\nknowledge-representation, thereby increasing range of utility, scope of\ninfluence (in terms of differentiating class sectors) and operational\nefficiency. It will finish with a discussion of these and other historical\nimplications.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.02334,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Self-recognition in conversational agents\n\n  In a standard Turing test, a machine has to prove its humanness to the\njudges. By successfully imitating a thinking entity such as a human, this\nmachine then proves that it can also think. Some objections claim that Turing\ntest is not a tool to demonstrate the existence of general intelligence or\nthinking activity. A compelling alternative is the Lovelace test, in which the\nagent must originate a product that the agent's creator cannot explain.\nTherefore, the agent must be the owner of an original product. However, for\nthis to happen the agent must exhibit the idea of self and distinguish oneself\nfrom others. Sustaining the idea of self within the Turing test is still\npossible if the judge decides to act as a textual mirror. Self-recognition\ntests applied on animals through mirrors appear to be viable tools to\ndemonstrate the existence of a type of general intelligence. Methodology here\nconstructs a textual version of the mirror test by placing the agent as the one\nand only judge to figure out whether the contacted one is an other, a mimicker,\nor oneself in an unsupervised manner. This textual version of the mirror test\nis objective, self-contained, and devoid of humanness. Any agent passing this\ntextual mirror test should have or can acquire a thought mechanism that can be\nreferred to as the inner-voice, answering the original and long lasting\nquestion of Turing \"Can machines think?\" in a constructive manner still within\nthe bounds of the Turing test. Moreover, it is possible that a successful\nself-recognition might pave way to stronger notions of self-awareness in\nartificial beings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.0208,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000034438,
      "text":"Temporal-adaptive Hierarchical Reinforcement Learning\n\n  Hierarchical reinforcement learning (HRL) helps address large-scale and\nsparse reward issues in reinforcement learning. In HRL, the policy model has an\ninner representation structured in levels. With this structure, the\nreinforcement learning task is expected to be decomposed into corresponding\nlevels with sub-tasks, and thus the learning can be more efficient. In HRL,\nalthough it is intuitive that a high-level policy only needs to make macro\ndecisions in a low frequency, the exact frequency is hard to be simply\ndetermined. Previous HRL approaches often employed a fixed-time skip strategy\nor learn a terminal condition without taking account of the context, which,\nhowever, not only requires manual adjustments but also sacrifices some decision\ngranularity. In this paper, we propose the \\emph{temporal-adaptive hierarchical\npolicy learning} (TEMPLE) structure, which uses a temporal gate to adaptively\ncontrol the high-level policy decision frequency. We train the TEMPLE structure\nwith PPO and test its performance in a range of environments including 2-D\nrooms, Mujoco tasks, and Atari games. The results show that the TEMPLE\nstructure can lead to improved performance in these environments with a\nsequential adaptive high-level control.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.12441,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"An efficient constraint based framework forhandling floating point SMT\n  problems\n\n  This paper introduces the 2019 version of \\us{}, a novel Constraint\nProgramming framework for floating point verification problems expressed with\nthe SMT language of SMTLIB. SMT solvers decompose their task by delegating to\nspecific theories (e.g., floating point, bit vectors, arrays, ...) the task to\nreason about combinatorial or otherwise complex constraints for which the SAT\nencoding would be cumbersome or ineffective. This decomposition and encoding\nprocesses lead to the obfuscation of the high-level constraints and a loss of\ninformation on the structure of the combinatorial model. In \\us{}, constraints\nover the floats are first class objects, and the purpose is to expose and\nexploit structures of floating point domains to enhance the search process. A\nsymbolic phase rewrites each SMTLIB instance to elementary constraints, and\neliminates auxiliary variables whose presence is counterproductive. A\ndiversification technique within the search steers it away from costly\nenumerations in unproductive areas of the search space. The empirical\nevaluation demonstrates that the 2019 version of \\us{} is competitive on\ncomputationally challenging floating point benchmarks that induce significant\nsearch efforts even for other CP solvers. It highlights that the ability to\nharness both inference and search is critical. Indeed, it yields a factor 3\nimprovement over Colibri and is up to 10 times faster than SMT solvers. The\nevaluation was conducted over 214 benchmarks (The Griggio suite) which is a\nstandard within SMTLIB.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.06261,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000055962,
      "text":"Stress Test Evaluation of Transformer-based Models in Natural Language\n  Understanding Tasks\n\n  There has been significant progress in recent years in the field of Natural\nLanguage Processing thanks to the introduction of the Transformer architecture.\nCurrent state-of-the-art models, via a large number of parameters and\npre-training on massive text corpus, have shown impressive results on several\ndownstream tasks. Many researchers have studied previous (non-Transformer)\nmodels to understand their actual behavior under different scenarios, showing\nthat these models are taking advantage of clues or failures of datasets and\nthat slight perturbations on the input data can severely reduce their\nperformance. In contrast, recent models have not been systematically tested\nwith adversarial-examples in order to show their robustness under severe stress\nconditions. For that reason, this work evaluates three Transformer-based models\n(RoBERTa, XLNet, and BERT) in Natural Language Inference (NLI) and Question\nAnswering (QA) tasks to know if they are more robust or if they have the same\nflaws as their predecessors. As a result, our experiments reveal that RoBERTa,\nXLNet and BERT are more robust than recurrent neural network models to stress\ntests for both NLI and QA tasks. Nevertheless, they are still very fragile and\ndemonstrate various unexpected behaviors, thus revealing that there is still\nroom for future improvement in this field.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.01088,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000007285,
      "text":"Neuro-evolutionary Frameworks for Generalized Learning Agents\n\n  The recent successes of deep learning and deep reinforcement learning have\nfirmly established their statuses as state-of-the-art artificial learning\ntechniques. However, longstanding drawbacks of these approaches, such as their\npoor sample efficiencies and limited generalization capabilities point to a\nneed for re-thinking the way such systems are designed and deployed. In this\npaper, we emphasize how the use of these learning systems, in conjunction with\na specific variation of evolutionary algorithms could lead to the emergence of\nunique characteristics such as the automated acquisition of a variety of\ndesirable behaviors and useful sets of behavior priors. This could pave the way\nfor learning to occur in a generalized and continual manner, with minimal\ninteractions with the environment. We discuss the anticipated improvements from\nsuch neuro-evolutionary frameworks, along with the associated challenges, as\nwell as its potential for application to a number of research areas.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.05104,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Development of an Expert System for Diabetic Type-2 Diet\n\n  A successful intelligent control of patient food for treatment purpose must\ncombines patient interesting food list and doctors efficient treatment food\nlist. Actually, many rural communities in Sudan have extremely limited access\nto diabetic diet centers. People travel long distances to clinics or medical\nfacilities, and there is a shortage of medical experts in most of these\nfacilities. This results in slow service, and patients end up waiting long\nhours without receiving any attention. Hence diabetic diet expert systems can\nplay a significant role in such cases where medical experts are not readily\navailable. This paper presents the design and implementation of an intelligent\nmedical expert system for diabetes diet that intended to be used in Sudan. The\ndevelopment of the proposed expert system went through a number of stages such\nproblem and need identification, requirements analysis, knowledge acquisition,\nformalization, design and implementation. Visual prolog was used for designing\nthe graphical user interface and the implementation of the system. The proposed\nexpert system is a promising helpful tool that reduces the workload for\nphysicians and provides diabetics with simple and valuable assistance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.04733,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"Mech-Elites: Illuminating the Mechanic Space of GVGAI\n\n  This paper introduces a fully automatic method of mechanic illumination for\ngeneral video game level generation. Using the Constrained MAP-Elites algorithm\nand the GVG-AI framework, this system generates the simplest tile based levels\nthat contain specific sets of game mechanics and also satisfy playability\nconstraints. We apply this method to illuminate mechanic space for $4$\ndifferent games in GVG-AI: Zelda, Solarfox, Plants, and RealPortals.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.08103,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000029471,
      "text":"Knowledge-Based Matching of $n$-ary Tuples\n\n  An increasing number of data and knowledge sources are accessible by human\nand software agents in the expanding Semantic Web. Sources may differ in\ngranularity or completeness, and thus be complementary. Consequently, they\nshould be reconciled in order to unlock the full potential of their conjoint\nknowledge. In particular, units should be matched within and across sources,\nand their level of relatedness should be classified into equivalent, more\nspecific, or similar. This task is challenging since knowledge units can be\nheterogeneously represented in sources (e.g., in terms of vocabularies). In\nthis paper, we focus on matching n-ary tuples in a knowledge base with a\nrule-based methodology. To alleviate heterogeneity issues, we rely on domain\nknowledge expressed by ontologies. We tested our method on the biomedical\ndomain of pharmacogenomics by searching alignments among 50,435 n-ary tuples\nfrom four different real-world sources. Results highlight noteworthy agreements\nand particularities within and across sources.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.09636,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.000002914,
      "text":"Conceptual Game Expansion\n\n  Automated game design is the problem of automatically producing games through\ncomputational processes. Traditionally, these methods have relied on the\nauthoring of search spaces by a designer, defining the space of all possible\ngames for the system to author. In this paper, we instead learn representations\nof existing games from gameplay video and use these to approximate a search\nspace of novel games. In a human subject study we demonstrate that these novel\ngames are indistinguishable from human games in terms of challenge, and that\none of the novel games was equivalent to one of the human games in terms of\nfun, frustration, and likeability.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.04827,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000025166,
      "text":"Approximate MMAP by Marginal Search\n\n  We present a heuristic strategy for marginal MAP (MMAP) queries in graphical\nmodels. The algorithm is based on a reduction of the task to a polynomial\nnumber of marginal inference computations. Given an input evidence, the\nmarginals mass functions of the variables to be explained are computed.\nMarginal information gain is used to decide the variables to be explained\nfirst, and their most probable marginal states are consequently moved to the\nevidence. The sequential iteration of this procedure leads to a MMAP\nexplanation and the minimum information gain obtained during the process can be\nregarded as a confidence measure for the explanation. Preliminary experiments\nshow that the proposed confidence measure is properly detecting instances for\nwhich the algorithm is accurate and, for sufficiently high confidence levels,\nthe algorithm gives the exact solution or an approximation whose Hamming\ndistance from the exact one is small.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2002.07985,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"Interpreting Interpretations: Organizing Attribution Methods by Criteria\n\n  Motivated by distinct, though related, criteria, a growing number of\nattribution methods have been developed tointerprete deep learning. While each\nrelies on the interpretability of the concept of \"importance\" and our ability\nto visualize patterns, explanations produced by the methods often differ. As a\nresult, input attribution for vision models fail to provide any level of human\nunderstanding of model behaviour. In this work we expand the foundationsof\nhuman-understandable concepts with which attributionscan be interpreted beyond\n\"importance\" and its visualization; we incorporate the logical concepts of\nnecessity andsufficiency, and the concept of proportionality. We definemetrics\nto represent these concepts as quantitative aspectsof an attribution. This\nallows us to compare attributionsproduced by different methods and interpret\nthem in novelways: to what extent does this attribution (or this\nmethod)represent the necessity or sufficiency of the highlighted inputs, and to\nwhat extent is it proportional? We evaluate our measures on a collection of\nmethods explaining convolutional neural networks (CNN) for image\nclassification. We conclude that some attribution methods are more appropriate\nfor interpretation in terms of necessity while others are in terms of\nsufficiency, while no method is always the most appropriate in terms of both.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.00683,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000058611,
      "text":"Detection and Mitigation of Bias in Ted Talk Ratings\n\n  Unbiased data collection is essential to guaranteeing fairness in artificial\nintelligence models. Implicit bias, a form of behavioral conditioning that\nleads us to attribute predetermined characteristics to members of certain\ngroups and informs the data collection process. This paper quantifies implicit\nbias in viewer ratings of TEDTalks, a diverse social platform assessing social\nand professional performance, in order to present the correlations of different\nkinds of bias across sensitive attributes. Although the viewer ratings of these\nvideos should purely reflect the speaker's competence and skill, our analysis\nof the ratings demonstrates the presence of overwhelming and predominant\nimplicit bias with respect to race and gender. In our paper, we present\nstrategies to detect and mitigate bias that are critical to removing unfairness\nin AI.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.09746,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000086096,
      "text":"Adaptive Informative Path Planning with Multimodal Sensing\n\n  Adaptive Informative Path Planning (AIPP) problems model an agent tasked with\nobtaining information subject to resource constraints in unknown, partially\nobservable environments. Existing work on AIPP has focused on representing\nobservations about the world as a result of agent movement. We formulate the\nmore general setting where the agent may choose between different sensors at\nthe cost of some energy, in addition to traversing the environment to gather\ninformation. We call this problem AIPPMS (MS for Multimodal Sensing). AIPPMS\nrequires reasoning jointly about the effects of sensing and movement in terms\nof both energy expended and information gained. We frame AIPPMS as a Partially\nObservable Markov Decision Process (POMDP) and solve it with online planning.\nOur approach is based on the Partially Observable Monte Carlo Planning\nframework with modifications to ensure constraint feasibility and a heuristic\nrollout policy tailored for AIPPMS. We evaluate our method on two domains: a\nsimulated search-and-rescue scenario and a challenging extension to the classic\nRockSample problem. We find that our approach outperforms a classic AIPP\nalgorithm that is modified for AIPPMS, as well as online planning using a\nrandom rollout policy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.00425,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"A hybrid optimization procedure for solving a tire curing scheduling\n  problem\n\n  This paper addresses a lot-sizing and scheduling problem variant arising from\nthe study of the curing process of a tire factory. The aim is to find the\nminimum makespan needed for producing enough tires to meet the demand\nrequirements on time, considering the availability and compatibility of\ndifferent resources involved. To solve this problem, we suggest a hybrid\napproach that consists in first applying a heuristic to obtain an estimated\nvalue of the makespan and then solving a mathematical model to determine the\nminimum value. We note that the size of the model (number of variables and\nconstraints) depends significantly on the estimated makespan. Extensive\nnumerical experiments over different instances based on real data are presented\nto evaluate the effectiveness of the hybrid procedure proposed. From the\nresults obtained we can note that the hybrid approach is able to achieve the\noptimal makespan for many of the instances, even large ones, since the results\nprovided by the heuristic allow to reduce significantly the size of the\nmathematical model.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.0477,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000088414,
      "text":"A Comparative Study on Parameter Estimation in Software Reliability\n  Modeling using Swarm Intelligence\n\n  This work focuses on a comparison between the performances of two well-known\nSwarm algorithms: Cuckoo Search (CS) and Firefly Algorithm (FA), in estimating\nthe parameters of Software Reliability Growth Models. This study is further\nreinforced using Particle Swarm Optimization (PSO) and Ant Colony Optimization\n(ACO). All algorithms are evaluated according to real software failure data,\nthe tests are performed and the obtained results are compared to show the\nperformance of each of the used algorithms. Furthermore, CS and FA are also\ncompared with each other on bases of execution time and iteration number.\nExperimental results show that CS is more efficient in estimating the\nparameters of SRGMs, and it has outperformed FA in addition to PSO and ACO for\nthe selected Data sets and employed models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.00475,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000040399,
      "text":"GPM: A Generic Probabilistic Model to Recover Annotator's Behavior and\n  Ground Truth Labeling\n\n  In the big data era, data labeling can be obtained through crowdsourcing.\nNevertheless, the obtained labels are generally noisy, unreliable or even\nadversarial. In this paper, we propose a probabilistic graphical annotation\nmodel to infer the underlying ground truth and annotator's behavior. To\naccommodate both discrete and continuous application scenarios (e.g.,\nclassifying scenes vs. rating videos on a Likert scale), the underlying ground\ntruth is considered following a distribution rather than a single value. In\nthis way, the reliable but potentially divergent opinions from \"good\"\nannotators can be recovered. The proposed model is able to identify whether an\nannotator has worked diligently towards the task during the labeling procedure,\nwhich could be used for further selection of qualified annotators. Our model\nhas been tested on both simulated data and real-world data, where it always\nshows superior performance than the other state-of-the-art models in terms of\naccuracy and robustness.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.09529,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Imagination-Augmented Deep Learning for Goal Recognition\n\n  Being able to infer the goal of people we observe, interact with, or read\nstories about is one of the hallmarks of human intelligence. A prominent idea\nin current goal-recognition research is to infer the likelihood of an agent's\ngoal from the estimations of the costs of plans to the different goals the\nagent might have. Different approaches implement this idea by relying only on\nhandcrafted symbolic representations. Their application to real-world settings\nis, however, quite limited, mainly because extracting rules for the factors\nthat influence goal-oriented behaviors remains a complicated task. In this\npaper, we introduce a novel idea of using a symbolic planner to compute\nplan-cost insights, which augment a deep neural network with an imagination\ncapability, leading to improved goal recognition accuracy in real and synthetic\ndomains compared to a symbolic recognizer or a deep-learning goal recognizer\nalone.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.1137,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000117885,
      "text":"Semantic interoperability based on the European Materials and Modelling\n  Ontology and its ontological paradigm: Mereosemiotics\n\n  The European Materials and Modelling Ontology (EMMO) has recently been\nadvanced in the computational molecular engineering and multiscale modelling\ncommunities as a top-level ontology, aiming to support semantic\ninteroperability and data integration solutions, e.g., for research data\ninfrastructures. The present work explores how top-level ontologies that are\nbased on the same paradigm - the same set of fundamental postulates - as the\nEMMO can be applied to models of physical systems and their use in\ncomputational engineering practice. This paradigm, which combines mereology (in\nits extension as mereotopology) and semiotics (following Peirce's approach), is\nhere referred to as mereosemiotics. Multiple conceivable ways of implementing\nmereosemiotics are compared, and the design space consisting of the possible\ntypes of top-level ontologies following this paradigm is characterized.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.1052,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Neural Game Engine: Accurate learning of generalizable forward models\n  from pixels\n\n  Access to a fast and easily copied forward model of a game is essential for\nmodel-based reinforcement learning and for algorithms such as Monte Carlo tree\nsearch, and is also beneficial as a source of unlimited experience data for\nmodel-free algorithms. Learning forward models is an interesting and important\nchallenge in order to address problems where a model is not available. Building\nupon previous work on the Neural GPU, this paper introduces the Neural Game\nEngine, as a way to learn models directly from pixels. The learned models are\nable to generalise to different size game levels to the ones they were trained\non without loss of accuracy. Results on 10 deterministic General Video Game AI\ngames demonstrate competitive performance, with many of the games models being\nlearned perfectly both in terms of pixel predictions and reward predictions.\nThe pre-trained models are available through the OpenAI Gym interface and are\navailable publicly for future research here:\n\\url{https:\/\/github.com\/Bam4d\/Neural-Game-Engine}\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.13668,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"Increasing negotiation performance at the edge of the network\n\n  Automated negotiation has been used in a variety of distributed settings,\nsuch as privacy in the Internet of Things (IoT) devices and power distribution\nin Smart Grids. The most common protocol under which these agents negotiate is\nthe Alternating Offers Protocol (AOP). Under this protocol, agents cannot\nexpress any additional information to each other besides a counter offer. This\ncan lead to unnecessarily long negotiations when, for example, negotiations are\nimpossible, risking to waste bandwidth that is a precious resource at the edge\nof the network. While alternative protocols exist which alleviate this problem,\nthese solutions are too complex for low power devices, such as IoT sensors\noperating at the edge of the network. To improve this bottleneck, we introduce\nan extension to AOP called Alternating Constrained Offers Protocol (ACOP), in\nwhich agents can also express constraints to each other. This allows agents to\nboth search the possibility space more efficiently and recognise impossible\nsituations sooner. We empirically show that agents using ACOP can significantly\nreduce the number of messages a negotiation takes, independently of the\nstrategy agents choose. In particular, we show our method significantly reduces\nthe number of messages when an agreement is not possible. Furthermore, when an\nagreement is possible it reaches this agreement sooner with no negative effect\non the utility.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.09661,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000060929,
      "text":"Basic concepts, definitions, and methods in D number theory\n\n  As a generalization of Dempster-Shafer theory, D number theory (DNT) aims to\nprovide a framework to deal with uncertain information with non-exclusiveness\nand incompleteness. Although there are some advances on DNT in previous\nstudies, however, they lack of systematicness, and many important issues have\nnot yet been solved. In this paper, several crucial aspects in constructing a\nperfect and systematic framework of DNT are considered. At first the\nnon-exclusiveness in DNT is formally defined and discussed. Secondly, a method\nto combine multiple D numbers is proposed by extending previous exclusive\nconflict redistribution (ECR) rule. Thirdly, a new pair of belief and\nplausibility measures for D numbers are defined and many desirable properties\nare satisfied by the proposed measures. Fourthly, the combination of\ninformation-incomplete D numbers is studied specially to show how to deal with\nthe incompleteness of information in DNT. In this paper, we mainly give\nrelative math definitions, properties, and theorems, concrete examples and\napplications will be considered in the future study.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.01008,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000056624,
      "text":"Learning and Solving Regular Decision Processes\n\n  Regular Decision Processes (RDPs) are a recently introduced model that\nextends MDPs with non-Markovian dynamics and rewards. The non-Markovian\nbehavior is restricted to depend on regular properties of the history. These\ncan be specified using regular expressions or formulas in linear dynamic logic\nover finite traces. Fully specified RDPs can be solved by compiling them into\nan appropriate MDP. Learning RDPs from data is a challenging problem that has\nyet to be addressed, on which we focus in this paper. Our approach rests on a\nnew representation for RDPs using Mealy Machines that emit a distribution and\nan expected reward for each state-action pair. Building on this representation,\nwe combine automata learning techniques with history clustering to learn such a\nMealy machine and solve it by adapting MCTS to it. We empirically evaluate this\napproach, demonstrating its feasibility.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.04445,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000012252,
      "text":"Convex Hull Monte-Carlo Tree Search\n\n  This work investigates Monte-Carlo planning for agents in stochastic\nenvironments, with multiple objectives. We propose the Convex Hull Monte-Carlo\nTree-Search (CHMCTS) framework, which builds upon Trial Based Heuristic Tree\nSearch and Convex Hull Value Iteration (CHVI), as a solution to multi-objective\nplanning in large environments. Moreover, we consider how to pose the problem\nof approximating multiobjective planning solutions as a contextual multi-armed\nbandits problem, giving a principled motivation for how to select actions from\nthe view of contextual regret. This leads us to the use of Contextual Zooming\nfor action selection, yielding Zooming CHMCTS. We evaluate our algorithm using\nthe Generalised Deep Sea Treasure environment, demonstrating that Zooming\nCHMCTS can achieve a sublinear contextual regret and scales better than CHVI on\na given computational budget.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.08727,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Decentralized MCTS via Learned Teammate Models\n\n  Decentralized online planning can be an attractive paradigm for cooperative\nmulti-agent systems, due to improved scalability and robustness. A key\ndifficulty of such approach lies in making accurate predictions about the\ndecisions of other agents. In this paper, we present a trainable online\ndecentralized planning algorithm based on decentralized Monte Carlo Tree\nSearch, combined with models of teammates learned from previous episodic runs.\nBy only allowing one agent to adapt its models at a time, under the assumption\nof ideal policy approximation, successive iterations of our method are\nguaranteed to improve joint policies, and eventually lead to convergence to a\nNash equilibrium. We test the efficiency of the algorithm by performing\nexperiments in several scenarios of the spatial task allocation environment\nintroduced in [Claes et al., 2015]. We show that deep learning and\nconvolutional neural networks can be employed to produce accurate policy\napproximators which exploit the spatial features of the problem, and that the\nproposed algorithm improves over the baseline planning performance for\nparticularly challenging domain configurations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.00749,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"A general framework for scientifically inspired explanations in AI\n\n  Explainability in AI is gaining attention in the computer science community\nin response to the increasing success of deep learning and the important need\nof justifying how such systems make predictions in life-critical applications.\nThe focus of explainability in AI has predominantly been on trying to gain\ninsights into how machine learning systems function by exploring relationships\nbetween input data and predicted outcomes or by extracting simpler\ninterpretable models. Through literature surveys of philosophy and social\nscience, authors have highlighted the sharp difference between these generated\nexplanations and human-made explanations and claimed that current explanations\nin AI do not take into account the complexity of human interaction to allow for\neffective information passing to not-expert users. In this paper we instantiate\nthe concept of structure of scientific explanation as the theoretical\nunderpinning for a general framework in which explanations for AI systems can\nbe implemented. This framework aims to provide the tools to build a\n\"mental-model\" of any AI system so that the interaction with the user can\nprovide information on demand and be closer to the nature of human-made\nexplanations. We illustrate how we can utilize this framework through two very\ndifferent examples: an artificial neural network and a Prolog solver and we\nprovide a possible implementation for both examples.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.1359,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000062254,
      "text":"Suphx: Mastering Mahjong with Deep Reinforcement Learning\n\n  Artificial Intelligence (AI) has achieved great success in many domains, and\ngame AI is widely regarded as its beachhead since the dawn of AI. In recent\nyears, studies on game AI have gradually evolved from relatively simple\nenvironments (e.g., perfect-information games such as Go, chess, shogi or\ntwo-player imperfect-information games such as heads-up Texas hold'em) to more\ncomplex ones (e.g., multi-player imperfect-information games such as\nmulti-player Texas hold'em and StartCraft II). Mahjong is a popular\nmulti-player imperfect-information game worldwide but very challenging for AI\nresearch due to its complex playing\/scoring rules and rich hidden information.\nWe design an AI for Mahjong, named Suphx, based on deep reinforcement learning\nwith some newly introduced techniques including global reward prediction,\noracle guiding, and run-time policy adaptation. Suphx has demonstrated stronger\nperformance than most top human players in terms of stable rank and is rated\nabove 99.99% of all the officially ranked human players in the Tenhou platform.\nThis is the first time that a computer program outperforms most top human\nplayers in Mahjong.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.13159,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"Extending Automated Deduction for Commonsense Reasoning\n\n  Commonsense reasoning has long been considered as one of the holy grails of\nartificial intelligence. Most of the recent progress in the field has been\nachieved by novel machine learning algorithms for natural language processing.\nHowever, without incorporating logical reasoning, these algorithms remain\narguably shallow. With some notable exceptions, developers of practical\nautomated logic-based reasoners have mostly avoided focusing on the problem.\nThe paper argues that the methods and algorithms used by existing automated\nreasoners for classical first-order logic can be extended towards commonsense\nreasoning. Instead of devising new specialized logics we propose a framework of\nextensions to the mainstream resolution-based search methods to make these\ncapable of performing search tasks for practical commonsense reasoning with\nreasonable efficiency. The proposed extensions mostly rely on operating on\nordinary proof trees and are devised to handle commonsense knowledge bases\ncontaining inconsistencies, default rules, taxonomies, topics, relevance,\nconfidence and similarity measures. We claim that machine learning is best\nsuited for the construction of commonsense knowledge bases while the extended\nlogic-based methods would be well-suited for actually answering queries from\nthese knowledge bases.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.00806,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"Causal Transfer for Imitation Learning and Decision Making under\n  Sensor-shift\n\n  Learning from demonstrations (LfD) is an efficient paradigm to train AI\nagents. But major issues arise when there are differences between (a) the\ndemonstrator's own sensory input, (b) our sensors that observe the demonstrator\nand (c) the sensory input of the agent we train. In this paper, we propose a\ncausal model-based framework for transfer learning under such \"sensor-shifts\",\nfor two common LfD tasks: (1) inferring the effect of the demonstrator's\nactions and (2) imitation learning. First we rigorously analyze, on the\npopulation-level, to what extent the relevant underlying mechanisms (the action\neffects and the demonstrator policy) can be identified and transferred from the\navailable observations together with prior knowledge of sensor characteristics.\nAnd we device an algorithm to infer these mechanisms. Then we introduce several\nproxy methods which are easier to calculate, estimate from finite data and\ninterpret than the exact solutions, alongside theoretical bounds on their\ncloseness to the exact ones. We validate our two main methods on simulated and\nsemi-real world data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.01207,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"BARD: A structured technique for group elicitation of Bayesian networks\n  to support analytic reasoning\n\n  In many complex, real-world situations, problem solving and decision making\nrequire effective reasoning about causation and uncertainty. However, human\nreasoning in these cases is prone to confusion and error. Bayesian networks\n(BNs) are an artificial intelligence technology that models uncertain\nsituations, supporting probabilistic and causal reasoning and decision making.\nHowever, to date, BN methodologies and software require significant upfront\ntraining, do not provide much guidance on the model building process, and do\nnot support collaboratively building BNs. BARD (Bayesian ARgumentation via\nDelphi) is both a methodology and an expert system that utilises (1) BNs as the\nunderlying structured representations for better argument analysis, (2) a\nmulti-user web-based software platform and Delphi-style social processes to\nassist with collaboration, and (3) short, high-quality e-courses on demand, a\nhighly structured process to guide BN construction, and a variety of helpful\ntools to assist in building and reasoning with BNs, including an automated\nexplanation tool to assist effective report writing. The result is an\nend-to-end online platform, with associated online training, for groups without\nprior BN expertise to understand and analyse a problem, build a model of its\nunderlying probabilistic causal structure, validate and reason with the causal\nmodel, and use it to produce a written analytic report. Initial experimental\nresults demonstrate that BARD aids in problem solving, reasoning and\ncollaboration.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.13633,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Coronavirus Optimization Algorithm: A bioinspired metaheuristic based on\n  the COVID-19 propagation model\n\n  A novel bioinspired metaheuristic is proposed in this work, simulating how\nthe coronavirus spreads and infects healthy people. From an initial individual\n(the patient zero), the coronavirus infects new patients at known rates,\ncreating new populations of infected people. Every individual can either die or\ninfect and, afterwards, be sent to the recovered population. Relevant terms\nsuch as re-infection probability, super-spreading rate or traveling rate are\nintroduced in the model in order to simulate as accurately as possible the\ncoronavirus activity. The Coronavirus Optimization Algorithm has two major\nadvantages compared to other similar strategies. First, the input parameters\nare already set according to the disease statistics, preventing researchers\nfrom initializing them with arbitrary values. Second, the approach has the\nability of ending after several iterations, without setting this value either.\nInfected population initially grows at an exponential rate but after some\niterations, when considering social isolation measures and the high number\nrecovered and dead people, the number of infected people starts decreasing in\nsubsequent iterations. Furthermore, a parallel multi-virus version is proposed\nin which several coronavirus strains evolve over time and explore wider search\nspace areas in less iterations. Finally, the metaheuristic has been combined\nwith deep learning models, in order to find optimal hyperparameters during the\ntraining phase. As application case, the problem of electricity load time\nseries forecasting has been addressed, showing quite remarkable performance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2003.0532,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000005298,
      "text":"How the Brain might use Division\n\n  One of the most fundamental questions in Biology or Artificial Intelligence\nis how the human brain performs mathematical functions. How does a neural\narchitecture that may organise itself mostly through statistics, know what to\ndo? One possibility is to extract the problem to something more abstract. This\nbecomes clear when thinking about how the brain handles large numbers, for\nexample to the power of something, when simply summing to an answer is not\nfeasible. In this paper, the author suggests that the maths question can be\nanswered more easily if the problem is changed into one of symbol manipulation\nand not just number counting. If symbols can be compared and manipulated, maybe\nwithout understanding completely what they are, then the mathematical\noperations become relative and some of them might even be rote learned. The\nproposed system may also be suggested as an alternative to the traditional\ncomputer binary system. Any of the actual maths still breaks down into binary\noperations, while a more symbolic level above that can manipulate the numbers\nand reduce the problem size, thus making the binary operations simpler. An\ninteresting result of looking at this is the possibility of a new fractal\nequation resulting from division, that can be used as a measure of good fit and\nwould help the brain decide how to solve something through self-replacement and\na comparison with this good fit.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.0592,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Game-theoretic applications of a relational risk model\n\n  The report suggests the concept of risk, outlining two mathematical\nstructures necessary for risk genesis: the set of outcomes and, in a general\ncase, partial order of preference on it. It is shown that this minimum partial\norder should constitute the structure of a semilattice. In some cases, there\nshould be a system of semilattices nested in a certain way. On this basis, the\nclassification of risk theory tasks is given in the context of specialization\nof mathematical knowledge. In other words, we are talking about the development\nof a new rela-tional risk theory. The problem of political decision making in\ngame-theoretic formulation in terms of having partial order of preference on\nthe set of outcomes for each par-ticipant of the game forming a certain system\nof nested semilattices is consid-ered as an example of a relational risk\nconcept implementation. Solutions to the problem obtained through the use of\nvarious optimality principles are investi-gated.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.13529,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000114905,
      "text":"Augmented Behavioral Cloning from Observation\n\n  Imitation from observation is a computational technique that teaches an agent\non how to mimic the behavior of an expert by observing only the sequence of\nstates from the expert demonstrations. Recent approaches learn the inverse\ndynamics of the environment and an imitation policy by interleaving epochs of\nboth models while changing the demonstration data. However, such approaches\noften get stuck into sub-optimal solutions that are distant from the expert,\nlimiting their imitation effectiveness. We address this problem with a novel\napproach that overcomes the problem of reaching bad local minima by exploring:\n(I) a self-attention mechanism that better captures global features of the\nstates; and (ii) a sampling strategy that regulates the observations that are\nused for learning. We show empirically that our approach outperforms the\nstate-of-the-art approaches in four different environments by a large margin.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.02746,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000119209,
      "text":"A new approach for generation of generalized basic probability\n  assignment in the evidence theory\n\n  The process of information fusion needs to deal with a large number of\nuncertain information with multi-source, heterogeneity, inaccuracy,\nunreliability, and incompleteness. In practical engineering applications,\nDempster-Shafer evidence theory is widely used in multi-source information\nfusion owing to its effectiveness in data fusion. Information sources have an\nimportant impact on multi-source information fusion in an environment of\ncomplex, unstable, uncertain, and incomplete characteristics. To address\nmulti-source information fusion problem, this paper considers the situation of\nuncertain information modeling from the closed world to the open world\nassumption and studies the generation of basic probability assignment (BPA)\nwith incomplete information. In this paper, a new method is proposed to\ngenerate generalized basic probability assignment (GBPA) based on the\ntriangular fuzzy number model under the open world assumption. The proposed\nmethod can not only be used in different complex environments simply and\nflexibly, but also have less information loss in information processing.\nFinally, a series of comprehensive experiments basing on the UCI data sets are\nused to verify the rationality and superiority of the proposed method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.04376,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000065896,
      "text":"ConsciousControlFlow(CCF): A Demonstration for conscious Artificial\n  Intelligence\n\n  In this demo, we present ConsciousControlFlow(CCF), a prototype system to\ndemonstrate conscious Artificial Intelligence (AI). The system is based on the\ncomputational model for consciousness and the hierarchy of needs. CCF supports\ntypical scenarios to show the behaviors and the mental activities of conscious\nAI. We demonstrate that CCF provides a useful tool for effective machine\nconsciousness demonstration and human behavior study assistance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.07822,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Order Matters: Generating Progressive Explanations for Planning Tasks in\n  Human-Robot Teaming\n\n  Prior work on generating explanations in a planning and decision-making\ncontext has focused on providing the rationale behind an AI agent's decision\nmaking. While these methods provide the right explanations from the explainer's\nperspective, they fail to heed the cognitive requirement of understanding an\nexplanation from the explainee's (the human's) perspective. In this work, we\nset out to address this issue by first considering the influence of information\norder in an explanation, or the progressiveness of explanations. Intuitively,\nprogression builds later concepts on previous ones and is known to contribute\nto better learning. In this work, we aim to investigate similar effects during\nexplanation generation when an explanation is broken into multiple parts that\nare communicated sequentially. The challenge here lies in modeling the humans'\npreferences for information order in receiving such explanations to assist\nunderstanding. Given this sequential process, a formulation based on goal-based\nMDP for generating progressive explanations is presented. The reward function\nof this MDP is learned via inverse reinforcement learning based on explanations\nthat are retrieved via human subject studies. We first evaluated our approach\non a scavenger-hunt domain to demonstrate its effectively in capturing the\nhumans' preferences. Upon analyzing the results, it revealed something more\nfundamental: the preferences arise strongly from both domain dependent and\nindependence features. The correlation with domain independent features pushed\nus to verify this result further in an escape room domain. Results confirmed\nour hypothesis that the process of understanding an explanation was a dynamic\nprocess. The human preference that reflected this aspect corresponded exactly\nto the progression for knowledge assimilation hidden deeper in our cognitive\nprocess.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.08128,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000031127,
      "text":"Whence the Expected Free Energy?\n\n  The Expected Free Energy (EFE) is a central quantity in the theory of active\ninference. It is the quantity that all active inference agents are mandated to\nminimize through action, and its decomposition into extrinsic and intrinsic\nvalue terms is key to the balance of exploration and exploitation that active\ninference agents evince. Despite its importance, the mathematical origins of\nthis quantity and its relation to the Variational Free Energy (VFE) remain\nunclear. In this paper, we investigate the origins of the EFE in detail and\nshow that it is not simply \"the free energy in the future\". We present a\nfunctional that we argue is the natural extension of the VFE, but which\nactively discourages exploratory behaviour, thus demonstrating that exploration\ndoes not directly follow from free energy minimization into the future. We then\ndevelop a novel objective, the Free-Energy of the Expected Future (FEEF), which\npossesses both the epistemic component of the EFE as well as an intuitive\nmathematical grounding as the divergence between predicted and desired futures.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.12193,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000005298,
      "text":"Machine Number Sense: A Dataset of Visual Arithmetic Problems for\n  Abstract and Relational Reasoning\n\n  As a comprehensive indicator of mathematical thinking and intelligence, the\nnumber sense (Dehaene 2011) bridges the induction of symbolic concepts and the\ncompetence of problem-solving. To endow such a crucial cognitive ability to\nmachine intelligence, we propose a dataset, Machine Number Sense (MNS),\nconsisting of visual arithmetic problems automatically generated using a\ngrammar model--And-Or Graph (AOG). These visual arithmetic problems are in the\nform of geometric figures: each problem has a set of geometric shapes as its\ncontext and embedded number symbols. Solving such problems is not trivial; the\nmachine not only has to recognize the number, but also to interpret the number\nwith its contexts, shapes, and relations (e.g., symmetry) together with proper\noperations. We benchmark the MNS dataset using four predominant neural network\nmodels as baselines in this visual reasoning task. Comprehensive experiments\nshow that current neural-network-based models still struggle to understand\nnumber concepts and relational operations. We show that a simple brute-force\nsearch algorithm could work out some of the problems without context\ninformation. Crucially, taking geometric context into account by an additional\nperception module would provide a sharp performance gain with fewer search\nsteps. Altogether, we call for attention in fusing the classic search-based\nalgorithms with modern neural networks to discover the essential number\nconcepts in future research.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.00981,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Benchmarking End-to-End Behavioural Cloning on Video Games\n\n  Behavioural cloning, where a computer is taught to perform a task based on\ndemonstrations, has been successfully applied to various video games and\nrobotics tasks, with and without reinforcement learning. This also includes\nend-to-end approaches, where a computer plays a video game like humans do: by\nlooking at the image displayed on the screen, and sending keystrokes to the\ngame. As a general approach to playing video games, this has many inviting\nproperties: no need for specialized modifications to the game, no lengthy\ntraining sessions and the ability to re-use the same tools across different\ngames. However, related work includes game-specific engineering to achieve the\nresults. We take a step towards a general approach and study the general\napplicability of behavioural cloning on twelve video games, including six\nmodern video games (published after 2010), by using human demonstrations as\ntraining data. Our results show that these agents cannot match humans in raw\nperformance but do learn basic dynamics and rules. We also demonstrate how the\nquality of the data matters, and how recording data from humans is subject to a\nstate-action mismatch, due to human reflexes.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.13482,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000164575,
      "text":"HAPRec: Hybrid Activity and Plan Recognizer\n\n  Computer-based assistants have recently attracted much interest due to its\napplicability to ambient assisted living. Such assistants have to detect and\nrecognize the high-level activities and goals performed by the assisted human\nbeings. In this work, we demonstrate activity recognition in an indoor\nenvironment in order to identify the goal towards which the subject of the\nvideo is pursuing. Our hybrid approach combines an action recognition module\nand a goal recognition algorithm to identify the ultimate goal of the subject\nin the video.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.01431,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0,
      "text":"Modeling Rare Interactions in Time Series Data Through Qualitative\n  Change: Application to Outcome Prediction in Intensive Care Units\n\n  Many areas of research are characterised by the deluge of large-scale\nhighly-dimensional time-series data. However, using the data available for\nprediction and decision making is hampered by the current lag in our ability to\nuncover and quantify true interactions that explain the outcomes.We are\ninterested in areas such as intensive care medicine, which are characterised by\ni) continuous monitoring of multivariate variables and non-uniform sampling of\ndata streams, ii) the outcomes are generally governed by interactions between a\nsmall set of rare events, iii) these interactions are not necessarily definable\nby specific values (or value ranges) of a given group of variables, but rather,\nby the deviations of these values from the normal state recorded over time, iv)\nthe need to explain the predictions made by the model. Here, while numerous\ndata mining models have been formulated for outcome prediction, they are unable\nto explain their predictions.\n  We present a model for uncovering interactions with the highest likelihood of\ngenerating the outcomes seen from highly-dimensional time series data.\nInteractions among variables are represented by a relational graph structure,\nwhich relies on qualitative abstractions to overcome non-uniform sampling and\nto capture the semantics of the interactions corresponding to the changes and\ndeviations from normality of variables of interest over time. Using the\nassumption that similar templates of small interactions are responsible for the\noutcomes (as prevalent in the medical domains), we reformulate the discovery\ntask to retrieve the most-likely templates from the data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.026,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000016888,
      "text":"Non-invasive modelling methodology for the diagnosis of Coronary Artery\n  Disease using Fuzzy Cognitive Maps\n\n  Cardiovascular Diseases (CVD) and strokes produce immense health and economic\nburdens globally. Coronary Artery Disease (CAD) is the most common type of\ncardiovascular disease. Coronary Angiography, which is an invasive treatment,\nis also the standard procedure for diagnosing CAD. In this work, we illustrate\na Medical Decision Support System for the prediction of Coronary Artery Disease\n(CAD) utilizing Fuzzy Cognitive Maps (FCMs). FCMs are a promising modeling\nmethodology, based on human knowledge, capable of dealing with ambiguity and\nuncertainty, and learning how to adapt to the unknown or changing environment.\nThe newly proposed MDSS is developed using the basic notions of Fuzzy Logic and\nFuzzy Cognitive Maps, with some adjustments to improve the results. The\nproposed model, tested on a labelled CAD dataset of 303 patients, obtains an\naccuracy of 78.2% outmatching several state-of-the-art classification\nalgorithms.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.13836,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000030796,
      "text":"Uncertainty Modelling in Risk-averse Supply Chain Systems Using\n  Multi-objective Pareto Optimization\n\n  One of the arduous tasks in supply chain modelling is to build robust models\nagainst irregular variations. During the proliferation of time-series analyses\nand machine learning models, several modifications were proposed such as\nacceleration of the classical levenberg-marquardt algorithm, weight decaying\nand normalization, which introduced an algorithmic optimization approach to\nthis problem. In this paper, we have introduced a novel methodology namely,\nPareto Optimization to handle uncertainties and bound the entropy of such\nuncertainties by explicitly modelling them under some apriori assumptions. We\nhave implemented Pareto Optimization using a genetic approach and compared the\nresults with classical genetic algorithms and Mixed-Integer Linear Programming\n(MILP) models. Our results yields empirical evidence suggesting that Pareto\nOptimization can elude such non-deterministic errors and is a formal approach\ntowards producing robust and reactive supply chain models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.07017,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.000006689,
      "text":"Ants can orienteer a thief in their robbery\n\n  The Thief Orienteering Problem (ThOP) is a multi-component problem that\ncombines features of two classic combinatorial optimization problems:\nOrienteering Problem and Knapsack Problem. The ThOP is challenging due to the\ngiven time constraint and the interaction between its components. We propose an\nAnt Colony Optimization algorithm together with a new packing heuristic to deal\nindividually and interactively with problem components. Our approach\noutperforms existing work on more than 90% of the benchmarking instances, with\nan average improvement of over 300%.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.02304,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"Morphological Computation and Learning to Learn In Natural Intelligent\n  Systems And AI\n\n  At present, artificial intelligence in the form of machine learning is making\nimpressive progress, especially the field of deep learning (DL) [1]. Deep\nlearning algorithms have been inspired from the beginning by nature,\nspecifically by the human brain, in spite of our incomplete knowledge about its\nbrain function. Learning from nature is a two-way process as discussed in\n[2][3][4], computing is learning from neuroscience, while neuroscience is\nquickly adopting information processing models. The question is, what can the\ninspiration from computational nature at this stage of the development\ncontribute to deep learning and how much models and experiments in machine\nlearning can motivate, justify and lead research in neuroscience and cognitive\nscience and to practical applications of artificial intelligence.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.11858,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000008941,
      "text":"Impact of different belief facets on agents' decision -- a refined\n  cognitive architecture to model the interaction between organisations'\n  institutional characteristics and agents' behaviour\n\n  This paper presents a conceptual refinement of agent cognitive architecture\ninspired from the beliefs-desires-intentions (BDI) and the theory of planned\nbehaviour (TPB) models, with an emphasis on different belief facets. This\nenables us to investigate the impact of personality and the way that an agent\nweights its internal beliefs and social sanctions on an agent's actions. The\nstudy also uses the concept of cognitive dissonance associated with the\nfairness of institutions to investigate the agents' behaviour. To showcase our\nmodel, we simulate two historical long-distance trading societies, namely\nArmenian merchants of New-Julfa and the English East India Company. The results\ndemonstrate the importance of internal beliefs of agents as a pivotal aspect\nfor following institutional rules.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.14933,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000019868,
      "text":"Perceptual reasoning based solution methodology for linguistic\n  optimization problems\n\n  Decision making in real-life scenarios may often be modeled as an\noptimization problem. It requires the consideration of various attributes like\nhuman preferences and thinking, which constrain achieving the optimal value of\nthe problem objectives. The value of the objectives may be maximized or\nminimized, depending on the situation. Numerous times, the values of these\nproblem parameters are in linguistic form, as human beings naturally understand\nand express themselves using words. These problems are therefore termed as\nlinguistic optimization problems (LOPs), and are of two types, namely single\nobjective linguistic optimization problems (SOLOPs) and multi-objective\nlinguistic optimization problems (MOLOPs). In these LOPs, the value of the\nobjective function(s) may not be known at all points of the decision space, and\ntherefore, the objective function(s) as well as problem constraints are linked\nby the if-then rules. Tsukamoto inference method has been used to solve these\nLOPs; however, it suffers from drawbacks. As, the use of linguistic information\ninevitably calls for the utilization of computing with words (CWW), and\ntherefore, 2-tuple linguistic model based solution methodologies were proposed\nfor LOPs. However, we found that 2-tuple linguistic model based solution\nmethodologies represent the semantics of the linguistic information using a\ncombination of type-1 fuzzy sets and ordinal term sets. As, the semantics of\nlinguistic information are best modeled using the interval type-2 fuzzy sets,\nhence we propose solution methodologies for LOPs based on CWW approach of\nperceptual computing, in this paper. The perceptual computing based solution\nmethodologies use a novel design of CWW engine, called the perceptual reasoning\n(PR). PR in the current form is suitable for solving SOLOPs and, hence, we have\nalso extended it to the MOLOPs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.13477,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0,
      "text":"Pushing the Envelope: From Discrete to Continuous Movements in\n  Multi-Agent Path Finding via Lazy Encodings\n\n  Multi-agent path finding in continuous space and time with geometric agents\nMAPF$^\\mathcal{R}$ is addressed in this paper. The task is to navigate agents\nthat move smoothly between predefined positions to their individual goals so\nthat they do not collide. We introduce a novel solving approach for obtaining\nmakespan optimal solutions called SMT-CBS$^\\mathcal{R}$ based on {\\em\nsatisfiability modulo theories} (SMT). The new algorithm combines collision\nresolution known from conflict-based search (CBS) with previous generation of\nincomplete SAT encodings on top of a novel scheme for selecting decision\nvariables in a potentially uncountable search space. We experimentally compare\nSMT-CBS$^\\mathcal{R}$ and previous CCBS algorithm for MAPF$^\\mathcal{R}$.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.04,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000026822,
      "text":"Learning from Learners: Adapting Reinforcement Learning Agents to be\n  Competitive in a Card Game\n\n  Learning how to adapt to complex and dynamic environments is one of the most\nimportant factors that contribute to our intelligence. Endowing artificial\nagents with this ability is not a simple task, particularly in competitive\nscenarios. In this paper, we present a broad study on how popular reinforcement\nlearning algorithms can be adapted and implemented to learn and to play a\nreal-world implementation of a competitive multiplayer card game. We propose\nspecific training and validation routines for the learning agents, in order to\nevaluate how the agents learn to be competitive and explain how they adapt to\neach others' playing style. Finally, we pinpoint how the behavior of each agent\nderives from their learning style and create a baseline for future research on\nthis scenario.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.01768,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"Generative Forensics: Procedural Generation and Information Games\n\n  Procedural generation is used across game design to achieve a wide variety of\nends, and has led to the creation of several game subgenres by injecting\nvariance, surprise or unpredictability into otherwise static designs.\nInformation games are a type of mystery game in which the player is tasked with\ngathering knowledge and developing an understanding of an event or system.\nTheir reliance on player knowledge leaves them vulnerable to spoilers and hard\nto replay. In this paper we introduce the notion of generative forensics games,\na subgenre of information games that challenge the player to understand the\noutput of a generative system. We introduce information games, show how\ngenerative forensics develops the idea, report on two prototype games we\ncreated, and evaluate our work on generative forensics so far from a player and\na designer perspective.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2004.14892,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"An empirical study of computing with words approaches for multi-person\n  and single-person systems\n\n  Computing with words (CWW) has emerged as a powerful tool for processing the\nlinguistic information, especially the one generated by human beings. Various\nCWW approaches have emerged since the inception of CWW, such as perceptual\ncomputing, extension principle based CWW approach, symbolic method based CWW\napproach, and 2-tuple based CWW approach. Furthermore, perceptual computing can\nuse interval approach (IA), enhanced interval approach (EIA), or Hao-Mendel\napproach (HMA), for data processing. There have been numerous works in which\nHMA was shown to be better at word modelling than EIA, and EIA better than IA.\nBut, a deeper study of these works reveals that HMA captures lesser fuzziness\nthan the EIA or IA. Thus, we feel that EIA is more suited for word modelling in\nmulti-person systems and HMA for single-person systems (as EIA is an\nimprovement over IA). Furthermore, another set of works, compared the\nperformances perceptual computing to the other above said CWW approaches. In\nall these works, perceptual computing was shown to be better than other CWW\napproaches. However, none of the works tried to investigate the reason behind\nthis observed better performance of perceptual computing. Also, no comparison\nhas been performed for scenarios where the inputs are differentially weighted.\nThus, the aim of this work is to empirically establish that EIA is suitable for\nmulti-person systems and HMA for single-person systems. Another dimension of\nthis work is also to empirically prove that perceptual computing gives better\nperformance than other CWW approaches based on extension principle, symbolic\nmethod and 2-tuple especially in scenarios where inputs are differentially\nweighted.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.05137,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"New Ideas for Brain Modelling 6\n\n  This paper describes implementation details for a 3-level cognitive model,\ndescribed in the paper series. The whole architecture is now modular, with\ndifferent levels using different types of information. The ensemble-hierarchy\nrelationship is maintained and placed in the bottom optimising and middle\naggregating levels, to store memory objects and their relations. The top-level\ncognitive layer has been re-designed to model the Cognitive Process Language\n(CPL) of an earlier paper, by refactoring it into a network structure with a\nlight scheduler. The cortex brain region is thought to be hierarchical -\nclustering from simple to more complex features. The refactored network might\ntherefore challenge conventional thinking on that brain region. It is also\nargued that the function and structure in particular, of the new top level, is\nsimilar to the psychology theory of chunking. The model is still only a\nframework and does not have enough information for real intelligence. But a\nframework is now implemented over the whole design and so can give a more\ncomplete picture about the potential for results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.14026,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000031458,
      "text":"An Exploratory Study of Hierarchical Fuzzy Systems Approach in\n  Recommendation System\n\n  Recommendation system or also known as a recommender system is a tool to help\nthe user in providing a suggestion of a specific dilemma. Thus, recently, the\ninterest in developing a recommendation system in many fields has increased.\nFuzzy Logic system (FLSs) is one of the approaches that can be used to model\nthe recommendation systems as it can deal with uncertainty and imprecise\ninformation. However, one of the fundamental issues in FLS is the problem of\nthe curse of dimensionality. That is, the number of rules in FLSs is increasing\nexponentially with the number of input variables. One effective way to overcome\nthis problem is by using Hierarchical Fuzzy System (HFSs). This paper aims to\nexplore the use of HFSs for Recommendation system. Specifically, we are\ninterested in exploring and comparing the HFS and FLS for the Career path\nrecommendation system (CPRS) based on four key criteria, namely topology, the\nnumber of rules, the rules structures and interpretability. The findings\nsuggested that the HFS has advantages over FLS towards improving the\ninterpretability models, in the context of a recommendation system example.\nThis study contributes to providing an insight into the development of\ninterpretable HFSs in the Recommendation systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.08425,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Finding the Loops that Matter\n\n  The Loops that Matter method (Schoenberg et. al, 2019) for understanding\nmodel behavior provides metrics showing the contribution of the feedback loops\nin a model to behavior at each point in time. To provide these metrics, it is\nnecessary find the set of loops on which to compute them. We show in this paper\nthe necessity of including loops that are important at different points in the\nsimulation. These important loops may not be independent of one another and\ncannot be determined from static analysis of the model structure. We then\ndescribe an algorithm that can be used to discover the most important loops in\nmodels that are too feedback rich for exhaustive loop discovery. We demonstrate\nthe use of this algorithm in terms of its ability to find the most explanatory\nloops, and its computational performance for large models. By using this\napproach, the Loops that Matter method can be applied to models of any size or\ncomplexity.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.08517,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000012583,
      "text":"Automatic Knowledge Acquisition for Object-Oriented Expert Systems\n\n  We describe an Object Oriented Model for building Expert Systems. This model\nand the detection of similarities allow to implement reasoning modes as\ninduction, deduction and simulation. We specially focus on similarity and its\nuse in induction. We propose original algorithms which deal with total and\npartial structural similitude of objects to facilitate knowledge acquisition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.13289,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Anytime Behavior of Inexact TSP Solvers and Perspectives for Automated\n  Algorithm Selection\n\n  The Traveling-Salesperson-Problem (TSP) is arguably one of the best-known\nNP-hard combinatorial optimization problems. The two sophisticated heuristic\nsolvers LKH and EAX and respective (restart) variants manage to calculate\nclose-to optimal or even optimal solutions, also for large instances with\nseveral thousand nodes in reasonable time. In this work we extend existing\nbenchmarking studies by addressing anytime behaviour of inexact TSP solvers\nbased on empirical runtime distributions leading to an increased understanding\nof solver behaviour and the respective relation to problem hardness. It turns\nout that performance ranking of solvers is highly dependent on the focused\napproximation quality. Insights on intersection points of performances offer\nhuge potential for the construction of hybridized solvers depending on instance\nfeatures. Moreover, instance features tailored to anytime performance and\ncorresponding performance indicators will highly improve automated algorithm\nselection models by including comprehensive information on solver quality.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.10131,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000049339,
      "text":"Combining the Causal Judgments of Experts with Possibly Different Focus\n  Areas\n\n  In many real-world settings, a decision-maker must combine information\nprovided by different experts in order to decide on an effective policy.\nAlrajeh, Chockler, and Halpern [2018] showed how to combine causal models that\nare compatible in the sense that, for variables that appear in both models, the\nexperts agree on the causal structure. In this work we show how causal models\ncan be combined in cases where the experts might disagree on the causal\nstructure for variables that appear in both models due to having different\nfocus areas. We provide a new formal definition of compatibility of models in\nthis setting and show how compatible models can be combined. We also consider\nthe complexity of determining whether models are compatible. We believe that\nthe notions defined in this work are of direct relevance to many practical\ndecision making scenarios that come up in natural, social, and medical science\nsettings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.03098,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000100997,
      "text":"Inference with Choice Functions Made Practical\n\n  We study how to infer new choices from previous choices in a conservative\nmanner. To make such inferences, we use the theory of choice functions: a\nunifying mathematical framework for conservative decision making that allows\none to impose axioms directly on the represented decisions. We here adopt the\ncoherence axioms of De Bock and De Cooman (2019). We show how to naturally\nextend any given choice assessment to such a coherent choice function, whenever\npossible, and use this natural extension to make new choices. We present a\npractical algorithm to compute this natural extension and provide several\nmethods that can be used to improve its scalability.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.08078,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000071526,
      "text":"Ontology and Cognitive Outcomes\n\n  Here we understand 'intelligence' as referring to items of knowledge\ncollected for the sake of assessing and maintaining national security. The\nintelligence community (IC) of the United States (US) is a community of\norganizations that collaborate in collecting and processing intelligence for\nthe US. The IC relies on human-machine-based analytic strategies that 1) access\nand integrate vast amounts of information from disparate sources, 2)\ncontinuously process this information, so that, 3) a maximally comprehensive\nunderstanding of world actors and their behaviors can be developed and updated.\nHerein we describe an approach to utilizing outcomes-based learning (OBL) to\nsupport these efforts that is based on an ontology of the cognitive processes\nperformed by intelligence analysts. Of particular importance to the Cognitive\nProcess Ontology is the class Representation that is Warranted. Such a\nrepresentation is descriptive in nature and deserving of trust in its\nveridicality. The latter is because a Representation that is Warranted is\nalways produced by a process that was vetted (or successfully designed) to\nreliably produce veridical representations. As such, Representations that are\nWarranted are what in other contexts we might refer to as 'items of knowledge'.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.04306,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Knowledge Patterns\n\n  This paper describes a new technique, called \"knowledge patterns\", for\nhelping construct axiom-rich, formal ontologies, based on identifying and\nexplicitly representing recurring patterns of knowledge (theory schemata) in\nthe ontology, and then stating how those patterns map onto domain-specific\nconcepts in the ontology. From a modeling perspective, knowledge patterns\nprovide an important insight into the structure of a formal ontology: rather\nthan viewing a formal ontology simply as a list of terms and axioms, knowledge\npatterns views it as a collection of abstract, modular theories (the \"knowledge\npatterns\") plus a collection of modeling decisions stating how different\naspects of the world can be modeled using those theories. Knowledge patterns\nmake both those abstract theories and their mappings to the domain of interest\nexplicit, thus making modeling decisions clear, and avoiding some of the\nontological confusion that can otherwise arise. In addition, from a\ncomputational perspective, knowledge patterns provide a simple and\ncomputationally efficient mechanism for facilitating knowledge reuse. We\ndescribe the technique and an application built using them, and then critique\nits strengths and weaknesses. We conclude that this technique enables us to\nbetter explicate both the structure and modeling decisions made when\nconstructing a formal axiom-rich ontology.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.01633,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Construction and Elicitation of a Black Box Model in the Game of Bridge\n\n  We address the problem of building a decision model for a specific bidding\nsituation in the game of Bridge. We propose the following multi-step\nmethodology i) Build a set of examples for the decision problem and use\nsimulations to associate a decision to each example ii) Use supervised\nrelational learning to build an accurate and readable model iii) Perform a\njoint analysis between domain experts and data scientists to improve the\nlearning language, including the production by experts of a handmade model iv)\nBuild a better, more readable and accurate model.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.0787,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000038412,
      "text":"Learning Transferable Concepts in Deep Reinforcement Learning\n\n  While humans and animals learn incrementally during their lifetimes and\nexploit their experience to solve new tasks, standard deep reinforcement\nlearning methods specialize to solve only one task at a time. As a result, the\ninformation they acquire is hardly reusable in new situations. Here, we\nintroduce a new perspective on the problem of leveraging prior knowledge to\nsolve future tasks. We show that learning discrete representations of sensory\ninputs can provide a high-level abstraction that is common across multiple\ntasks, thus facilitating the transference of information. In particular, we\nshow that it is possible to learn such representations by self-supervision,\nfollowing an information theoretic approach. Our method is able to learn\nconcepts in locomotive and optimal control tasks that increase the sample\nefficiency in both known and unknown tasks, opening a new path to endow\nartificial agents with generalization abilities.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.05131,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.000001159,
      "text":"Extending the Tsetlin Machine With Integer-Weighted Clauses for\n  Increased Interpretability\n\n  Despite significant effort, building models that are both interpretable and\naccurate is an unresolved challenge for many pattern recognition problems. In\ngeneral, rule-based and linear models lack accuracy, while deep learning\ninterpretability is based on rough approximations of the underlying inference.\nUsing a linear combination of conjunctive clauses in propositional logic,\nTsetlin Machines (TMs) have shown competitive performance on diverse\nbenchmarks. However, to do so, many clauses are needed, which impacts\ninterpretability. Here, we address the accuracy-interpretability challenge in\nmachine learning by equipping the TM clauses with integer weights. The\nresulting Integer Weighted TM (IWTM) deals with the problem of learning which\nclauses are inaccurate and thus must team up to obtain high accuracy as a team\n(low weight clauses), and which clauses are sufficiently accurate to operate\nmore independently (high weight clauses). Since each TM clause is formed\nadaptively by a team of Tsetlin Automata, identifying effective weights becomes\na challenging online learning problem. We address this problem by extending\neach team of Tsetlin Automata with a stochastic searching on the line (SSL)\nautomaton. In our novel scheme, the SSL automaton learns the weight of its\nclause in interaction with the corresponding Tsetlin Automata team, which, in\nturn, adapts the composition of the clause by the adjusting weight. We evaluate\nIWTM empirically using five datasets, including a study of interpetability. On\naverage, IWTM uses 6.5 times fewer literals than the vanilla TM and 120 times\nfewer literals than a TM with real-valued weights. Furthermore, in terms of\naverage F1-Score, IWTM outperforms simple Multi-Layered Artificial Neural\nNetworks, Decision Trees, Support Vector Machines, K-Nearest Neighbor, Random\nForest, XGBoost, Explainable Boosting Machines, and standard and real-value\nweighted TMs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.09645,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"The Second Type of Uncertainty in Monte Carlo Tree Search\n\n  Monte Carlo Tree Search (MCTS) efficiently balances exploration and\nexploitation in tree search based on count-derived uncertainty. However, these\nlocal visit counts ignore a second type of uncertainty induced by the size of\nthe subtree below an action. We first show how, due to the lack of this second\nuncertainty type, MCTS may completely fail in well-known sparse exploration\nproblems, known from the reinforcement learning community. We then introduce a\nnew algorithm, which estimates the size of the subtree below an action, and\nleverages this information in the UCB formula to better direct exploration.\nSubsequently, we generalize these ideas by showing that loops, i.e., the\nrepeated occurrence of (approximately) the same state in the same trace, are\nactually a special case of subtree depth variation. Testing on a variety of\ntasks shows that our algorithms increase sample efficiency, especially when the\nplanning budget per timestep is small.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.11963,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000004636,
      "text":"Non-Destructive Sample Generation From Conditional Belief Functions\n\n  This paper presents a new approach to generate samples from conditional\nbelief functions for a restricted but non trivial subset of conditional belief\nfunctions. It assumes the factorization (decomposition) of a belief function\nalong a bayesian network structure. It applies general conditional belief\nfunctions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.11979,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"On Irrelevance of Attributes in Flexible Prediction\n\n  This paper analyses properties of conceptual hierarchy obtained via\nincremental concept formation method called \"flexible prediction\" in order to\ndetermine what kind of \"relevance\" of participating attributes may be requested\nfor meaningful conceptual hierarchy. The impact of selection of simple and\ncombined attributes, of scaling and of distribution of individual attributes\nand of correlation strengths among them is investigated. Paradoxically, both:\nattributes weakly and strongly related with other attributes have deteriorating\nimpact onto the overall classification. Proper construction of derived\nattributes as well as selection of scaling of individual attributes strongly\ninfluences the obtained concept hierarchy. Attribute density of distribution\nseems to influence the classification weakly\n  It seems also, that concept hierarchies (taxonomies) reflect a compromise\nbetween the data and our interests in some objective truth about the data. To\nobtain classifications more suitable for one's purposes, breaking the symmetry\namong attributes (by dividing them into dependent and independent and applying\ndiffering evaluation formulas for their contribution) is suggested. Both\ncontinuous and discrete variables are considered. Some methodologies for the\nformer are considered.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.05712,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"Goal Recognition over Imperfect Domain Models\n\n  Goal recognition is the problem of recognizing the intended goal of\nautonomous agents or humans by observing their behavior in an environment. Over\nthe past years, most existing approaches to goal and plan recognition have been\nignoring the need to deal with imperfections regarding the domain model that\nformalizes the environment where autonomous agents behave. In this thesis, we\nintroduce the problem of goal recognition over imperfect domain models, and\ndevelop solution approaches that explicitly deal with two distinct types of\nimperfect domains models: (1) incomplete discrete domain models that have\npossible, rather than known, preconditions and effects in action descriptions;\nand (2) approximate continuous domain models, where the transition function is\napproximated from past observations and not well-defined. We develop novel goal\nrecognition approaches over imperfect domains models by leveraging and adapting\nexisting recognition approaches from the literature. Experiments and evaluation\nover these two types of imperfect domains models show that our novel goal\nrecognition approaches are accurate in comparison to baseline approaches from\nthe literature, at several levels of observability and imperfections.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.08954,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000103646,
      "text":"On the Complexity of Breaking Symmetry\n\n  We can break symmetry by eliminating solutions within a symmetry class that\nare not least in the lexicographical ordering. This is often referred to as the\nlex-leader method. Unfortunately, as symmetry groups can be large, the\nlexleader method is not tractable in general. We prove that using other total\norderings besides the usual lexicographical ordering will not reduce the\ncomputational complexity of breaking symmetry in general. It follows that\nbreaking symmetry with other orderings like the Gray code ordering or the\nSnake-Lex ordering is intractable in general.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.05721,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Preference Elicitation in Assumption-Based Argumentation\n\n  Various structured argumentation frameworks utilize preferences as part of\ntheir standard inference procedure to enable reasoning with preferences. In\nthis paper, we consider an inverse of the standard reasoning problem, seeking\nto identify what preferences over assumptions could lead to a given set of\nconclusions being drawn. We ground our work in the Assumption-Based\nArgumentation (ABA) framework, and present an algorithm which computes and\nenumerates all possible sets of preferences over the assumptions in the system\nfrom which a desired conflict free set of conclusions can be obtained under a\ngiven semantic. After describing our algorithm, we establish its soundness,\ncompleteness and complexity.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.11247,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000020862,
      "text":"Evaluating Generalisation in General Video Game Playing\n\n  The General Video Game Artificial Intelligence (GVGAI) competition has been\nrunning for several years with various tracks. This paper focuses on the\nchallenge of the GVGAI learning track in which 3 games are selected and 2\nlevels are given for training, while 3 hidden levels are left for evaluation.\nThis setup poses a difficult challenge for current Reinforcement Learning (RL)\nalgorithms, as they typically require much more data. This work investigates 3\nversions of the Advantage Actor-Critic (A2C) algorithm trained on a maximum of\n2 levels from the available 5 from the GVGAI framework and compares their\nperformance on all levels. The selected sub-set of games have different\ncharacteristics, like stochasticity, reward distribution and objectives. We\nfound that stochasticity improves the generalisation, but too much can cause\nthe algorithms to fail to learn the training levels. The quality of the\ntraining levels also matters, different sets of training levels can boost\ngeneralisation over all levels. In the GVGAI competition agents are scored\nbased on their win rates and then their scores achieved in the games. We found\nthat solely using the rewards provided by the game might not encourage winning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2005.1236,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000006292,
      "text":"Non-cooperative Multi-agent Systems with Exploring Agents\n\n  Multi-agent learning is a challenging problem in machine learning that has\napplications in different domains such as distributed control, robotics, and\neconomics. We develop a prescriptive model of multi-agent behavior using Markov\ngames. Since in many multi-agent systems, agents do not necessary select their\noptimum strategies against other agents (e.g., multi-pedestrian interaction),\nwe focus on models in which the agents play \"exploration but near optimum\nstrategies\". We model such policies using the Boltzmann-Gibbs distribution.\nThis leads to a set of coupled Bellman equations that describes the behavior of\nthe agents. We introduce a set of conditions under which the set of equations\nadmit a unique solution and propose two algorithms that provably provide the\nsolution in finite and infinite time horizon scenarios. We also study a\npractical setting in which the interactions can be described using the\noccupancy measures and propose a simplified Markov game with less complexity.\nFurthermore, we establish the connection between the Markov games with\nexploration strategies and the principle of maximum causal entropy for\nmulti-agent systems. Finally, we evaluate the performance of our algorithms via\nseveral well-known games from the literature and some games that are designed\nbased on real world applications.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.11309,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000013908,
      "text":"Modelling Agent Policies with Interpretable Imitation Learning\n\n  As we deploy autonomous agents in safety-critical domains, it becomes\nimportant to develop an understanding of their internal mechanisms and\nrepresentations. We outline an approach to imitation learning for\nreverse-engineering black box agent policies in MDP environments, yielding\nsimplified, interpretable models in the form of decision trees. As part of this\nprocess, we explicitly model and learn agents' latent state representations by\nselecting from a large space of candidate features constructed from the Markov\nstate. We present initial promising results from an implementation in a\nmulti-agent traffic environment.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.04042,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000012914,
      "text":"An Algorithm for Fuzzification of WordNets, Supported by a Mathematical\n  Proof\n\n  WordNet-like Lexical Databases (WLDs) group English words into sets of\nsynonyms called \"synsets.\" Although the standard WLDs are being used in many\nsuccessful Text-Mining applications, they have the limitation that word-senses\nare considered to represent the meaning associated to their corresponding\nsynsets, to the same degree, which is not generally true. In order to overcome\nthis limitation, several fuzzy versions of synsets have been proposed. A common\ntrait of these studies is that, to the best of our knowledge, they do not aim\nto produce fuzzified versions of the existing WLD's, but build new WLDs from\nscratch, which has limited the attention received from the Text-Mining\ncommunity, many of whose resources and applications are based on the existing\nWLDs. In this study, we present an algorithm for constructing fuzzy versions of\nWLDs of any language, given a corpus of documents and a word-sense\ndisambiguation (WSD) system for that language. Then, using the\nOpen-American-National-Corpus and UKB WSD as algorithm inputs, we construct and\npublish online the fuzzified version of English WordNet (FWN). We also propose\na theoretical (mathematical) proof of the validity of its results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.07532,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"Online Bayesian Goal Inference for Boundedly-Rational Planning Agents\n\n  People routinely infer the goals of others by observing their actions over\ntime. Remarkably, we can do so even when those actions lead to failure,\nenabling us to assist others when we detect that they might not achieve their\ngoals. How might we endow machines with similar capabilities? Here we present\nan architecture capable of inferring an agent's goals online from both optimal\nand non-optimal sequences of actions. Our architecture models agents as\nboundedly-rational planners that interleave search with execution by\nreplanning, thereby accounting for sub-optimal behavior. These models are\nspecified as probabilistic programs, allowing us to represent and perform\nefficient Bayesian inference over an agent's goals and internal planning\nprocesses. To perform such inference, we develop Sequential Inverse Plan Search\n(SIPS), a sequential Monte Carlo algorithm that exploits the online replanning\nassumption of these models, limiting computation by incrementally extending\ninferred plans as new actions are observed. We present experiments showing that\nthis modeling and inference architecture outperforms Bayesian inverse\nreinforcement learning baselines, accurately inferring goals from both optimal\nand non-optimal trajectories involving failure and back-tracking, while\ngeneralizing across domains with compositional structure and sparse rewards.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.04387,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000007285,
      "text":"An ASP approach for reasoning in a concept-aware multipreferential\n  lightweight DL\n\n  In this paper we develop a concept aware multi-preferential semantics for\ndealing with typicality in description logics, where preferences are associated\nwith concepts, starting from a collection of ranked TBoxes containing\ndefeasible concept inclusions. Preferences are combined to define a\npreferential interpretation in which defeasible inclusions can be evaluated.\nThe construction of the concept-aware multipreference semantics is related to\nBrewka's framework for qualitative preferences. We exploit Answer Set\nProgramming (in particular, asprin) to achieve defeasible reasoning under the\nmultipreference approach for the lightweight description logic EL+bot.\n  The paper is under consideration for acceptance in TPLP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.05219,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000549687,
      "text":"SANOM Results for OAEI 2019\n\n  Simulated annealing-based ontology matching (SANOM) participates for the\nsecond time at the ontology alignment evaluation initiative (OAEI) 2019. This\npaper contains the configuration of SANOM and its results on the anatomy and\nconference tracks. In comparison to the OAEI 2017, SANOM has improved\nsignificantly, and its results are competitive with the state-of-the-art\nsystems. In particular, SANOM has the highest recall rate among the\nparticipated systems in the conference track, and is competitive with AML, the\nbest performing system, in terms of F-measure. SANOM is also competitive with\nLogMap on the anatomy track, which is the best performing system in this track\nwith no usage of particular biomedical background knowledge. SANOM has been\nadapted to the HOBBIT platfrom and is now available for the registered users.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.08659,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Does it matter how well I know what you're thinking? Opponent Modelling\n  in an RTS game\n\n  Opponent Modelling tries to predict the future actions of opponents, and is\nrequired to perform well in multi-player games. There is a deep literature on\nlearning an opponent model, but much less on how accurate such models must be\nto be useful. We investigate the sensitivity of Monte Carlo Tree Search (MCTS)\nand a Rolling Horizon Evolutionary Algorithm (RHEA) to the accuracy of their\nmodelling of the opponent in a simple Real-Time Strategy game. We find that in\nthis domain RHEA is much more sensitive to the accuracy of an opponent model\nthan MCTS. MCTS generally does better even with an inaccurate model, while this\nwill degrade RHEA's performance. We show that faced with an unknown opponent\nand a low computational budget it is better not to use any explicit model with\nRHEA, and to model the opponent's actions within the tree as part of the MCTS\nalgorithm.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.06896,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000016226,
      "text":"A New Perspective on Learning Context-Specific Independence\n\n  Local structure such as context-specific independence (CSI) has received much\nattention in the probabilistic graphical model (PGM) literature, as it\nfacilitates the modeling of large complex systems, as well as for reasoning\nwith them. In this paper, we provide a new perspective on how to learn CSIs\nfrom data. We propose to first learn a functional and parameterized\nrepresentation of a conditional probability table (CPT), such as a neural\nnetwork. Next, we quantize this continuous function, into an arithmetic circuit\nrepresentation that facilitates efficient inference. In the first step, we can\nleverage the many powerful tools that have been developed in the machine\nlearning literature. In the second step, we exploit more recently-developed\nanalytic tools from explainable AI, for the purposes of learning CSIs. Finally,\nwe contrast our approach, empirically and conceptually, with more traditional\nvariable-splitting approaches, that search for CSIs more explicitly.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.0663,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000049339,
      "text":"Petri Nets with Parameterised Data: Modelling and Verification (Extended\n  Version)\n\n  During the last decade, various approaches have been put forward to integrate\nbusiness processes with different types of data. Each of such approaches\nreflects specific demands in the whole process-data integration spectrum. One\nparticular important point is the capability of these approaches to flexibly\naccommodate processes with multiple cases that need to co-evolve. In this work,\nwe introduce and study an extension of coloured Petri nets, called\ncatalog-nets, providing two key features to capture this type of processes. On\nthe one hand, net transitions are equipped with guards that simultaneously\ninspect the content of tokens and query facts stored in a read-only, persistent\ndatabase. On the other hand, such transitions can inject data into tokens by\nextracting relevant values from the database or by generating genuinely fresh\nones. We systematically encode catalog-nets into one of the reference\nframeworks for the (parameterised) verification of data and processes. We show\nthat fresh-value injection is a particularly complex feature to handle, and\ndiscuss strategies to tame it. Finally, we discuss how catalog nets relate to\nwell-known formalisms in this area.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.01444,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"Descriptor Revision for Conditionals: Literal Descriptors and\n  Conditional Preservation\n\n  Descriptor revision by Hansson is a framework for addressing the problem of\nbelief change. In descriptor revision, different kinds of change processes are\ndealt with in a joint framework. Individual change requirements are qualified\nby specific success conditions expressed by a belief descriptor, and belief\ndescriptors can be combined by logical connectives. This is in contrast to the\ncurrently dominating AGM paradigm shaped by Alchourr\\'on, G\\\"ardenfors, and\nMakinson, where different kinds of changes, like a revision or a contraction,\nare dealt with separately. In this article, we investigate the realisation of\ndescriptor revision for a conditional logic while restricting descriptors to\nthe conjunction of literal descriptors. We apply the principle of conditional\npreservation developed by Kern-Isberner to descriptor revision for\nconditionals, show how descriptor revision for conditionals under these\nrestrictions can be characterised by a constraint satisfaction problem, and\nimplement it using constraint logic programming. Since our conditional logic\nsubsumes propositional logic, our approach also realises descriptor revision\nfor propositional logic.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.08409,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000164575,
      "text":"Machine Common Sense\n\n  Machine common sense remains a broad, potentially unbounded problem in\nartificial intelligence (AI). There is a wide range of strategies that can be\nemployed to make progress on this challenge. This article deals with the\naspects of modeling commonsense reasoning focusing on such domain as\ninterpersonal interactions. The basic idea is that there are several types of\ncommonsense reasoning: one is manifested at the logical level of physical\nactions, the other deals with the understanding of the essence of human-human\ninteractions. Existing approaches, based on formal logic and artificial neural\nnetworks, allow for modeling only the first type of common sense. To model the\nsecond type, it is vital to understand the motives and rules of human behavior.\nThis model is based on real-life heuristics, i.e., the rules of thumb,\ndeveloped through knowledge and experience of different generations. Such\nknowledge base allows for development of an expert system with inference and\nexplanatory mechanisms (commonsense reasoning algorithms and personal models).\nAlgorithms provide tools for a situation analysis, while personal models make\nit possible to identify personality traits. The system so designed should\nperform the function of amplified intelligence for interactions, including\nhuman-machine.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.08295,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Efficient Reasoning in Regular Boardgames\n\n  We present the technical side of reasoning in Regular Boardgames (RBG)\nlanguage -- a universal General Game Playing (GGP) formalism for the class of\nfinite deterministic games with perfect information, encoding rules in the form\nof regular expressions. RBG serves as a research tool that aims to aid in the\ndevelopment of generalized algorithms for knowledge inference, analysis,\ngeneration, learning, and playing games. In all these tasks, both generality\nand efficiency are important.\n  In the first part, this paper describes optimizations used by the RBG\ncompiler. The impact of these optimizations ranges from 1.7 to even 33-fold\nefficiency improvement when measuring the number of possible game playouts per\nsecond. Then, we perform an in-depth efficiency comparison with three other\nmodern GGP systems (GDL, Ludii, Ai Ai). We also include our own highly\noptimized game-specific reasoners to provide a point of reference of the\nmaximum speed. Our experiments show that RBG is currently the fastest among the\nabstract general game playing languages, and its efficiency can be competitive\nto common interface-based systems that rely on handcrafted game-specific\nimplementations. Finally, we discuss some issues and methodology of computing\nbenchmarks like this.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.01195,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.000025034,
      "text":"Revisiting Bounded-Suboptimal Safe Interval Path Planning\n\n  Safe-interval path planning (SIPP) is a powerful algorithm for finding a path\nin the presence of dynamic obstacles. SIPP returns provably optimal solutions.\nHowever, in many practical applications of SIPP such as path planning for\nrobots, one would like to trade-off optimality for shorter planning time. In\nthis paper we explore different ways to build a bounded-suboptimal SIPP and\ndiscuss their pros and cons. We compare the different bounded-suboptimal\nversions of SIPP experimentally. While there is no universal winner, the\nresults provide insights into when each method should be used.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.06412,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000032451,
      "text":"Modeling Human Driving Behavior through Generative Adversarial Imitation\n  Learning\n\n  An open problem in autonomous vehicle safety validation is building reliable\nmodels of human driving behavior in simulation. This work presents an approach\nto learn neural driving policies from real world driving demonstration data. We\nmodel human driving as a sequential decision making problem that is\ncharacterized by non-linearity and stochasticity, and unknown underlying cost\nfunctions. Imitation learning is an approach for generating intelligent\nbehavior when the cost function is unknown or difficult to specify. Building\nupon work in inverse reinforcement learning (IRL), Generative Adversarial\nImitation Learning (GAIL) aims to provide effective imitation even for problems\nwith large or continuous state and action spaces, such as modeling human\ndriving. This article describes the use of GAIL for learning-based driver\nmodeling. Because driver modeling is inherently a multi-agent problem, where\nthe interaction between agents needs to be modeled, this paper describes a\nparameter-sharing extension of GAIL called PS-GAIL to tackle multi-agent driver\nmodeling. In addition, GAIL is domain agnostic, making it difficult to encode\nspecific knowledge relevant to driving in the learning process. This paper\ndescribes Reward Augmented Imitation Learning (RAIL), which modifies the reward\nsignal to provide domain-specific knowledge to the agent. Finally, human\ndemonstrations are dependent upon latent factors that may not be captured by\nGAIL. This paper describes Burn-InfoGAIL, which allows for disentanglement of\nlatent variability in demonstrations. Imitation learning experiments are\nperformed using NGSIM, a real-world highway driving dataset. Experiments show\nthat these modifications to GAIL can successfully model highway driving\nbehavior, accurately replicating human demonstrations and generating realistic,\nemergent behavior in the traffic flow arising from the interaction between\ndriving agents.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.05962,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.000002053,
      "text":"At-Most-One Constraints in Efficient Representations of Mutex Networks\n\n  The At-Most-One (AMO) constraint is a special case of cardinality constraint\nthat requires at most one variable from a set of Boolean variables to be set to\nTRUE. AMO is important for modeling problems as Boolean satisfiability (SAT)\nfrom domains where decision variables represent spatial or temporal placements\nof some objects that cannot share the same spatial or temporal slot. The AMO\nconstraint can be used for more efficient representation and problem solving in\nmutex networks consisting of pair-wise mutual exclusions forbidding pairs of\nBoolean variable to be simultaneously TRUE. An on-line method for automated\ndetection of cliques for efficient representation of incremental mutex networks\nwhere new mutexes arrive using AMOs is presented. A comparison of SAT-based\nproblem solving in mutex networks represented by AMO constraints using various\nencodings is shown.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.1202,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000063909,
      "text":"Online Handbook of Argumentation for AI: Volume 1\n\n  This volume contains revised versions of the papers selected for the first\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.11704,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000023842,
      "text":"Hierarchical Reinforcement Learning for Deep Goal Reasoning: An\n  Expressiveness Analysis\n\n  Hierarchical DQN (h-DQN) is a two-level architecture of feedforward neural\nnetworks where the meta level selects goals and the lower level takes actions\nto achieve the goals. We show tasks that cannot be solved by h-DQN,\nexemplifying the limitation of this type of hierarchical framework (HF). We\ndescribe the recurrent hierarchical framework (RHF), generalizing architectures\nthat use a recurrent neural network at the meta level. We analyze the\nexpressiveness of HF and RHF using context-sensitive grammars. We show that RHF\nis more expressive than HF. We perform experiments comparing an implementation\nof RHF with two HF baselines; the results corroborate our theoretical findings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.13607,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000035101,
      "text":"Circuit Routing Using Monte Carlo Tree Search and Deep Neural Networks\n\n  Circuit routing is a fundamental problem in designing electronic systems such\nas integrated circuits (ICs) and printed circuit boards (PCBs) which form the\nhardware of electronics and computers. Like finding paths between pairs of\nlocations, circuit routing generates traces of wires to connect contacts or\nleads of circuit components. It is challenging because finding paths between\ndense and massive electronic components involves a very large search space.\nExisting solutions are either manually designed with domain knowledge or\ntailored to specific design rules, hence, difficult to adapt to new problems or\ndesign needs. Therefore, a general routing approach is highly desired. In this\npaper, we model the circuit routing as a sequential decision-making problem,\nand solve it by Monte Carlo tree search (MCTS) with deep neural network (DNN)\nguided rollout. It could be easily extended to routing cases with more routing\nconstraints and optimization goals. Experiments on randomly generated\nsingle-layer circuits show the potential to route complex circuits. The\nproposed approach can solve the problems that benchmark methods such as\nsequential A* method and Lee's algorithm cannot solve, and can also outperform\nthe vanilla MCTS approach.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.11814,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000014239,
      "text":"A blindspot of AI ethics: anti-fragility in statistical prediction\n\n  With this paper, we aim to put an issue on the agenda of AI ethics that in\nour view is overlooked in the current discourse. The current discussions are\ndominated by topics suchas trustworthiness and bias, whereas the issue we like\nto focuson is counter to the debate on trustworthiness. We fear that the\noveruse of currently dominant AI systems that are driven by short-term\nobjectives and optimized for avoiding error leads to a society that loses its\ndiversity and flexibility needed for true progress. We couch our concerns in\nthe discourse around the term anti-fragility and show with some examples what\nthreats current methods used for decision making pose for society.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.14804,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Widening the Pipeline in Human-Guided Reinforcement Learning with\n  Explanation and Context-Aware Data Augmentation\n\n  Human explanation (e.g., in terms of feature importance) has been recently\nused to extend the communication channel between human and agent in interactive\nmachine learning. Under this setting, human trainers provide not only the\nground truth but also some form of explanation. However, this kind of human\nguidance was only investigated in supervised learning tasks, and it remains\nunclear how to best incorporate this type of human knowledge into deep\nreinforcement learning. In this paper, we present the first study of using\nhuman visual explanations in human-in-the-loop reinforcement learning (HRL). We\nfocus on the task of learning from feedback, in which the human trainer not\nonly gives binary evaluative \"good\" or \"bad\" feedback for queried state-action\npairs, but also provides a visual explanation by annotating relevant features\nin images. We propose EXPAND (EXPlanation AugmeNted feeDback) to encourage the\nmodel to encode task-relevant features through a context-aware data\naugmentation that only perturbs irrelevant features in human salient\ninformation. We choose five tasks, namely Pixel-Taxi and four Atari games, to\nevaluate the performance and sample efficiency of this approach. We show that\nour method significantly outperforms methods leveraging human explanation that\nare adapted from supervised learning, and Human-in-the-loop RL baselines that\nonly utilize evaluative feedback.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2006.04003,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Every Action Based Sensor\n\n  In studying robots and planning problems, a basic question is what is the\nminimal information a robot must obtain to guarantee task completion. Erdmann's\ntheory of action-based sensors is a classical approach to characterizing\nfundamental information requirements. That approach uses a plan to derive a\ntype of virtual sensor which prescribes actions that make progress toward a\ngoal. We show that the established theory is incomplete: the previous method\nfor obtaining such sensors, using backchained plans, overlooks some sensors.\nFurthermore, there are plans, that are guaranteed to achieve goals, where the\nexisting methods are unable to provide any action-based sensor. We identify the\nunderlying feature common to all such plans. Then, we show how to produce\naction-based sensors even for plans where the existing treatment is inadequate,\nalthough for these cases they have no single canonical sensor. Consequently,\nthe approach is generalized to produce sets of sensors. Finally, we show also\nthat this is a complete characterization of action-based sensors for planning\nproblems and discuss how an action-based sensor translates into the traditional\nconception of a sensor.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.15185,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0003899468,
      "text":"Improving probability selecting based weights for Satisfiability Problem\n\n  The Boolean Satisfiability problem (SAT) is important on artificial\nintelligence community and the impact of its solving on complex problems.\nRecently, great breakthroughs have been made respectively on stochastic local\nsearch (SLS) algorithms for uniform random k-SAT resulting in several\nstate-of-the-art SLS algorithms Score2SAT, YalSAT, ProbSAT, CScoreSAT and on a\nhybrid algorithm for hard random SAT (HRS) resulting in one state-of-the-art\nhybrid algorithm SparrowToRiss. However, there is no an algorithm which can\neffectively solve both uniform random k-SAT and HRS. In this paper, we present\na new SLS algorithm named SelectNTS for uniform random k-SAT and HRS. SelectNTS\nis an improved probability selecting based local search algorithm for SAT\nproblem. The core of SelectNTS relies on new clause and variable selection\nheuristics. The new clause selection heuristic uses a new clause weighting\nscheme and a biased random walk. The new variable selection heuristic uses a\nprobability selecting strategy with the variation of CC strategy based on a new\nvariable weighting scheme. Extensive experimental results on the well-known\nrandom benchmarks instances from the SAT Competitions in 2017 and 2018, and on\nrandomly generated problems, show that our algorithm outperforms\nstate-of-the-art random SAT algorithms, and our SelectNTS can effectively solve\nboth uniform random k-SAT and HRS.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.00364,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000016226,
      "text":"Medical idioms for clinical Bayesian network development\n\n  Bayesian Networks (BNs) are graphical probabilistic models that have proven\npopular in medical applications. While numerous medical BNs have been\npublished, most are presented fait accompli without explanation of how the\nnetwork structure was developed or justification of why it represents the\ncorrect structure for the given medical application. This means that the\nprocess of building medical BNs from experts is typically ad hoc and offers\nlittle opportunity for methodological improvement. This paper proposes\ngenerally applicable and reusable medical reasoning patterns to aid those\ndeveloping medical BNs. The proposed method complements and extends the\nidiom-based approach introduced by Neil, Fenton, and Nielsen in 2000. We\npropose instances of their generic idioms that are specific to medical BNs. We\nrefer to the proposed medical reasoning patterns as medical idioms. In\naddition, we extend the use of idioms to represent interventional and\ncounterfactual reasoning. We believe that the proposed medical idioms are\nlogical reasoning patterns that can be combined, reused and applied generically\nto help develop medical BNs. All proposed medical idioms have been illustrated\nusing medical examples on coronary artery disease. The method has also been\napplied to other ongoing BNs being developed with medical experts. Finally, we\nshow that applying the proposed medical idioms to published BN models results\nin models with a clearer structure.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.0082,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"Designing Environments Conducive to Interpretable Robot Behavior\n\n  Designing robots capable of generating interpretable behavior is a\nprerequisite for achieving effective human-robot collaboration. This means that\nthe robots need to be capable of generating behavior that aligns with human\nexpectations and, when required, provide explanations to the humans in the\nloop. However, exhibiting such behavior in arbitrary environments could be\nquite expensive for robots, and in some cases, the robot may not even be able\nto exhibit the expected behavior. Given structured environments (like\nwarehouses and restaurants), it may be possible to design the environment so as\nto boost the interpretability of the robot's behavior or to shape the human's\nexpectations of the robot's behavior. In this paper, we investigate the\nopportunities and limitations of environment design as a tool to promote a type\nof interpretable behavior -- known in the literature as explicable behavior. We\nformulate a novel environment design framework that considers design over\nmultiple tasks and over a time horizon. In addition, we explore the\nlongitudinal aspect of explicable behavior and the trade-off that arises\nbetween the cost of design and the cost of generating explicable behavior over\na time horizon.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.0954,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"Multi-Principal Assistance Games\n\n  Assistance games (also known as cooperative inverse reinforcement learning\ngames) have been proposed as a model for beneficial AI, wherein a robotic agent\nmust act on behalf of a human principal but is initially uncertain about the\nhumans payoff function. This paper studies multi-principal assistance games,\nwhich cover the more general case in which the robot acts on behalf of N humans\nwho may have widely differing payoffs. Impossibility theorems in social choice\ntheory and voting theory can be applied to such games, suggesting that\nstrategic behavior by the human principals may complicate the robots task in\nlearning their payoffs. We analyze in particular a bandit apprentice game in\nwhich the humans act first to demonstrate their individual preferences for the\narms and then the robot acts to maximize the sum of human payoffs. We explore\nthe extent to which the cost of choosing suboptimal arms reduces the incentive\nto mislead, a form of natural mechanism design. In this context we propose a\nsocial choice method that uses shared control of a system to combine preference\ninference with social welfare optimization.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.03328,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000047021,
      "text":"Guided Exploration with Proximal Policy Optimization using a Single\n  Demonstration\n\n  Solving sparse reward tasks through exploration is one of the major\nchallenges in deep reinforcement learning, especially in three-dimensional,\npartially-observable environments. Critically, the algorithm proposed in this\narticle uses a single human demonstration to solve hard-exploration problems.\nWe train an agent on a combination of demonstrations and own experience to\nsolve problems with variable initial conditions. We adapt this idea and\nintegrate it with the proximal policy optimization (PPO). The agent is able to\nincrease its performance and to tackle harder problems by replaying its own\npast trajectories prioritizing them based on the obtained reward and the\nmaximum value of the trajectory. We compare different variations of this\nalgorithm to behavioral cloning on a set of hard-exploration tasks in the\nAnimal-AI Olympics environment. To the best of our knowledge, learning a task\nin a three-dimensional environment with comparable difficulty has never been\nconsidered before using only one human demonstration.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.14778,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000019206,
      "text":"Bayesian preference elicitation for multiobjective combinatorial\n  optimization\n\n  We introduce a new incremental preference elicitation procedure able to deal\nwith noisy responses of a Decision Maker (DM). The originality of the\ncontribution is to propose a Bayesian approach for determining a preferred\nsolution in a multiobjective decision problem involving a combinatorial set of\nalternatives. We assume that the preferences of the DM are represented by an\naggregation function whose parameters are unknown and that the uncertainty\nabout them is represented by a density function on the parameter space.\nPairwise comparison queries are used to reduce this uncertainty (by Bayesian\nrevision). The query selection strategy is based on the solution of a mixed\ninteger linear program with a combinatorial set of variables and constraints,\nwhich requires to use columns and constraints generation methods. Numerical\ntests are provided to show the practicability of the approach.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.04614,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000028147,
      "text":"Weakness Analysis of Cyberspace Configuration Based on Reinforcement\n  Learning\n\n  In this work, we present a learning-based approach to analysis cyberspace\nconfiguration. Unlike prior methods, our approach has the ability to learn from\npast experience and improve over time. In particular, as we train over a\ngreater number of agents as attackers, our method becomes better at rapidly\nfinding attack paths for previously hidden paths, especially in multiple domain\ncyberspace. To achieve these results, we pose finding attack paths as a\nReinforcement Learning (RL) problem and train an agent to find multiple domain\nattack paths. To enable our RL policy to find more hidden attack paths, we\nground representation introduction an multiple domain action select module in\nRL. By designing a simulated cyberspace experimental environment to verify our\nmethod. Our objective is to find more hidden attack paths, to analysis the\nweakness of cyberspace configuration. The experimental results show that our\nmethod can find more hidden multiple domain attack paths than existing\nbaselines methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.06282,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000065896,
      "text":"Strengthening neighbourhood substitution\n\n  Domain reduction is an essential tool for solving the constraint satisfaction\nproblem (CSP). In the binary CSP, neighbourhood substitution consists in\neliminating a value if there exists another value which can be substituted for\nit in each constraint. We show that the notion of neighbourhood substitution\ncan be strengthened in two distinct ways without increasing time complexity. We\nalso show the theoretical result that, unlike neighbourhood substitution,\nfinding an optimal sequence of these new operations is NP-hard.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.09288,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000059274,
      "text":"Object Tracking by Least Spatiotemporal Searches\n\n  Tracking a car or a person in a city is crucial for urban safety management.\nHow can we complete the task with minimal number of spatiotemporal searches\nfrom massive camera records? This paper proposes a strategy named IHMs\n(Intermediate Searching at Heuristic Moments): each step we figure out which\nmoment is the best to search according to a heuristic indicator, then at that\nmoment search locations one by one in descending order of predicted appearing\nprobabilities, until a search hits; iterate this step until we get the object's\ncurrent location. Five searching strategies are compared in experiments, and\nIHMs is validated to be most efficient, which can save up to 1\/3 total costs.\nThis result provides an evidence that \"searching at intermediate moments can\nsave cost\".\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.0722,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Exploring Dynamic Difficulty Adjustment in Videogames\n\n  Videogames are nowadays one of the biggest entertainment industries in the\nworld. Being part of this industry means competing against lots of other\ncompanies and developers, thus, making fanbases of vital importance. They are a\ngroup of clients that constantly support your company because your video games\nare fun. Videogames are most entertaining when the difficulty level is a good\nmatch for the player's skill, increasing the player engagement. However, not\nall players are equally proficient, so some kind of difficulty selection is\nrequired. In this paper, we will present Dynamic Difficulty Adjustment (DDA), a\nrecently arising research topic, which aims to develop an automated difficulty\nselection mechanism that keeps the player engaged and properly challenged,\nneither bored nor overwhelmed. We will present some recent research addressing\nthis issue, as well as an overview of how to implement it. Satisfactorily\nsolving the DDA problem directly affects the player's experience when playing\nthe game, making it of high interest to any game developer, from independent\nones, to 100 billion dollar businesses, because of the potential impacts in\nplayer retention and monetization.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.02352,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000033445,
      "text":"Mission schedule of agile satellites based on Proximal Policy\n  Optimization Algorithm\n\n  Mission schedule of satellites is an important part of space operation\nnowadays, since the number and types of satellites in orbit are increasing\ntremendously and their corresponding tasks are also becoming more and more\ncomplicated. In this paper, a mission schedule model combined with Proximal\nPolicy Optimization Algorithm(PPO) is proposed. Different from the traditional\nheuristic planning method, this paper incorporate reinforcement learning\nalgorithms into it and find a new way to describe the problem. Several\nconstraints including data download are considered in this paper.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.02742,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000021524,
      "text":"Towards Game-Playing AI Benchmarks via Performance Reporting Standards\n\n  While games have been used extensively as milestones to evaluate game-playing\nAI, there exists no standardised framework for reporting the obtained\nobservations. As a result, it remains difficult to draw general conclusions\nabout the strengths and weaknesses of different game-playing AI algorithms. In\nthis paper, we propose reporting guidelines for AI game-playing performance\nthat, if followed, provide information suitable for unbiased comparisons\nbetween different AI approaches. The vision we describe is to build benchmarks\nand competitions based on such guidelines in order to be able to draw more\ngeneral conclusions about the behaviour of different AI algorithms, as well as\nthe types of challenges different games pose.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.04949,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000019206,
      "text":"A Generative Graph Method to Solve the Travelling Salesman Problem\n\n  The Travelling Salesman Problem (TSP) is a challenging graph task in\ncombinatorial optimization that requires reasoning about both local node\nneighborhoods and global graph structure. In this paper, we propose to use the\nnovel Graph Learning Network (GLN), a generative approach, to approximately\nsolve the TSP. GLN model learns directly the pattern of TSP instances as\ntraining dataset, encodes the graph properties, and merge the different node\nembeddings to output node-to-node an optimal tour directly or via graph search\ntechnique that validates the final tour. The preliminary results of the\nproposed novel approach proves its applicability to this challenging problem\nproviding a low optimally gap with significant computation saving compared to\nthe optimal solution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.01647,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"Learning intuitive physics and one-shot imitation using\n  state-action-prediction self-organizing maps\n\n  Human learning and intelligence work differently from the supervised pattern\nrecognition approach adopted in most deep learning architectures. Humans seem\nto learn rich representations by exploration and imitation, build causal models\nof the world, and use both to flexibly solve new tasks. We suggest a simple but\neffective unsupervised model which develops such characteristics. The agent\nlearns to represent the dynamical physical properties of its environment by\nintrinsically motivated exploration, and performs inference on this\nrepresentation to reach goals. For this, a set of self-organizing maps which\nrepresent state-action pairs is combined with a causal model for sequence\nprediction. The proposed system is evaluated in the cartpole environment. After\nan initial phase of playful exploration, the agent can execute kinematic\nsimulations of the environment's future, and use those for action planning. We\ndemonstrate its performance on a set of several related, but different one-shot\nimitation tasks, which the agent flexibly solves in an active inference style.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.05674,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000012252,
      "text":"Illuminating Mario Scenes in the Latent Space of a Generative\n  Adversarial Network\n\n  Generative adversarial networks (GANs) are quickly becoming a ubiquitous\napproach to procedurally generating video game levels. While GAN generated\nlevels are stylistically similar to human-authored examples, human designers\noften want to explore the generative design space of GANs to extract\ninteresting levels. However, human designers find latent vectors opaque and\nwould rather explore along dimensions the designer specifies, such as number of\nenemies or obstacles. We propose using state-of-the-art quality diversity\nalgorithms designed to optimize continuous spaces, i.e. MAP-Elites with a\ndirectional variation operator and Covariance Matrix Adaptation MAP-Elites, to\nefficiently explore the latent space of a GAN to extract levels that vary\nacross a set of specified gameplay measures. In the benchmark domain of Super\nMario Bros, we demonstrate how designers may specify gameplay measures to our\nsystem and extract high-quality (playable) levels with a diverse range of level\nmechanics, while still maintaining stylistic similarity to human authored\nexamples. An online user study shows how the different mechanics of the\nautomatically generated levels affect subjective ratings of their perceived\ndifficulty and appearance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.12586,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000078811,
      "text":"Introduction to Behavior Algorithms for Fighting Games\n\n  The quality of opponent Artificial Intelligence (AI) in fighting videogames\nis crucial. Some other game genres can rely on their story or visuals, but\nfighting games are all about the adversarial experience. In this paper, we will\nintroduce standard behavior algorithms in videogames, such as Finite-State\nMachines and Behavior Trees, as well as more recent developments, such as\nMonte-Carlo Tree Search. We will also discuss the existing and potential\ncombinations of these algorithms, and how they might be used in fighting games.\nSince we are at the financial peak of fighting games, both for casual players\nand in tournaments, it is important to build and expand on fighting game AI, as\nit is one of the pillars of this growing market.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.13475,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"Towards an ontology of HTTP interactions\n\n  Enterprise information systems have adopted Web-based foundations for\nexchanges between heterogeneous programmes. These programs provide and consume\nvia Web APIs some resources identified by URIs, whose representations are\ntransmitted via HTTP. Furthermore HTTP remains at the heart of all Web\ndevelopments (Semantic Web, linked data, IoT...). Thus, situations where a\nprogram must be able to reason about HTTP interactions (request-response) are\nmultiplying. This requires an explicit formal specification of a shared\nconceptualization of those interactions. A proposal for an RDF vocabulary\nexists, developed with a view to carrying out web application conformity tests\nand record the tests outputs. This vocabulary has already been reused. In this\npaper we propose to adapt and extend it for making it more reusable.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.05254,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000022517,
      "text":"Solving the Clustered Traveling Salesman Problem via TSP methods\n\n  The Clustered Traveling Salesman Problem (CTSP) is a variant of the popular\nTraveling Salesman Problem (TSP) arising from a number of real-life\napplications. In this work, we explore a transformation approach that solves\nthe CTSP by converting it to the well-studied TSP. For this purpose, we first\ninvestigate a technique to convert a CTSP instance to a TSP and then apply\npowerful TSP solvers (including exact and heuristic solvers) to solve the\nresulting TSP instance. We want to answer the following questions: How do\nstate-of-the-art TSP solvers perform on clustered instances converted from the\nCTSP? Do state-of-the-art TSP solvers compete well with the best performing\nmethods specifically designed for the CTSP? For this purpose, we present\nintensive computational experiments on various benchmark instances to draw\nconclusions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.06108,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000360608,
      "text":"Tabletop Roleplaying Games as Procedural Content Generators\n\n  Tabletop roleplaying games (TTRPGs) and procedural content generators can\nboth be understood as systems of rules for producing content. In this paper, we\nargue that TTRPG design can usefully be viewed as procedural content generator\ndesign. We present several case studies linking key concepts from PCG research\n-- including possibility spaces, expressive range analysis, and generative\npipelines -- to key concepts in TTRPG design. We then discuss the implications\nof these relationships and suggest directions for future work uniting research\nin TTRPGs and PCG.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2007.15703,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000333455,
      "text":"Improving Multi-Agent Cooperation using Theory of Mind\n\n  Recent advances in Artificial Intelligence have produced agents that can beat\nhuman world champions at games like Go, Starcraft, and Dota2. However, most of\nthese models do not seem to play in a human-like manner: People infer others'\nintentions from their behaviour, and use these inferences in scheming and\nstrategizing. Here, using a Bayesian Theory of Mind (ToM) approach, we\ninvestigated how much an explicit representation of others' intentions improves\nperformance in a cooperative game. We compared the performance of humans\nplaying with optimal-planning agents with and without ToM, in a cooperative\ngame where players have to flexibly cooperate to achieve joint goals. We find\nthat teams with ToM agents significantly outperform non-ToM agents when\ncollaborating with all types of partners: non-ToM, ToM, as well as human\nplayers, and that the benefit of ToM increases the more ToM agents there are.\nThese findings have implications for designing better cooperative agents.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.13146,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000006623,
      "text":"Deep Learning Techniques for Geospatial Data Analysis\n\n  Consumer electronic devices such as mobile handsets, goods tagged with RFID\nlabels, location and position sensors are continuously generating a vast amount\nof location enriched data called geospatial data. Conventionally such\ngeospatial data is used for military applications. In recent times, many useful\ncivilian applications have been designed and deployed around such geospatial\ndata. For example, a recommendation system to suggest restaurants or places of\nattraction to a tourist visiting a particular locality. At the same time, civic\nbodies are harnessing geospatial data generated through remote sensing devices\nto provide better services to citizens such as traffic monitoring, pothole\nidentification, and weather reporting. Typically such applications are\nleveraged upon non-hierarchical machine learning techniques such as Naive-Bayes\nClassifiers, Support Vector Machines, and decision trees. Recent advances in\nthe field of deep-learning showed that Neural Network-based techniques\noutperform conventional techniques and provide effective solutions for many\ngeospatial data analysis tasks such as object recognition, image\nclassification, and scene understanding. The chapter presents a survey on the\ncurrent state of the applications of deep learning techniques for analyzing\ngeospatial data.\n  The chapter is organized as below: (i) A brief overview of deep learning\nalgorithms. (ii)Geospatial Analysis: a Data Science Perspective (iii)\nDeep-learning techniques for Remote Sensing data analytics tasks (iv)\nDeep-learning techniques for GPS data analytics(iv) Deep-learning techniques\nfor RFID data analytics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.01253,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"An Application of ASP in Nuclear Engineering: Explaining the Three Mile\n  Island Nuclear Accident Scenario\n\n  The paper describes an ongoing effort in developing a declarative system for\nsupporting operators in the Nuclear Power Plant (NPP) control room. The focus\nis on two modules: diagnosis and explanation of events that happened in NPPs.\nWe describe an Answer Set Programming (ASP) representation of an NPP, which\nconsists of declarations of state variables, components, their connections, and\nrules encoding the plant behavior. We then show how the ASP program can be used\nto explain the series of events that occurred in the Three Mile Island, Unit 2\n(TMI-2) NPP accident, the most severe accident in the USA nuclear power plant\noperating history. We also describe an explanation module aimed at addressing\nanswers to questions such as ``why an event occurs?'' or ``what should be\ndone?'' given the collected data.\n  This paper is *under consideration* for acceptance in TPLP Journal.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.03444,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000080135,
      "text":"Hierarchical Reinforcement Learning in StarCraft II with Human Expertise\n  in Subgoals Selection\n\n  This work is inspired by recent advances in hierarchical reinforcement\nlearning (HRL) (Barto and Mahadevan 2003; Hengst 2010), and improvements in\nlearning efficiency from heuristic-based subgoal selection, experience replay\n(Lin 1993; Andrychowicz et al. 2017), and task-based curriculum learning\n(Bengio et al. 2009; Zaremba and Sutskever 2014). We propose a new method to\nintegrate HRL, experience replay and effective subgoal selection through an\nimplicit curriculum design based on human expertise to support sample-efficient\nlearning and enhance interpretability of the agent's behavior. Human expertise\nremains indispensable in many areas such as medicine (Buch, Ahmed, and\nMaruthappu 2018) and law (Cath 2018), where interpretability, explainability\nand transparency are crucial in the decision making process, for ethical and\nlegal reasons. Our method simplifies the complex task sets for achieving the\noverall objectives by decomposing them into subgoals at different levels of\nabstraction. Incorporating relevant subjective knowledge also significantly\nreduces the computational resources spent in exploration for RL, especially in\nhigh speed, changing, and complex environments where the transition dynamics\ncannot be effectively learned and modelled in a short time. Experimental\nresults in two StarCraft II (SC2) (Vinyals et al. 2017) minigames demonstrate\nthat our method can achieve better sample efficiency than flat and end-to-end\nRL methods, and provides an effective method for explaining the agent's\nperformance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.01415,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000017881,
      "text":"Modular Constraint Solver Cooperation via Abstract Interpretation\n\n  Cooperation among constraint solvers is difficult because different solving\nparadigms have different theoretical foundations. Recent works have shown that\nabstract interpretation can provide a unifying theory for various constraint\nsolvers. In particular, it relies on abstract domains which capture constraint\nlanguages as ordered structures. The key insight of this paper is viewing\ncooperation schemes as abstract domains combinations. We propose a modular\nframework in which solvers and cooperation schemes can be seamlessly added and\ncombined. This differs from existing approaches such as SMT where the\ncooperation scheme is usually fixed (e.g., Nelson-Oppen). We contribute to two\nnew cooperation schemes: (i) interval propagators completion that allows\nabstract domains to exchange bound constraints, and (ii) delayed product which\nexchanges over-approximations of constraints between two abstract domains.\nMoreover, the delayed product is based on delayed goal of logic programming,\nand it shows that abstract domains can also capture control aspects of\nconstraint solving. Finally, to achieve modularity, we propose the shared\nproduct to combine abstract domains and cooperation schemes. Our approach has\nbeen fully implemented, and we provide various examples on the flexible job\nshop scheduling problem. Under consideration for acceptance in TPLP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.00463,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"Structural Causal Models Are (Solvable by) Credal Networks\n\n  A structural causal model is made of endogenous (manifest) and exogenous\n(latent) variables. We show that endogenous observations induce linear\nconstraints on the probabilities of the exogenous variables. This allows to\nexactly map a causal model into a credal network. Causal inferences, such as\ninterventions and counterfactuals, can consequently be obtained by standard\nalgorithms for the updating of credal nets. These natively return sharp values\nin the identifiable case, while intervals corresponding to the exact bounds are\nproduced for unidentifiable queries. A characterization of the causal models\nthat allow the map above to be compactly derived is given, along with a\ndiscussion about the scalability for general models. This contribution should\nbe regarded as a systematic approach to represent structural causal models by\ncredal networks and hence to systematically compute causal inferences. A number\nof demonstrative examples is presented to clarify our methodology. Extensive\nexperiments show that approximate algorithms for credal networks can\nimmediately be used to do causal inference in real-size problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.039,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000024835,
      "text":"Wikidata Constraints on MARS (Extended Technical Report)\n\n  Wikidata constraints, albeit useful, are represented and processed in an\nincomplete, ad hoc fashion. Constraint declarations do not fully express their\nmeaning, and thus do not provide a precise, unambiguous basis for constraint\nspecification, or a logical foundation for constraint-checking implementations.\nIn prior work we have proposed a logical framework for Wikidata as a whole,\nbased on multi-attributed relational structures (MARS) and related logical\nlanguages. In this paper we explain how constraints are handled in the proposed\nframework, and show that nearly all of Wikidata's existing property constraints\ncan be completely characterized in it, in a natural and economical fashion. We\nalso give characterizations for several proposed property constraints, and show\nthat a variety of non-property constraints can be handled in the same\nframework.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.04793,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"Future Trends for Human-AI Collaboration: A Comprehensive Taxonomy of\n  AI\/AGI Using Multiple Intelligences and Learning Styles\n\n  This article discusses some trends and concepts in developing new generation\nof future Artificial General Intelligence (AGI) systems which relate to complex\nfacets and different types of human intelligence, especially social, emotional,\nattentional and ethical intelligence. We describe various aspects of multiple\nhuman intelligences and learning styles, which may impact on a variety of AI\nproblem domains. Using the concept of 'multiple intelligences' rather than a\nsingle type of intelligence, we categorize and provide working definitions of\nvarious AGI depending on their cognitive skills or capacities. Future AI\nsystems will be able not only to communicate with human users and each other,\nbut also to efficiently exchange knowledge and wisdom with abilities of\ncooperation, collaboration and even co-creating something new and valuable and\nhave meta-learning capacities. Multi-agent systems such as these can be used to\nsolve problems that would be difficult to solve by any individual intelligent\nagent.\n  Key words: Artificial General Intelligence (AGI), multiple intelligences,\nlearning styles, physical intelligence, emotional intelligence, social\nintelligence, attentional intelligence, moral-ethical intelligence, responsible\ndecision making, creative-innovative intelligence, cognitive functions,\nmeta-learning of AI systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.06693,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000009272,
      "text":"Explainability in Deep Reinforcement Learning\n\n  A large set of the explainable Artificial Intelligence (XAI) literature is\nemerging on feature relevance techniques to explain a deep neural network (DNN)\noutput or explaining models that ingest image source data. However, assessing\nhow XAI techniques can help understand models beyond classification tasks, e.g.\nfor reinforcement learning (RL), has not been extensively studied. We review\nrecent works in the direction to attain Explainable Reinforcement Learning\n(XRL), a relatively new subfield of Explainable Artificial Intelligence,\nintended to be used in general public applications, with diverse audiences,\nrequiring ethical, responsible and trustable algorithms. In critical situations\nwhere it is essential to justify and explain the agent's behaviour, better\nexplainability and interpretability of RL models could help gain scientific\ninsight on the inner workings of what is still considered a black box. We\nevaluate mainly studies directly linking explainability to RL, and split these\ninto two categories according to the way the explanations are generated:\ntransparent algorithms and post-hoc explainaility. We also review the most\nprominent XAI works from the lenses of how they could potentially enlighten the\nfurther deployment of the latest advances in RL, in the demanding present and\nfuture of everyday problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.01188,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000008278,
      "text":"Learning to Play Two-Player Perfect-Information Games without Knowledge\n\n  In this paper, several techniques for learning game state evaluation\nfunctions by reinforcement are proposed. The first is a generalization of tree\nbootstrapping (tree learning): it is adapted to the context of reinforcement\nlearning without knowledge based on non-linear functions. With this technique,\nno information is lost during the reinforcement learning process. The second is\na modification of minimax with unbounded depth extending the best sequences of\nactions to the terminal states. This modified search is intended to be used\nduring the learning process. The third is to replace the classic gain of a game\n(+1 \/ -1) with a reinforcement heuristic. We study particular reinforcement\nheuristics such as: quick wins and slow defeats ; scoring ; mobility or\npresence. The four is a new action selection distribution. The conducted\nexperiments suggest that these techniques improve the level of play. Finally,\nwe apply these different techniques to design program-players to the game of\nHex (size 11 and 13) surpassing the level of Mohex 3HNN with reinforcement\nlearning from self-play without knowledge.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.01519,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000005298,
      "text":"A Generalised Approach for Encoding and Reasoning with Qualitative\n  Theories in Answer Set Programming\n\n  Qualitative reasoning involves expressing and deriving knowledge based on\nqualitative terms such as natural language expressions, rather than strict\nmathematical quantities. Well over 40 qualitative calculi have been proposed so\nfar, mostly in the spatial and temporal domains, with several practical\napplications such as naval traffic monitoring, warehouse process optimisation\nand robot manipulation. Even if a number of specialised qualitative reasoning\ntools have been developed so far, an important barrier to the wider adoption of\nthese tools is that only qualitative reasoning is supported natively, when\nreal-world problems most often require a combination of qualitative and other\nforms of reasoning. In this work, we propose to overcome this barrier by using\nASP as a unifying formalism to tackle problems that require qualitative\nreasoning in addition to non-qualitative reasoning. A family of ASP encodings\nis proposed which can handle any qualitative calculus with binary relations.\nThese encodings are experimentally evaluated using a real-world dataset based\non a case study of determining optimal coverage of telecommunication antennas,\nand compared with the performance of two well-known dedicated reasoners.\nExperimental results show that the proposed encodings outperform one of the two\nreasoners, but fall behind the other, an acceptable trade-off given the added\nbenefits of handling any type of reasoning as well as the interpretability of\nlogic programs. This paper is under consideration for acceptance in TPLP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.06599,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000057949,
      "text":"Wikidata on MARS\n\n  Multi-attributed relational structures (MARSs) have been proposed as a formal\ndata model for generalized property graphs, along with multi-attributed\nrule-based predicate logic (MARPL) as a useful rule-based logic in which to\nwrite inference rules over property graphs. Wikidata can be modelled in an\nextended MARS that adds the (imprecise) datatypes of Wikidata. The rules of\ninference for the Wikidata ontology can be modelled as a MARPL ontology, with\nextensions to handle the Wikidata datatypes and functions over these datatypes.\nBecause many Wikidata qualifiers should participate in most inference rules in\nWikidata a method of implicitly handling qualifier values on a per-qualifier\nbasis is needed to make this modelling useful. The meaning of Wikidata is then\nthe extended MARS that is the closure of running these rules on the Wikidata\ndata model. Wikidata constraints can be modelled as multi-attributed predicate\nlogic (MAPL) formulae, again extended with datatypes, that are evaluated over\nthis extended MARS. The result models Wikidata in a way that fixes several of\nits major problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.031,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Conflict Generalisation in ASP: Learning Correct and Effective\n  Non-Ground Constraints\n\n  Generalising and re-using knowledge learned while solving one problem\ninstance has been neglected by state-of-the-art answer set solvers. We suggest\na new approach that generalises learned nogoods for re-use to speed-up the\nsolving of future problem instances. Our solution combines well-known ASP\nsolving techniques with deductive logic-based machine learning. Solving\nperformance can be improved by adding learned non-ground constraints to the\noriginal program. We demonstrate the effects of our method by means of\nrealistic examples, showing that our approach requires low computational cost\nto learn constraints that yield significant performance benefits in our test\ncases. These benefits can be seen with ground-and-solve systems as well as\nlazy-grounding systems. However, ground-and-solve systems suffer from\nadditional grounding overheads, induced by the additional constraints in some\ncases. By means of conflict minimization, non-minimal learned constraints can\nbe reduced. This can result in significant reductions of grounding and solving\nefforts, as our experiments show. (Under consideration for acceptance in TPLP.)\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.01508,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Explanation of Reinforcement Learning Model in Dynamic Multi-Agent\n  System\n\n  Recently, there has been increasing interest in transparency and\ninterpretability in Deep Reinforcement Learning (DRL) systems. Verbal\nexplanations, as the most natural way of communication in our daily life,\ndeserve more attention, since they allow users to gain a better understanding\nof the system which ultimately could lead to a high level of trust and smooth\ncollaboration. This paper reports a novel work in generating verbal\nexplanations for DRL behaviors agent. A rule-based model is designed to\nconstruct explanations using a series of rules which are predefined with prior\nknowledge. A learning model is then proposed to expand the implicit logic of\ngenerating verbal explanation to general situations by employing rule-based\nexplanations as training data. The learning model is shown to have better\nflexibility and generalizability than the static rule-based model. The\nperformance of both models is evaluated quantitatively through objective\nmetrics. The results show that verbal explanation generated by both models\nimprove subjective satisfaction of users towards the interpretability of DRL\nsystems. Additionally, seven variants of the learning model are designed to\nillustrate the contribution of input channels, attention mechanism, and\nproposed encoder in improving the quality of verbal explanation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.046,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"Planimation\n\n  Planimation is a modular and extensible open source framework to visualise\nsequential solutions of planning problems specified in PDDL. We introduce a\npreliminary declarative PDDL-like animation profile specification, expressive\nenough to synthesise animations of arbitrary initial states and goals of a\nbenchmark with just a single profile.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.08548,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000028478,
      "text":"A Survey of Knowledge-based Sequential Decision Making under Uncertainty\n\n  Reasoning with declarative knowledge (RDK) and sequential decision-making\n(SDM) are two key research areas in artificial intelligence. RDK methods reason\nwith declarative domain knowledge, including commonsense knowledge, that is\neither provided a priori or acquired over time, while SDM methods\n(probabilistic planning and reinforcement learning) seek to compute action\npolicies that maximize the expected cumulative utility over a time horizon;\nboth classes of methods reason in the presence of uncertainty. Despite the rich\nliterature in these two areas, researchers have not fully explored their\ncomplementary strengths. In this paper, we survey algorithms that leverage RDK\nmethods while making sequential decisions under uncertainty. We discuss\nsignificant developments, open problems, and directions for future work.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.10114,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000114905,
      "text":"Handling of uncertainty in medical data using machine learning and\n  probability theory techniques: A review of 30 years (1991-2020)\n\n  Understanding data and reaching valid conclusions are of paramount importance\nin the present era of big data. Machine learning and probability theory methods\nhave widespread application for this purpose in different fields. One\ncritically important yet less explored aspect is how data and model\nuncertainties are captured and analyzed. Proper quantification of uncertainty\nprovides valuable information for optimal decision making. This paper reviewed\nrelated studies conducted in the last 30 years (from 1991 to 2020) in handling\nuncertainties in medical data using probability theory and machine learning\ntechniques. Medical data is more prone to uncertainty due to the presence of\nnoise in the data. So, it is very important to have clean medical data without\nany noise to get accurate diagnosis. The sources of noise in the medical data\nneed to be known to address this issue. Based on the medical data obtained by\nthe physician, diagnosis of disease, and treatment plan are prescribed. Hence,\nthe uncertainty is growing in healthcare and there is limited knowledge to\naddress these problems. We have little knowledge about the optimal treatment\nmethods as there are many sources of uncertainty in medical science. Our\nfindings indicate that there are few challenges to be addressed in handling the\nuncertainty in medical raw data and new models. In this work, we have\nsummarized various methods employed to overcome this problem. Nowadays,\napplication of novel deep learning techniques to deal such uncertainties have\nsignificantly increased.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.02735,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000024504,
      "text":"Towards Ranking-based Semantics for Abstract Argumentation using\n  Conditional Logic Semantics\n\n  We propose a novel ranking-based semantics for Dung-style argumentation\nframeworks with the help of conditional logics. Using an intuitive translation\nfor an argumentation framework to generate conditionals, we can apply\nnonmonotonic inference systems to generate a ranking on possible worlds. With\nthis ranking we construct a ranking for our arguments. With a small extension\nto this ranking-based semantics we already satisfy some desirable properties\nfor a ranking over arguments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.08114,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000025829,
      "text":"Commonsense Knowledge in Wikidata\n\n  Wikidata and Wikipedia have been proven useful for reason-ing in natural\nlanguage applications, like question answering or entitylinking. Yet, no\nexisting work has studied the potential of Wikidata for commonsense reasoning.\nThis paper investigates whether Wikidata con-tains commonsense knowledge which\nis complementary to existing commonsense sources. Starting from a definition of\ncommon sense, we devise three guiding principles, and apply them to generate a\ncommonsense subgraph of Wikidata (Wikidata-CS). Within our approach, we map the\nrelations of Wikidata to ConceptNet, which we also leverage to integrate\nWikidata-CS into an existing consolidated commonsense graph. Our experiments\nreveal that: 1) albeit Wikidata-CS represents a small portion of Wikidata, it\nis an indicator that Wikidata contains relevant commonsense knowledge, which\ncan be mapped to 15 ConceptNet relations; 2) the overlap between Wikidata-CS\nand other commonsense sources is low, motivating the value of knowledge\nintegration; 3) Wikidata-CS has been evolving over time at a slightly slower\nrate compared to the overall Wikidata, indicating a possible lack of focus on\ncommonsense knowledge. Based on these findings, we propose three recommended\nactions to improve the coverage and quality of Wikidata-CS further.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.04875,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"Ortus: an Emotion-Driven Approach to (artificial) Biological\n  Intelligence\n\n  Ortus is a simple virtual organism that also serves as an initial framework\nfor investigating and developing biologically-based artificial intelligence.\nBorn from a goal to create complex virtual intelligence and an initial attempt\nto model C. elegans, Ortus implements a number of mechanisms observed in\norganic nervous systems, and attempts to fill in unknowns based upon plausible\nbiological implementations and psychological observations. Implemented\nmechanisms include excitatory and inhibitory chemical synapses, bidirectional\ngap junctions, and Hebbian learning with its Stentian extension. We present an\ninitial experiment that showcases Ortus' fundamental principles; specifically,\na cyclic respiratory circuit, and emotionally-driven associative learning with\nrespect to an input stimulus. Finally, we discuss the implications and future\ndirections for Ortus and similar systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2008.05297,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000017219,
      "text":"Fuzzy OWL-BOOST: Learning Fuzzy Concept Inclusions via Real-Valued\n  Boosting\n\n  OWL ontologies are nowadays a quite popular way to describe structured\nknowledge in terms of classes, relations among classes and class instances. In\nthis paper, given a target class T of an OWL ontology, we address the problem\nof learning fuzzy concept inclusion axioms that describe sufficient conditions\nfor being an individual instance of T. To do so, we present Fuzzy OWL-BOOST\nthat relies on the Real AdaBoost boosting algorithm adapted to the (fuzzy) OWL\ncase. We illustrate its effectiveness by means of an experimentation. An\ninteresting feature is that the learned rules can be represented directly into\nFuzzy OWL 2. As a consequence, any Fuzzy OWL 2 reasoner can then be used to\nautomatically determine\/classify (and to which degree) whether an individual\nbelongs to the target class T.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.0637,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000000662,
      "text":"Transparency and granularity in the SP Theory of Intelligence and its\n  realisation in the SP Computer Model\n\n  This chapter describes how the SP System, meaning the SP Theory of\nIntelligence, and its realisation as the SP Computer Model, may promote\ntransparency and granularity in AI, and some other areas of application. The\nchapter describes how transparency in the workings and output of the SP\nComputer Model may be achieved via three routes: 1) the program provides a very\nfull audit trail for such processes as recognition, reasoning, analysis of\nlanguage, and so on. There is also an explicit audit trail for the unsupervised\nlearning of new knowledge; 2) knowledge from the system is likely to be\ngranular and easy for people to understand; and 3) there are seven principles\nfor the organisation of knowledge which are central in the workings of the SP\nSystem and also very familiar to people (eg chunking-with-codes, part-whole\nhierarchies, and class-inclusion hierarchies), and that kind of familiarity in\nthe way knowledge is structured by the system, is likely to be important in the\ninterpretability, explainability, and transparency of that knowledge. Examples\nfrom the SP Computer Model are shown throughout the chapter.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.14654,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000046028,
      "text":"OWL2Vec*: Embedding of OWL Ontologies\n\n  Semantic embedding of knowledge graphs has been widely studied and used for\nprediction and statistical analysis tasks across various domains such as\nNatural Language Processing and the Semantic Web. However, less attention has\nbeen paid to developing robust methods for embedding OWL (Web Ontology\nLanguage) ontologies which can express a much wider range of semantics than\nknowledge graphs and have been widely adopted in domains such as\nbioinformatics. In this paper, we propose a random walk and word embedding\nbased ontology embedding method named OWL2Vec*, which encodes the semantics of\nan OWL ontology by taking into account its graph structure, lexical information\nand logical constructors. Our empirical evaluation with three real world\ndatasets suggests that OWL2Vec* benefits from these three different aspects of\nan ontology in class membership prediction and class subsumption prediction\ntasks. Furthermore, OWL2Vec* often significantly outperforms the\nstate-of-the-art methods in our experiments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.05912,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000410279,
      "text":"DualDE: Dually Distilling Knowledge Graph Embedding for Faster and\n  Cheaper Reasoning\n\n  Knowledge Graph Embedding (KGE) is a popular method for KG reasoning and\ntraining KGEs with higher dimension are usually preferred since they have\nbetter reasoning capability. However, high-dimensional KGEs pose huge\nchallenges to storage and computing resources and are not suitable for\nresource-limited or time-constrained applications, for which faster and cheaper\nreasoning is necessary. To address this problem, we propose DualDE, a knowledge\ndistillation method to build low-dimensional student KGE from pre-trained\nhigh-dimensional teacher KGE. DualDE considers the dual-influence between the\nteacher and the student. In DualDE, we propose a soft label evaluation\nmechanism to adaptively assign different soft label and hard label weights to\ndifferent triples, and a two-stage distillation approach to improve the\nstudent's acceptance of the teacher. Our DualDE is general enough to be applied\nto various KGEs. Experimental results show that our method can successfully\nreduce the embedding parameters of a high-dimensional KGE by 7 times - 15 times\nand increase the inference speed by 2 times - 6 times while retaining a high\nperformance. We also experimentally prove the effectiveness of our soft label\nevaluation mechanism and two-stage distillation approach via ablation study.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.08776,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000070863,
      "text":"Dealing with Incompatibilities among Procedural Goals under Uncertainty\n\n  By considering rational agents, we focus on the problem of selecting goals\nout of a set of incompatible ones. We consider three forms of incompatibility\nintroduced by Castelfranchi and Paglieri, namely the terminal, the instrumental\n(or based on resources), and the superfluity. We represent the agent's plans by\nmeans of structured arguments whose premises are pervaded with uncertainty. We\nmeasure the strength of these arguments in order to determine the set of\ncompatible goals. We propose two novel ways for calculating the strength of\nthese arguments, depending on the kind of incompatibility that exists between\nthem. The first one is the logical strength value, it is denoted by a\nthree-dimensional vector, which is calculated from a probabilistic interval\nassociated with each argument. The vector represents the precision of the\ninterval, the location of it, and the combination of precision and location.\nThis type of representation and treatment of the strength of a structured\nargument has not been defined before by the state of the art. The second way\nfor calculating the strength of the argument is based on the cost of the plans\n(regarding the necessary resources) and the preference of the goals associated\nwith the plans. Considering our novel approach for measuring the strength of\nstructured arguments, we propose a semantics for the selection of plans and\ngoals that is based on Dung's abstract argumentation theory. Finally, we make a\ntheoretical evaluation of our proposal.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.1378,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000186099,
      "text":"Cross Learning in Deep Q-Networks\n\n  In this work, we propose a novel cross Q-learning algorithm, aim at\nalleviating the well-known overestimation problem in value-based reinforcement\nlearning methods, particularly in the deep Q-networks where the overestimation\nis exaggerated by function approximation errors. Our algorithm builds on double\nQ-learning, by maintaining a set of parallel models and estimate the Q-value\nbased on a randomly selected network, which leads to reduced overestimation\nbias as well as the variance. We provide empirical evidence on the advantages\nof our method by evaluating on some benchmark environment, the experimental\nresults demonstrate significant improvement of performance in reducing the\noverestimation bias and stabilizing the training, further leading to better\nderived policies.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.14365,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000102652,
      "text":"Toolpath design for additive manufacturing using deep reinforcement\n  learning\n\n  Toolpath optimization of metal-based additive manufacturing processes is\ncurrently hampered by the high-dimensionality of its design space. In this\nwork, a reinforcement learning platform is proposed that dynamically learns\ntoolpath strategies to build an arbitrary part. To this end, three prominent\nmodel-free reinforcement learning formulations are investigated to design\nadditive manufacturing toolpaths and demonstrated for two cases of dense and\nsparse reward structures. The results indicate that this learning-based\ntoolpath design approach achieves high scores, especially when a dense reward\nstructure is present.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.09263,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000103315,
      "text":"Inductive Learning on Commonsense Knowledge Graph Completion\n\n  Commonsense knowledge graph (CKG) is a special type of knowledge graph (KG),\nwhere entities are composed of free-form text. However, most existing CKG\ncompletion methods focus on the setting where all the entities are presented at\ntraining time. Although this setting is standard for conventional KG\ncompletion, it has limitations for CKG completion. At test time, entities in\nCKGs can be unseen because they may have unseen text\/names and entities may be\ndisconnected from the training graph, since CKGs are generally very sparse.\nHere, we propose to study the inductive learning setting for CKG completion\nwhere unseen entities may present at test time. We develop a novel learning\nframework named InductivE. Different from previous approaches, InductiveE\nensures the inductive learning capability by directly computing entity\nembeddings from raw entity attributes\/text. InductiveE consists of a free-text\nencoder, a graph encoder, and a KG completion decoder. Specifically, the\nfree-text encoder first extracts the textual representation of each entity\nbased on the pre-trained language model and word embedding. The graph encoder\nis a gated relational graph convolutional neural network that learns from a\ndensified graph for more informative entity representation learning. We develop\na method that densifies CKGs by adding edges among semantic-related entities\nand provide more supportive information for unseen entities, leading to better\ngeneralization ability of entity embedding for unseen entities. Finally,\ninductiveE employs Conv-TransE as the CKG completion decoder. Experimental\nresults show that InductiveE significantly outperforms state-of-the-art\nbaselines in both standard and inductive settings on ATOMIC and ConceptNet\nbenchmarks. InductivE performs especially well on inductive scenarios where it\nachieves above 48% improvement over present methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.01509,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000031789,
      "text":"User Intention Recognition and Requirement Elicitation Method for\n  Conversational AI Services\n\n  In recent years, chat-bot has become a new type of intelligent terminal to\nguide users to consume services. However, it is criticized most that the\nservices it provides are not what users expect or most expect. This defect\nmostly dues to two problems, one is that the incompleteness and uncertainty of\nuser's requirement expression caused by the information asymmetry, the other is\nthat the diversity of service resources leads to the difficulty of service\nselection. Conversational bot is a typical mesh device, so the guided\nmulti-rounds Q$\\&$A is the most effective way to elicit user requirements.\nObviously, complex Q$\\&$A with too many rounds is boring and always leads to\nbad user experience. Therefore, we aim to obtain user requirements as\naccurately as possible in as few rounds as possible. To achieve this, a user\nintention recognition method based on Knowledge Graph (KG) was developed for\nfuzzy requirement inference, and a requirement elicitation method based on\nGranular Computing was proposed for dialog policy generation. Experimental\nresults show that these two methods can effectively reduce the number of\nconversation rounds, and can quickly and accurately identify the user\nintention.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.00048,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000010928,
      "text":"Creative Captioning: An AI Grand Challenge Based on the Dixit Board Game\n\n  We propose a new class of \"grand challenge\" AI problems that we call creative\ncaptioning---generating clever, interesting, or abstract captions for images,\nas well as understanding such captions. Creative captioning draws on core AI\nresearch areas of vision, natural language processing, narrative reasoning, and\nsocial reasoning, and across all these areas, it requires sophisticated uses of\ncommon sense and cultural knowledge. In this paper, we analyze several specific\nresearch problems that fall under creative captioning, using the popular board\ngame Dixit as both inspiration and proposed testing ground. We expect that\nDixit could serve as an engaging and motivating benchmark for creative\ncaptioning across numerous AI research communities for the coming 1-2 decades.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.05991,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000036756,
      "text":"GIKT: A Graph-based Interaction Model for Knowledge Tracing\n\n  With the rapid development in online education, knowledge tracing (KT) has\nbecome a fundamental problem which traces students' knowledge status and\npredicts their performance on new questions. Questions are often numerous in\nonline education systems, and are always associated with much fewer skills.\nHowever, the previous literature fails to involve question information together\nwith high-order question-skill correlations, which is mostly limited by data\nsparsity and multi-skill problems. From the model perspective, previous models\ncan hardly capture the long-term dependency of student exercise history, and\ncannot model the interactions between student-questions, and student-skills in\na consistent way. In this paper, we propose a Graph-based Interaction model for\nKnowledge Tracing (GIKT) to tackle the above probems. More specifically, GIKT\nutilizes graph convolutional network (GCN) to substantially incorporate\nquestion-skill correlations via embedding propagation. Besides, considering\nthat relevant questions are usually scattered throughout the exercise history,\nand that question and skill are just different instantiations of knowledge,\nGIKT generalizes the degree of students' master of the question to the\ninteractions between the student's current state, the student's history related\nexercises, the target question, and related skills. Experiments on three\ndatasets demonstrate that GIKT achieves the new state-of-the-art performance,\nwith at least 1% absolute AUC improvement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.02164,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000006292,
      "text":"Technical Report: The Policy Graph Improvement Algorithm\n\n  Optimizing a partially observable Markov decision process (POMDP) policy is\nchallenging. The policy graph improvement (PGI) algorithm for POMDPs represents\nthe policy as a fixed size policy graph and improves the policy monotonically.\nDue to the fixed policy size, computation time for each improvement iteration\nis known in advance. Moreover, the method allows for compact understandable\npolicies. This report describes the technical details of the PGI [1] and\nparticle based PGI [2] algorithms for POMDPs in a more accessible way than [1]\nor [2] allowing practitioners and students to understand and implement the\nalgorithms.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.07448,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Question Directed Graph Attention Network for Numerical Reasoning over\n  Text\n\n  Numerical reasoning over texts, such as addition, subtraction, sorting and\ncounting, is a challenging machine reading comprehension task, since it\nrequires both natural language understanding and arithmetic computation. To\naddress this challenge, we propose a heterogeneous graph representation for the\ncontext of the passage and question needed for such reasoning, and design a\nquestion directed graph attention network to drive multi-step numerical\nreasoning over this context graph. The code link is at:\nhttps:\/\/github.com\/emnlp2020qdgat\/QDGAT\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.00964,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000068545,
      "text":"A framework for a modular multi-concept lexicographic closure semantics\n\n  We define a modular multi-concept extension of the lexicographic closure\nsemantics for defeasible description logics with typicality. The idea is that\nof distributing the defeasible properties of concepts into different modules,\naccording to their subject, and of defining a notion of preference for each\nmodule based on the lexicographic closure semantics. The preferential semantics\nof the knowledge base can then be defined as a combination of the preferences\nof the single modules. The range of possibilities, from fine grained to coarse\ngrained modules, provides a spectrum of alternative semantics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.14795,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Explaining AI as an Exploratory Process: The Peircean Abduction Model\n\n  Current discussions of \"Explainable AI\" (XAI) do not much consider the role\nof abduction in explanatory reasoning (see Mueller, et al., 2018). It might be\nworthwhile to pursue this, to develop intelligent systems that allow for the\nobservation and analysis of abductive reasoning and the assessment of abductive\nreasoning as a learnable skill. Abductive inference has been defined in many\nways. For example, it has been defined as the achievement of insight. Most\noften abduction is taken as a single, punctuated act of syllogistic reasoning,\nlike making a deductive or inductive inference from given premises. In\ncontrast, the originator of the concept of abduction---the American\nscientist\/philosopher Charles Sanders Peirce---regarded abduction as an\nexploratory activity. In this regard, Peirce's insights about reasoning align\nwith conclusions from modern psychological research. Since abduction is often\ndefined as \"inferring the best explanation,\" the challenge of implementing\nabductive reasoning and the challenge of automating the explanation process are\nclosely linked. We explore these linkages in this report. This analysis\nprovides a theoretical framework for understanding what the XAI researchers are\nalready doing, it explains why some XAI projects are succeeding (or might\nsucceed), and it leads to design advice.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.06756,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.000000298,
      "text":"Analysis of Models for Decentralized and Collaborative AI on Blockchain\n\n  Machine learning has recently enabled large advances in artificial\nintelligence, but these results can be highly centralized. The large datasets\nrequired are generally proprietary; predictions are often sold on a per-query\nbasis; and published models can quickly become out of date without effort to\nacquire more data and maintain them. Published proposals to provide models and\ndata for free for certain tasks include Microsoft Research's Decentralized and\nCollaborative AI on Blockchain. The framework allows participants to\ncollaboratively build a dataset and use smart contracts to share a continuously\nupdated model on a public blockchain. The initial proposal gave an overview of\nthe framework omitting many details of the models used and the incentive\nmechanisms in real world scenarios. In this work, we evaluate the use of\nseveral models and configurations in order to propose best practices when using\nthe Self-Assessment incentive mechanism so that models can remain accurate and\nwell-intended participants that submit correct data have the chance to profit.\nWe have analyzed simulations for each of three models: Perceptron, Na\\\"ive\nBayes, and a Nearest Centroid Classifier, with three different datasets:\npredicting a sport with user activity from Endomondo, sentiment analysis on\nmovie reviews from IMDB, and determining if a news article is fake. We compare\nseveral factors for each dataset when models are hosted in smart contracts on a\npublic blockchain: their accuracy over time, balances of a good and bad user,\nand transaction costs (or gas) for deploying, updating, collecting refunds, and\ncollecting rewards. A free and open source implementation for the Ethereum\nblockchain and simulations written in Python is provided at\nhttps:\/\/github.com\/microsoft\/0xDeCA10B. This version has updated gas costs\nusing newer optimizations written after the original publication.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.08656,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000025166,
      "text":"EM-RBR: a reinforced framework for knowledge graph completion from\n  reasoning perspective\n\n  Knowledge graph completion aims to predict the new links in given entities\namong the knowledge graph (KG). Most mainstream embedding methods focus on fact\ntriplets contained in the given KG, however, ignoring the rich background\ninformation provided by logic rules driven from knowledge base implicitly. To\nsolve this problem, in this paper, we propose a general framework, named\nEM-RBR(embedding and rule-based reasoning), capable of combining the advantages\nof reasoning based on rules and the state-of-the-art models of embedding.\nEM-RBR aims to utilize relational background knowledge contained in rules to\nconduct multi-relation reasoning link prediction rather than superficial vector\ntriangle linkage in embedding models. By this way, we can explore relation\nbetween two entities in deeper context to achieve higher accuracy. In\nexperiments, we demonstrate that EM-RBR achieves better performance compared\nwith previous models on FB15k, WN18 and our new dataset FB15k-R, especially the\nnew dataset where our model perform futher better than those state-of-the-arts.\nWe make the implementation of EM-RBR available at\nhttps:\/\/github.com\/1173710224\/link-prediction-with-rule-based-reasoning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.08087,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.000025034,
      "text":"Urban Traffic Flow Forecast Based on FastGCRNN\n\n  Traffic forecasting is an important prerequisite for the application of\nintelligent transportation systems in urban traffic networks. The existing\nworks adopted RNN and CNN\/GCN, among which GCRN is the state of art work, to\ncharacterize the temporal and spatial correlation of traffic flows. However, it\nis hard to apply GCRN to the large scale road networks due to high\ncomputational complexity. To address this problem, we propose to abstract the\nroad network into a geometric graph and build a Fast Graph Convolution\nRecurrent Neural Network (FastGCRNN) to model the spatial-temporal dependencies\nof traffic flow. Specifically, We use FastGCN unit to efficiently capture the\ntopological relationship between the roads and the surrounding roads in the\ngraph with reducing the computational complexity through importance sampling,\ncombine GRU unit to capture the temporal dependency of traffic flow, and embed\nthe spatiotemporal features into Seq2Seq based on the Encoder-Decoder\nframework. Experiments on large-scale traffic data sets illustrate that the\nproposed method can greatly reduce computational complexity and memory\nconsumption while maintaining relatively high accuracy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.07445,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000006954,
      "text":"Theory of Mind with Guilt Aversion Facilitates Cooperative Reinforcement\n  Learning\n\n  Guilt aversion induces experience of a utility loss in people if they believe\nthey have disappointed others, and this promotes cooperative behaviour in\nhuman. In psychological game theory, guilt aversion necessitates modelling of\nagents that have theory about what other agents think, also known as Theory of\nMind (ToM). We aim to build a new kind of affective reinforcement learning\nagents, called Theory of Mind Agents with Guilt Aversion (ToMAGA), which are\nequipped with an ability to think about the wellbeing of others instead of just\nself-interest. To validate the agent design, we use a general-sum game known as\nStag Hunt as a test bed. As standard reinforcement learning agents could learn\nsuboptimal policies in social dilemmas like Stag Hunt, we propose to use\nbelief-based guilt aversion as a reward shaping mechanism. We show that our\nbelief-based guilt averse agents can efficiently learn cooperative behaviours\nin Stag Hunt Games.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.04903,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000083447,
      "text":"Possible Controllability of Control Argumentation Frameworks -- Extended\n  Version\n\n  The recent Control Argumentation Framework (CAF) is a generalization of\nDung's Argumentation Framework which handles argumentation dynamics under\nuncertainty; especially it can be used to model the behavior of an agent which\ncan anticipate future changes in the environment. Here we provide new insights\non this model by defining the notion of possible controllability of a CAF. We\nstudy the complexity of this new form of reasoning for the four classical\nsemantics, and we provide a logical encoding for reasoning with this framework.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2009.04743,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000010265,
      "text":"TripleTree: A Versatile Interpretable Representation of Black Box Agents\n  and their Environments\n\n  In explainable artificial intelligence, there is increasing interest in\nunderstanding the behaviour of autonomous agents to build trust and validate\nperformance. Modern agent architectures, such as those trained by deep\nreinforcement learning, are currently so lacking in interpretable structure as\nto effectively be black boxes, but insights may still be gained from an\nexternal, behaviourist perspective. Inspired by conceptual spaces theory, we\nsuggest that a versatile first step towards general understanding is to\ndiscretise the state space into convex regions, jointly capturing similarities\nover the agent's action, value function and temporal dynamics within a dataset\nof observations. We create such a representation using a novel variant of the\nCART decision tree algorithm, and demonstrate how it facilitates practical\nunderstanding of black box agents through prediction, visualisation and\nrule-based explanation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.0518,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000010265,
      "text":"Contrastive Explanations for Reinforcement Learning via Embedded Self\n  Predictions\n\n  We investigate a deep reinforcement learning (RL) architecture that supports\nexplaining why a learned agent prefers one action over another. The key idea is\nto learn action-values that are directly represented via human-understandable\nproperties of expected futures. This is realized via the embedded\nself-prediction (ESP)model, which learns said properties in terms of human\nprovided features. Action preferences can then be explained by contrasting the\nfuture properties predicted for each action. To address cases where there are a\nlarge number of features, we develop a novel method for computing minimal\nsufficient explanations from anESP. Our case studies in three domains,\nincluding a complex strategy game, show that ESP models can be effectively\nlearned and support insightful explanations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.08218,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.000000298,
      "text":"Deep-HOSeq: Deep Higher Order Sequence Fusion for Multimodal Sentiment\n  Analysis\n\n  Multimodal sentiment analysis utilizes multiple heterogeneous modalities for\nsentiment classification. The recent multimodal fusion schemes customize LSTMs\nto discover intra-modal dynamics and design sophisticated attention mechanisms\nto discover the inter-modal dynamics from multimodal sequences. Although\npowerful, these schemes completely rely on attention mechanisms which is\nproblematic due to two major drawbacks 1) deceptive attention masks, and 2)\ntraining dynamics. Nevertheless, strenuous efforts are required to optimize\nhyperparameters of these consolidate architectures, in particular their\ncustom-designed LSTMs constrained by attention schemes. In this research, we\nfirst propose a common network to discover both intra-modal and inter-modal\ndynamics by utilizing basic LSTMs and tensor based convolution networks. We\nthen propose unique networks to encapsulate temporal-granularity among the\nmodalities which is essential while extracting information within asynchronous\nsequences. We then integrate these two kinds of information via a fusion layer\nand call our novel multimodal fusion scheme as Deep-HOSeq (Deep network with\nhigher order Common and Unique Sequence information). The proposed Deep-HOSeq\nefficiently discovers all-important information from multimodal sequences and\nthe effectiveness of utilizing both types of information is empirically\ndemonstrated on CMU-MOSEI and CMU-MOSI benchmark datasets. The source code of\nour proposed Deep-HOSeq is and available at\nhttps:\/\/github.com\/sverma88\/Deep-HOSeq--ICDM-2020.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.06425,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Temporal Collaborative Filtering with Graph Convolutional Neural\n  Networks\n\n  Temporal collaborative filtering (TCF) methods aim at modelling non-static\naspects behind recommender systems, such as the dynamics in users' preferences\nand social trends around items. State-of-the-art TCF methods employ recurrent\nneural networks (RNNs) to model such aspects. These methods deploy\nmatrix-factorization-based (MF-based) approaches to learn the user and item\nrepresentations. Recently, graph-neural-network-based (GNN-based) approaches\nhave shown improved performance in providing accurate recommendations over\ntraditional MF-based approaches in non-temporal CF settings. Motivated by this,\nwe propose a novel TCF method that leverages GNNs to learn user and item\nrepresentations, and RNNs to model their temporal dynamics. A challenge with\nthis method lies in the increased data sparsity, which negatively impacts\nobtaining meaningful quality representations with GNNs. To overcome this\nchallenge, we train a GNN model at each time step using a set of observed\ninteractions accumulated time-wise. Comprehensive experiments on real-world\ndata show the improved performance obtained by our method over several\nstate-of-the-art temporal and non-temporal CF models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.14388,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000057949,
      "text":"An Experimentation Platform for Explainable Coalition Situational\n  Understanding\n\n  We present an experimentation platform for coalition situational\nunderstanding research that highlights capabilities in explainable artificial\nintelligence\/machine learning (AI\/ML) and integration of symbolic and\nsubsymbolic AI\/ML approaches for event processing. The Situational\nUnderstanding Explorer (SUE) platform is designed to be lightweight, to easily\nfacilitate experiments and demonstrations, and open. We discuss our\nrequirements to support coalition multi-domain operations with emphasis on\nasset interoperability and ad hoc human-machine teaming in a dense urban\nterrain setting. We describe the interface functionality and give examples of\nSUE applied to coalition situational understanding tasks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.00238,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000069539,
      "text":"Multi-grained Semantics-aware Graph Neural Networks\n\n  Graph Neural Networks (GNNs) are powerful techniques in representation\nlearning for graphs and have been increasingly deployed in a multitude of\ndifferent applications that involve node- and graph-wise tasks. Most existing\nstudies solve either the node-wise task or the graph-wise task independently\nwhile they are inherently correlated. This work proposes a unified model,\nAdamGNN, to interactively learn node and graph representations in a\nmutual-optimisation manner. Compared with existing GNN models and graph pooling\nmethods, AdamGNN enhances the node representation with the learned\nmulti-grained semantics and avoids losing node features and graph structure\ninformation during pooling. Specifically, a differentiable pooling operator is\nproposed to adaptively generate a multi-grained structure that involves meso-\nand macro-level semantic information in the graph. We also devise the unpooling\noperator and the flyback aggregator in AdamGNN to better leverage the\nmulti-grained semantics to enhance node representations. The updated node\nrepresentations can further adjust the graph representation in the next\niteration. Experiments on 14 real-world graph datasets show that AdamGNN can\nsignificantly outperform 17 competing models on both node- and graph-wise\ntasks. The ablation studies confirm the effectiveness of AdamGNN's components,\nand the last empirical analysis further reveals the ingenious ability of\nAdamGNN in capturing long-range interactions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.13266,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000019868,
      "text":"Biases in Generative Art -- A Causal Look from the Lens of Art History\n\n  With rapid progress in artificial intelligence (AI), popularity of generative\nart has grown substantially. From creating paintings to generating novel art\nstyles, AI based generative art has showcased a variety of applications.\nHowever, there has been little focus concerning the ethical impacts of AI based\ngenerative art. In this work, we investigate biases in the generative art AI\npipeline right from those that can originate due to improper problem\nformulation to those related to algorithm design. Viewing from the lens of art\nhistory, we discuss the socio-cultural impacts of these biases. Leveraging\ncausal models, we highlight how current methods fall short in modeling the\nprocess of art creation and thus contribute to various types of biases. We\nillustrate the same through case studies, in particular those related to style\ntransfer. To the best of our knowledge, this is the first extensive analysis\nthat investigates biases in the generative art AI pipeline from the perspective\nof art history. We hope our work sparks interdisciplinary discussions related\nto accountability of generative art.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.15296,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000043048,
      "text":"Fact or Factitious? Contextualized Opinion Spam Detection\n\n  In this paper we perform an analytic comparison of a number of techniques\nused to detect fake and deceptive online reviews. We apply a number machine\nlearning approaches found to be effective, and introduce our own approach by\nfine-tuning state of the art contextualised embeddings. The results we obtain\nshow the potential of contextualised embeddings for fake review detection, and\nlay the groundwork for future research in this area.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.14202,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000076493,
      "text":"A Clarifying Question Selection System from NTES_ALONG in Convai3\n  Challenge\n\n  This paper presents the participation of NetEase Game AI Lab team for the\nClariQ challenge at Search-oriented Conversational AI (SCAI) EMNLP workshop in\n2020. The challenge asks for a complete conversational information retrieval\nsystem that can understanding and generating clarification questions. We\npropose a clarifying question selection system which consists of response\nunderstanding, candidate question recalling and clarifying question ranking. We\nfine-tune a RoBERTa model to understand user's responses and use an enhanced\nBM25 model to recall the candidate questions. In clarifying question ranking\nstage, we reconstruct the training dataset and propose two models based on\nELECTRA. Finally we ensemble the models by summing up their output\nprobabilities and choose the question with the highest probability as the\nclarification question. Experiments show that our ensemble ranking model\noutperforms in the document relevance task and achieves the best recall@[20,30]\nmetrics in question relevance task. And in multi-turn conversation evaluation\nin stage2, our system achieve the top score of all document relevance metrics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.09387,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000009272,
      "text":"Evaluating the Safety of Deep Reinforcement Learning Models using\n  Semi-Formal Verification\n\n  Groundbreaking successes have been achieved by Deep Reinforcement Learning\n(DRL) in solving practical decision-making problems. Robotics, in particular,\ncan involve high-cost hardware and human interactions. Hence, scrupulous\nevaluations of trained models are required to avoid unsafe behaviours in the\noperational environment. However, designing metrics to measure the safety of a\nneural network is an open problem, since standard evaluation parameters (e.g.,\ntotal reward) are not informative enough. In this paper, we present a\nsemi-formal verification approach for decision-making tasks, based on interval\nanalysis, that addresses the computational demanding of previous verification\nframeworks and design metrics to measure the safety of the models. Our method\nobtains comparable results over standard benchmarks with respect to formal\nverifiers, while drastically reducing the computation time. Moreover, our\napproach allows to efficiently evaluate safety properties for decision-making\nmodels in practical applications such as mapless navigation for mobile robots\nand trajectory generation for manipulators.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.07533,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000043379,
      "text":"TDRE: A Tensor Decomposition Based Approach for Relation Extraction\n\n  Extracting entity pairs along with relation types from unstructured texts is\na fundamental subtask of information extraction. Most existing joint models\nrely on fine-grained labeling scheme or focus on shared embedding parameters.\nThese methods directly model the joint probability of multi-labeled triplets,\nwhich suffer from extracting redundant triplets with all relation types.\nHowever, each sentence may contain very few relation types. In this paper, we\nfirst model the final triplet extraction result as a three-order tensor of\nword-to-word pairs enriched with each relation type. And in order to obtain the\nsentence contained relations, we introduce an independent but joint training\nrelation classification module. The tensor decomposition strategy is finally\nutilized to decompose the triplet tensor with predicted relational components\nwhich omits the calculations for unpredicted relation types. According to\neffective decomposition methods, we propose the Tensor Decomposition based\nRelation Extraction (TDRE) approach which is able to extract overlapping\ntriplets and avoid detecting unnecessary entity pairs. Experiments on benchmark\ndatasets NYT, CoNLL04 and ADE datasets demonstrate that the proposed method\noutperforms existing strong baselines.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.16244,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Interleaving Fast and Slow Decision Making\n\n  The \"Thinking, Fast and Slow\" paradigm of Kahneman proposes that we use two\ndifferent styles of thinking -- a fast and intuitive System 1 for certain\ntasks, along with a slower but more analytical System 2 for others. While the\nidea of using this two-system style of thinking is gaining popularity in AI and\nrobotics, our work considers how to interleave the two styles of\ndecision-making, i.e., how System 1 and System 2 should be used together. For\nthis, we propose a novel and general framework which includes a new System 0 to\noversee Systems 1 and 2. At every point when a decision needs to be made,\nSystem 0 evaluates the situation and quickly hands over the decision-making\nprocess to either System 1 or System 2. We evaluate such a framework on a\nmodified version of the classic Pac-Man game, with an already-trained RL\nalgorithm for System 1, a Monte-Carlo tree search for System 2, and several\ndifferent possible strategies for System 0. As expected, arbitrary switches\nbetween Systems 1 and 2 do not work, but certain strategies do well. With\nSystem 0, an agent is able to perform better than one that uses only System 1\nor System 2.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.12069,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000025166,
      "text":"Improving Policy-Constrained Kidney Exchange via Pre-Screening\n\n  In barter exchanges, participants swap goods with one another without\nexchanging money; exchanges are often facilitated by a central clearinghouse,\nwith the goal of maximizing the aggregate quality (or number) of swaps. Barter\nexchanges are subject to many forms of uncertainty--in participant preferences,\nthe feasibility and quality of various swaps, and so on. Our work is motivated\nby kidney exchange, a real-world barter market in which patients in need of a\nkidney transplant swap their willing living donors, in order to find a better\nmatch. Modern exchanges include 2- and 3-way swaps, making the kidney exchange\nclearing problem NP-hard. Planned transplants often fail for a variety of\nreasons--if the donor organ is refused by the recipient's medical team, or if\nthe donor and recipient are found to be medically incompatible. Due to 2- and\n3-way swaps, failed transplants can \"cascade\" through an exchange; one US-based\nexchange estimated that about 85% of planned transplants failed in 2019. Many\noptimization-based approaches have been designed to avoid these failures;\nhowever most exchanges cannot implement these methods due to legal and policy\nconstraints. Instead we consider a setting where exchanges can query the\npreferences of certain donors and recipients--asking whether they would accept\na particular transplant. We characterize this as a two-stage decision problem,\nin which the exchange program (a) queries a small number of transplants before\ncommitting to a matching, and (b) constructs a matching according to fixed\npolicy. We show that selecting these edges is a challenging combinatorial\nproblem, which is non-monotonic and non-submodular, in addition to being\nNP-hard. We propose both a greedy heuristic and a Monte Carlo tree search,\nwhich outperforms previous approaches, using experiments on both synthetic data\nand real kidney exchange data from the United Network for Organ Sharing.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.04282,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"RBF-HS: Recursive Best-First Hitting Set Search\n\n  Various model-based diagnosis scenarios require the computation of most\npreferred fault explanations. Existing algorithms that are sound (i.e., output\nonly actual fault explanations) and complete (i.e., can return all\nexplanations), however, require exponential space to achieve this task. As a\nremedy, we propose two novel diagnostic search algorithms, called RBF-HS\n(Recursive Best-First Hitting Set Search) and HBF-HS (Hybrid Best-First Hitting\nSet Search), which build upon tried and tested techniques from the heuristic\nsearch domain. RBF-HS can enumerate an arbitrary predefined finite number of\nfault explanations in best-first order within linear space bounds, without\nsacrificing the desirable soundness or completeness properties. The idea of\nHBF-HS is to find a trade-off between runtime optimization and a restricted\nspace consumption that does not exceed the available memory.\n  In extensive experiments on real-world diagnosis cases we compared our\napproaches to Reiter's HS-Tree, a state-of-the-art method that gives the same\ntheoretical guarantees and is as general(ly applicable) as the suggested\nalgorithms. For the computation of minimum-cardinality fault explanations, we\nfind that (1) RBF-HS reduces memory requirements substantially in most cases by\nup to several orders of magnitude, (2) in more than a third of the cases, both\nmemory savings and runtime savings are achieved, and (3) given the runtime\noverhead is significant, using HBF-HS instead of RBF-HS reduces the runtime to\nvalues comparable with HS-Tree while keeping the used memory reasonably\nbounded. When computing most probable fault explanations, we observe that\nRBF-HS tends to trade memory savings more or less one-to-one for runtime\noverheads. Again, HBF-HS proves to be a reasonable remedy to cut down the\nruntime while complying with practicable memory bounds.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.1172,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"A study of the Multicriteria decision analysis based on the time-series\n  features and a TOPSIS method proposal for a tensorial approach\n\n  A number of Multiple Criteria Decision Analysis (MCDA) methods have been\ndeveloped to rank alternatives based on several decision criteria. Usually,\nMCDA methods deal with the criteria value at the time the decision is made\nwithout considering their evolution over time. However, it may be relevant to\nconsider the criteria' time series since providing essential information for\ndecision-making (e.g., an improvement of the criteria). To deal with this\nissue, we propose a new approach to rank the alternatives based on the criteria\ntime-series features (tendency, variance, etc.). In this novel approach, the\ndata is structured in three dimensions, which require a more complex data\nstructure, as the \\textit{tensors}, instead of the classical matrix\nrepresentation used in MCDA. Consequently, we propose an extension for the\nTOPSIS method to handle a tensor rather than a matrix. Computational results\nreveal that it is possible to rank the alternatives from a new perspective by\nconsidering meaningful decision-making information.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.14289,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000026491,
      "text":"Affordance as general value function: A computational model\n\n  General value functions (GVFs) in the reinforcement learning (RL) literature\nare long-term predictive summaries of the outcomes of agents following specific\npolicies in the environment. Affordances as perceived action possibilities with\nspecific valence may be cast into predicted policy-relative goodness and\nmodelled as GVFs. A systematic explication of this connection shows that GVFs\nand especially their deep learning embodiments (1) realize affordance\nprediction as a form of direct perception, (2) illuminate the fundamental\nconnection between action and perception in affordance, and (3) offer a\nscalable way to learn affordances using RL methods. Through an extensive review\nof existing literature on GVF applications and representative affordance\nresearch in robotics, we demonstrate that GVFs provide the right framework for\nlearning affordances in real-world applications. In addition, we highlight a\nfew new avenues of research opened up by the perspective of \"affordance as\nGVF\", including using GVFs for orchestrating complex behaviors.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.0499,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"The emergence of Explainability of Intelligent Systems: Delivering\n  Explainable and Personalised Recommendations for Energy Efficiency\n\n  The recent advances in artificial intelligence namely in machine learning and\ndeep learning, have boosted the performance of intelligent systems in several\nways. This gave rise to human expectations, but also created the need for a\ndeeper understanding of how intelligent systems think and decide. The concept\nof explainability appeared, in the extent of explaining the internal system\nmechanics in human terms. Recommendation systems are intelligent systems that\nsupport human decision making, and as such, they have to be explainable in\norder to increase user trust and improve the acceptance of recommendations. In\nthis work, we focus on a context-aware recommendation system for energy\nefficiency and develop a mechanism for explainable and persuasive\nrecommendations, which are personalized to user preferences and habits. The\npersuasive facts either emphasize on the economical saving prospects (Econ) or\non a positive ecological impact (Eco) and explanations provide the reason for\nrecommending an energy saving action. Based on a study conducted using a\nTelegram bot, different scenarios have been validated with actual data and\nhuman feedback. Current results show a total increase of 19\\% on the\nrecommendation acceptance ratio when both economical and ecological persuasive\nfacts are employed. This revolutionary approach on recommendation systems,\ndemonstrates how intelligent recommendations can effectively encourage energy\nsaving behavior.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.13033,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Robust Hierarchical Planning with Policy Delegation\n\n  We propose a novel framework and algorithm for hierarchical planning based on\nthe principle of delegation. This framework, the Markov Intent Process,\nfeatures a collection of skills which are each specialised to perform a single\ntask well. Skills are aware of their intended effects and are able to analyse\nplanning goals to delegate planning to the best-suited skill. This principle\ndynamically creates a hierarchy of plans, in which each skill plans for\nsub-goals for which it is specialised. The proposed planning method features\non-demand execution---skill policies are only evaluated when needed. Plans are\nonly generated at the highest level, then expanded and optimised when the\nlatest state information is available. The high-level plan retains the initial\nplanning intent and previously computed skills, effectively reducing the\ncomputation needed to adapt to environmental changes. We show this planning\napproach is experimentally very competitive to classic planning and\nreinforcement learning techniques on a variety of domains, both in terms of\nsolution length and planning time.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.01685,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000021855,
      "text":"Entity Embedding as Game Representation\n\n  Procedural content generation via machine learning (PCGML) has shown success\nat producing new video game content with machine learning. However, the\nmajority of the work has focused on the production of static game content,\nincluding game levels and visual elements. There has been much less work on\ndynamic game content, such as game mechanics. One reason for this is the lack\nof a consistent representation for dynamic game content, which is key for a\nnumber of statistical machine learning approaches. We present an autoencoder\nfor deriving what we call \"entity embeddings\", a consistent way to represent\ndifferent dynamic entities across multiple games in the same representation. In\nthis paper we introduce the learned representation, along with some evidence\ntowards its quality and future utility.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.11719,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000019868,
      "text":"Conformance Checking for a Medical Training Process Using Petri net\n  Simulation and Sequence Alignment\n\n  Process Mining has recently gained popularity in healthcare due to its\npotential to provide a transparent, objective and data-based view on processes.\nConformance checking is a sub-discipline of process mining that has the\npotential to answer how the actual process executions deviate from existing\nguidelines. In this work, we analyze a medical training process for a surgical\nprocedure. Ten students were trained to install a Central Venous Catheters\n(CVC) with ultrasound. Event log data was collected directly after instruction\nby the supervisors during a first test run and additionally after a subsequent\nindividual training phase. In order to provide objective performance measures,\nwe formulate an optimal, global sequence alignment problem inspired by\napproaches in bioinformatics. Therefore, we use the Petri net model\nrepresentation of the medical process guideline to simulate a representative\nset of guideline conform sequences. Next, we calculate the optimal, global\nsequence alignment of the recorded and simulated event logs. Finally, the\noutput measures and visualization of aligned sequences are provided for\nobjective feedback.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2010.08101,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000086758,
      "text":"Modeling Token-level Uncertainty to Learn Unknown Concepts in SLU via\n  Calibrated Dirichlet Prior RNN\n\n  One major task of spoken language understanding (SLU) in modern personal\nassistants is to extract semantic concepts from an utterance, called slot\nfilling. Although existing slot filling models attempted to improve extracting\nnew concepts that are not seen in training data, the performance in practice is\nstill not satisfied. Recent research collected question and answer annotated\ndata to learn what is unknown and should be asked, yet not practically scalable\ndue to the heavy data collection effort. In this paper, we incorporate\nsoftmax-based slot filling neural architectures to model the sequence\nuncertainty without question supervision. We design a Dirichlet Prior RNN to\nmodel high-order uncertainty by degenerating as softmax layer for RNN model\ntraining. To further enhance the uncertainty modeling robustness, we propose a\nnovel multi-task training to calibrate the Dirichlet concentration parameters.\nWe collect unseen concepts to create two test datasets from SLU benchmark\ndatasets Snips and ATIS. On these two and another existing Concept Learning\nbenchmark datasets, we show that our approach significantly outperforms\nstate-of-the-art approaches by up to 8.18%. Our method is generic and can be\napplied to any RNN or Transformer based slot filling models with a softmax\nlayer.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.08182,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Uncertainty measures for probabilistic hesitant fuzzy sets in multiple\n  criteria decision making\n\n  This contribution reviews critically the existing entropy measures for\nprobabilistic hesitant fuzzy sets (PHFSs), and demonstrates that these entropy\nmeasures fail to effectively distinguish a variety of different PHFSs in some\ncases. In the sequel, we develop a new axiomatic framework of entropy measures\nfor probabilistic hesitant fuzzy elements (PHFEs) by considering two facets of\nuncertainty associated with PHFEs which are known as fuzziness and\nnonspecificity. Respect to each kind of uncertainty, a number of formulae are\nderived to permit flexible selection of PHFE entropy measures. Moreover, based\non the proposed PHFE entropy measures, we introduce some entropy-based distance\nmeasures which are used in the portion of comparative analysis.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.15067,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000019206,
      "text":"Learning a metacognition for object perception\n\n  Beyond representing the external world, humans also represent their own\ncognitive processes. In the context of perception, this metacognition helps us\nidentify unreliable percepts, such as when we recognize that we are seeing an\nillusion. Here we propose MetaGen, a model for the unsupervised learning of\nmetacognition. In MetaGen, metacognition is expressed as a generative model of\nhow a perceptual system produces noisy percepts. Using basic principles of how\nthe world works (such as object permanence, part of infants' core knowledge),\nMetaGen jointly infers the objects in the world causing the percepts and a\nrepresentation of its own perceptual system. MetaGen can then use this\nmetacognition to infer which objects are actually present in the world. On\nsimulated data, we find that MetaGen quickly learns a metacognition and\nimproves overall accuracy, outperforming models that lack a metacognition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.08733,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000012914,
      "text":"Using Explainable Scheduling for the Mars 2020 Rover Mission\n\n  Understanding the reasoning behind the behavior of an automated scheduling\nsystem is essential to ensure that it will be trusted and consequently used to\nits full capabilities in critical applications. In cases where a scheduler\nschedules activities in an invalid location, it is usually easy for the user to\ninfer the missing constraint by inspecting the schedule with the invalid\nactivity to determine the missing constraint. If a scheduler fails to schedule\nactivities because constraints could not be satisfied, determining the cause\ncan be more challenging. In such cases it is important to understand which\nconstraints caused the activities to fail to be scheduled and how to alter\nconstraints to achieve the desired schedule. In this paper, we describe such a\nscheduling system for NASA's Mars 2020 Perseverance Rover, as well as\nCrosscheck, an explainable scheduling tool that explains the scheduler\nbehavior. The scheduling system and Crosscheck are the baseline for operational\nuse to schedule activities for the Mars 2020 rover. As we describe, the\nscheduler generates a schedule given a set of activities and their constraints\nand Crosscheck: (1) provides a visual representation of the generated schedule;\n(2) analyzes and explains why activities failed to schedule given the\nconstraints provided; and (3) provides guidance on potential constraint\nrelaxations to enable the activities to schedule in future scheduler runs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.06102,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000012252,
      "text":"Improving Multimodal Accuracy Through Modality Pre-training and\n  Attention\n\n  Training a multimodal network is challenging and it requires complex\narchitectures to achieve reasonable performance. We show that one reason for\nthis phenomena is the difference between the convergence rate of various\nmodalities. We address this by pre-training modality-specific sub-networks in\nmultimodal architectures independently before end-to-end training of the entire\nnetwork. Furthermore, we show that the addition of an attention mechanism\nbetween sub-networks after pre-training helps identify the most important\nmodality during ambiguous scenarios boosting the performance. We demonstrate\nthat by performing these two tricks a simple network can achieve similar\nperformance to a complicated architecture that is significantly more expensive\nto train on multiple tasks including sentiment analysis, emotion recognition,\nand speaker trait recognition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.063,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"A Knowledge Representation Approach to Automated Mathematical Modelling\n\n  In this paper, we propose a new mixed-integer linear programming (MILP) model\nontology and a novel constraint typology of MILP formulations. MILP is a\ncommonly used mathematical programming technique for modelling and solving\nreal-life scheduling, routing, planning, resource allocation, and timetabling\noptimization problems providing optimized business solutions for industry\nsectors such as manufacturing, agriculture, defence, healthcare, medicine,\nenergy, finance, and transportation. Despite the numerous real-life\nCombinatorial Optimization Problems found and solved and millions yet to be\ndiscovered and formulated, the number of types of constraints (the building\nblocks of a MILP) is relatively small. In the search for a suitable\nmachine-readable knowledge representation structure for MILPs, we propose an\noptimization modelling tree built based upon an MILP model ontology that can be\nused as a guide for automated systems to elicit an MILP model from end-users on\ntheir combinatorial business optimization problems. Our ultimate aim is to\ndevelop a machine-readable knowledge representation for MILP that allows us to\nmap an end-user's natural language description of the business optimization\nproblem to an MILP formal specification as a first step towards automated\nmathematical modelling.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.01832,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Goal recognition via model-based and model-free techniques\n\n  Goal recognition aims at predicting human intentions from a trace of\nobservations. This ability allows people or organizations to anticipate future\nactions and intervene in a positive (collaborative) or negative (adversarial)\nway. Goal recognition has been successfully used in many domains, but it has\nbeen seldom been used by financial institutions. We claim the techniques are\nripe for its wide use in finance-related tasks. The main two approaches to\nperform goal recognition are model-based (planning-based) and model-free\n(learning-based). In this paper, we adapt state-of-the-art learning techniques\nto goal recognition, and compare model-based and model-free approaches in\ndifferent domains. We analyze the experimental data to understand the\ntrade-offs of using both types of methods. The experiments show that\nplanning-based approaches are ready for some goal-recognition finance tasks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.12443,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000032783,
      "text":"The Human Effect Requires Affect: Addressing Social-Psychological\n  Factors of Climate Change with Machine Learning\n\n  Machine learning has the potential to aid in mitigating the human effects of\nclimate change. Previous applications of machine learning to tackle the human\neffects in climate change include approaches like informing individuals of\ntheir carbon footprint and strategies to reduce it. For these methods to be the\nmost effective they must consider relevant social-psychological factors for\neach individual. Of social-psychological factors at play in climate change,\naffect has been previously identified as a key element in perceptions and\nwillingness to engage in mitigative behaviours. In this work, we propose an\ninvestigation into how affect could be incorporated to enhance machine learning\nbased interventions for climate change. We propose using affective agent-based\nmodelling for climate change as well as the use of a simulated climate change\nsocial dilemma to explore the potential benefits of affective machine learning\ninterventions. Behavioural and informational interventions can be a powerful\ntool in helping humans adopt mitigative behaviours. We expect that utilizing\naffective ML can make interventions an even more powerful tool and help\nmitigative behaviours become widely adopted.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.14475,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"An Artificial Consciousness Model and its relations with Philosophy of\n  Mind\n\n  This work seeks to study the beneficial properties that an autonomous agent\ncan obtain by implementing a cognitive architecture similar to the one of\nconscious beings. Along this document, a conscious model of autonomous agent\nbased in a global workspace architecture is presented. We describe how this\nagent is viewed from different perspectives of philosophy of mind, being\ninspired by their ideas. The goal of this model is to create autonomous agents\nable to navigate within an environment composed of multiple independent\nmagnitudes, adapting to its surroundings in order to find the best possible\nposition in base of its inner preferences. The purpose of the model is to test\nthe effectiveness of many cognitive mechanisms that are incorporated, such as\nan attention mechanism for magnitude selection, pos-session of inner feelings\nand preferences, usage of a memory system to storage beliefs and past\nexperiences, and incorporating a global workspace which controls and integrates\ninformation processed by all the subsystem of the model. We show in a large\nexperiment set how an autonomous agent can benefit from having a cognitive\narchitecture such as the one described.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.0989,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000006954,
      "text":"Fuzzy C-means-based scenario bundling for stochastic service network\n  design\n\n  Stochastic service network designs with uncertain demand represented by a set\nof scenarios can be modelled as a large-scale two-stage stochastic\nmixed-integer program (SMIP). The progressive hedging algorithm (PHA) is a\ndecomposition method for solving the resulting SMIP. The computational\nperformance of the PHA can be greatly enhanced by decomposing according to\nscenario bundles instead of individual scenarios. At the heart of bundle-based\ndecomposition is the method for grouping the scenarios into bundles. In this\npaper, we present a fuzzy c-means-based scenario bundling method to address\nthis problem. Rather than full membership of a bundle, which is typically the\ncase in existing scenario bundling strategies such as k-means, a scenario has\npartial membership in each of the bundles and can be assigned to more than one\nbundle in our method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.10672,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"Artificial Intelligence Governance for Businesses\n\nArtificial Intelligence (AI) governance regulates the exercise of authority and control over the management of AI. It aims at leveraging AI through effective use of data and minimization of AI-related cost and risk. While topics such as AI governance and AI ethics are thoroughly discussed on a theoretical, philosophical, societal and regulatory level, there is limited work on AI governance targeted to companies and corporations. This work views AI products as systems, where key functionality is delivered by machine learning (ML) models leveraging (training) data. We derive a conceptual framework by synthesizing literature on AI and related fields such as ML. Our framework decomposes AI governance into governance of data, (ML) models and (AI) systems along four dimensions. It relates to existing IT and data governance frameworks and practices. It can be adopted by practitioners and academics alike. For practitioners the synthesis of mainly research papers, but also practitioner publications and publications of regulatory bodies provides a valuable starting point to implement AI governance, while for academics the paper highlights a number of areas of AI governance that deserve more attention.",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.13297,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000036756,
      "text":"Totally and Partially Ordered Hierarchical Planners in PDDL4J Library\n\n  In this paper, we outline the implementation of the TFD (Totally Ordered Fast\nDownward) and the PFD (Partially ordered Fast Downward) hierarchical planners\nthat participated in the first HTN IPC competition in 2020. These two planners\nare based on forward-chaining task decomposition coupled with a compact\ngrounding of actions, methods, tasks and HTN problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.07509,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000036094,
      "text":"Automated Intersection Management with MiniZinc\n\n  Ill-managed intersections are the primary reasons behind the increasing\ntraffic problem in urban areas, leading to nonoptimal traffic-flow and\nunnecessary deadlocks. In this paper, we propose an automated intersection\nmanagement system that extracts data from a well-defined grid of sensors and\noptimizes traffic flow by controlling traffic signals. The data extraction\nmechanism is independent of the optimization algorithm and this paper primarily\nemphasizes the later one. We have used MiniZinc modeling language to define our\nsystem as a constraint satisfaction problem which can be solved using any\noff-the-shelf solver. The proposed system performs much better than the systems\ncurrently in use. Our system reduces the mean waiting time and standard\ndeviation of the waiting time of vehicles and avoids deadlocks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.00781,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000233783,
      "text":"Searching k-Optimal Goals for an Orienteering Problem on a Specialized\n  Graph with Budget Constraints\n\n  We propose a novel non-randomized anytime orienteering algorithm for finding\nk-optimal goals that maximize reward on a specialized graph with budget\nconstraints. This specialized graph represents a real-world scenario which is\nanalogous to an orienteering problem of finding k-most optimal goal states.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.09533,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000006623,
      "text":"Is Independent Learning All You Need in the StarCraft Multi-Agent\n  Challenge?\n\n  Most recently developed approaches to cooperative multi-agent reinforcement\nlearning in the \\emph{centralized training with decentralized execution}\nsetting involve estimating a centralized, joint value function. In this paper,\nwe demonstrate that, despite its various theoretical shortcomings, Independent\nPPO (IPPO), a form of independent learning in which each agent simply estimates\nits local value function, can perform just as well as or better than\nstate-of-the-art joint learning approaches on popular multi-agent benchmark\nsuite SMAC with little hyperparameter tuning. We also compare IPPO to several\nvariants; the results suggest that IPPO's strong performance may be due to its\nrobustness to some forms of environment non-stationarity.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.12599,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000046359,
      "text":"The Landscape of Ontology Reuse Approaches\n\n  Ontology reuse aims to foster interoperability and facilitate knowledge\nreuse. Several approaches are typically evaluated by ontology engineers when\nbootstrapping a new project. However, current practices are often motivated by\nsubjective, case-by-case decisions, which hamper the definition of a\nrecommended behaviour. In this chapter we argue that to date there are no\neffective solutions for supporting developers' decision-making process when\ndeciding on an ontology reuse strategy. The objective is twofold: (i) to survey\ncurrent approaches to ontology reuse, presenting motivations, strategies,\nbenefits and limits, and (ii) to analyse two representative approaches and\ndiscuss their merits.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.01826,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Simulating and classifying behavior in adversarial environments based on\n  action-state traces: an application to money laundering\n\n  Many business applications involve adversarial relationships in which both\nsides adapt their strategies to optimize their opposing benefits. One of the\nkey characteristics of these applications is the wide range of strategies that\nan adversary may choose as they adapt their strategy dynamically to sustain\nbenefits and evade authorities. In this paper, we present a novel way of\napproaching these types of applications, in particular in the context of\nAnti-Money Laundering. We provide a mechanism through which diverse, realistic\nand new unobserved behavior may be generated to discover potential unobserved\nadversarial actions to enable organizations to preemptively mitigate these\nrisks. In this regard, we make three main contributions. (a) Propose a novel\nbehavior-based model as opposed to individual transactions-based models\ncurrently used by financial institutions. We introduce behavior traces as\nenriched relational representation to represent observed human behavior. (b) A\nmodelling approach that observes these traces and is able to accurately infer\nthe goals of actors by classifying the behavior into money laundering or\nstandard behavior despite significant unobserved activity. And (c) a synthetic\nbehavior simulator that can generate new previously unseen traces. The\nsimulator incorporates a high level of flexibility in the behavioral parameters\nso that we can challenge the detection algorithm. Finally, we provide\nexperimental results that show that the learning module (automated\ninvestigator) that has only partial observability can still successfully infer\nthe type of behavior, and thus the simulated goals, followed by customers based\non traces - a key aspiration for many applications today.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.14124,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000010928,
      "text":"Human-Agent Cooperation in Bridge Bidding\n\n  We introduce a human-compatible reinforcement-learning approach to a\ncooperative game, making use of a third-party hand-coded human-compatible bot\nto generate initial training data and to perform initial evaluation. Our\nlearning approach consists of imitation learning, search, and policy iteration.\nOur trained agents achieve a new state-of-the-art for bridge bidding in three\nsettings: an agent playing in partnership with a copy of itself; an agent\npartnering a pre-existing bot; and an agent partnering a human player.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.03974,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Gaussian Processes with Skewed Laplace Spectral Mixture Kernels for\n  Long-term Forecasting\n\n  Long-term forecasting involves predicting a horizon that is far ahead of the\nlast observation. It is a problem of high practical relevance, for instance for\ncompanies in order to decide upon expensive long-term investments. Despite the\nrecent progress and success of Gaussian processes (GPs) based on spectral\nmixture kernels, long-term forecasting remains a challenging problem for these\nkernels because they decay exponentially at large horizons. This is mainly due\nto their use of a mixture of Gaussians to model spectral densities.\nCharacteristics of the signal important for long-term forecasting can be\nunravelled by investigating the distribution of the Fourier coefficients of\n(the training part of) the signal, which is non-smooth, heavy-tailed, sparse,\nand skewed. The heavy tail and skewness characteristics of such distributions\nin the spectral domain allow to capture long-range covariance of the signal in\nthe time domain. Motivated by these observations, we propose to model spectral\ndensities using a skewed Laplace spectral mixture (SLSM) due to the skewness of\nits peaks, sparsity, non-smoothness, and heavy tail characteristics. By\napplying the inverse Fourier Transform to this spectral density we obtain a new\nGP kernel for long-term forecasting. In addition, we adapt the lottery ticket\nmethod, originally developed to prune weights of a neural network, to GPs in\norder to automatically select the number of kernel components. Results of\nextensive experiments, including a multivariate time series, show the\nbeneficial effect of the proposed SLSM kernel for long-term extrapolation and\nrobustness to the choice of the number of mixture components.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.04085,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.000002053,
      "text":"A Semantic Framework for Enabling Radio Spectrum Policy Management and\n  Evaluation\n\n  Because radio spectrum is a finite resource, its usage and sharing is\nregulated by government agencies. These agencies define policies to manage\nspectrum allocation and assignment across multiple organizations, systems, and\ndevices. With more portions of the radio spectrum being licensed for commercial\nuse, the importance of providing an increased level of automation when\nevaluating such policies becomes crucial for the efficiency and efficacy of\nspectrum management. We introduce our Dynamic Spectrum Access Policy Framework\nfor supporting the United States government's mission to enable both federal\nand non-federal entities to compatibly utilize available spectrum. The DSA\nPolicy Framework acts as a machine-readable policy repository providing policy\nmanagement features and spectrum access request evaluation. The framework\nutilizes a novel policy representation using OWL and PROV-O along with a\ndomain-specific reasoning implementation that mixes GeoSPARQL, OWL reasoning,\nand knowledge graph traversal to evaluate incoming spectrum access requests and\nexplain how applicable policies were used. The framework is currently being\nused to support live, over-the-air field exercises involving a diverse set of\nfederal and commercial radios, as a component of a prototype spectrum\nmanagement system.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2011.01306,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000063909,
      "text":"Pairwise Relations Discriminator for Unsupervised Raven's Progressive\n  Matrices\n\n  The ability to hypothesise, develop abstract concepts based on concrete\nobservations and apply these hypotheses to justify future actions has been\nparamount in human development. An existing line of research in outfitting\nintelligent machines with abstract reasoning capabilities revolves around the\nRaven's Progressive Matrices (RPM). There have been many breakthroughs in\nsupervised approaches to solving RPM in recent years. However, this process\nrequires external assistance, and thus it cannot be claimed that machines have\nachieved reasoning ability comparable to humans. Namely, humans can solve RPM\nproblems without supervision or prior experience once the RPM rule that\nrelations can only exist row\/column-wise is properly introduced. In this paper,\nwe introduce a pairwise relations discriminator (PRD), a technique to develop\nunsupervised models with sufficient reasoning abilities to tackle an RPM\nproblem. PRD reframes the RPM problem into a relation comparison task, which we\ncan solve without requiring the labelling of the RPM problem. We can identify\nthe optimal candidate by adapting the application of PRD to the RPM problem.\nOur approach, the PRD, establishes a new state-of-the-art unsupervised learning\nbenchmark with an accuracy of 55.9% on the I-RAVEN, presenting a significant\nimprovement and a step forward in equipping machines with abstract reasoning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.12218,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"BKT-LSTM: Efficient Student Modeling for knowledge tracing and student\n  performance prediction\n\n  Recently, we have seen a rapid rise in usage of online educational platforms.\nThe personalized education became crucially important in future learning\nenvironments. Knowledge tracing (KT) refers to the detection of students'\nknowledge states and predict future performance given their past outcomes for\nproviding adaptive solution to Intelligent Tutoring Systems (ITS). Bayesian\nKnowledge Tracing (BKT) is a model to capture mastery level of each skill with\npsychologically meaningful parameters and widely used in successful tutoring\nsystems. However, it is unable to detect learning transfer across skills\nbecause each skill model is learned independently and shows lower efficiency in\nstudent performance prediction. While recent KT models based on deep neural\nnetworks shows impressive predictive power but it came with a price. Ten of\nthousands of parameters in neural networks are unable to provide\npsychologically meaningful interpretation that reflect to cognitive theory. In\nthis paper, we proposed an efficient student model called BKT-LSTM. It contains\nthree meaningful components: individual \\textit{skill mastery} assessed by BKT,\n\\textit{ability profile} (learning transfer across skills) detected by k-means\nclustering and \\textit{problem difficulty}. All these components are taken into\naccount in student's future performance prediction by leveraging predictive\npower of LSTM. BKT-LSTM outperforms state-of-the-art student models in\nstudent's performance prediction by considering these meaningful features\ninstead of using binary values of student's past interaction in DKT. We also\nconduct ablation studies on each of BKT-LSTM model components to examine their\nvalue and each component shows significant contribution in student's\nperformance prediction. Thus, it has potential for providing adaptive and\npersonalized instruction in real-world educational systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.12192,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000000298,
      "text":"Query Answering via Decentralized Search\n\n  Expert networks are formed by a group of expert-professionals with different\nspecialties to collaboratively resolve specific queries posted to the network.\nIn such networks, when a query reaches an expert who does not have sufficient\nexpertise, this query needs to be routed to other experts for further\nprocessing until it is completely solved; therefore, query answering efficiency\nis sensitive to the underlying query routing mechanism being used. Among all\npossible query routing mechanisms, decentralized search, operating purely on\neach expert's local information without any knowledge of network global\nstructure, represents the most basic and scalable routing mechanism, which is\napplicable to any network scenarios even in dynamic networks. However, there is\nstill a lack of fundamental understanding of the efficiency of decentralized\nsearch in expert networks. In this regard, we investigate decentralized search\nby quantifying its performance under a variety of network settings. Our key\nfindings reveal the existence of network conditions, under which decentralized\nsearch can achieve significantly short query routing paths (i.e., between\n$O(\\log n)$ and $O(\\log^2 n)$ hops, $n$: total number of experts in the\nnetwork). Based on such theoretical foundation, we further study how the unique\nproperties of decentralized search in expert networks is related to the\nanecdotal small-world phenomenon. In addition, we demonstrate that\ndecentralized search is robust against estimation errors introduced by\nmisinterpreting the required expertise levels. To the best of our knowledge,\nthis is the first work studying fundamental behaviors of decentralized search\nin expert networks. The developed performance bounds, confirmed by real\ndatasets, are able to assist in predicting network performance and designing\ncomplex expert networks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.13136,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000028147,
      "text":"LCEval: Learned Composite Metric for Caption Evaluation\n\n  Automatic evaluation metrics hold a fundamental importance in the development\nand fine-grained analysis of captioning systems. While current evaluation\nmetrics tend to achieve an acceptable correlation with human judgements at the\nsystem level, they fail to do so at the caption level. In this work, we propose\na neural network-based learned metric to improve the caption-level caption\nevaluation. To get a deeper insight into the parameters which impact a learned\nmetrics performance, this paper investigates the relationship between different\nlinguistic features and the caption-level correlation of the learned metrics.\nWe also compare metrics trained with different training examples to measure the\nvariations in their evaluation. Moreover, we perform a robustness analysis,\nwhich highlights the sensitivity of learned and handcrafted metrics to various\nsentence perturbations. Our empirical analysis shows that our proposed metric\nnot only outperforms the existing metrics in terms of caption-level correlation\nbut it also shows a strong system-level correlation against human assessments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.12262,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000023842,
      "text":"The Last State of Artificial Intelligence in Project Management\n\n  Artificial intelligence (AI) has been used to advance different fields, such\nas education, healthcare, and finance. However, the application of AI in the\nfield of project management (PM) has not progressed equally. This paper reports\non a systematic review of the published studies used to investigate the\napplication of AI in PM. This systematic review identified relevant papers\nusing Web of Science, Science Direct, and Google Scholar databases. Of the 652\narticles found, 58 met the predefined criteria and were included in the review.\nIncluded papers were classified per the following dimensions: PM knowledge\nareas, PM processes, and AI techniques. The results indicated that the\napplication of AI in PM was in its early stages and AI models have not applied\nfor multiple PM processes especially in processes groups of project stakeholder\nmanagement, project procurements management, and project communication\nmanagement. However, the most popular PM processes among included papers were\nproject effort prediction and cost estimation, and the most popular AI\ntechniques were support vector machines, neural networks, and genetic\nalgorithms.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.04751,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000024835,
      "text":"EvoCraft: A New Challenge for Open-Endedness\n\n  This paper introduces EvoCraft, a framework for Minecraft designed to study\nopen-ended algorithms. We introduce an API that provides an open-source Python\ninterface for communicating with Minecraft to place and track blocks. In\ncontrast to previous work in Minecraft that focused on learning to play the\ngame, the grand challenge we pose here is to automatically search for\nincreasingly complex artifacts in an open-ended fashion. Compared to other\nenvironments used to study open-endedness, Minecraft allows the construction of\nalmost any kind of structure, including actuated machines with circuits and\nmechanical components. We present initial baseline results in evolving simple\nMinecraft creations through both interactive and automated evolution. While\nevolution succeeds when tasked to grow a structure towards a specific target,\nit is unable to find a solution when rewarded for creating a simple machine\nthat moves. Thus, EvoCraft offers a challenging new environment for automated\nsearch methods (such as evolution) to find complex artifacts that we hope will\nspur the development of more open-ended algorithms. A Python implementation of\nthe EvoCraft framework is available at:\nhttps:\/\/github.com\/real-itu\/Evocraft-py.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.133,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000520547,
      "text":"Hierarchical Planning for Resource Allocation in Emergency Response\n  Systems\n\n  A classical problem in city-scale cyber-physical systems (CPS) is resource\nallocation under uncertainty. Typically, such problems are modeled as Markov\n(or semi-Markov) decision processes. While online, offline, and decentralized\napproaches have been applied to such problems, they have difficulty scaling to\nlarge decision problems. We present a general approach to hierarchical planning\nthat leverages structure in city-level CPS problems for resource allocation\nunder uncertainty. We use the emergency response as a case study and show how a\nlarge resource allocation problem can be split into smaller problems. We then\ncreate a principled framework for solving the smaller problems and tackling the\ninteraction between them. Finally, we use real-world data from Nashville,\nTennessee, a major metropolitan area in the United States, to validate our\napproach. Our experiments show that the proposed approach outperforms\nstate-of-the-art approaches used in the field of emergency response.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.11936,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Knowledge Graphs Evolution and Preservation -- A Technical Report from\n  ISWS 2019\n\n  One of the grand challenges discussed during the Dagstuhl Seminar \"Knowledge\nGraphs: New Directions for Knowledge Representation on the Semantic Web\" and\ndescribed in its report is that of a: \"Public FAIR Knowledge Graph of\nEverything: We increasingly see the creation of knowledge graphs that capture\ninformation about the entirety of a class of entities. [...] This grand\nchallenge extends this further by asking if we can create a knowledge graph of\n\"everything\" ranging from common sense concepts to location based entities.\nThis knowledge graph should be \"open to the public\" in a FAIR manner\ndemocratizing this mass amount of knowledge.\" Although linked open data (LOD)\nis one knowledge graph, it is the closest realisation (and probably the only\none) to a public FAIR Knowledge Graph (KG) of everything. Surely, LOD provides\na unique testbed for experimenting and evaluating research hypotheses on open\nand FAIR KG. One of the most neglected FAIR issues about KGs is their ongoing\nevolution and long term preservation. We want to investigate this problem, that\nis to understand what preserving and supporting the evolution of KGs means and\nhow these problems can be addressed. Clearly, the problem can be approached\nfrom different perspectives and may require the development of different\napproaches, including new theories, ontologies, metrics, strategies,\nprocedures, etc. This document reports a collaborative effort performed by 9\nteams of students, each guided by a senior researcher as their mentor,\nattending the International Semantic Web Research School (ISWS 2019). Each team\nprovides a different perspective to the problem of knowledge graph evolution\nsubstantiated by a set of research questions as the main subject of their\ninvestigation. In addition, they provide their working definition for KG\npreservation and evolution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.13387,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000007285,
      "text":"Adaptive Summaries: A Personalized Concept-based Summarization Approach\n  by Learning from Users' Feedback\n\n  Exploring the tremendous amount of data efficiently to make a decision,\nsimilar to answering a complicated question, is challenging with many\nreal-world application scenarios. In this context, automatic summarization has\nsubstantial importance as it will provide the foundation for big data analytic.\nTraditional summarization approaches optimize the system to produce a short\nstatic summary that fits all users that do not consider the subjectivity aspect\nof summarization, i.e., what is deemed valuable for different users, making\nthese approaches impractical in real-world use cases. This paper proposes an\ninteractive concept-based summarization model, called Adaptive Summaries, that\nhelps users make their desired summary instead of producing a single inflexible\nsummary. The system learns from users' provided information gradually while\ninteracting with the system by giving feedback in an iterative loop. Users can\nchoose either reject or accept action for selecting a concept being included in\nthe summary with the importance of that concept from users' perspectives and\nconfidence level of their feedback. The proposed approach can guarantee\ninteractive speed to keep the user engaged in the process. Furthermore, it\neliminates the need for reference summaries, which is a challenging issue for\nsummarization tasks. Evaluations show that Adaptive Summaries helps users make\nhigh-quality summaries based on their preferences by maximizing the\nuser-desired content in the generated summaries.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.02179,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000009603,
      "text":"The case for psychometric artificial general intelligence\n\n  A short review of the literature on measurement and detection of artificial\ngeneral intelligence is made. Proposed benchmarks and tests for artificial\ngeneral intelligence are critically evaluated against multiple criteria. Based\non the findings, the most promising approaches are identified and some useful\ndirections for future work are proposed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.12732,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"Identification of Unexpected Decisions in Partially Observable\n  Monte-Carlo Planning: a Rule-Based Approach\n\n  Partially Observable Monte-Carlo Planning (POMCP) is a powerful online\nalgorithm able to generate approximate policies for large Partially Observable\nMarkov Decision Processes. The online nature of this method supports\nscalability by avoiding complete policy representation. The lack of an explicit\nrepresentation however hinders interpretability. In this work, we propose a\nmethodology based on Satisfiability Modulo Theory (SMT) for analyzing POMCP\npolicies by inspecting their traces, namely sequences of\nbelief-action-observation triplets generated by the algorithm. The proposed\nmethod explores local properties of policy behavior to identify unexpected\ndecisions. We propose an iterative process of trace analysis consisting of\nthree main steps, i) the definition of a question by means of a parametric\nlogical formula describing (probabilistic) relationships between beliefs and\nactions, ii) the generation of an answer by computing the parameters of the\nlogical formula that maximize the number of satisfied clauses (solving a\nMAX-SMT problem), iii) the analysis of the generated logical formula and the\nrelated decision boundaries for identifying unexpected decisions made by POMCP\nwith respect to the original question. We evaluate our approach on Tiger, a\nstandard benchmark for POMDPs, and a real-world problem related to mobile robot\nnavigation. Results show that the approach can exploit human knowledge on the\ndomain, outperforming state-of-the-art anomaly detection methods in identifying\nunexpected decisions. An improvement of the Area Under Curve up to 47\\% has\nbeen achieved in our tests.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.08479,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000017219,
      "text":"Bayes Meets Entailment and Prediction: Commonsense Reasoning with\n  Non-monotonicity, Paraconsistency and Predictive Accuracy\n\n  The recent success of Bayesian methods in neuroscience and artificial\nintelligence gives rise to the hypothesis that the brain is a Bayesian machine.\nSince logic and learning are both practices of the human brain, it leads to\nanother hypothesis that there is a Bayesian interpretation underlying both\nlogical reasoning and machine learning. In this paper, we introduce a\ngenerative model of logical consequence relations. It formalises the process of\nhow the truth value of a sentence is probabilistically generated from the\nprobability distribution over states of the world. We show that the generative\nmodel characterises a classical consequence relation, paraconsistent\nconsequence relation and nonmonotonic consequence relation. In particular, the\ngenerative model gives a new consequence relation that outperforms them in\nreasoning with inconsistent knowledge. We also show that the generative model\ngives a new classification algorithm that outperforms several representative\nalgorithms in predictive accuracy and complexity on the Kaggle Titanic dataset.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.06,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000013908,
      "text":"The Three Ghosts of Medical AI: Can the Black-Box Present Deliver?\n\n  Our title alludes to the three Christmas ghosts encountered by Ebenezer\nScrooge in \\textit{A Christmas Carol}, who guide Ebenezer through the past,\npresent, and future of Christmas holiday events. Similarly, our article will\ntake readers through a journey of the past, present, and future of medical AI.\nIn doing so, we focus on the crux of modern machine learning: the reliance on\npowerful but intrinsically opaque models. When applied to the healthcare\ndomain, these models fail to meet the needs for transparency that their\nclinician and patient end-users require. We review the implications of this\nfailure, and argue that opaque models (1) lack quality assurance, (2) fail to\nelicit trust, and (3) restrict physician-patient dialogue. We then discuss how\nupholding transparency in all aspects of model design and model validation can\nhelp ensure the reliability of medical AI.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.08888,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000033445,
      "text":"Solving the Travelling Thief Problem based on Item Selection Weight and\n  Reverse Order Allocation\n\n  The Travelling Thief Problem (TTP) is a challenging combinatorial\noptimization problem that attracts many scholars. The TTP interconnects two\nwell-known NP-hard problems: the Travelling Salesman Problem (TSP) and the 0-1\nKnapsack Problem (KP). Increasingly algorithms have been proposed for solving\nthis novel problem that combines two interdependent sub-problems. In this\npaper, TTP is investigated theoretically and empirically. An algorithm based on\nthe score value calculated by our proposed formulation in picking items and\nsorting items in the reverse order in the light of the scoring value is\nproposed to solve the problem. Different approaches for solving the TTP are\ncompared and analyzed; the experimental investigations suggest that our\nproposed approach is very efficient in meeting or beating current\nstate-of-the-art heuristic solutions on a comprehensive set of benchmark TTP\ninstances.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.02947,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Neurosymbolic AI for Situated Language Understanding\n\n  In recent years, data-intensive AI, particularly the domain of natural\nlanguage processing and understanding, has seen significant progress driven by\nthe advent of large datasets and deep neural networks that have sidelined more\nclassic AI approaches to the field. These systems can apparently demonstrate\nsophisticated linguistic understanding or generation capabilities, but often\nfail to transfer their skills to situations they have not encountered before.\nWe argue that computational situated grounding provides a solution to some of\nthese learning challenges by creating situational representations that both\nserve as a formal model of the salient phenomena, and contain rich amounts of\nexploitable, task-appropriate data for training new, flexible computational\nmodels. Our model reincorporates some ideas of classic AI into a framework of\nneurosymbolic intelligence, using multimodal contextual modeling of interactive\nsituations, events, and object properties. We discuss how situated grounding\nprovides diverse data and multiple levels of modeling for a variety of AI\nlearning challenges, including learning how to interact with object\naffordances, learning semantics for novel structures and configurations, and\ntransferring such learned knowledge to new objects and situations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.13315,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000007285,
      "text":"Generalization in portfolio-based algorithm selection\n\n  Portfolio-based algorithm selection has seen tremendous practical success\nover the past two decades. This algorithm configuration procedure works by\nfirst selecting a portfolio of diverse algorithm parameter settings, and then,\non a given problem instance, using an algorithm selector to choose a parameter\nsetting from the portfolio with strong predicted performance. Oftentimes, both\nthe portfolio and the algorithm selector are chosen using a training set of\ntypical problem instances from the application domain at hand. In this paper,\nwe provide the first provable guarantees for portfolio-based algorithm\nselection. We analyze how large the training set should be to ensure that the\nresulting algorithm selector's average performance over the training set is\nclose to its future (expected) performance. This involves analyzing three key\nreasons why these two quantities may diverge: 1) the learning-theoretic\ncomplexity of the algorithm selector, 2) the size of the portfolio, and 3) the\nlearning-theoretic complexity of the algorithm's performance as a function of\nits parameters. We introduce an end-to-end learning-theoretic analysis of the\nportfolio construction and algorithm selection together. We prove that if the\nportfolio is large, overfitting is inevitable, even with an extremely simple\nalgorithm selector. With experiments, we illustrate a tradeoff exposed by our\ntheoretical analysis: as we increase the portfolio size, we can hope to include\na well-suited parameter setting for every possible problem instance, but it\nbecomes impossible to avoid overfitting.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.04442,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000006292,
      "text":"URoboSim -- An Episodic Simulation Framework for Prospective Reasoning\n  in Robotic Agents\n\n  Anticipating what might happen as a result of an action is an essential\nability humans have in order to perform tasks effectively. On the other hand,\nrobots capabilities in this regard are quite lacking. While machine learning is\nused to increase the ability of prospection it is still limiting for novel\nsituations. A possibility to improve the prospection ability of robots is\nthrough simulation of imagined motions and the physical results of these\nactions. Therefore, we present URoboSim, a robot simulator that allows robots\nto perform tasks as mental simulation before performing this task in reality.\nWe show the capabilities of URoboSim in form of mental simulations, generating\ndata for machine learning and the usage as belief state for a real robot.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.07464,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000005828,
      "text":"Online Action Recognition\n\n  Recognition in planning seeks to find agent intentions, goals or activities\ngiven a set of observations and a knowledge library (e.g. goal states, plans or\ndomain theories). In this work we introduce the problem of Online Action\nRecognition. It consists in recognizing, in an open world, the planning action\nthat best explains a partially observable state transition from a knowledge\nlibrary of first-order STRIPS actions, which is initially empty. We frame this\nas an optimization problem, and propose two algorithms to address it: Action\nUnification (AU) and Online Action Recognition through Unification (OARU). The\nformer builds on logic unification and generalizes two input actions using\nweighted partial MaxSAT. The latter looks for an action within the library that\nexplains an observed transition. If there is such action, it generalizes it\nmaking use of AU, building in this way an AU hierarchy. Otherwise, OARU inserts\na Trivial Grounded Action (TGA) in the library that explains just that\ntransition. We report results on benchmarks from the International Planning\nCompetition and PDDLGym, where OARU recognizes actions accurately with respect\nto expert knowledge, and shows real-time performance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.00583,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000172853,
      "text":"Obtain Employee Turnover Rate and Optimal Reduction Strategy Based On\n  Neural Network and Reinforcement Learning\n\n  Nowadays, human resource is an important part of various resources of\nenterprises. For enterprises, high-loyalty and high-quality talented persons\nare often the core competitiveness of enterprises. Therefore, it is of great\npractical significance to predict whether employees leave and reduce the\nturnover rate of employees. First, this paper established a multi-layer\nperceptron predictive model of employee turnover rate. A model based on Sarsa\nwhich is a kind of reinforcement learning algorithm is proposed to\nautomatically generate a set of strategies to reduce the employee turnover\nrate. These strategies are a collection of strategies that can reduce the\nemployee turnover rate the most and cost less from the perspective of the\nenterprise, and can be used as a reference plan for the enterprise to optimize\nthe employee system. The experimental results show that the algorithm can\nindeed improve the efficiency and accuracy of the specific strategy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.08911,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"Communicative Message Passing for Inductive Relation Reasoning\n\n  Relation prediction for knowledge graphs aims at predicting missing\nrelationships between entities. Despite the importance of inductive relation\nprediction, most previous works are limited to a transductive setting and\ncannot process previously unseen entities. The recent proposed subgraph-based\nrelation reasoning models provided alternatives to predict links from the\nsubgraph structure surrounding a candidate triplet inductively. However, we\nobserve that these methods often neglect the directed nature of the extracted\nsubgraph and weaken the role of relation information in the subgraph modeling.\nAs a result, they fail to effectively handle the asymmetric\/anti-symmetric\ntriplets and produce insufficient embeddings for the target triplets. To this\nend, we introduce a \\textbf{C}\\textbf{o}mmunicative \\textbf{M}essage\n\\textbf{P}assing neural network for \\textbf{I}nductive re\\textbf{L}ation\nr\\textbf{E}asoning, \\textbf{CoMPILE}, that reasons over local directed subgraph\nstructures and has a vigorous inductive bias to process entity-independent\nsemantic relations. In contrast to existing models, CoMPILE strengthens the\nmessage interactions between edges and entitles through a communicative kernel\nand enables a sufficient flow of relation information. Moreover, we demonstrate\nthat CoMPILE can naturally handle asymmetric\/anti-symmetric relations without\nthe need for explosively increasing the number of model parameters by\nextracting the directed enclosing subgraphs. Extensive experiments show\nsubstantial performance gains in comparison to state-of-the-art methods on\ncommonly used benchmark datasets with variant inductive settings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2012.05773,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2020,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000006954,
      "text":"Influence-Driven Explanations for Bayesian Network Classifiers\n\n  One of the most pressing issues in AI in recent years has been the need to\naddress the lack of explainability of many of its models. We focus on\nexplanations for discrete Bayesian network classifiers (BCs), targeting greater\ntransparency of their inner workings by including intermediate variables in\nexplanations, rather than just the input and output variables as is standard\npractice. The proposed influence-driven explanations (IDXs) for BCs are\nsystematically generated using the causal relationships between variables\nwithin the BC, called influences, which are then categorised by logical\nrequirements, called relation properties, according to their behaviour. These\nrelation properties both provide guarantees beyond heuristic explanation\nmethods and allow the information underpinning an explanation to be tailored to\na particular context's and user's requirements, e.g., IDXs may be dialectical\nor counterfactual. We demonstrate IDXs' capability to explain various forms of\nBCs, e.g., naive or multi-label, binary or categorical, and also integrate\nrecent approaches to explanations for BCs from the literature. We evaluate IDXs\nwith theoretical and empirical analyses, demonstrating their considerable\nadvantages when compared with existing explanation methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.02456,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000008278,
      "text":"Neural Fitted Q Iteration based Optimal Bidding Strategy in Real Time\n  Reactive Power Market_1\n\n  In real time electricity markets, the objective of generation companies while\nbidding is to maximize their profit. The strategies for learning optimal\nbidding have been formulated through game theoretical approaches and stochastic\noptimization problems. Similar studies in reactive power markets have not been\nreported so far because the network voltage operating conditions have an\nincreased impact on reactive power markets than on active power markets.\nContrary to active power markets, the bids of rivals are not directly related\nto fuel costs in reactive power markets. Hence, the assumption of a suitable\nprobability distribution function is unrealistic, making the strategies adopted\nin active power markets unsuitable for learning optimal bids in reactive power\nmarket mechanisms. Therefore, a bidding strategy is to be learnt from market\nobservations and experience in imperfect oligopolistic competition-based\nmarkets. In this paper, a pioneer work on learning optimal bidding strategies\nfrom observation and experience in a three-stage reactive power market is\nreported.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.00286,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"An Ontology Design Pattern for representing Recurrent Situations\n\n  In this paper, we present an Ontology Design Pattern for representing\nsituations that recur at regular periods and share some invariant factors,\nwhich unify them conceptually: we refer to this set of recurring situations as\nrecurrent situation series. The proposed pattern appears to be foundational,\nsince it can be generalised for modelling the top-level domain-independent\nconcept of recurrence, which is strictly associated with invariance. The\npattern reuses other foundational patterns such as Collection, Description and\nSituation, Classification, Sequence. Indeed, a recurrent situation series is\nformalised as both a collection of situations occurring regularly over time and\nunified according to some properties that are common to all the members, and a\nsituation itself, which provides a relational context to its members that\nsatisfy a reference description. Besides including some exemplifying instances\nof this pattern, we show how it has been implemented and specialised to model\nrecurrent cultural events and ceremonies in ArCo, the Knowledge Graph of\nItalian cultural heritage.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.1067,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000000298,
      "text":"Ordinal Monte Carlo Tree Search\n\n  In many problem settings, most notably in game playing, an agent receives a\npossibly delayed reward for its actions. Often, those rewards are handcrafted\nand not naturally given. Even simple terminal-only rewards, like winning equals\none and losing equals minus one, can not be seen as an unbiased statement,\nsince these values are chosen arbitrarily, and the behavior of the learner may\nchange with different encodings. It is hard to argue about good rewards and the\nperformance of an agent often depends on the design of the reward signal. In\nparticular, in domains where states by nature only have an ordinal ranking and\nwhere meaningful distance information between game state values is not\navailable, a numerical reward signal is necessarily biased. In this paper we\ntake a look at MCTS, a popular algorithm to solve MDPs, highlight a reoccurring\nproblem concerning its use of rewards, and show that an ordinal treatment of\nthe rewards overcomes this problem. Using the General Video Game Playing\nframework we show dominance of our newly proposed ordinal MCTS algorithm over\nother MCTS variants, based on a novel bandit algorithm that we also introduce\nand test versus UCB.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.02046,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000122521,
      "text":"TextBox: A Unified, Modularized, and Extensible Framework for Text\n  Generation\n\n  In this paper, we release an open-source library, called TextBox, to provide\na unified, modularized, and extensible text generation framework. TextBox aims\nto support a broad set of text generation tasks and models. In our library, we\nimplement 21 text generation models on 9 benchmark datasets, covering the\ncategories of VAE, GAN, and pretrained language models. Meanwhile, our library\nmaintains sufficient modularity and extensibility by properly decomposing the\nmodel architecture, inference, and learning process into highly reusable\nmodules, which allows users to easily incorporate new models into our\nframework. The above features make TextBox specially suitable for researchers\nand practitioners to quickly reproduce baseline models and develop new models.\nTextBox is implemented based on PyTorch, and released under Apache License 2.0\nat https:\/\/github.com\/RUCAIBox\/TextBox.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.0722,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"A Tensor-Based Formulation of Hetero-functional Graph Theory\n\n  Recently, hetero-functional graph theory (HFGT) has developed as a means to\nmathematically model the structure of large-scale complex flexible engineering\nsystems. It does so by fusing concepts from network science and model-based\nsystems engineering (MBSE). For the former, it utilizes multiple graph-based\ndata structures to support a matrix-based quantitative analysis. For the\nlatter, HFGT inherits the heterogeneity of conceptual and ontological\nconstructs found in model-based systems engineering including system form,\nsystem function, and system concept. These diverse conceptual constructs\nindicate multi-dimensional rather than two-dimensional relationships. This\npaper provides the first tensor-based treatment of hetero-functional graph\ntheory. In particular, it addresses the ``system concept\" and the\nhetero-functional adjacency matrix from the perspective of tensors and\nintroduces the hetero-functional incidence tensor as a new data structure. The\ntensor-based formulation described in this work makes a stronger tie between\nHFGT and its ontological foundations in MBSE. Finally, the tensor-based\nformulation facilitates several analytical results that provide an\nunderstanding of the relationships between HFGT and multi-layer networks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.01883,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000039405,
      "text":"Off-Policy Meta-Reinforcement Learning Based on Feature Embedding Spaces\n\n  Meta-reinforcement learning (RL) addresses the problem of sample inefficiency\nin deep RL by using experience obtained in past tasks for a new task to be\nsolved.\n  However, most meta-RL methods require partially or fully on-policy data,\ni.e., they cannot reuse the data collected by past policies, which hinders the\nimprovement of sample efficiency.\n  To alleviate this problem, we propose a novel off-policy meta-RL method,\nembedding learning and evaluation of uncertainty (ELUE).\n  An ELUE agent is characterized by the learning of a feature embedding space\nshared among tasks.\n  It learns a belief model over the embedding space and a belief-conditional\npolicy and Q-function.\n  Then, for a new task, it collects data by the pretrained policy, and updates\nits belief based on the belief model.\n  Thanks to the belief update, the performance can be improved with a small\namount of data.\n  In addition, it updates the parameters of the neural networks to adjust the\npretrained relationships when there are enough data.\n  We demonstrate that ELUE outperforms state-of-the-art meta RL methods through\nexperiments on meta-RL benchmarks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.0151,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000101659,
      "text":"Modeling Global Semantics for Question Answering over Knowledge Bases\n\n  Semantic parsing, as an important approach to question answering over\nknowledge bases (KBQA), transforms a question into the complete query graph for\nfurther generating the correct logical query. Existing semantic parsing\napproaches mainly focus on relations matching with paying less attention to the\nunderlying internal structure of questions (e.g., the dependencies and\nrelations between all entities in a question) to select the query graph. In\nthis paper, we present a relational graph convolutional network (RGCN)-based\nmodel gRGCN for semantic parsing in KBQA. gRGCN extracts the global semantics\nof questions and their corresponding query graphs, including structure\nsemantics via RGCN and relational semantics (label representation of relations\nbetween entities) via a hierarchical relation attention mechanism. Experiments\nevaluated on benchmarks show that our model outperforms off-the-shelf models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.04017,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000013908,
      "text":"A Commonsense Reasoning Framework for Explanatory Emotion Attribution,\n  Generation and Re-classification\n\n  We present DEGARI (Dynamic Emotion Generator And ReclassIfier), an\nexplainable system for emotion attribution and recommendation. This system\nrelies on a recently introduced commonsense reasoning framework, the TCL logic,\nwhich is based on a human-like procedure for the automatic generation of novel\nconcepts in a Description Logics knowledge base. Starting from an ontological\nformalization of emotions based on the Plutchik model, known as ArsEmotica, the\nsystem exploits the logic TCL to automatically generate novel commonsense\nsemantic representations of compound emotions (e.g. Love as derived from the\ncombination of Joy and Trust according to Plutchik). The generated emotions\ncorrespond to prototypes, i.e. commonsense representations of given concepts,\nand have been used to reclassify emotion-related contents in a variety of\nartistic domains, ranging from art datasets to the editorial contents available\nin RaiPlay, the online platform of RAI Radiotelevisione Italiana (the Italian\npublic broadcasting company). We show how the reported results (evaluated in\nthe light of the obtained reclassifications, the user ratings assigned to such\nreclassifications, and their explainability) are encouraging, and pave the way\nto many further research directions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.02991,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000013908,
      "text":"Artificial Intelligence enabled Smart Learning\n\n  Artificial Intelligence (AI) is a discipline of computer science that deals\nwith machine intelligence. It is essential to bring AI into the context of\nlearning because it helps in analysing the enormous amounts of data that is\ncollected from individual students, teachers and academic staff. The major\npriorities of implementing AI in education are making innovative use of\nexisting digital technologies for learning, and teaching practices that\nsignificantly improve traditional educational methods. The main problem with\ntraditional learning is that it cannot be suited to every student in class.\nSome students may grasp the concepts well, while some may have difficulties in\nunderstanding them and some may be more auditory or visual learners. The World\nBank report on education has indicated that the learning gap created by this\nproblem causes many students to drop out (World Development Report, 2018).\nPersonalised learning has been able to solve this grave problem.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.07337,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"Dissonance Between Human and Machine Understanding\n\n  Complex machine learning models are deployed in several critical domains\nincluding healthcare and autonomous vehicles nowadays, albeit as functional\nblack boxes. Consequently, there has been a recent surge in interpreting\ndecisions of such complex models in order to explain their actions to humans.\nModels that correspond to human interpretation of a task are more desirable in\ncertain contexts and can help attribute liability, build trust, expose biases\nand in turn build better models. It is, therefore, crucial to understand how\nand which models conform to human understanding of tasks. In this paper, we\npresent a large-scale crowdsourcing study that reveals and quantifies the\ndissonance between human and machine understanding, through the lens of an\nimage classification task. In particular, we seek to answer the following\nquestions: Which (well-performing) complex ML models are closer to humans in\ntheir use of features to make accurate predictions? How does task difficulty\naffect the feature selection capability of machines in comparison to humans?\nAre humans consistently better at selecting features that make image\nrecognition more accurate? Our findings have important implications on\nhuman-machine collaboration, considering that a long term goal in the field of\nartificial intelligence is to make machines capable of learning and reasoning\nlike humans.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.00417,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000027153,
      "text":"Priority-based Post-Processing Bias Mitigation for Individual and Group\n  Fairness\n\n  Previous post-processing bias mitigation algorithms on both group and\nindividual fairness don't work on regression models and datasets with\nmulti-class numerical labels. We propose a priority-based post-processing bias\nmitigation on both group and individual fairness with the notion that similar\nindividuals should get similar outcomes irrespective of socio-economic factors\nand more the unfairness, more the injustice. We establish this proposition by a\ncase study on tariff allotment in a smart grid. Our novel framework establishes\nit by using a user segmentation algorithm to capture the consumption strategy\nbetter. This process ensures priority-based fair pricing for group and\nindividual facing the maximum injustice. It upholds the notion of fair tariff\nallotment to the entire population taken into consideration without modifying\nthe in-built process for tariff calculation. We also validate our method and\nshow superior performance to previous work on a real-world dataset in criminal\nsentencing.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.00774,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000003212,
      "text":"Retrieving and Reading: A Comprehensive Survey on Open-domain Question\n  Answering\n\n  Open-domain Question Answering (OpenQA) is an important task in Natural\nLanguage Processing (NLP), which aims to answer a question in the form of\nnatural language based on large-scale unstructured documents. Recently, there\nhas been a surge in the amount of research literature on OpenQA, particularly\non techniques that integrate with neural Machine Reading Comprehension (MRC).\nWhile these research works have advanced performance to new heights on\nbenchmark datasets, they have been rarely covered in existing surveys on QA\nsystems. In this work, we review the latest research trends in OpenQA, with\nparticular attention to systems that incorporate neural MRC techniques.\nSpecifically, we begin with revisiting the origin and development of OpenQA\nsystems. We then introduce modern OpenQA architecture named \"Retriever-Reader\"\nand analyze the various systems that follow this architecture as well as the\nspecific techniques adopted in each of the components. We then discuss key\nchallenges to developing OpenQA systems and offer an analysis of benchmarks\nthat are commonly used. We hope our work would enable researchers to be\ninformed of the recent advancement and also the open challenges in OpenQA\nresearch, so as to stimulate further progress in this field.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.0321,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"Optimizing Hospital Room Layout to Reduce the Risk of Patient Falls\n\n  Despite years of research into patient falls in hospital rooms, falls and\nrelated injuries remain a serious concern to patient safety. In this work, we\nformulate a gradient-free constrained optimization problem to generate and\nreconfigure the hospital room interior layout to minimize the risk of falls. We\ndefine a cost function built on a hospital room fall model that takes into\naccount the supportive or hazardous effect of the patient's surrounding\nobjects, as well as simulated patient trajectories inside the room. We define a\nconstraint set that ensures the functionality of the generated room layouts in\naddition to conforming to architectural guidelines. We solve this problem\nefficiently using a variant of simulated annealing. We present results for two\nreal-world hospital room types and demonstrate a significant improvement of 18%\non average in patient fall risk when compared with a traditional hospital room\nlayout and 41% when compared with randomly generated layouts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.0028,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000001457,
      "text":"A General Counterexample to Any Decision Theory and Some Responses\n\n  In this paper I present an argument and a general schema which can be used to\nconstruct a problem case for any decision theory, in a way that could be taken\nto show that one cannot formulate a decision theory that is never outperformed\nby any other decision theory. I also present and discuss a number of possible\nresponses to this argument. One of these responses raises the question of what\nit means for two decision problems to be \"equivalent\" in the relevant sense,\nand gives an answer to this question which would invalidate the first argument.\nHowever, this position would have further consequences for how we compare\ndifferent decision theories in decision problems already discussed in the\nliterature (including e.g. Newcomb's problem).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.10162,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Solving a Multi-resource Partial-ordering Flexible Variant of the\n  Job-shop Scheduling Problem with Hybrid ASP\n\n  Many complex activities of production cycles, such as quality control or\nfault analysis, require highly experienced specialists to perform various\noperations on (semi)finished products using different tools. In practical\nscenarios, the selection of a next operation is complicated, since each expert\nhas only a local view on the total set of operations to be performed. As a\nresult, decisions made by the specialists are suboptimal and might cause\nsignificant costs. In this paper, we consider a Multi-resource Partial-ordering\nFlexible Job-shop Scheduling (MPF-JSS) problem where partially-ordered\nsequences of operations must be scheduled on multiple required resources, such\nas tools and specialists. The resources are flexible and can perform one or\nmore operations depending on their properties. The problem is modeled using\nAnswer Set Programming (ASP) in which the time assignments are efficiently done\nusing Difference Logic. Moreover, we suggest two multi-shot solving strategies\naiming at the identification of the time bounds allowing for a solution of the\nschedule optimization problem. Experiments conducted on a set of instances\nextracted from a medium-sized semiconductor fault analysis lab indicate that\nour approach can find schedules for 87 out of 91 considered real-world\ninstances.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.00692,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000009934,
      "text":"Learning General Policies from Small Examples Without Supervision\n\n  Generalized planning is concerned with the computation of general policies\nthat solve multiple instances of a planning domain all at once. It has been\nrecently shown that these policies can be computed in two steps: first, a\nsuitable abstraction in the form of a qualitative numerical planning problem\n(QNP) is learned from sample plans, then the general policies are obtained from\nthe learned QNP using a planner. In this work, we introduce an alternative\napproach for computing more expressive general policies which does not require\nsample plans or a QNP planner. The new formulation is very simple and can be\ncast in terms that are more standard in machine learning: a large but finite\npool of features is defined from the predicates in the planning examples using\na general grammar, and a small subset of features is sought for separating\n\"good\" from \"bad\" state transitions, and goals from non-goals. The problems of\nfinding such a \"separating surface\" while labeling the transitions as \"good\" or\n\"bad\" are jointly addressed as a single combinatorial optimization problem\nexpressed as a Weighted Max-SAT problem. The advantage of looking for the\nsimplest policy in the given feature space that solves the given examples,\npossibly non-optimally, is that many domains have no general, compact policies\nthat are optimal. The approach yields general policies for a number of\nbenchmark domains.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.00675,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"Sentiment Analysis for Open Domain Conversational Agent\n\n  The applicability of common sentiment analysis models to open domain human\nrobot interaction is investigated within this paper. The models are used on a\ndataset specific to user interaction with the Alana system (a Alexa prize\nsystem) in order to determine which would be more appropriate for the task of\nidentifying sentiment when a user interacts with a non-human driven socialbot.\nWith the identification of a model, various improvements are attempted and\ndetailed prior to integration into the Alana system. The study showed that a\nRandom Forest Model with 25 trees trained on the dataset specific to user\ninteraction with the Alana system combined with the dataset present in NLTK\nVader outperforms other models. The new system (called 'Rob') matches it's\noutput utterance sentiment with the user's utterance sentiment. This method is\nexpected to improve user experience because it builds upon the overall\nsentiment detection which makes it seem that new system sympathises with user\nfeelings. Furthermore, the results obtained from the user feedback confirms our\nexpectation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.00333,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000028147,
      "text":"Deep Reinforcement Learning-Based Product Recommender for Online\n  Advertising\n\n  In online advertising, recommender systems try to propose items from a list\nof products to potential customers according to their interests. Such systems\nhave been increasingly deployed in E-commerce due to the rapid growth of\ninformation technology and availability of large datasets. The ever-increasing\nprogress in the field of artificial intelligence has provided powerful tools\nfor dealing with such real-life problems. Deep reinforcement learning (RL) that\ndeploys deep neural networks as universal function approximators can be viewed\nas a valid approach for design and implementation of recommender systems. This\npaper provides a comparative study between value-based and policy-based deep RL\nalgorithms for designing recommender systems for online advertising. The\nRecoGym environment is adopted for training these RL-based recommender systems,\nwhere the long short term memory (LSTM) is deployed to build value and policy\nnetworks in these two approaches, respectively. LSTM is used to take account of\nthe key role that order plays in the sequence of item observations by users.\nThe designed recommender systems aim at maximising the click-through rate (CTR)\nfor the recommended items. Finally, guidelines are provided for choosing proper\nRL algorithms for different scenarios that the recommender system is expected\nto handle.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.05125,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"Formalising Concepts as Grounded Abstractions\n\n  The notion of concept has been studied for centuries, by philosophers,\nlinguists, cognitive scientists, and researchers in artificial intelligence\n(Margolis & Laurence, 1999). There is a large literature on formal,\nmathematical models of concepts, including a whole sub-field of AI -- Formal\nConcept Analysis -- devoted to this topic (Ganter & Obiedkov, 2016). Recently,\nresearchers in machine learning have begun to investigate how methods from\nrepresentation learning can be used to induce concepts from raw perceptual data\n(Higgins, Sonnerat, et al., 2018). The goal of this report is to provide a\nformal account of concepts which is compatible with this latest work in deep\nlearning.\n  The main technical goal of this report is to show how techniques from\nrepresentation learning can be married with a lattice-theoretic formulation of\nconceptual spaces. The mathematics of partial orders and lattices is a standard\ntool for modelling conceptual spaces (Ch.2, Mitchell (1997), Ganter and\nObiedkov (2016)); however, there is no formal work that we are aware of which\ndefines a conceptual lattice on top of a representation that is induced using\nunsupervised deep learning (Goodfellow et al., 2016). The advantages of\npartially-ordered lattice structures are that these provide natural mechanisms\nfor use in concept discovery algorithms, through the meets and joins of the\nlattice.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2101.0505,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000014272,
      "text":"Top Program Construction and Reduction for polynomial time\n  Meta-Interpretive Learning\n\n  Meta-Interpretive Learners, like most ILP systems, learn by searching for a\ncorrect hypothesis in the hypothesis space, the powerset of all constructible\nclauses. We show how this exponentially-growing search can be replaced by the\nconstruction of a Top program: the set of clauses in all correct hypotheses\nthat is itself a correct hypothesis. We give an algorithm for Top program\nconstruction and show that it constructs a correct Top program in polynomial\ntime and from a finite number of examples. We implement our algorithm in Prolog\nas the basis of a new MIL system, Louise, that constructs a Top program and\nthen reduces it by removing redundant clauses. We compare Louise to the\nstate-of-the-art search-based MIL system Metagol in experiments on grid world\nnavigation, graph connectedness and grammar learning datasets and find that\nLouise improves on Metagol's predictive accuracy when the hypothesis space and\nthe target theory are both large, or when the hypothesis space does not include\na correct hypothesis because of \"classification noise\" in the form of\nmislabelled examples. When the hypothesis space or the target theory are small,\nLouise and Metagol perform equally well.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.03666,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000006623,
      "text":"Tree of Knowledge: an Online Platform for Learning the Behaviour of\n  Complex Systems\n\n  Many social sciences such as psychology and economics try to learn the\nbehaviour of complex agents such as humans, organisations and countries. The\ncurrent statistical methods used for learning this behaviour try to infer\ngenerally valid behaviour, but can only learn from one type of study at a time.\nFurthermore, only data from carefully designed studies can be used, as the\nphenomenon of interest has to be isolated and confounding factors accounted\nfor. These restrictions limit the robustness and accuracy of insights that can\nbe gained from social\/economic systems. Here we present the online platform\nTreeOfKnowledge which implements a new methodology specifically designed for\nlearning complex behaviours from complex systems: agent-based behaviour\nlearning. With agent-based behaviour learning it is possible to gain more\naccurate and robust insights as it does not have the restriction of\nconventional statistics. It learns agent behaviour from many heterogenous\ndatasets and can learn from these datasets even if the phenomenon of interest\nis not directly observed, but appears deep within complex systems. This new\nmethodology shows how the internet and advances in computational power allow\nfor more accurate and powerful mathematical models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.00187,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000057618,
      "text":"Multi-agent Reinforcement Learning in OpenSpiel: A Reproduction Report\n\n  In this report, we present results reproductions for several core algorithms\nimplemented in the OpenSpiel framework for learning in games. The primary\ncontribution of this work is a validation of OpenSpiel's re-implemented search\nand Reinforcement Learning algorithms against the results reported in their\nrespective originating works. Additionally, we provide complete documentation\nof hyperparameters and source code required to reproduce these experiments\neasily and exactly.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.09005,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000042717,
      "text":"An Efficient Diagnosis Algorithm for Inconsistent Constraint Sets\n\n  Constraint sets can become inconsistent in different contexts. For example,\nduring a configuration session the set of customer requirements can become\ninconsistent with the configuration knowledge base. Another example is the\nengineering phase of a configuration knowledge base where the underlying\nconstraints can become inconsistent with a set of test cases. In such\nsituations we are in the need of techniques that support the identification of\nminimal sets of faulty constraints that have to be deleted in order to restore\nconsistency. In this paper we introduce a divide-and-conquer based diagnosis\nalgorithm (FastDiag) which identifies minimal sets of faulty constraints in an\nover-constrained problem. This algorithm is specifically applicable in\nscenarios where the efficient identification of leading (preferred) diagnoses\nis crucial. We compare the performance of FastDiag with the conflict-directed\ncalculation of hitting sets and present an in-depth performance analysis that\nshows the advantages of our approach.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.08771,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000010596,
      "text":"Comparing and Combining Approximate Computing Frameworks\n\n  Approximate computing frameworks configure applications so they can operate\nat a range of points in an accuracy-performance trade-off space. Prior work has\nintroduced many frameworks to create approximate programs. As approximation\nframeworks proliferate, it is natural to ask how they can be compared and\ncombined to create even larger, richer trade-off spaces. We address these\nquestions by presenting VIPER and BOA. VIPER compares trade-off spaces induced\nby different approximation frameworks by visualizing performance improvements\nacross the full range of possible accuracies. BOA is a family of exploration\ntechniques that quickly locate Pareto-efficient points in the immense trade-off\nspace produced by the combination of two or more approximation frameworks. We\nuse VIPER and BOA to compare and combine three different approximation\nframeworks from across the system stack, including: one that changes numerical\nprecision, one that skips loop iterations, and one that manipulates existing\napplication parameters. Compared to simply looking at Pareto-optimal curves, we\nfind VIPER's visualizations provide a quicker and more convenient way to\ndetermine the best approximation technique for any accuracy loss. Compared to a\nstate-of-the-art evolutionary algorithm, we find that BOA explores 14x fewer\nconfigurations yet locates 35% more Pareto-efficient points.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.07539,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000012914,
      "text":"Crowdsourcing Parallel Corpus for English-Oromo Neural Machine\n  Translation using Community Engagement Platform\n\n  Even though Afaan Oromo is the most widely spoken language in the Cushitic\nfamily by more than fifty million people in the Horn and East Africa, it is\nsurprisingly resource-scarce from a technological point of view. The increasing\namount of various useful documents written in English language brings to\ninvestigate the machine that can translate those documents and make it easily\naccessible for local language. The paper deals with implementing a translation\nof English to Afaan Oromo and vice versa using Neural Machine Translation. But\nthe implementation is not very well explored due to the limited amount and\ndiversity of the corpus. However, using a bilingual corpus of just over 40k\nsentence pairs we have collected, this study showed a promising result. About a\nquarter of this corpus is collected via Community Engagement Platform (CEP)\nthat was implemented to enrich the parallel corpus through crowdsourcing\ntranslations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.0712,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000064572,
      "text":"Long-Term Resource Allocation Fairness in Average Markov Decision\n  Process (AMDP) Environment\n\n  Fairness has emerged as an important concern in automated decision-making in\nrecent years, especially when these decisions affect human welfare. In this\nwork, we study fairness in temporally extended decision-making settings,\nspecifically those formulated as Markov Decision Processes (MDPs). Our proposed\nnotion of fairness ensures that each state's long-term visitation frequency is\nat least a specified fraction. This quota-based notion of fairness is natural\nin many resource-allocation settings where the dynamics of a single resource\nbeing allocated is governed by an MDP and the distribution of the shared\nresource is captured by its state-visitation frequency. In an average-reward\nMDP (AMDP) setting, we formulate the problem as a bilinear saddle point program\nand, for a generative model, solve it using a Stochastic Mirror Descent (SMD)\nbased algorithm. The proposed solution guarantees a simultaneous approximation\non the expected average-reward and fairness requirement. We give sample\ncomplexity bounds for the proposed algorithm and validate our theoretical\nresults with experiments on simulated data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.13564,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000316236,
      "text":"Improving ENIGMA-Style Clause Selection While Learning From History\n\n  We re-examine the topic of machine-learned clause selection guidance in\nsaturation-based theorem provers. The central idea, recently popularized by the\nENIGMA system, is to learn a classifier for recognizing clauses that appeared\nin previously discovered proofs. In subsequent runs, clauses classified\npositively are prioritized for selection. We propose several improvements to\nthis approach and experimentally confirm their viability. For the\ndemonstration, we use a recursive neural network to classify clauses based on\ntheir derivation history and the presence or absence of automatically supplied\ntheory axioms therein. The automatic theorem prover Vampire guided by the\nnetwork achieves a 41% improvement on a relevant subset of SMT-LIB in a real\ntime evaluation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.11137,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000470214,
      "text":"Program Synthesis Guided Reinforcement Learning for Partially Observed\n  Environments\n\n  A key challenge for reinforcement learning is solving long-horizon planning\nproblems. Recent work has leveraged programs to guide reinforcement learning in\nthese settings. However, these approaches impose a high manual burden on the\nuser since they must provide a guiding program for every new task. Partially\nobserved environments further complicate the programming task because the\nprogram must implement a strategy that correctly, and ideally optimally,\nhandles every possible configuration of the hidden regions of the environment.\nWe propose a new approach, model predictive program synthesis (MPPS), that uses\nprogram synthesis to automatically generate the guiding programs. It trains a\ngenerative model to predict the unobserved portions of the world, and then\nsynthesizes a program based on samples from this model in a way that is robust\nto its uncertainty. In our experiments, we show that our approach significantly\noutperforms non-program-guided approaches on a set of challenging benchmarks,\nincluding a 2D Minecraft-inspired environment where the agent must complete a\ncomplex sequence of subtasks to achieve its goal, and achieves a similar\nperformance as using handcrafted programs to guide the agent. Our results\ndemonstrate that our approach can obtain the benefits of program-guided\nreinforcement learning without requiring the user to provide a new guiding\nprogram for every new task.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.11232,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000017881,
      "text":"Uncertainty Maximization in Partially Observable Domains: A Cognitive\n  Perspective\n\n  Faced with an ever-increasing complexity of their domains of application,\nartificial learning agents are now able to scale up in their ability to process\nan overwhelming amount of information coming from their interaction with an\nenvironment. However, this process of scaling does come with a cost of encoding\nand processing an increasing amount of redundant information that is not\nnecessarily beneficial to the learning process itself. This work exploits the\nproperties of the learning systems defined over partially observable domains by\nselectively focusing on the specific type of information that is more likely to\nexpress the causal interaction among the transitioning states of the\nenvironment. Adaptive masking of the observation space based on the temporal\ndifference displacement criterion enabled a significant improvement in\nconvergence of temporal difference algorithms defined over a partially\nobservable Markov process.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.002,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000193053,
      "text":"Siamese Labels Auxiliary Learning\n\n  In deep learning, auxiliary training has been widely used to assist the\ntraining of models. During the training phase, using auxiliary modules to\nassist training can improve the performance of the model. During the testing\nphase, auxiliary modules can be removed, so the test parameters are not\nincreased. In this paper, we propose a novel auxiliary training method, Siamese\nLabels Auxiliary Learning (SiLa). Unlike Deep Mutual Learning (DML), SiLa\nemphasizes auxiliary learning and can be easily combined with DML. In general,\nthe main work of this paper include: (1) propose SiLa Learning, which improves\nthe performance of common models without increasing test parameters; (2)\ncompares SiLa with DML and proves that SiLa can improve the generalization of\nthe model; (3) SiLa is applied to Dynamic Neural Networks, and proved that SiLa\ncan be used for various types of network structures.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.11352,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000040399,
      "text":"Individualized Context-Aware Tensor Factorization for Online Games\n  Predictions\n\n  Individual behavior and decisions are substantially influenced by their\ncontexts, such as location, environment, and time. Changes along these\ndimensions can be readily observed in Multiplayer Online Battle Arena games\n(MOBA), where players face different in-game settings for each match and are\nsubject to frequent game patches. Existing methods utilizing contextual\ninformation generalize the effect of a context over the entire population, but\ncontextual information tailored to each individual can be more effective. To\nachieve this, we present the Neural Individualized Context-aware Embeddings\n(NICE) model for predicting user performance and game outcomes. Our proposed\nmethod identifies individual behavioral differences in different contexts by\nlearning latent representations of users and contexts through non-negative\ntensor factorization. Using a dataset from the MOBA game League of Legends, we\ndemonstrate that our model substantially improves the prediction of winning\noutcome, individual user performance, and user engagement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.03896,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Consequences of Misaligned AI\n\n  AI systems often rely on two key components: a specified goal or reward\nfunction and an optimization algorithm to compute the optimal behavior for that\ngoal. This approach is intended to provide value for a principal: the user on\nwhose behalf the agent acts. The objectives given to these agents often refer\nto a partial specification of the principal's goals. We consider the cost of\nthis incompleteness by analyzing a model of a principal and an agent in a\nresource constrained world where the $L$ attributes of the state correspond to\ndifferent sources of utility for the principal. We assume that the reward\nfunction given to the agent only has support on $J < L$ attributes. The\ncontributions of our paper are as follows: 1) we propose a novel model of an\nincomplete principal-agent problem from artificial intelligence; 2) we provide\nnecessary and sufficient conditions under which indefinitely optimizing for any\nincomplete proxy objective leads to arbitrarily low overall utility; and 3) we\nshow how modifying the setup to allow reward functions that reference the full\nstate or allowing the principal to update the proxy objective over time can\nlead to higher utility solutions. The results in this paper argue that we\nshould view the design of reward functions as an interactive and dynamic\nprocess and identifies a theoretical scenario where some degree of\ninteractivity is desirable.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.03002,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000030796,
      "text":"Zero Training Overhead Portfolios for Learning to Solve Combinatorial\n  Problems\n\n  There has been an increasing interest in harnessing deep learning to tackle\ncombinatorial optimization (CO) problems in recent years. Typical CO deep\nlearning approaches leverage the problem structure in the model architecture.\nNevertheless, the model selection is still mainly based on the conventional\nmachine learning setting. Due to the discrete nature of CO problems, a single\nmodel is unlikely to learn the problem entirely. We introduce ZTop, which\nstands for Zero Training Overhead Portfolio, a simple yet effective model\nselection and ensemble mechanism for learning to solve combinatorial problems.\nZTop is inspired by algorithm portfolios, a popular CO ensembling strategy,\nparticularly restart portfolios, which periodically restart a randomized CO\nalgorithm, de facto exploring the search space with different heuristics. We\nhave observed that well-trained models acquired in the same training\ntrajectory, with similar top validation performance, perform well on very\ndifferent validation instances. Following this observation, ZTop ensembles a\nset of well-trained models, each providing a unique heuristic with zero\ntraining overhead, and applies them, sequentially or in parallel, to solve the\ntest instances. We show how ZTopping, i.e., using a ZTop ensemble strategy with\na given deep learning approach, can significantly improve the performance of\nthe current state-of-the-art deep learning approaches on three prototypical CO\ndomains, the hardest unique-solution Sudoku instances, challenging routing\nproblems, and the graph maximum cut problem, as well as on multi-label\nclassification, a machine learning task with a large combinatorial label space.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.06943,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000038743,
      "text":"Goods Transportation Problem Solving via Routing Algorithm\n\n  This paper outlines the ideas behind developing a graph-based\nheuristic-driven routing algorithm designed for a particular instance of a\ngoods transportation problem with a single good type. The proposed algorithm\nsolves the optimization problem of satisfying the demand of goods on a given\nundirected transportation graph with minimizing the estimated cost for each\ntraversed segment of the delivery path. The operation of the routing algorithm\nis discussed and overall evaluation of the proposed problem solving technique\nis given.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.05147,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Relational Dynamic Bayesian Network Modeling for Uncertainty\n  Quantification and Propagation in Airline Disruption Management\n\n  Disruption management during the airline scheduling process can be\ncompartmentalized into proactive and reactive processes depending upon the time\nof schedule execution. The state of the art for decision-making in airline\ndisruption management involves a heuristic human-centric approach that does not\ncategorically study uncertainty in proactive and reactive processes for\nmanaging airline schedule disruptions. Hence, this paper introduces an\nuncertainty transfer function model (UTFM) framework that characterizes\nuncertainty for proactive airline disruption management before schedule\nexecution, reactive airline disruption management during schedule execution,\nand proactive airline disruption management after schedule execution to enable\nthe construction of quantitative tools that can allow an intelligent agent to\nrationalize complex interactions and procedures for robust airline disruption\nmanagement. Specifically, we use historical scheduling and operations data from\na major U.S. airline to facilitate the development and assessment of the UTFM,\ndefined by hidden Markov models (a special class of probabilistic graphical\nmodels) that can efficiently perform pattern learning and inference on portions\nof large data sets. We employ the UTFM to assess two independent and separately\ndisrupted flight legs from the airline route network. Assessment of a flight\nleg from Dallas to Houston, disrupted by air traffic control hold for bad\nweather at Dallas, revealed that proactive disruption management for turnaround\nin Dallas before schedule execution is impractical because of zero transition\nprobability between turnaround and taxi-out.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.10062,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000015232,
      "text":"A Review of Biomedical Datasets Relating to Drug Discovery: A Knowledge\n  Graph Perspective\n\n  Drug discovery and development is a complex and costly process. Machine\nlearning approaches are being investigated to help improve the effectiveness\nand speed of multiple stages of the drug discovery pipeline. Of these, those\nthat use Knowledge Graphs (KG) have promise in many tasks, including drug\nrepurposing, drug toxicity prediction and target gene-disease prioritisation.\nIn a drug discovery KG, crucial elements including genes, diseases and drugs\nare represented as entities, whilst relationships between them indicate an\ninteraction. However, to construct high-quality KGs, suitable data is required.\nIn this review, we detail publicly available sources suitable for use in\nconstructing drug discovery focused KGs. We aim to help guide machine learning\nand KG practitioners who are interested in applying new techniques to the drug\ndiscovery field, but who may be unfamiliar with the relevant data sources. The\ndatasets are selected via strict criteria, categorised according to the primary\ntype of information contained within and are considered based upon what\ninformation could be extracted to build a KG. We then present a comparative\nanalysis of existing public drug discovery KGs and a evaluation of selected\nmotivating case studies from the literature. Additionally, we raise numerous\nand unique challenges and issues associated with the domain and its datasets,\nwhilst also highlighting key future research directions. We hope this review\nwill motivate KGs use in solving key and emerging questions in the drug\ndiscovery domain.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.07617,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"On the Philosophical, Cognitive and Mathematical Foundations of\n  Symbiotic Autonomous Systems (SAS)\n\n  Symbiotic Autonomous Systems (SAS) are advanced intelligent and cognitive\nsystems exhibiting autonomous collective intelligence enabled by coherent\nsymbiosis of human-machine interactions in hybrid societies. Basic research in\nthe emerging field of SAS has triggered advanced general AI technologies\nfunctioning without human intervention or hybrid symbiotic systems synergizing\nhumans and intelligent machines into coherent cognitive systems. This work\npresents a theoretical framework of SAS underpinned by the latest advances in\nintelligence, cognition, computer, and system sciences. SAS are characterized\nby the composition of autonomous and symbiotic systems that adopt\nbio-brain-social-inspired and heterogeneously synergized structures and\nautonomous behaviors. This paper explores their cognitive and mathematical\nfoundations. The challenge to seamless human-machine interactions in a hybrid\nenvironment is addressed. SAS-based collective intelligence is explored in\norder to augment human capability by autonomous machine intelligence towards\nthe next generation of general AI, autonomous computers, and trustworthy\nmission-critical intelligent systems. Emerging paradigms and engineering\napplications of SAS are elaborated via an autonomous knowledge learning system\nthat symbiotically works between humans and cognitive robots.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.03529,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000112255,
      "text":"Vampire With a Brain Is a Good ITP Hammer\n\n  Vampire has been for a long time the strongest first-order automatic theorem\nprover, widely used for hammer-style proof automation in ITPs such as Mizar,\nIsabelle, HOL, and Coq. In this work, we considerably improve the performance\nof Vampire in hammering over the full Mizar library by enhancing its saturation\nprocedure with efficient neural guidance. In particular, we employ a recently\nproposed recursive neural network classifying the generated clauses based only\non their derivation history. Compared to previous neural methods based on\nconsidering the logical content of the clauses, our architecture makes\nevaluating a single clause much less time consuming. The resulting system shows\ngood learning capability and improves on the state-of-the-art performance on\nthe Mizar library, while proving many theorems that the related ENIGMA system\ncould not prove in a similar hammering evaluation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.09312,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000135104,
      "text":"Hierarchical Learning Using Deep Optimum-Path Forest\n\n  Bag-of-Visual Words (BoVW) and deep learning techniques have been widely used\nin several domains, which include computer-assisted medical diagnoses. In this\nwork, we are interested in developing tools for the automatic identification of\nParkinson's disease using machine learning and the concept of BoVW. The\nproposed approach concerns a hierarchical-based learning technique to design\nvisual dictionaries through the Deep Optimum-Path Forest classifier. The\nproposed method was evaluated in six datasets derived from data collected from\nindividuals when performing handwriting exams. Experimental results showed the\npotential of the technique, with robust achievements.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2102.00617,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000114905,
      "text":"The Controllability of Planning, Responsibility, and Security in\n  Automatic Driving Technology\n\n  People hope automated driving technology is always in a stable and\ncontrollable state; specifically, it can be divided into controllable planning,\ncontrollable responsibility, and controllable information. When this\ncontrollability is undermined, it brings about the problems, e.g., trolley\ndilemma, responsibility attribution, information leakage, and security. This\narticle discusses these three types of issues separately and clarifies the\nmisunderstandings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.08249,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Evolving parametrized Loss for Image Classification Learning on Small\n  Datasets\n\n  This paper proposes a meta-learning approach to evolving a parametrized loss\nfunction, which is called Meta-Loss Network (MLN), for training the image\nclassification learning on small datasets. In our approach, the MLN is embedded\nin the framework of classification learning as a differentiable objective\nfunction. The MLN is evolved with the Evolutionary Strategy algorithm (ES) to\nan optimized loss function, such that a classifier, which optimized to minimize\nthis loss, will achieve a good generalization effect. A classifier learns on a\nsmall training dataset to minimize MLN with Stochastic Gradient Descent (SGD),\nand then the MLN is evolved with the precision of the small-dataset-updated\nclassifier on a large validation dataset. In order to evaluate our approach,\nthe MLN is trained with a large number of small sample learning tasks sampled\nfrom FashionMNIST and tested on validation tasks sampled from FashionMNIST and\nCIFAR10. Experiment results demonstrate that the MLN effectively improved\ngeneralization compared to classical cross-entropy error and mean squared\nerror.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.07877,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0001070235,
      "text":"R-GSN: The Relation-based Graph Similar Network for Heterogeneous Graph\n\n  Heterogeneous graph is a kind of data structure widely existing in real life.\nNowadays, the research of graph neural network on heterogeneous graph has\nbecome more and more popular. The existing heterogeneous graph neural network\nalgorithms mainly have two ideas, one is based on meta-path and the other is\nnot. The idea based on meta-path often requires a lot of manual preprocessing,\nat the same time it is difficult to extend to large scale graphs. In this\npaper, we proposed the general heterogeneous message passing paradigm and\ndesigned R-GSN that does not need meta-path, which is much improved compared to\nthe baseline R-GCN. Experiments have shown that our R-GSN algorithm achieves\nthe state-of-the-art performance on the ogbn-mag large scale heterogeneous\ngraph dataset.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.151,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"The General Theory of General Intelligence: A Pragmatic Patternist\n  Perspective\n\n  A multi-decade exploration into the theoretical foundations of artificial and\nnatural general intelligence, which has been expressed in a series of books and\npapers and used to guide a series of practical and research-prototype software\nsystems, is reviewed at a moderate level of detail. The review covers\nunderlying philosophies (patternist philosophy of mind, foundational\nphenomenological and logical ontology), formalizations of the concept of\nintelligence, and a proposed high level architecture for AGI systems partly\ndriven by these formalizations and philosophies. The implementation of specific\ncognitive processes such as logical reasoning, program learning, clustering and\nattention allocation in the context and language of this high level\narchitecture is considered, as is the importance of a common (e.g. typed\nmetagraph based) knowledge representation for enabling \"cognitive synergy\"\nbetween the various processes. The specifics of human-like cognitive\narchitecture are presented as manifestations of these general principles, and\nkey aspects of machine consciousness and machine ethics are also treated in\nthis context. Lessons for practical implementation of advanced AGI in\nframeworks such as OpenCog Hyperon are briefly considered.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.06371,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000009934,
      "text":"Hard Attention Control By Mutual Information Maximization\n\n  Biological agents have adopted the principle of attention to limit the rate\nof incoming information from the environment. One question that arises is if an\nartificial agent has access to only a limited view of its surroundings, how can\nit control its attention to effectively solve tasks? We propose an approach for\nlearning how to control a hard attention window by maximizing the mutual\ninformation between the environment state and the attention location at each\nstep. The agent employs an internal world model to make predictions about its\nstate and focuses attention towards where the predictions may be wrong.\nAttention is trained jointly with a dynamic memory architecture that stores\npartial observations and keeps track of the unobserved state. We demonstrate\nthat our approach is effective in predicting the full state from a sequence of\npartial observations. We also show that the agent's internal representation of\nthe surroundings, a live mental map, can be used for control in two partially\nobservable reinforcement learning tasks. Videos of the trained agent can be\nfound at https:\/\/sites.google.com\/view\/hard-attention-control.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.11345,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000001457,
      "text":"Monte Carlo Information-Oriented Planning\n\n  In this article, we discuss how to solve information-gathering problems\nexpressed as rho-POMDPs, an extension of Partially Observable Markov Decision\nProcesses (POMDPs) whose reward rho depends on the belief state. Point-based\napproaches used for solving POMDPs have been extended to solving rho-POMDPs as\nbelief MDPs when its reward rho is convex in B or when it is\nLipschitz-continuous. In the present paper, we build on the POMCP algorithm to\npropose a Monte Carlo Tree Search for rho-POMDPs, aiming for an efficient\non-line planner which can be used for any rho function. Adaptations are\nrequired due to the belief-dependent rewards to (i) propagate more than one\nstate at a time, and (ii) prevent biases in value estimates. An asymptotic\nconvergence proof to epsilon-optimal values is given when rho is continuous.\nExperiments are conducted to analyze the algorithms at hand and show that they\noutperform myopic approaches.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.02099,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000004073,
      "text":"Design of an Affordable Prosthetic Arm Equipped with Deep Learning\n  Vision-Based Manipulation\n\n  Many amputees throughout the world are left with limited options to\npersonally own a prosthetic arm due to the expensive cost, mechanical system\ncomplexity, and lack of availability. The three main control methods of\nprosthetic hands are: (1) body-powered control, (2) extrinsic mechanical\ncontrol, and (3) myoelectric control. These methods can perform well under a\ncontrolled situation but will often break down in clinical and everyday use due\nto poor robustness, weak adaptability, long-term training, and heavy mental\nburden during use. This paper lays the complete outline of the design process\nof an affordable and easily accessible novel prosthetic arm that reduces the\ncost of prosthetics from $10,000 to $700 on average. The 3D printed prosthetic\narm is equipped with a depth camera and closed-loop off-policy deep learning\nalgorithm to help form grasps to the object in view. Current work in\nreinforcement learning masters only individual skills and is heavily focused on\nparallel jaw grippers for in-hand manipulation. In order to create\ngeneralization, which better performs real-world manipulation, the focus is\nspecifically on using the general framework of Markov Decision Process (MDP)\nthrough scalable learning with off-policy algorithms such as deep deterministic\npolicy gradient (DDPG) and to study this question in the context of grasping a\nprosthetic arm. We were able to achieve a 78% grasp success rate on previously\nunseen objects and generalize across multiple objects for manipulation tasks.\nThis work will make prosthetics cheaper, easier to use and accessible globally\nfor amputees. Future work includes applying similar approaches to other medical\nassistive devices where a human is interacting with a machine to complete a\ntask.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.02363,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000001159,
      "text":"Reinforcement Learning with External Knowledge by using Logical Neural\n  Networks\n\n  Conventional deep reinforcement learning methods are sample-inefficient and\nusually require a large number of training trials before convergence. Since\nsuch methods operate on an unconstrained action set, they can lead to useless\nactions. A recent neuro-symbolic framework called the Logical Neural Networks\n(LNNs) can simultaneously provide key-properties of both neural networks and\nsymbolic logic. The LNNs functions as an end-to-end differentiable network that\nminimizes a novel contradiction loss to learn interpretable rules. In this\npaper, we utilize LNNs to define an inference graph using basic logical\noperations, such as AND and NOT, for faster convergence in reinforcement\nlearning. Specifically, we propose an integrated method that enables model-free\nreinforcement learning from external knowledge sources in an LNNs-based logical\nconstrained framework such as action shielding and guide. Our results\nempirically demonstrate that our method converges faster compared to a\nmodel-free reinforcement learning method that doesn't have such logical\nconstraints.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.15171,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"A Bayesian Approach to Identifying Representational Errors\n\n  Trained AI systems and expert decision makers can make errors that are often\ndifficult to identify and understand. Determining the root cause for these\nerrors can improve future decisions. This work presents Generative Error Model\n(GEM), a generative model for inferring representational errors based on\nobservations of an actor's behavior (either simulated agent, robot, or human).\nThe model considers two sources of error: those that occur due to\nrepresentational limitations -- \"blind spots\" -- and non-representational\nerrors, such as those caused by noise in execution or systematic errors present\nin the actor's policy. Disambiguating these two error types allows for targeted\nrefinement of the actor's policy (i.e., representational errors require\nperceptual augmentation, while other errors can be reduced through methods such\nas improved training or attention support). We present a Bayesian inference\nalgorithm for GEM and evaluate its utility in recovering representational\nerrors on multiple domains. Results show that our approach can recover blind\nspots of both reinforcement learning agents as well as human users.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.07903,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"Investigating Value of Curriculum Reinforcement Learning in Autonomous\n  Driving Under Diverse Road and Weather Conditions\n\n  Applications of reinforcement learning (RL) are popular in autonomous driving\ntasks. That being said, tuning the performance of an RL agent and guaranteeing\nthe generalization performance across variety of different driving scenarios is\nstill largely an open problem. In particular, getting good performance on\ncomplex road and weather conditions require exhaustive tuning and computation\ntime. Curriculum RL, which focuses on solving simpler automation tasks in order\nto transfer knowledge to complex tasks, is attracting attention in RL\ncommunity. The main contribution of this paper is a systematic study for\ninvestigating the value of curriculum reinforcement learning in autonomous\ndriving applications. For this purpose, we setup several different driving\nscenarios in a realistic driving simulator, with varying road complexity and\nweather conditions. Next, we train and evaluate performance of RL agents on\ndifferent sequences of task combinations and curricula. Results show that\ncurriculum RL can yield significant gains in complex driving tasks, both in\nterms of driving performance and sample complexity. Results also demonstrate\nthat different curricula might enable different benefits, which hints future\nresearch directions for automated curriculum training.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.16704,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000030465,
      "text":"Probabilistic Analogical Mapping with Semantic Relation Networks\n\n  The human ability to flexibly reason using analogies with domain-general\ncontent depends on mechanisms for identifying relations between concepts, and\nfor mapping concepts and their relations across analogs. Building on a recent\nmodel of how semantic relations can be learned from non-relational word\nembeddings, we present a new computational model of mapping between two\nanalogs. The model adopts a Bayesian framework for probabilistic graph\nmatching, operating on semantic relation networks constructed from distributed\nrepresentations of individual concepts and of relations between concepts.\nThrough comparisons of model predictions with human performance in a novel\nmapping task requiring integration of multiple relations, as well as in several\nclassic studies, we demonstrate that the model accounts for a broad range of\nphenomena involving analogical mapping by both adults and children. We also\nshow the potential for extending the model to deal with analog retrieval. Our\napproach demonstrates that human-like analogical mapping can emerge from\ncomparison mechanisms applied to rich semantic representations of individual\nconcepts and relations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.11961,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000013577,
      "text":"Artificial Intelligence Narratives: An Objective Perspective on Current\n  Developments\n\n  This work provides a starting point for researchers interested in gaining a\ndeeper understanding of the big picture of artificial intelligence (AI). To\nthis end, a narrative is conveyed that allows the reader to develop an\nobjective view on current developments that is free from false promises that\ndominate public communication. An essential takeaway for the reader is that AI\nmust be understood as an umbrella term encompassing a plethora of different\nmethods, schools of thought, and their respective historical movements.\nConsequently, a bottom-up strategy is pursued in which the field of AI is\nintroduced by presenting various aspects that are characteristic of the\nsubject. This paper is structured in three parts: (i) Discussion of current\ntrends revealing false public narratives, (ii) an introduction to the history\nof AI focusing on recurring patterns and main characteristics, and (iii) a\ncritical discussion on the limitations of current methods in the context of the\npotential emergence of a strong(er) AI. It should be noted that this work does\nnot cover any of these aspects holistically; rather, the content addressed is a\nselection made by the author and subject to a didactic strategy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.11692,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000002053,
      "text":"Recognizing LTLf\/PLTLf Goals in Fully Observable Non-Deterministic\n  Domain Models\n\n  Goal Recognition is the task of discerning the correct intended goal that an\nagent aims to achieve, given a set of possible goals, a domain model, and a\nsequence of observations as a sample of the plan being executed in the\nenvironment. Existing approaches assume that the possible goals are formalized\nas a conjunction in deterministic settings. In this paper, we develop a novel\napproach that is capable of recognizing temporally extended goals in Fully\nObservable Non-Deterministic (FOND) planning domain models, focusing on goals\non finite traces expressed in Linear Temporal Logic (LTLf) and (Pure) Past\nLinear Temporal Logic (PLTLf). We empirically evaluate our goal recognition\napproach using different LTLf and PLTLf goals over six common FOND planning\ndomain models, and show that our approach is accurate to recognize temporally\nextended goals at several levels of observability.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.15452,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000006292,
      "text":"Boosting the Speed of Entity Alignment 10*: Dual Attention Matching\n  Network with Normalized Hard Sample Mining\n\n  Seeking the equivalent entities among multi-source Knowledge Graphs (KGs) is\nthe pivotal step to KGs integration, also known as \\emph{entity alignment}\n(EA). However, most existing EA methods are inefficient and poor in\nscalability. A recent summary points out that some of them even require several\ndays to deal with a dataset containing 200,000 nodes (DWY100K). We believe\nover-complex graph encoder and inefficient negative sampling strategy are the\ntwo main reasons. In this paper, we propose a novel KG encoder -- Dual\nAttention Matching Network (Dual-AMN), which not only models both intra-graph\nand cross-graph information smartly, but also greatly reduces computational\ncomplexity. Furthermore, we propose the Normalized Hard Sample Mining Loss to\nsmoothly select hard negative samples with reduced loss shift. The experimental\nresults on widely used public datasets indicate that our method achieves both\nhigh accuracy and high efficiency. On DWY100K, the whole running process of our\nmethod could be finished in 1,100 seconds, at least 10* faster than previous\nwork. The performances of our method also outperform previous works across all\ndatasets, where Hits@1 and MRR have been improved from 6% to 13%.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.17245,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Digital Twin Based Disaster Management System Proposal: DT-DMS\n\n  The damage and the impact of natural disasters are becoming more destructive\nwith the increase of urbanization. Today's metropolitan cities are not\nsufficiently prepared for the pre and post-disaster situations. Digital Twin\ntechnology can provide a solution. A virtual copy of the physical city could be\ncreated by collecting data from sensors of the Internet of Things (IoT) devices\nand stored on the cloud infrastructure. This virtual copy is kept current and\nup to date with the continuous flow of the data coming from the sensors. We\npropose a disaster management system utilizing machine learning called DT-DMS\nis used to support decision-making mechanisms. This study aims to show how to\neducate and prepare emergency center staff by simulating potential disaster\nsituations on the virtual copy. The event of a disaster will be simulated\nallowing emergency center staff to make decisions and depicting the potential\noutcomes of these decisions. A rescue operation after an earthquake is\nsimulated. Test results are promising and the simulation scope is planned to be\nextended.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.08391,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000013245,
      "text":"Flexible FOND Planning with Explicit Fairness Assumptions\n\n  We consider the problem of reaching a propositional goal condition in\nfully-observable non-deterministic (FOND) planning under a general class of\nfairness assumptions that are given explicitly. The fairness assumptions are of\nthe form A\/B and say that state trajectories that contain infinite occurrences\nof an action a from A in a state s and finite occurrence of actions from B,\nmust also contain infinite occurrences of action a in s followed by each one of\nits possible outcomes. The infinite trajectories that violate this condition\nare deemed as unfair, and the solutions are policies for which all the fair\ntrajectories reach a goal state. We show that strong and strong-cyclic FOND\nplanning, as well as QNP planning, a planning model introduced recently for\ngeneralized planning, are all special cases of FOND planning with fairness\nassumptions of this form which can also be combined. FOND+ planning, as this\nform of planning is called, combines the syntax of FOND planning with some of\nthe versatility of LTL for expressing fairness constraints. A new planner is\nimplemented by reducing FOND+ planning to answer set programs, and the\nperformance of the planner is evaluated in comparison with FOND and QNP\nplanners, and LTL synthesis tools.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.14986,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000049339,
      "text":"Generating Negations of Probability Distributions\n\n  Recently it was introduced a negation of a probability distribution. The need\nfor such negation arises when a knowledge-based system can use the terms like\nNOT HIGH, where HIGH is represented by a probability distribution (pd). For\nexample, HIGH PROFIT or HIGH PRICE can be considered. The application of this\nnegation in Dempster-Shafer theory was considered in many works. Although\nseveral negations of probability distributions have been proposed, it was not\nclear how to construct other negations. In this paper, we consider negations of\nprobability distributions as point-by-point transformations of pd using\ndecreasing functions defined on [0,1] called negators. We propose the general\nmethod of generation of negators and corresponding negations of pd, and study\ntheir properties. We give a characterization of linear negators as a convex\ncombination of Yager and uniform negators.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.12854,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000001755,
      "text":"Actionable Cognitive Twins for Decision Making in Manufacturing\n\n  Actionable Cognitive Twins are the next generation Digital Twins enhanced\nwith cognitive capabilities through a knowledge graph and artificial\nintelligence models that provide insights and decision-making options to the\nusers. The knowledge graph describes the domain-specific knowledge regarding\nentities and interrelationships related to a manufacturing setting. It also\ncontains information on possible decision-making options that can assist\ndecision-makers, such as planners or logisticians. In this paper, we propose a\nknowledge graph modeling approach to construct actionable cognitive twins for\ncapturing specific knowledge related to demand forecasting and production\nplanning in a manufacturing plant. The knowledge graph provides semantic\ndescriptions and contextualization of the production lines and processes,\nincluding data identification and simulation or artificial intelligence\nalgorithms and forecasts used to support them. Such semantics provide ground\nfor inferencing, relating different knowledge types: creative, deductive,\ndefinitional, and inductive. To develop the knowledge graph models for\ndescribing the use case completely, systems thinking approach is proposed to\ndesign and verify the ontology, develop a knowledge graph and build an\nactionable cognitive twin. Finally, we evaluate our approach in two use cases\ndeveloped for a European original equipment manufacturer related to the\nautomotive industry as part of the European Horizon 2020 project FACTLOG.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.03798,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000071194,
      "text":"Training a First-Order Theorem Prover from Synthetic Data\n\n  A major challenge in applying machine learning to automated theorem proving\nis the scarcity of training data, which is a key ingredient in training\nsuccessful deep learning models. To tackle this problem, we propose an approach\nthat relies on training purely with synthetically generated theorems, without\nany human data aside from axioms. We use these theorems to train a\nneurally-guided saturation-based prover. Our neural prover outperforms the\nstate-of-the-art E-prover on this synthetic data in both time and search steps,\nand shows significant transfer to the unseen human-written theorems from the\nTPTP library, where it solves 72\\% of first-order problems without equality.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.00778,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000014901,
      "text":"Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis\n\n  Despite many proposed algorithms to provide robustness to deep learning (DL)\nmodels, DL models remain susceptible to adversarial attacks. We hypothesize\nthat the adversarial vulnerability of DL models stems from two factors. The\nfirst factor is data sparsity which is that in the high dimensional input data\nspace, there exist large regions outside the support of the data distribution.\nThe second factor is the existence of many redundant parameters in the DL\nmodels. Owing to these factors, different models are able to come up with\ndifferent decision boundaries with comparably high prediction accuracy. The\nappearance of the decision boundaries in the space outside the support of the\ndata distribution does not affect the prediction accuracy of the model.\nHowever, it makes an important difference in the adversarial robustness of the\nmodel. We hypothesize that the ideal decision boundary is as far as possible\nfrom the support of the data distribution. In this paper, we develop a training\nframework to observe if DL models are able to learn such a decision boundary\nspanning the space around the class distributions further from the data points\nthemselves. Semi-supervised learning was deployed during training by leveraging\nunlabeled data generated in the space outside the support of the data\ndistribution. We measured adversarial robustness of the models trained using\nthis training framework against well-known adversarial attacks and by using\nrobustness metrics. We found that models trained using our framework, as well\nas other regularization methods and adversarial training support our hypothesis\nof data sparsity and that models trained with these methods learn to have\ndecision boundaries more similar to the aforementioned ideal decision boundary.\nThe code for our training framework is available at\nhttps:\/\/github.com\/MahsaPaknezhad\/AdversariallyRobustTraining.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2103.03429,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000026822,
      "text":"Human-Understandable Decision Making for Visual Recognition\n\n  The widespread use of deep neural networks has achieved substantial success\nin many tasks. However, there still exists a huge gap between the operating\nmechanism of deep learning models and human-understandable decision making, so\nthat humans cannot fully trust the predictions made by these models. To date,\nlittle work has been done on how to align the behaviors of deep learning models\nwith human perception in order to train a human-understandable model. To fill\nthis gap, we propose a new framework to train a deep neural network by\nincorporating the prior of human perception into the model learning process.\nOur proposed model mimics the process of perceiving conceptual parts from\nimages and assessing their relative contributions towards the final\nrecognition. The effectiveness of our proposed model is evaluated on two\nclassical visual recognition tasks. The experimental results and analysis\nconfirm our model is able to provide interpretable explanations for its\npredictions, but also maintain competitive recognition accuracy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.02545,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000021524,
      "text":"Data-driven Design of Context-aware Monitors for Hazard Prediction in\n  Artificial Pancreas Systems\n\n  Medical Cyber-physical Systems (MCPS) are vulnerable to accidental or\nmalicious faults that can target their controllers and cause safety hazards and\nharm to patients. This paper proposes a combined model and data-driven approach\nfor designing context-aware monitors that can detect early signs of hazards and\nmitigate them in MCPS. We present a framework for formal specification of\nunsafe system context using Signal Temporal Logic (STL) combined with an\noptimization method for patient-specific refinement of STL formulas based on\nreal or simulated faulty data from the closed-loop system for the generation of\nmonitor logic. We evaluate our approach in simulation using two\nstate-of-the-art closed-loop Artificial Pancreas Systems (APS). The results\nshow the context-aware monitor achieves up to 1.4 times increase in average\nhazard prediction accuracy (F1-score) over several baseline monitors, reduces\nfalse-positive and false-negative rates, and enables hazard mitigation with a\n54% success rate while decreasing the average risk for patients.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.03571,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000243054,
      "text":"On Mixed Iterated Revisions\n\n  Several forms of iterable belief change exist, differing in the kind of\nchange and its strength: some operators introduce formulae, others remove them;\nsome add formulae unconditionally, others only as additions to the previous\nbeliefs; some only relative to the current situation, others in all possible\ncases. A sequence of changes may involve several of them: for example, the\nfirst step is a revision, the second a contraction and the third a refinement\nof the previous beliefs. The ten operators considered in this article are shown\nto be all reducible to three: lexicographic revision, refinement and severe\nwithdrawal. In turn, these three can be expressed in terms of lexicographic\nrevision at the cost of restructuring the sequence. This restructuring needs\nnot to be done explicitly: an algorithm that works on the original sequence is\nshown. The complexity of mixed sequences of belief change operators is also\nanalyzed. Most of them require only a polynomial number of calls to a\nsatisfiability checker, some are even easier.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.0689,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000431471,
      "text":"An Introduction of mini-AlphaStar\n\n  StarCraft II (SC2) is a real-time strategy game in which players produce and\ncontrol multiple units to fight against opponent's units. Due to its\ndifficulties, such as huge state space, various action space, a long time\nhorizon, and imperfect information, SC2 has been a research hotspot in\nreinforcement learning. Recently, an agent called AlphaStar (AS) has been\nproposed, which shows good performance, obtaining a high win rate of 99.8%\nagainst human players. We implemented a mini-scaled version of it called\nmini-AlphaStar (mAS) based on AS's paper and pseudocode. The difference between\nAS and mAS is that we substituted the hyper-parameters of AS with smaller ones\nfor mini-scale training. Codes of mAS are all open-sourced\n(https:\/\/github.com\/liuruoze\/mini-AlphaStar) for future research.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.0006,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"Ethical Implementation of Artificial Intelligence to Select Embryos in\n  In Vitro Fertilization\n\n  AI has the potential to revolutionize many areas of healthcare. Radiology,\ndermatology, and ophthalmology are some of the areas most likely to be impacted\nin the near future, and they have received significant attention from the\nbroader research community. But AI techniques are now also starting to be used\nin in vitro fertilization (IVF), in particular for selecting which embryos to\ntransfer to the woman. The contribution of AI to IVF is potentially\nsignificant, but must be done carefully and transparently, as the ethical\nissues are significant, in part because this field involves creating new\npeople. We first give a brief introduction to IVF and review the use of AI for\nembryo selection. We discuss concerns with the interpretation of the reported\nresults from scientific and practical perspectives. We then consider the\nbroader ethical issues involved. We discuss in detail the problems that result\nfrom the use of black-box methods in this context and advocate strongly for the\nuse of interpretable models. Importantly, there have been no published trials\nof clinical effectiveness, a problem in both the AI and IVF communities, and we\ntherefore argue that clinical implementation at this point would be premature.\nFinally, we discuss ways for the broader AI community to become involved to\nensure scientifically sound and ethically responsible development of AI in IVF.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.07666,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000308951,
      "text":"A Note on Data Simulations for Voting by Evaluation\n\n  Voting rules based on evaluation inputs rather than preference orders have\nbeen recently proposed, like majority judgement, range voting or approval\nvoting. Traditionally, probabilistic analysis of voting rules supposes the use\nof simulation models to generate preferences data, like the Impartial Culture\n(IC) or Impartial and Anonymous Culture (IAC) models. But these simulation\nmodels are not suitable for the analysis of evaluation-based voting rules as\nthey generate preference orders instead of the needed evaluations. We propose\nin this paper several simulation models for generating evaluation-based voting\ninputs. These models, inspired by classical ones, are defined, tested and\ncompared for recommendation purpose.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.05416,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000042386,
      "text":"An approach utilizing negation of extended-dimensional vector of\n  disposing mass for ordinal evidences combination in a fuzzy environment\n\n  How to measure the degree of uncertainty of a given frame of discernment has\nbeen a hot topic for years. A lot of meaningful works have provided some\neffective methods to measure the degree properly. However, a crucial factor,\nsequence of propositions, is missing in the definition of traditional frame of\ndiscernment. In this paper, a detailed definition of ordinal frame of\ndiscernment has been provided. Besides, an innovative method utilizing a\nconcept of computer vision to combine the order of propositions and the mass of\nthem is proposed to better manifest relationships between the two important\nelement of the frame of discernment. More than that, a specially designed\nmethod covering some powerful tools in indicating the degree of uncertainty of\na traditional frame of discernment is also offered to give an indicator of\nlevel of uncertainty of an ordinal frame of discernment on the level of vector.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.07225,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000058942,
      "text":"Text Guide: Improving the quality of long text classification by a text\n  selection method based on feature importance\n\n  The performance of text classification methods has improved greatly over the\nlast decade for text instances of less than 512 tokens. This limit has been\nadopted by most state-of-the-research transformer models due to the high\ncomputational cost of analyzing longer text instances. To mitigate this problem\nand to improve classification for longer texts, researchers have sought to\nresolve the underlying causes of the computational cost and have proposed\noptimizations for the attention mechanism, which is the key element of every\ntransformer model. In our study, we are not pursuing the ultimate goal of long\ntext classification, i.e., the ability to analyze entire text instances at one\ntime while preserving high performance at a reasonable computational cost.\nInstead, we propose a text truncation method called Text Guide, in which the\noriginal text length is reduced to a predefined limit in a manner that improves\nperformance over naive and semi-naive approaches while preserving low\ncomputational costs. Text Guide benefits from the concept of feature\nimportance, a notion from the explainable artificial intelligence domain. We\ndemonstrate that Text Guide can be used to improve the performance of recent\nlanguage models specifically designed for long text classification, such as\nLongformer. Moreover, we discovered that parameter optimization is the key to\nText Guide performance and must be conducted before the method is deployed.\nFuture experiments may reveal additional benefits provided by this new method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.04278,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.000007285,
      "text":"Batch Monte Carlo Tree Search\n\n  Making inferences with a deep neural network on a batch of states is much\nfaster with a GPU than making inferences on one state after another. We build\non this property to propose Monte Carlo Tree Search algorithms using batched\ninferences. Instead of using either a search tree or a transposition table we\npropose to use both in the same algorithm. The transposition table contains the\nresults of the inferences while the search tree contains the statistics of\nMonte Carlo Tree Search. We also propose to analyze multiple heuristics that\nimprove the search: the $\\mu$ FPU, the Virtual Mean, the Last Iteration and the\nSecond Move heuristics. They are evaluated for the game of Go using a MobileNet\nneural network.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.08641,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000018875,
      "text":"Generating Diverse and Competitive Play-Styles for Strategy Games\n\n  Designing agents that are able to achieve different play-styles while\nmaintaining a competitive level of play is a difficult task, especially for\ngames for which the research community has not found super-human performance\nyet, like strategy games. These require the AI to deal with large action\nspaces, long-term planning and partial observability, among other well-known\nfactors that make decision-making a hard problem. On top of this, achieving\ndistinct play-styles using a general algorithm without reducing playing\nstrength is not trivial. In this paper, we propose Portfolio Monte Carlo Tree\nSearch with Progressive Unpruning for playing a turn-based strategy game\n(Tribes) and show how it can be parameterized so a quality-diversity algorithm\n(MAP-Elites) is used to achieve different play-styles while keeping a\ncompetitive level of play. Our results show that this algorithm is capable of\nachieving these goals even for an extensive collection of game levels beyond\nthose used for training.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.05755,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000006954,
      "text":"Tensor Processing Primitives: A Programming Abstraction for Efficiency\n  and Portability in Deep Learning & HPC Workloads\n\n  During the past decade, novel Deep Learning (DL) algorithms, workloads and\nhardware have been developed to tackle a wide range of problems. Despite the\nadvances in workload and hardware ecosystems, the programming methodology of DL\nsystems is stagnant. DL workloads leverage either highly-optimized, yet\nplatform-specific and inflexible kernels from DL libraries, or in the case of\nnovel operators, reference implementations are built via DL framework\nprimitives with underwhelming performance. This work introduces the Tensor\nProcessing Primitives (TPP), a programming abstraction striving for efficient,\nportable implementation of DL workloads with high-productivity. TPPs define a\ncompact, yet versatile set of 2D-tensor operators (or a virtual Tensor ISA),\nwhich subsequently can be utilized as building-blocks to construct complex\noperators on high-dimensional tensors. The TPP specification is\nplatform-agnostic, thus code expressed via TPPs is portable, whereas the TPP\nimplementation is highly-optimized and platform-specific. We demonstrate the\nefficacy and viability of our approach using standalone kernels and end-to-end\nDL & HPC workloads expressed entirely via TPPs that outperform state-of-the-art\nimplementations on multiple platforms.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.00362,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Evaluating Predictive Business Process Monitoring Approaches on Small\n  Event Logs\n\n  Predictive business process monitoring is concerned with the prediction how a\nrunning process instance will unfold up to its completion at runtime. Most of\nthe proposed approaches rely on a wide number of different machine learning\n(ML) techniques. In the last years numerous comparative studies, reviews, and\nbenchmarks of such approaches where published and revealed that they can be\nsuccessfully applied for different prediction targets. ML techniques require a\nqualitatively and quantitatively sufficient data set. However, there are many\nsituations in business process management (BPM) where only a quantitatively\ninsufficient data set is available. The problem of insufficient data in the\ncontext of BPM is still neglected. Hence, none of the comparative studies or\nbenchmarks investigates the performance of predictive business process\nmonitoring techniques in environments with small data sets. In this paper an\nevaluation framework for comparing existing approaches with regard to their\nsuitability for small data sets is developed and exemplarily applied to\nstate-of-the-art approaches in predictive business process monitoring.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.09936,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000013577,
      "text":"Network-wide traffic signal control optimization using a multi-agent\n  deep reinforcement learning\n\n  Inefficient traffic control may cause numerous problems such as traffic\ncongestion and energy waste. This paper proposes a novel multi-agent\nreinforcement learning method, named KS-DDPG (Knowledge Sharing Deep\nDeterministic Policy Gradient) to achieve optimal control by enhancing the\ncooperation between traffic signals. By introducing the knowledge-sharing\nenabled communication protocol, each agent can access to the collective\nrepresentation of the traffic environment collected by all agents. The proposed\nmethod is evaluated through two experiments respectively using synthetic and\nreal-world datasets. The comparison with state-of-the-art reinforcement\nlearning-based and conventional transportation methods demonstrate the proposed\nKS-DDPG has significant efficiency in controlling large-scale transportation\nnetworks and coping with fluctuations in traffic flow. In addition, the\nintroduced communication mechanism has also been proven to speed up the\nconvergence of the model without significantly increasing the computational\nburden.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.14602,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"D-VAL: An automatic functional equivalence validation tool for planning\n  domain models\n\n  This paper introduces an approach to validate the functional equivalence of\nplanning domain models. Validating the functional equivalence of planning\ndomain models is the problem of formally confirming that two planning domain\nmodels can be used to solve the same set of problems for any set of objects.\nThe need for techniques to validate the functional equivalence of planning\ndomain models has been highlighted in previous research and has applications in\nmodel learning, development and extension. We prove the soundness and\ncompleteness of our method. We also develop D-VAL, an automatic functional\nequivalence validation tool for planning domain models. Empirical evaluation\nshows that D-VAL validates the functional equivalence of all examined domains\nin less than 43 seconds. Additionally, we provide a benchmark to evaluate the\nfeasibility and performance of this and future related work.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.10743,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"A Unifying Bayesian Formulation of Measures of Interpretability in\n  Human-AI\n\n  Existing approaches for generating human-aware agent behaviors have\nconsidered different measures of interpretability in isolation. Further, these\nmeasures have been studied under differing assumptions, thus precluding the\npossibility of designing a single framework that captures these measures under\nthe same assumptions. In this paper, we present a unifying Bayesian framework\nthat models a human observer's evolving beliefs about an agent and thereby\ndefine the problem of Generalized Human-Aware Planning. We will show that the\ndefinitions of interpretability measures like explicability, legibility and\npredictability from the prior literature fall out as special cases of our\ngeneral framework. Through this framework, we also bring a previously ignored\nfact to light that the human-robot interactions are in effect open-world\nproblems, particularly as a result of modeling the human's beliefs over the\nagent. Since the human may not only hold beliefs unknown to the agent but may\nalso form new hypotheses about the agent when presented with novel or\nunexpected behaviors.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.12278,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000058611,
      "text":"Causal Learning for Socially Responsible AI\n\n  There have been increasing concerns about Artificial Intelligence (AI) due to\nits unfathomable potential power. To make AI address ethical challenges and\nshun undesirable outcomes, researchers proposed to develop socially responsible\nAI (SRAI). One of these approaches is causal learning (CL). We survey\nstate-of-the-art methods of CL for SRAI. We begin by examining the seven CL\ntools to enhance the social responsibility of AI, then review how existing\nworks have succeeded using these tools to tackle issues in developing SRAI such\nas fairness. The goal of this survey is to bring forefront the potentials and\npromises of CL for SRAI.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.10857,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.000011656,
      "text":"Attribute-Modulated Generative Meta Learning for Zero-Shot\n  Classification\n\n  Zero-shot learning (ZSL) aims to transfer knowledge from seen classes to\nsemantically related unseen classes, which are absent during training. The\npromising strategies for ZSL are to synthesize visual features of unseen\nclasses conditioned on semantic side information and to incorporate\nmeta-learning to eliminate the model's inherent bias towards seen classes.\nWhile existing meta generative approaches pursue a common model shared across\ntask distributions, we aim to construct a generative network adaptive to task\ncharacteristics. To this end, we propose an Attribute-Modulated generAtive\nmeta-model for Zero-shot learning (AMAZ). Our model consists of an\nattribute-aware modulation network, an attribute-augmented generative network,\nand an attribute-weighted classifier. Given unseen classes, the modulation\nnetwork adaptively modulates the generator by applying task-specific\ntransformations so that the generative network can adapt to highly diverse\ntasks. The weighted classifier utilizes the data quality to enhance the\ntraining procedure, further improving the model performance. Our empirical\nevaluations on four widely-used benchmarks show that AMAZ outperforms\nstate-of-the-art methods by 3.8% and 3.1% in ZSL and generalized ZSL settings,\nrespectively, demonstrating the superiority of our method. Our experiments on a\nzero-shot image retrieval task show AMAZ's ability to synthesize instances that\nportray real visual characteristics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.13155,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000012252,
      "text":"Watershed of Artificial Intelligence: Human Intelligence, Machine\n  Intelligence, and Biological Intelligence\n\n  This article reviews the \"Once learning\" mechanism that was proposed 23 years\nago and the subsequent successes of \"One-shot learning\" in image classification\nand \"You Only Look Once - YOLO\" in objective detection. Analyzing the current\ndevelopment of Artificial Intelligence (AI), the proposal is that AI should be\nclearly divided into the following categories: Artificial Human Intelligence\n(AHI), Artificial Machine Intelligence (AMI), and Artificial Biological\nIntelligence (ABI), which will also be the main directions of theory and\napplication development for AI. As a watershed for the branches of AI, some\nclassification standards and methods are discussed: 1) Human-oriented,\nmachine-oriented, and biological-oriented AI R&D; 2) Information input\nprocessed by Dimensionality-up or Dimensionality-reduction; 3) The use of\none\/few or large samples for knowledge learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.08543,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000016557,
      "text":"Planning with Expectation Models for Control\n\n  In model-based reinforcement learning (MBRL), Wan et al. (2019) showed\nconditions under which the environment model could produce the expectation of\nthe next feature vector rather than the full distribution, or a sample thereof,\nwith no loss in planning performance. Such expectation models are of interest\nwhen the environment is stochastic and non-stationary, and the model is\napproximate, such as when it is learned using function approximation. In these\ncases a full distribution model may be impractical and a sample model may be\neither more expensive computationally or of high variance. Wan et al.\nconsidered only planning for prediction to evaluate a fixed policy. In this\npaper, we treat the control case - planning to improve and find a good\napproximate policy. We prove that planning with an expectation model must\nupdate a state-value function, not an action-value function as previously\nsuggested (e.g., Sorg & Singh, 2010). This opens the question of how planning\ninfluences action selections. We consider three strategies for this and present\ngeneral MBRL algorithms for each. We identify the strengths and weaknesses of\nthese algorithms in computational experiments. Our algorithms and experiments\nare the first to treat MBRL with expectation models in a general setting.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.00698,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000048015,
      "text":"Back to Square One: Superhuman Performance in Chutes and Ladders Through\n  Deep Neural Networks and Tree Search\n\n  We present AlphaChute: a state-of-the-art algorithm that achieves superhuman\nperformance in the ancient game of Chutes and Ladders. We prove that our\nalgorithm converges to the Nash equilibrium in constant time, and therefore is\n-- to the best of our knowledge -- the first such formal solution to this game.\nSurprisingly, despite all this, our implementation of AlphaChute remains\nrelatively straightforward due to domain-specific adaptations. We provide the\nsource code for AlphaChute here in our Appendix.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2104.12379,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"Towards Visual Semantics\n\n  Lexical Semantics is concerned with how words encode mental representations\nof the world, i.e., concepts . We call this type of concepts, classification\nconcepts . In this paper, we focus on Visual Semantics , namely on how humans\nbuild concepts representing what they perceive visually. We call this second\ntype of concepts, substance concepts . As shown in the paper, these two types\nof concepts are different and, furthermore, the mapping between them is\nmany-to-many. In this paper we provide a theory and an algorithm for how to\nbuild substance concepts which are in a one-to-one correspondence with\nclassifications concepts, thus paving the way to the seamless integration\nbetween natural language descriptions and visual perception. This work builds\nupon three main intuitions: (i) substance concepts are modeled as visual\nobjects , namely sequences of similar frames, as perceived in multiple\nencounters ; (ii) substance concepts are organized into a visual subsumption\nhierarchy based on the notions of Genus and Differentia ; (iii) the human\nfeedback is exploited not to name objects, but, rather, to align the hierarchy\nof substance concepts with that of classification concepts. The learning\nalgorithm is implemented for the base case of a hierarchy of depth two. The\nexperiments, though preliminary, show that the algorithm manages to acquire the\nnotions of Genus and Differentia with reasonable accuracy, this despite seeing\na small number of examples and receiving supervision on a fraction of them.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.0354,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000025166,
      "text":"An Intelligent Model for Solving Manpower Scheduling Problems\n\n  The manpower scheduling problem is a critical research field in the resource\nmanagement area. Based on the existing studies on scheduling problem solutions,\nthis paper transforms the manpower scheduling problem into a combinational\noptimization problem under multi-constraint conditions from a new perspective.\nIt also uses logical paradigms to build a mathematical model for problem\nsolution and an improved multi-dimensional evolution algorithm for solving the\nmodel. Moreover, the constraints discussed in this paper basically cover all\nthe requirements of human resource coordination in modern society and are\nsupported by our experiment results. In the discussion part, we compare our\nmodel with other heuristic algorithms or linear programming methods and prove\nthat the model proposed in this paper makes a 25.7% increase in efficiency and\na 17% increase in accuracy at most. In addition, to the numerical solution of\nthe manpower scheduling problem, this paper also studies the algorithm for\nscheduling task list generation and the method of displaying scheduling\nresults. As a result, we not only provide various modifications for the basic\nalgorithm to solve different condition problems but also propose a new\nalgorithm that increases at least 28.91% in time efficiency by comparing with\ndifferent baseline models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.07224,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000009272,
      "text":"Estimating Heterogeneous Causal Effect of Polysubstance Usage on Drug\n  Overdose from Large-Scale Electronic Health Record\n\n  Drug overdose has become a public health crisis in the United States with\ndevastating consequences. However, most of the drug overdose incidences are the\nconsequence of recitative polysubstance usage over a defined period of time\nwhich can be happened by either the intentional usage of required drug with\nother drugs or by accident. Thus, predicting the effects of polysubstance usage\nis extremely important for clinicians to decide which combination of drugs\nshould be prescribed. Recent advancement of structural causal models can\nprovide ample insights of causal effects from observational data via\nidentifiable causal directed graphs. In this paper, we propose a system to\nestimate heterogeneous concurrent drug usage effects on overdose estimation,\nthat consists of efficient co-variate selection, sub-group selection and\nheterogeneous causal effect estimation. We apply our framework to answer a\ncritical question, can concurrent usage of benzodiazepines and opioids have\nheterogeneous causal effects on the opioid overdose epidemic? Using Truven\nMarketScan claim data collected from 2001 to 2013 have shown significant\npromise of our proposed framework's efficacy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.08692,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000063578,
      "text":"Coach-Player Multi-Agent Reinforcement Learning for Dynamic Team\n  Composition\n\n  In real-world multi-agent systems, agents with different capabilities may\njoin or leave without altering the team's overarching goals. Coordinating teams\nwith such dynamic composition is challenging: the optimal team strategy varies\nwith the composition. We propose COPA, a coach-player framework to tackle this\nproblem. We assume the coach has a global view of the environment and\ncoordinates the players, who only have partial views, by distributing\nindividual strategies. Specifically, we 1) adopt the attention mechanism for\nboth the coach and the players; 2) propose a variational objective to\nregularize learning; and 3) design an adaptive communication method to let the\ncoach decide when to communicate with the players. We validate our methods on a\nresource collection task, a rescue game, and the StarCraft micromanagement\ntasks. We demonstrate zero-shot generalization to new team compositions. Our\nmethod achieves comparable or better performance than the setting where all\nplayers have a full view of the environment. Moreover, we see that the\nperformance remains high even when the coach communicates as little as 13% of\nthe time using the adaptive communication strategy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.11266,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000017219,
      "text":"Argumentative XAI: A Survey\n\n  Explainable AI (XAI) has been investigated for decades and, together with AI\nitself, has witnessed unprecedented growth in recent years. Among various\napproaches to XAI, argumentative models have been advocated in both the AI and\nsocial science literature, as their dialectical nature appears to match some\nbasic desirable features of the explanation activity. In this survey we\noverview XAI approaches built using methods from the field of computational\nargumentation, leveraging its wide array of reasoning abstractions and\nexplanation delivery methods. We overview the literature focusing on different\ntypes of explanation (intrinsic and post-hoc), different models with which\nargumentation-based explanations are deployed, different forms of delivery, and\ndifferent argumentation frameworks they use. We also lay out a roadmap for\nfuture work.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.04595,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000022848,
      "text":"A Deep Dive into Conflict Generating Decisions\n\n  Boolean Satisfiability (SAT) is a well-known NP-complete problem. Despite\nthis theoretical hardness, SAT solvers based on Conflict Driven Clause Learning\n(CDCL) can solve large SAT instances from many important domains. CDCL learns\nclauses from conflicts, a technique that allows a solver to prune its search\nspace. The selection heuristics in CDCL prioritize variables that are involved\nin recent conflicts. While only a fraction of decisions generate any conflicts,\nmany generate multiple conflicts.\n  In this paper, we study conflict-generating decisions in CDCL in detail. We\ninvestigate the impact of single conflict (sc) decisions, which generate only\none conflict, and multi-conflict (mc) decisions which generate two or more. We\nempirically characterize these two types of decisions based on the quality of\nthe learned clauses produced by each type of decision. We also show an\nimportant connection between consecutive clauses learned within the same mc\ndecision, where one learned clause triggers the learning of the next one\nforming a chain of clauses. This leads to the consideration of similarity\nbetween conflicts, for which we formulate the notion of conflictsproximity as a\nsimilarity measure. We show that conflicts in mc decisions are more closely\nrelated than consecutive conflicts generated from sc decisions. Finally, we\ndevelop Common Reason Variable Reduction (CRVR) as a new decision strategy that\nreduces the selection priority of some variables from the learned clauses of mc\ndecisions. Our empirical evaluation of CRVR implemented in three leading\nsolvers demonstrates performance gains in benchmarks from the main track of SAT\nCompetition-2020.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.137,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000307295,
      "text":"Fair and Adventurous Enumeration of Quantifier Instantiations\n\n  SMT solvers generally tackle quantifiers by instantiating their variables\nwith tuples of terms from the ground part of the formula. Recent enumerative\napproaches for quantifier instantiation consider tuples of terms in some\nheuristic order. This paper studies different strategies to order such tuples\nand their impact on performance. We decouple the ordering problem into two\nparts. First is the order of the sequence of terms to consider for each\nquantified variable, and second is the order of the instantiation tuples\nthemselves. While the most and least preferred tuples, i.e. those with all\nvariables assigned to the most or least preferred terms, are clear, the\ncombinations in between allow flexibility in an implementation. We look at\nprincipled strategies of complete enumeration, where some strategies are more\nfair, meaning they treat all the variables the same but some strategies may be\nmore adventurous, meaning that they may venture further down the preference\nlist. We further describe new techniques for discarding irrelevant\ninstantiations which are crucial for the performance of these strategies in\npractice. These strategies are implemented in the SMT solver cvc5, where they\ncontribute to the diversification of the solver's configuration space, as shown\nby our experimental results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.05395,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"Bayesian Model Averaging for Data Driven Decision Making when Causality\n  is Partially Known\n\n  Probabilistic machine learning models are often insufficient to help with\ndecisions on interventions because those models find correlations - not causal\nrelationships. If observational data is only available and experimentation are\ninfeasible, the correct approach to study the impact of an intervention is to\ninvoke Pearl's causality framework. Even that framework assumes that the\nunderlying causal graph is known, which is seldom the case in practice. When\nthe causal structure is not known, one may use out-of-the-box algorithms to\nfind causal dependencies from observational data. However, there exists no\nmethod that also accounts for the decision-maker's prior knowledge when\ndeveloping the causal structure either. The objective of this paper is to\ndevelop rational approaches for making decisions from observational data in the\npresence of causal graph uncertainty and prior knowledge from the\ndecision-maker. We use ensemble methods like Bayesian Model Averaging (BMA) to\ninfer set of causal graphs that can represent the data generation process. We\nprovide decisions by computing the expected value and risk of potential\ninterventions explicitly. We demonstrate our approach by applying them in\ndifferent example contexts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.00525,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Planning for Proactive Assistance in Environments with Partial\n  Observability\n\n  This paper addresses the problem of synthesizing the behavior of an AI agent\nthat provides proactive task assistance to a human in settings like factory\nfloors where they may coexist in a common environment. Unlike in the case of\nrequested assistance, the human may not be expecting proactive assistance and\nhence it is crucial for the agent to ensure that the human is aware of how the\nassistance affects her task. This becomes harder when there is a possibility\nthat the human may neither have full knowledge of the AI agent's capabilities\nnor have full observability of its activities. Therefore, our \\textit{proactive\nassistant} is guided by the following three principles: \\textbf{(1)} its\nactivity decreases the human's cost towards her goal; \\textbf{(2)} the human is\nable to recognize the potential reduction in her cost; \\textbf{(3)} its\nactivity optimizes the human's overall cost (time\/resources) of achieving her\ngoal. Through empirical evaluation and user studies, we demonstrate the\nusefulness of our approach.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.08867,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.000003212,
      "text":"AI and Ethics -- Operationalising Responsible AI\n\n  In the last few years, AI continues demonstrating its positive impact on\nsociety while sometimes with ethically questionable consequences. Building and\nmaintaining public trust in AI has been identified as the key to successful and\nsustainable innovation. This chapter discusses the challenges related to\noperationalizing ethical AI principles and presents an integrated view that\ncovers high-level ethical AI principles, the general notion of\ntrust\/trustworthiness, and product\/process support in the context of\nresponsible AI, which helps improve both trust and trustworthiness of AI for a\nwider set of stakeholders.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.11864,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000070863,
      "text":"Predicting Human Card Selection in Magic: The Gathering with Contextual\n  Preference Ranking\n\n  Drafting, i.e., the selection of a subset of items from a larger candidate\nset, is a key element of many games and related problems. It encompasses team\nformation in sports or e-sports, as well as deck selection in many modern card\ngames. The key difficulty of drafting is that it is typically not sufficient to\nsimply evaluate each item in a vacuum and to select the best items. The\nevaluation of an item depends on the context of the set of items that were\nalready selected earlier, as the value of a set is not just the sum of the\nvalues of its members - it must include a notion of how well items go together.\n  In this paper, we study drafting in the context of the card game Magic: The\nGathering. We propose the use of a contextual preference network, which learns\nto compare two possible extensions of a given deck of cards. We demonstrate\nthat the resulting network is better able to evaluate card decks in this game\nthan previous attempts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.07952,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000418557,
      "text":"MMGET: A Markov model for generalized evidence theory\n\n  In real life, lots of information merges from time to time. To appropriately\ndescribe the actual situations, lots of theories have been proposed. Among\nthem, Dempster-Shafer evidence theory is a very useful tool in managing\nuncertain information. To better adapt to complex situations of open world, a\ngeneralized evidence theory is designed. However, everything occurs in sequence\nand owns some underlying relationships with each other. In order to further\nembody the details of information and better conforms to situations of real\nworld, a Markov model is introduced into the generalized evidence theory which\nhelps extract complete information volume from evidence provided. Besides, some\nnumerical examples is offered to verify the correctness and rationality of the\nproposed method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.12846,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000033445,
      "text":"General Game Heuristic Prediction Based on Ludeme Descriptions\n\n  This paper investigates the performance of different general-game-playing\nheuristics for games in the Ludii general game system. Based on these results,\nwe train several regression learning models to predict the performance of these\nheuristics based on each game's description file. We also provide a condensed\nanalysis of the games available in Ludii, and the different ludemes that define\nthem.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.04088,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000255969,
      "text":"PEARL: Parallelized Expert-Assisted Reinforcement Learning for Scene\n  Rearrangement Planning\n\n  Scene Rearrangement Planning (SRP) is an interior task proposed recently. The\nprevious work defines the action space of this task with handcrafted\ncoarse-grained actions that are inflexible to be used for transforming scene\narrangement and intractable to be deployed in practice. Additionally, this new\ntask lacks realistic indoor scene rearrangement data to feed popular\ndata-hungry learning approaches and meet the needs of quantitative evaluation.\nTo address these problems, we propose a fine-grained action definition for SRP\nand introduce a large-scale scene rearrangement dataset. We also propose a\nnovel learning paradigm to efficiently train an agent through self-playing,\nwithout any prior knowledge. The agent trained via our paradigm achieves\nsuperior performance on the introduced dataset compared to the baseline agents.\nWe provide a detailed analysis of the design of our approach in our\nexperiments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.00648,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000062585,
      "text":"A novel hybrid methodology of measuring sentence similarity\n\n  The problem of measuring sentence similarity is an essential issue in the\nnatural language processing (NLP) area. It is necessary to measure the\nsimilarity between sentences accurately. There are many approaches to measuring\nsentence similarity. Deep learning methodology shows a state-of-the-art\nperformance in many natural language processing fields and is used a lot in\nsentence similarity measurement methods. However, in the natural language\nprocessing field, considering the structure of the sentence or the word\nstructure that makes up the sentence is also important. In this study, we\npropose a methodology combined with both deep learning methodology and a method\nconsidering lexical relationships. Our evaluation metric is the Pearson\ncorrelation coefficient and Spearman correlation coefficient. As a result, the\nproposed method outperforms the current approaches on a KorSTS standard\nbenchmark Korean dataset. Moreover, it performs a maximum of 65% increase than\nonly using deep learning methodology. Experiments show that our proposed method\ngenerally results in better performance than those with only a deep learning\nmodel.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.09914,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000049339,
      "text":"CREAD: Combined Resolution of Ellipses and Anaphora in Dialogues\n\n  Anaphora and ellipses are two common phenomena in dialogues. Without\nresolving referring expressions and information omission, dialogue systems may\nfail to generate consistent and coherent responses. Traditionally, anaphora is\nresolved by coreference resolution and ellipses by query rewrite. In this work,\nwe propose a novel joint learning framework of modeling coreference resolution\nand query rewriting for complex, multi-turn dialogue understanding. Given an\nongoing dialogue between a user and a dialogue assistant, for the user query,\nour joint learning model first predicts coreference links between the query and\nthe dialogue context, and then generates a self-contained rewritten user query.\nTo evaluate our model, we annotate a dialogue based coreference resolution\ndataset, MuDoCo, with rewritten queries. Results show that the performance of\nquery rewrite can be substantially boosted (+2.3% F1) with the aid of\ncoreference modeling. Furthermore, our joint model outperforms the\nstate-of-the-art coreference resolution model (+2% F1) on this dataset.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.14149,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000012252,
      "text":"Log2NS: Enhancing Deep Learning Based Analysis of Logs With Formal to\n  Prevent Survivorship Bias\n\n  Analysis of large observational data sets generated by a reactive system is a\ncommon challenge in debugging system failures and determining their root cause.\nOne of the major problems is that these observational data suffer from\nsurvivorship bias. Examples include analyzing traffic logs from networks, and\nsimulation logs from circuit design. In such applications, users want to detect\nnon-spurious correlations from observational data and obtain actionable\ninsights about them. In this paper, we introduce log to Neuro-symbolic\n(Log2NS), a framework that combines probabilistic analysis from machine\nlearning (ML) techniques on observational data with certainties derived from\nsymbolic reasoning on an underlying formal model. We apply the proposed\nframework to network traffic debugging by employing the following steps. To\ndetect patterns in network logs, we first generate global embedding vector\nrepresentations of entities such as IP addresses, ports, and applications.\nNext, we represent large log flow entries as clusters that make it easier for\nthe user to visualize and detect interesting scenarios that will be further\nanalyzed. To generalize these patterns, Log2NS provides an ability to query\nfrom static logs and correlation engines for positive instances, as well as\nformal reasoning for negative and unseen instances. By combining the strengths\nof deep learning and symbolic methods, Log2NS provides a very powerful\nreasoning and debugging tool for log-based data. Empirical evaluations on a\nreal internal data set demonstrate the capabilities of Log2NS.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.0412,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000023842,
      "text":"Fast constraint satisfaction problem and learning-based algorithm for\n  solving Minesweeper\n\n  Minesweeper is a popular spatial-based decision-making game that works with\nincomplete information. As an exemplary NP-complete problem, it is a major area\nof research employing various artificial intelligence paradigms. The present\nwork models this game as Constraint Satisfaction Problem (CSP) and Markov\nDecision Process (MDP). We propose a new method named as dependents from the\nindependent set using deterministic solution search (DSScsp) for the faster\nenumeration of all solutions of a CSP based Minesweeper game and improve the\nresults by introducing heuristics. Using MDP, we implement machine learning\nmethods on these heuristics. We train the classification model on sparse data\nwith results from CSP formulation. We also propose a new rewarding method for\napplying a modified deep Q-learning for better accuracy and versatile learning\nin the Minesweeper game. The overall results have been analyzed for different\nkinds of Minesweeper games and their accuracies have been recorded. Results\nfrom these experiments show that the proposed method of MDP based\nclassification model and deep Q-learning overall is the best methods in terms\nof accuracy for games with given mine densities.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.12205,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000016888,
      "text":"A New Score for Adaptive Tests in Bayesian and Credal Networks\n\n  A test is adaptive when its sequence and number of questions is dynamically\ntuned on the basis of the estimated skills of the taker. Graphical models, such\nas Bayesian networks, are used for adaptive tests as they allow to model the\nuncertainty about the questions and the skills in an explainable fashion,\nespecially when coping with multiple skills. A better elicitation of the\nuncertainty in the question\/skills relations can be achieved by interval\nprobabilities. This turns the model into a credal network, thus making more\nchallenging the inferential complexity of the queries required to select\nquestions. This is especially the case for the information theoretic quantities\nused as scores to drive the adaptive mechanism. We present an alternative\nfamily of scores, based on the mode of the posterior probabilities, and hence\neasier to explain. This makes considerably simpler the evaluation in the credal\ncase, without significantly affecting the quality of the adaptive process.\nNumerical tests on synthetic and real-world data are used to support this\nclaim.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.07382,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000024504,
      "text":"Uncertainty Measurement of Basic Probability Assignment Integrity Based\n  on Approximate Entropy in Evidence Theory\n\n  Evidence theory is that the extension of probability can better deal with\nunknowns and inaccurate information. Uncertainty measurement plays a vital role\nin both evidence theory and probability theory. Approximate Entropy (ApEn) is\nproposed by Pincus to describe the irregularities of complex systems. The more\nirregular the time series, the greater the approximate entropy. The ApEn of the\nnetwork represents the ability of a network to generate new nodes, or the\npossibility of undiscovered nodes. Through the association of network\ncharacteristics and basic probability assignment (BPA) , a measure of the\nuncertainty of BPA regarding completeness can be obtained. The main\ncontribution of paper is to define the integrity of the basic probability\nassignment then the approximate entropy of the BPA is proposed to measure the\nuncertainty of the integrity of the BPA. The proposed method is based on the\nlogical network structure to calculate the uncertainty of BPA in evidence\ntheory. The uncertainty based on the proposed method represents the uncertainty\nof integrity of BPA and contributes to the identification of the credibility of\nBPA.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2105.10095,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000102652,
      "text":"Variational Gaussian Topic Model with Invertible Neural Projections\n\n  Neural topic models have triggered a surge of interest in extracting topics\nfrom text automatically since they avoid the sophisticated derivations in\nconventional topic models. However, scarce neural topic models incorporate the\nword relatedness information captured in word embedding into the modeling\nprocess. To address this issue, we propose a novel topic modeling approach,\ncalled Variational Gaussian Topic Model (VaGTM). Based on the variational\nauto-encoder, the proposed VaGTM models each topic with a multivariate Gaussian\nin decoder to incorporate word relatedness. Furthermore, to address the\nlimitation that pre-trained word embeddings of topic-associated words do not\nfollow a multivariate Gaussian, Variational Gaussian Topic Model with\nInvertible neural Projections (VaGTM-IP) is extended from VaGTM. Three\nbenchmark text corpora are used in experiments to verify the effectiveness of\nVaGTM and VaGTM-IP. The experimental results show that VaGTM and VaGTM-IP\noutperform several competitive baselines and obtain more coherent topics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.01786,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000030796,
      "text":"What Happened Next? Using Deep Learning to Value Defensive Actions in\n  Football Event-Data\n\n  Objectively quantifying the value of player actions in football (soccer) is a\nchallenging problem. To date, studies in football analytics have mainly focused\non the attacking side of the game, while there has been less work on\nevent-driven metrics for valuing defensive actions (e.g., tackles and\ninterceptions). Therefore in this paper, we use deep learning techniques to\ndefine a novel metric that values such defensive actions by studying the threat\nof passages of play that preceded them. By doing so, we are able to value\ndefensive actions based on what they prevented from happening in the game. Our\nDefensive Action Expected Threat (DAxT) model has been validated using\nreal-world event-data from the 2017\/2018 and 2018\/2019 English Premier League\nseasons, and we combine our model outputs with additional features to derive an\noverall rating of defensive ability for players. Overall, we find that our\nmodel is able to predict the impact of defensive actions allowing us to better\nvalue defenders using event-data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.04866,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000019206,
      "text":"Planning for Novelty: Width-Based Algorithms for Common Problems in\n  Control, Planning and Reinforcement Learning\n\n  Width-based algorithms search for solutions through a general definition of\nstate novelty. These algorithms have been shown to result in state-of-the-art\nperformance in classical planning, and have been successfully applied to\nmodel-based and model-free settings where the dynamics of the problem are given\nthrough simulation engines. Width-based algorithms performance is understood\ntheoretically through the notion of planning width, providing polynomial\nguarantees on their runtime and memory consumption. To facilitate synergies\nacross research communities, this paper summarizes the area of width-based\nplanning, and surveys current and future research directions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.11397,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000006623,
      "text":"Evaluating Team Skill Aggregation in Online Competitive Games\n\n  One of the main goals of online competitive games is increasing player\nengagement by ensuring fair matches. These games use rating systems for\ncreating balanced match-ups. Rating systems leverage statistical estimation to\nrate players' skills and use skill ratings to predict rank before matching\nplayers. Skill ratings of individual players can be aggregated to compute the\nskill level of a team. While research often aims to improve the accuracy of\nskill estimation and fairness of match-ups, less attention has been given to\nhow the skill level of a team is calculated from the skill level of its\nmembers. In this paper, we propose two new aggregation methods and compare them\nwith a standard approach extensively used in the research literature. We\npresent an exhaustive analysis of the impact of these methods on the predictive\nperformance of rating systems. We perform our experiments using three popular\nrating systems, Elo, Glicko, and TrueSkill, on three real-world datasets\nincluding over 100,000 battle royale and head-to-head matches. Our evaluations\nshow the superiority of the MAX method over the other two methods in the\nmajority of the tested cases, implying that the overall performance of a team\nis best determined by the performance of its most skilled member. The results\nof this study highlight the necessity of devising more elaborated methods for\ncalculating a team's performance -- methods covering different aspects of\nplayers' behavior such as skills, strategy, or goals.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.12151,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000008941,
      "text":"Width-based Lookaheads with Learnt Base Policies and Heuristics Over the\n  Atari-2600 Benchmark\n\n  We propose new width-based planning and learning algorithms inspired from a\ncareful analysis of the design decisions made by previous width-based planners.\nThe algorithms are applied over the Atari-2600 games and our best performing\nalgorithm, Novelty guided Critical Path Learning (N-CPL), outperforms the\npreviously introduced width-based planning and learning algorithms $\\pi$-IW(1),\n$\\pi$-IW(1)+ and $\\pi$-HIW(n, 1). Furthermore, we present a taxonomy of the\nAtari-2600 games according to some of their defining characteristics. This\nanalysis of the games provides further insight into the behaviour and\nperformance of the algorithms introduced. Namely, for games with large\nbranching factors, and games with sparse meaningful rewards, N-CPL outperforms\n$\\pi$-IW, $\\pi$-IW(1)+ and $\\pi$-HIW(n, 1).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.152,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Action Set Based Policy Optimization for Safe Power Grid Management\n\n  Maintaining the stability of the modern power grid is becoming increasingly\ndifficult due to fluctuating power consumption, unstable power supply coming\nfrom renewable energies, and unpredictable accidents such as man-made and\nnatural disasters. As the operation on the power grid must consider its impact\non future stability, reinforcement learning (RL) has been employed to provide\nsequential decision-making in power grid management. However, existing methods\nhave not considered the environmental constraints. As a result, the learned\npolicy has risk of selecting actions that violate the constraints in\nemergencies, which will escalate the issue of overloaded power lines and lead\nto large-scale blackouts. In this work, we propose a novel method for this\nproblem, which builds on top of the search-based planning algorithm. At the\nplanning stage, the search space is limited to the action set produced by the\npolicy. The selected action strictly follows the constraints by testing its\noutcome with the simulation function provided by the system. At the learning\nstage, to address the problem that gradients cannot be propagated to the\npolicy, we introduce Evolutionary Strategies (ES) with black-box policy\noptimization to improve the policy directly, maximizing the returns of the long\nrun. In NeurIPS 2020 Learning to Run Power Network (L2RPN) competition, our\nsolution safely managed the power grid and ranked first in both tracks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.02578,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000004636,
      "text":"Alexa, Google, Siri: What are Your Pronouns? Gender and Anthropomorphism\n  in the Design and Perception of Conversational Assistants\n\n  Technology companies have produced varied responses to concerns about the\neffects of the design of their conversational AI systems. Some have claimed\nthat their voice assistants are in fact not gendered or human-like -- despite\ndesign features suggesting the contrary. We compare these claims to user\nperceptions by analysing the pronouns they use when referring to AI assistants.\nWe also examine systems' responses and the extent to which they generate output\nwhich is gendered and anthropomorphic. We find that, while some companies\nappear to be addressing the ethical concerns raised, in some cases, their\nclaims do not seem to hold true. In particular, our results show that system\noutputs are ambiguous as to the humanness of the systems, and that users tend\nto personify and gender them as a result.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.07288,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000049008,
      "text":"Learning-Aided Heuristics Design for Storage System\n\n  Computer systems such as storage systems normally require transparent\nwhite-box algorithms that are interpretable for human experts. In this work, we\npropose a learning-aided heuristic design method, which automatically generates\nhuman-readable strategies from Deep Reinforcement Learning (DRL) agents. This\nmethod benefits from the power of deep learning but avoids the shortcoming of\nits black-box property. Besides the white-box advantage, experiments in our\nstorage productions resource allocation scenario also show that this solution\noutperforms the systems default settings and the elaborately handcrafted\nstrategy by human experts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.09013,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000070863,
      "text":"An Intelligent Question Answering System based on Power Knowledge Graph\n\n  The intelligent question answering (IQA) system can accurately capture users'\nsearch intention by understanding the natural language questions, searching\nrelevant content efficiently from a massive knowledge-base, and returning the\nanswer directly to the user. Since the IQA system can save inestimable time and\nworkforce in data search and reasoning, it has received more and more attention\nin data science and artificial intelligence. This article introduced a domain\nknowledge graph using the graph database and graph computing technologies from\nmassive heterogeneous data in electric power. It then proposed an IQA system\nbased on the electrical power knowledge graph to extract the intent and\nconstraints of natural interrogation based on the natural language processing\n(NLP) method, to construct graph data query statements via knowledge reasoning,\nand to complete the accurate knowledge search and analysis to provide users\nwith an intuitive visualization. This method thoroughly combined knowledge\ngraph and graph computing characteristics, realized high-speed multi-hop\nknowledge correlation reasoning analysis in tremendous knowledge. The proposed\nwork can also provide a basis for the context-aware intelligent question and\nanswer.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.08732,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000067883,
      "text":"AMA-GCN: Adaptive Multi-layer Aggregation Graph Convolutional Network\n  for Disease Prediction\n\n  Recently, Graph Convolutional Networks (GCNs) have proven to be a powerful\nmean for Computer Aided Diagnosis (CADx). This approach requires building a\npopulation graph to aggregate structural information, where the graph adjacency\nmatrix represents the relationship between nodes. Until now, this adjacency\nmatrix is usually defined manually based on phenotypic information. In this\npaper, we propose an encoder that automatically selects the appropriate\nphenotypic measures according to their spatial distribution, and uses the text\nsimilarity awareness mechanism to calculate the edge weights between nodes. The\nencoder can automatically construct the population graph using phenotypic\nmeasures which have a positive impact on the final results, and further\nrealizes the fusion of multimodal information. In addition, a novel graph\nconvolution network architecture using multi-layer aggregation mechanism is\nproposed. The structure can obtain deep structure information while suppressing\nover-smooth, and increase the similarity between the same type of nodes.\nExperimental results on two databases show that our method can significantly\nimprove the diagnostic accuracy for Autism spectrum disorder and breast cancer,\nindicating its universality in leveraging multimodal data for disease\nprediction.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.00258,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000010265,
      "text":"Divide and Rule: Recurrent Partitioned Network for Dynamic Processes\n\n  In general, many dynamic processes are involved with interacting variables,\nfrom physical systems to sociological analysis. The interplay of components in\nthe system can give rise to confounding dynamic behavior. Many approaches model\ntemporal sequences holistically ignoring the internal interaction which are\nimpotent in capturing the protogenic actuation. Differently, our goal is to\nrepresent a system with a part-whole hierarchy and discover the implied\ndependencies among intra-system variables: inferring the interactions that\npossess causal effects on the sub-system behavior with REcurrent partItioned\nNetwork (REIN). The proposed architecture consists of (i) a perceptive module\nthat extracts a hierarchical and temporally consistent representation of the\nobservation at multiple levels, (ii) a deductive module for determining the\nrelational connection between neurons at each level, and (iii) a statistical\nmodule that can predict the future by conditioning on the temporal\ndistributional estimation. Our model is demonstrated to be effective in\nidentifying the componential interactions with limited observation and stable\nin long-term future predictions experimented with diverse physical systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.09258,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000008941,
      "text":"Knowledge Graphs and Machine Learning in biased C4I applications\n\n  This paper introduces our position on the critical issue of bias that\nrecently appeared in AI applications. Specifically, we discuss the combination\nof current technologies used in AI applications i.e., Machine Learning and\nKnowledge Graphs, and point to their involvement in (de)biased applications of\nthe C4I domain. Although this is a wider problem that currently emerges from\ndifferent application domains, bias appears more critical in C4I than in others\ndue to its security-related nature. While proposing certain actions to be taken\ntowards debiasing C4I applications, we acknowledge the immature aspect of this\ntopic within the Knowledge Graph and Semantic Web communities.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.12831,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000028809,
      "text":"Extraction of common conceptual components from multiple ontologies\n\n  Understanding large ontologies is still an issue, and has an impact on many\nontology engineering tasks. We describe a novel method for identifying and\nextracting conceptual components from domain ontologies, which are used to\nunderstand and compare them. The method is applied to two corpora of ontologies\nin the Cultural Heritage and Conference domain, respectively. The results,\nwhich show good quality, are evaluated by manual inspection and by correlation\nwith datasets and tool performance from the ontology alignment evaluation\ninitiative.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.07854,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000034107,
      "text":"Population-coding and Dynamic-neurons improved Spiking Actor Network for\n  Reinforcement Learning\n\n  With the Deep Neural Networks (DNNs) as a powerful function approximator,\nDeep Reinforcement Learning (DRL) has been excellently demonstrated on robotic\ncontrol tasks. Compared to DNNs with vanilla artificial neurons, the\nbiologically plausible Spiking Neural Network (SNN) contains a diverse\npopulation of spiking neurons, making it naturally powerful on state\nrepresentation with spatial and temporal information. Based on a hybrid\nlearning framework, where a spike actor-network infers actions from states and\na deep critic network evaluates the actor, we propose a Population-coding and\nDynamic-neurons improved Spiking Actor Network (PDSAN) for efficient state\nrepresentation from two different scales: input coding and neuronal coding. For\ninput coding, we apply population coding with dynamically receptive fields to\ndirectly encode each input state component. For neuronal coding, we propose\ndifferent types of dynamic-neurons (containing 1st-order and 2nd-order neuronal\ndynamics) to describe much more complex neuronal dynamics. Finally, the PDSAN\nis trained in conjunction with deep critic networks using the Twin Delayed Deep\nDeterministic policy gradient algorithm (TD3-PDSAN). Extensive experimental\nresults show that our TD3-PDSAN model achieves better performance than\nstate-of-the-art models on four OpenAI gym benchmark tasks. It is an important\nattempt to improve RL with SNN towards the effective computation satisfying\nbiological plausibility.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.00266,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000027816,
      "text":"Did I do that? Blame as a means to identify controlled effects in\n  reinforcement learning\n\n  Identifying controllable aspects of the environment has proven to be an\nextraordinary intrinsic motivator to reinforcement learning agents. Despite\nrepeatedly achieving State-of-the-Art results, this approach has only been\nstudied as a proxy to a reward-based task and has not yet been evaluated on its\nown. Current methods are based on action-prediction. Humans, on the other hand,\nassign blame to their actions to decide what they controlled. This work\nproposes Controlled Effect Network (CEN), an unsupervised method based on\ncounterfactual measures of blame to identify effects on the environment\ncontrolled by the agent. CEN is evaluated in a wide range of environments\nshowing that it can accurately identify controlled effects. Moreover, we\ndemonstrate CEN's capabilities as intrinsic motivator by integrating it in the\nstate-of-the-art exploration method, achieving substantially better performance\nthan action-prediction models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.07114,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000009603,
      "text":"Intelligent Agent for Hurricane Emergency Identification and Text\n  Information Extraction from Streaming Social Media Big Data\n\n  This paper presents our research on leveraging social media Big Data and AI\nto support hurricane disaster emergency response. The current practice of\nhurricane emergency response for rescue highly relies on emergency call\ncentres. The more recent Hurricane Harvey event reveals the limitations of the\ncurrent systems. We use Hurricane Harvey and the associated Houston flooding as\nthe motivating scenario to conduct research and develop a prototype as a\nproof-of-concept of using an intelligent agent as a complementary role to\nsupport emergency centres in hurricane emergency response. This intelligent\nagent is used to collect real-time streaming tweets during a natural disaster\nevent, to identify tweets requesting rescue, to extract key information such as\naddress and associated geocode, and to visualize the extracted information in\nan interactive map in decision supports. Our experiment shows promising\noutcomes and the potential application of the research in support of hurricane\nemergency response.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.06931,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000013245,
      "text":"Learning on Abstract Domains: A New Approach for Verifiable Guarantee in\n  Reinforcement Learning\n\n  Formally verifying Deep Reinforcement Learning (DRL) systems is a challenging\ntask due to the dynamic continuity of system behaviors and the black-box\nfeature of embedded neural networks. In this paper, we propose a novel\nabstraction-based approach to train DRL systems on finite abstract domains\ninstead of concrete system states. It yields neural networks whose input states\nare finite, making hosting DRL systems directly verifiable using model checking\ntechniques. Our approach is orthogonal to existing DRL algorithms and\noff-the-shelf model checkers. We implement a resulting prototype training and\nverification framework and conduct extensive experiments on the\nstate-of-the-art benchmark. The results show that the systems trained in our\napproach can be verified more efficiently while they retain comparable\nperformance against those that are trained without abstraction.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.07921,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000063578,
      "text":"Diagnosing the Impact of AI on Radiology in China\n\n  Artificial Intelligence will significantly impact the work environment of\nradiologists. I suggest that up to 50% of a radiologists work in 2021 will be\nperformed by AI-models in 2025. However, it won't increase beyond that 50%\nlevel, as radiologists remain key for human-centered aspects of their job. I\nproject that few to no radiologists will be laid off in China due to the\nexisting supply shortage of radiology services in 2021. The application of AI\nin radiology could contribute 1.7 billion USD to China's GDP in 2025. It will\nfurther allow radiologists to start productive work up to four years earlier.\nAI in radiology will positively impact the health of patients and radiologists\nthemselves.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.07211,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.000001457,
      "text":"Differentiable Neural Architecture Search with Morphism-based\n  Transformable Backbone Architectures\n\n  This study aims at making the architecture search process more adaptive for\none-shot or online training. It is extended from the existing study on\ndifferentiable neural architecture search, and we made the backbone\narchitecture transformable rather than fixed during the training process. As is\nknown, differentiable neural architecture search (DARTS) requires a pre-defined\nover-parameterized backbone architecture, while its size is to be determined\nmanually. Also, in DARTS backbone, Hadamard product of two elements is not\nintroduced, which exists in both LSTM and GRU cells for recurrent nets. This\nstudy introduces a growing mechanism for differentiable neural architecture\nsearch based on network morphism. It enables growing of the cell structures\nfrom small size towards large size ones with one-shot training. Two modes can\nbe applied in integrating the growing and original pruning process. We also\nimplement a recently proposed two-input backbone architecture for recurrent\nneural networks. Initial experimental results indicate that our approach and\nthe two-input backbone structure can be quite effective compared with other\nbaseline architectures including LSTM, in a variety of learning tasks including\nmulti-variate time series forecasting and language modeling. On the other hand,\nwe find that dynamic network transformation is promising in improving the\nefficiency of differentiable architecture search.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.00327,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000044703,
      "text":"Search from History and Reason for Future: Two-stage Reasoning on\n  Temporal Knowledge Graphs\n\n  Temporal Knowledge Graphs (TKGs) have been developed and used in many\ndifferent areas. Reasoning on TKGs that predicts potential facts (events) in\nthe future brings great challenges to existing models. When facing a prediction\ntask, human beings usually search useful historical information (i.e., clues)\nin their memories and then reason for future meticulously. Inspired by this\nmechanism, we propose CluSTeR to predict future facts in a two-stage manner,\nClue Searching and Temporal Reasoning, accordingly. Specifically, at the clue\nsearching stage, CluSTeR learns a beam search policy via reinforcement learning\n(RL) to induce multiple clues from historical facts. At the temporal reasoning\nstage, it adopts a graph convolution network based sequence method to deduce\nanswers from clues. Experiments on four datasets demonstrate the substantial\nadvantages of CluSTeR compared with the state-of-the-art methods. Moreover, the\nclues found by CluSTeR further provide interpretability for the results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2106.14431,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"Modelling Monotonic and Non-Monotonic Attribute Dependencies with\n  Embeddings: A Theoretical Analysis\n\n  During the last decade, entity embeddings have become ubiquitous in\nArtificial Intelligence. Such embeddings essentially serve as compact but\nsemantically meaningful representations of the entities of interest. In most\napproaches, vectors are used for representing the entities themselves, as well\nas for representing their associated attributes. An important advantage of\nusing attribute embeddings is that (some of the) semantic dependencies between\nthe attributes can thus be captured. However, little is known about what kinds\nof semantic dependencies can be modelled in this way. The aim of this paper is\nto shed light on this question, focusing on settings where the embedding of an\nentity is obtained by pooling the embeddings of its known attributes. Our\nparticular focus is on studying the theoretical limitations of different\nembedding strategies, rather than their ability to effectively learn attribute\ndependencies in practice. We first show a number of negative results, revealing\nthat some of the most popular embedding models are not able to capture even\nbasic Horn rules. However, we also find that some embedding strategies are\ncapable, in principle, of modelling both monotonic and non-monotonic attribute\ndependencies.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.13435,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000035763,
      "text":"MWP-BERT: Numeracy-Augmented Pre-training for Math Word Problem Solving\n\n  Math word problem (MWP) solving faces a dilemma in number representation\nlearning. In order to avoid the number representation issue and reduce the\nsearch space of feasible solutions, existing works striving for MWP solving\nusually replace real numbers with symbolic placeholders to focus on logic\nreasoning. However, different from common symbolic reasoning tasks like program\nsynthesis and knowledge graph reasoning, MWP solving has extra requirements in\nnumerical reasoning. In other words, instead of the number value itself, it is\nthe reusable numerical property that matters more in numerical reasoning.\nTherefore, we argue that injecting numerical properties into symbolic\nplaceholders with contextualized representation learning schema can provide a\nway out of the dilemma in the number representation issue here. In this work,\nwe introduce this idea to the popular pre-training language model (PLM)\ntechniques and build MWP-BERT, an effective contextual number representation\nPLM. We demonstrate the effectiveness of our MWP-BERT on MWP solving and\nseveral MWP-specific understanding tasks on both English and Chinese\nbenchmarks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.13977,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000530812,
      "text":"Underwater Acoustic Networks for Security Risk Assessment in Public\n  Drinking Water Reservoirs\n\n  We have built a novel system for the surveillance of drinking water\nreservoirs using underwater sensor networks. We implement an innovative\nAI-based approach to detect, classify and localize underwater events. In this\npaper, we describe the technology and cognitive AI architecture of the system\nbased on one of the sensor networks, the hydrophone network. We discuss the\nchallenges of installing and using the hydrophone network in a water reservoir\nwhere traffic, visitors, and variable water conditions create a complex,\nvarying environment. Our AI solution uses an autoencoder for unsupervised\nlearning of latent encodings for classification and anomaly detection, and time\ndelay estimates for sound localization. Finally, we present the results of\nexperiments carried out in a laboratory pool and the water reservoir and\ndiscuss the system's potential.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.02298,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000138084,
      "text":"Knowledge Modelling and Active Learning in Manufacturing\n\n  The increasing digitalization of the manufacturing domain requires adequate\nknowledge modeling to capture relevant information. Ontologies and Knowledge\nGraphs provide means to model and relate a wide range of concepts, problems,\nand configurations. Both can be used to generate new knowledge through\ndeductive inference and identify missing knowledge. While digitalization\nincreases the amount of data available, much data is not labeled and cannot be\ndirectly used to train supervised machine learning models. Active learning can\nbe used to identify the most informative data instances for which to obtain\nusers' feedback, reduce friction, and maximize knowledge acquisition. By\ncombining semantic technologies and active learning, multiple use cases in the\nmanufacturing domain can be addressed taking advantage of the available\nknowledge and data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.1115,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"User Preferences and the Shortest Path\n\n  Indoor navigation systems leverage shortest path algorithms to calculate\nroutes. In order to define the \"shortest path\", a cost function has to be\nspecified based on theories and heuristics in the application domain. For the\ndomain of indoor routing, we survey theories and criteria identified in the\nliterature as essential for human path planning. We drive quantitative\ndefinitions and integrate them into a cost function that weights each of the\ncriteria separately. We then apply an exhaustive grid search to find weights\nthat lead to an ideal cost function. \"Ideal\" here is defined as guiding the\nalgorithm to plan routes that are most similar to those chosen by humans. To\nexplore which criteria should be taken into account in an improved pathfinding\nalgorithm, eleven different factors whose favorable impact on route selection\nhas been established in past research were considered. Each factor was included\nseparately in the Dijkstra algorithm and the similarity of thus calculated\nroutes to the actual routes chosen by students at the University of Regensburg\nwas determined. This allows for a quantitative assessment of the factors'\nimpact and further constitutes a way to directly compare them. A reduction of\nthe number of turns, streets, revolving doors, entryways, elevators as well as\nthe combination of the aforementioned factors was found to have a positive\neffect and generate paths that were favored over the shortest path. Turns and\nthe combination of criteria turned out to be most impactful.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.09129,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"Thing Foundational Ontology: ThingFO v1.3's Terms, Properties,\n  Relationships and Axioms\n\n  This preprint specifies and defines all terms, properties, relationships and\naxioms of ThingFO (Thing Foundational Ontology) v1.3, which is a slightly\nupdated version of its predecessor, ThingFO v1.2. It is an ontology for\nparticular and universal Things placed at the foundational level in the context\nof a five-tier ontological architecture named FCD-OntoArch (Foundational, Core,\nDomain and instance Ontological Architecture for sciences). Figure 2 depicts\nits five tiers, which entail Foundational, Core, Top-Domain, Low-Domain and\nInstance levels. Two guidelines and three rules that guide the placement and\nconstraints of ontologies in this ontological architecture are documented in a\nseparate section. Each level is populated with ontological components or, in\nother words, ontologies. Ontologies at the same level can be related to each\nother, except at the foundational level, where only the ThingFO ontology is\nfound. In addition, ontologies' terms and relationships at lower levels can be\nsemantically enriched by ontologies' terms and relationships from the higher\nlevels. ThingFO and ontologies at the core level such as ProcessCO,\nSituationCO, among others, are domain independent or neutral. ThingFO is made\nup of three main concepts, namely: Thing, Thing Category, and Assertion that\nrepresents human expressions about different aspects of particular and\nuniversal Things. Figure 1 shows the conceptualization of ThingFO specified in\nthe UML language. Note that annotations of updates from the previous version\n(v1.2) to the current one (v1.3) can be found in Appendix A.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.13181,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000024835,
      "text":"Packet Routing with Graph Attention Multi-agent Reinforcement Learning\n\n  Packet routing is a fundamental problem in communication networks that\ndecides how the packets are directed from their source nodes to their\ndestination nodes through some intermediate nodes. With the increasing\ncomplexity of network topology and highly dynamic traffic demand, conventional\nmodel-based and rule-based routing schemes show significant limitations, due to\nthe simplified and unrealistic model assumptions, and lack of flexibility and\nadaption. Adding intelligence to the network control is becoming a trend and\nthe key to achieving high-efficiency network operation. In this paper, we\ndevelop a model-free and data-driven routing strategy by leveraging\nreinforcement learning (RL), where routers interact with the network and learn\nfrom the experience to make some good routing configurations for the future.\nConsidering the graph nature of the network topology, we design a multi-agent\nRL framework in combination with Graph Neural Network (GNN), tailored to the\nrouting problem. Three deployment paradigms, centralized, federated, and\ncooperated learning, are explored respectively. Simulation results demonstrate\nthat our algorithm outperforms some existing benchmark algorithms in terms of\npacket transmission delay and affordable load.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.06413,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000032783,
      "text":"Monotonicity and Noise-Tolerance in Case-Based Reasoning with Abstract\n  Argumentation (with Appendix)\n\n  Recently, abstract argumentation-based models of case-based reasoning\n($AA{\\text -} CBR$ in short) have been proposed, originally inspired by the\nlegal domain, but also applicable as classifiers in different scenarios.\nHowever, the formal properties of $AA{\\text -} CBR$ as a reasoning system\nremain largely unexplored. In this paper, we focus on analysing the\nnon-monotonicity properties of a regular version of $AA{\\text -} CBR$ (that we\ncall $AA{\\text -} CBR_{\\succeq}$). Specifically, we prove that $AA{\\text -}\nCBR_{\\succeq}$ is not cautiously monotonic, a property frequently considered\ndesirable in the literature. We then define a variation of $AA{\\text -}\nCBR_{\\succeq}$ which is cautiously monotonic. Further, we prove that such\nvariation is equivalent to using $AA{\\text -} CBR_{\\succeq}$ with a restricted\ncasebase consisting of all \"surprising\" and \"sufficient\" cases in the original\ncasebase. As a by-product, we prove that this variation of $AA{\\text -}\nCBR_{\\succeq}$ is cumulative, rationally monotonic, and empowers a principled\ntreatment of noise in \"incoherent\" casebases. Finally, we illustrate $AA{\\text\n-} CBR$ and cautious monotonicity questions on a case study on the U.S. Trade\nSecrets domain, a legal casebase.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.1213,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000032783,
      "text":"Structural Learning of Probabilistic Sentential Decision Diagrams under\n  Partial Closed-World Assumption\n\n  Probabilistic sentential decision diagrams are a class of\nstructured-decomposable probabilistic circuits especially designed to embed\nlogical constraints. To adapt the classical LearnSPN scheme to learn the\nstructure of these models, we propose a new scheme based on a partial\nclosed-world assumption: data implicitly provide the logical base of the\ncircuit. Sum nodes are thus learned by recursively clustering batches in the\ninitial data base, while the partitioning of the variables obeys a given input\nvtree. Preliminary experiments show that the proposed approach might properly\nfit training data, and generalize well to test data, provided that these remain\nconsistent with the underlying logical base, that is a relaxation of the\ntraining data base.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.1039,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Reinforcement Learning Agent Training with Goals for Real World Tasks\n\n  Reinforcement Learning (RL) is a promising approach for solving various\ncontrol, optimization, and sequential decision making tasks. However, designing\nreward functions for complex tasks (e.g., with multiple objectives and safety\nconstraints) can be challenging for most users and usually requires multiple\nexpensive trials (reward function hacking). In this paper we propose a\nspecification language (Inkling Goal Specification) for complex control and\noptimization tasks, which is very close to natural language and allows a\npractitioner to focus on problem specification instead of reward function\nhacking. The core elements of our framework are: (i) mapping the high level\nlanguage to a predicate temporal logic tailored to control and optimization\ntasks, (ii) a novel automaton-guided dense reward generation that can be used\nto drive RL algorithms, and (iii) a set of performance metrics to assess the\nbehavior of the system. We include a set of experiments showing that the\nproposed method provides great ease of use to specify a wide range of real\nworld tasks; and that the reward generated is able to drive the policy training\nto achieve the specified goal.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.14654,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000026491,
      "text":"Brain-Inspired Deep Imitation Learning for Autonomous Driving Systems\n\n  Autonomous driving has attracted great attention from both academics and\nindustries. To realise autonomous driving, Deep Imitation Learning (DIL) is\ntreated as one of the most promising solutions, because it improves autonomous\ndriving systems by automatically learning a complex mapping from human driving\ndata, compared to manually designing the driving policy. However, existing DIL\nmethods cannot generalise well across domains, that is, a network trained on\nthe data of source domain gives rise to poor generalisation on the data of\ntarget domain. In the present study, we propose a novel brain-inspired deep\nimitation method that builds on the evidence from human brain functions, to\nimprove the generalisation ability of deep neural networks so that autonomous\ndriving systems can perform well in various scenarios. Specifically, humans\nhave a strong generalisation ability which is beneficial from the structural\nand functional asymmetry of the two sides of the brain. Here, we design dual\nNeural Circuit Policy (NCP) architectures in deep neural networks based on the\nasymmetry of human neural networks. Experimental results demonstrate that our\nbrain-inspired method outperforms existing methods regarding generalisation\nwhen dealing with unseen data. Our source codes and pretrained models are\navailable at\nhttps:\/\/github.com\/Intenzo21\/Brain-Inspired-Deep-Imitation-Learning-for-Autonomous-Driving-Systems}{https:\/\/github.com\/Intenzo21\/Brain-Inspired-Deep-Imitation-Learning-for-Autonomous-Driving-Systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.12877,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000001755,
      "text":"Efficient TBox Reasoning with Value Restrictions using the\n  $\\mathcal{FL}_{o}$wer reasoner\n\n  The inexpressive Description Logic (DL) $\\mathcal{FL}_0$, which has\nconjunction and value restriction as its only concept constructors, had fallen\ninto disrepute when it turned out that reasoning in $\\mathcal{FL}_0$ w.r.t.\ngeneral TBoxes is ExpTime-complete, i.e., as hard as in the considerably more\nexpressive logic $\\mathcal{ALC}$. In this paper, we rehabilitate\n$\\mathcal{FL}_0$ by presenting a dedicated subsumption algorithm for\n$\\mathcal{FL}_0$, which is much simpler than the tableau-based algorithms\nemployed by highly optimized DL reasoners. Our experiments show that the\nperformance of our novel algorithm, as prototypically implemented in our\n$\\mathcal{FL}_o$wer reasoner, compares very well with that of the highly\noptimized reasoners. $\\mathcal{FL}_o$wer can also deal with ontologies written\nin the extension $\\mathcal{FL}_{\\bot}$ of $\\mathcal{FL}_0$ with the top and the\nbottom concept by employing a polynomial-time reduction, shown in this paper,\nwhich eliminates top and bottom. We also investigate the complexity of\nreasoning in DLs related to the Horn-fragments of $\\mathcal{FL}_0$ and\n$\\mathcal{FL}_{\\bot}$.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.12178,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000016888,
      "text":"Novel Span Measure, Spanning Sets and Applications\n\n  Rough Set based Spanning Sets were recently proposed to deal with\nuncertainties arising in the problem in domain of natural language processing\nproblems. This paper presents a novel span measure using upper approximations.\nThe key contribution of this paper is to propose another uncertainty measure of\nspan and spanning sets. Firstly, this paper proposes a new definition of\ncomputing span which use upper approximation instead of boundary regions. This\nis useful in situations where computing upper approximations are much more\nconvenient that computing boundary region. Secondly, properties of novel span\nand relation with earlier span measure are discussed. Thirdly, the paper\npresents application areas where the proposed span measure can be utilized.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.01654,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000162588,
      "text":"Efficient Explanations for Knowledge Compilation Languages\n\n  Knowledge compilation (KC) languages find a growing number of practical uses,\nincluding in Constraint Programming (CP) and in Machine Learning (ML). In most\napplications, one natural question is how to explain the decisions made by\nmodels represented by a KC language. This paper shows that for many of the best\nknown KC languages, well-known classes of explanations can be computed in\npolynomial time. These classes include deterministic decomposable negation\nnormal form (d-DNNF), and so any KC language that is strictly less succinct\nthan d-DNNF. Furthermore, the paper also investigates the conditions under\nwhich polynomial time computation of explanations can be extended to KC\nlanguages more succinct than d-DNNF.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.05877,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000031789,
      "text":"GA and ILS for optimizing the size of NFA models\n\n  Grammatical inference consists in learning a formal grammar (as a set of\nrewrite rules or a finite state machine). We are concerned with learning\nNondeterministic Finite Automata (NFA) of a given size from samples of positive\nand negative words. NFA can naturally be modeled in SAT. The standard model [1]\nbeing enormous, we also try a model based on prefixes [2] which generates\nsmaller instances. We also propose a new model based on suffixes and a hybrid\nmodel based on prefixes and suffixes. We then focus on optimizing the size of\ngenerated SAT instances issued from the hybrid models. We present two\ntechniques to optimize this combination, one based on Iterated Local Search\n(ILS), the second one based on Genetic Algorithm (GA). Optimizing the\ncombination significantly reduces the SAT instances and their solving time, but\nat the cost of longer generation time. We, therefore, study the balance between\ngeneration time and solving time thanks to some experimental comparisons, and\nwe analyze our various model improvements.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.09288,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000030465,
      "text":"MIPO: Mutual Integration of Patient Journey and Medical Ontology for\n  Healthcare Representation Learning\n\n  Healthcare representation learning on the Electronic Health Records is\ncrucial for downstream medical prediction tasks in health informatics. Many NLP\ntechniques, such as RNN and self-attention, have been adapted to learn medical\nrepresentations from hierarchical and time-stamped EHRs data, but fail when\nthey lack either general or task-specific data. Hence, some recent works train\nhealthcare representations by incorporating medical ontology, by\nself-supervised tasks like diagnosis prediction, but (1) the small-scale,\nmonotonous ontology is insufficient for robust learning, and (2) critical\ncontexts or dependencies underlying patient journeys are barely exploited to\nenhance ontology learning. To address the challenges, we propose a\nTransformer-based representation learning approach: Mutual Integration of\nPatient journey and medical Ontology (MIPO), which is a robust end-to-end\nframework. Specifically, the proposed method focuses on task-specific\nrepresentation learning by a sequential diagnoses predictive task, which is\nalso beneficial to the ontology-based disease typing task. To integrate\ninformation in the patient's visiting records, we further introduce a\ngraph-embedding module, which can mitigate the challenge of data insufficiency\nin healthcare. In this way, MIPO creates a mutual integration to benefit both\nhealthcare representation learning and medical ontology embedding. Such an\neffective integration is guaranteed by joint training over fused embeddings of\nthe two modules, targeting both task-specific prediction and ontology-based\ndisease typing tasks simultaneously. Extensive experiments conducted on two\nreal-world benchmark datasets have shown MIPO consistently achieves better\nperformance than state-of-the-art methods no matter whether the training data\nis sufficient or not. Also, MIPO derives more interpretable diagnose embedding\nresults compared to its counterparts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.00317,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000015232,
      "text":"Towards Utilitarian Combinatorial Assignment with Deep Neural Networks\n  and Heuristic Algorithms\n\n  This paper presents preliminary work on using deep neural networks to guide\ngeneral-purpose heuristic algorithms for performing utilitarian combinatorial\nassignment. In more detail, we use deep learning in an attempt to produce\nheuristics that can be used together with e.g., search algorithms to generate\nfeasible solutions of higher quality more quickly. Our results indicate that\nour approach could be a promising future method for constructing such\nheuristics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.05346,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000000662,
      "text":"SimDem A Multi-agent Simulation Environment to Model Persons with\n  Dementia and their Assistance\n\n  Developing artificial intelligence based assistive systems to aid Persons\nwith Dementia (PwD) requires large amounts of training data. However, data\ncollection poses ethical, legal, economic, and logistic issues. Synthetic data\ngeneration tools, in this regard, provide a potential solution. However, we\nbelieve that already available such tools do not adequately reflect cognitive\ndeficiencies in behavior simulation. To counter these issues we propose a\nsimulation model (SimDem ) that primarily focuses on cognitive impairments\nsuffered by PwD and can be easily configured and adapted by the users to model\nand evaluate assistive solutions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.05151,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"Document Embedding for Scientific Articles: Efficacy of Word Embeddings\n  vs TFIDF\n\n  Over the last few years, neural network derived word embeddings became\npopular in the natural language processing literature. Studies conducted have\nmostly focused on the quality and application of word embeddings trained on\npublic available corpuses such as Wikipedia or other news and social media\nsources. However, these studies are limited to generic text and thus lack\ntechnical and scientific nuances such as domain specific vocabulary,\nabbreviations, or scientific formulas which are commonly used in academic\ncontext. This research focuses on the performance of word embeddings applied to\na large scale academic corpus. More specifically, we compare quality and\nefficiency of trained word embeddings to TFIDF representations in modeling\ncontent of scientific articles. We use a word2vec skip-gram model trained on\ntitles and abstracts of about 70 million scientific articles. Furthermore, we\nhave developed a benchmark to evaluate content models in a scientific context.\nThe benchmark is based on a categorization task that matches articles to\njournals for about 1.3 million articles published in 2017. Our results show\nthat content models based on word embeddings are better for titles (short text)\nwhile TFIDF works better for abstracts (longer text). However, the slight\nimprovement of TFIDF for larger text comes at the expense of 3.7 times more\nmemory requirement as well as up to 184 times higher computation times which\nmay make it inefficient for online applications. In addition, we have created a\n2-dimensional visualization of the journals modeled via embeddings to\nqualitatively inspect embedding model. This graph shows useful insights and can\nbe used to find competitive journals or gaps to propose new journals.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.04378,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000016226,
      "text":"Rail Topology Ontology: A Rail Infrastructure Base Ontology\n\n  Engineering projects for railway infrastructure typically involve many\nsubsystems which need consistent views of the planned and built infrastructure\nand its underlying topology. Consistency is typically ensured by exchanging and\nverifying data between tools using XML-based data formats and UML-based\nobject-oriented models. A tighter alignment of these data representations via a\ncommon topology model could decrease the development effort of railway\ninfrastructure engineering tools. A common semantic model is also a\nprerequisite for the successful adoption of railway knowledge graphs. Based on\nthe RailTopoModel standard, we developed the Rail Topology Ontology as a model\nto represent core features of railway infrastructures in a standard-compliant\nmanner. This paper describes the ontology and its development method, and\ndiscusses its suitability for integrating data of railway engineering systems\nand other sources in a knowledge graph.\n  With the Rail Topology Ontology, software engineers and knowledge scientists\nhave a standard-based ontology for representing railway topologies to integrate\ndisconnected data sources. We use the Rail Topology Ontology for our rail\nknowledge graph and plan to extend it by rail infrastructure ontologies derived\nfrom existing data exchange standards, since many such standards use the same\nbase model as the presented ontology, viz., RailTopoModel.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2107.13179,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000235438,
      "text":"Conflict Detection in IoT-based Smart Homes\n\n  We propose a novel framework that detects conflicts in IoT-based smart homes.\nConflicts may arise during interactions between the resident and IoT services\nin smart homes. We propose a generic knowledge graph to represent the relations\nbetween IoT services and environment entities. We also profile a generic\nknowledge graph to a specific smart home setting based on the context\ninformation. We propose a conflict taxonomy to capture different types of\nconflicts in a single resident smart home setting. A conflict detection\nalgorithm is proposed to identify potential conflicts using the profiled\nknowledge graph. We conduct a set of experiments on real datasets and\nsynthesized datasets to validate the effectiveness and efficiency of our\nproposed approach.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.02816,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"ProcessCO v1.3's Terms, Properties, Relationships and Axioms - A Core\n  Ontology for Processes\n\n  The present preprint specifies and defines all Terms, Properties,\nRelationships and Axioms of ProcessCO (Process Core Ontology). ProcessCO is an\nontology devoted mainly for Work Entities and related terms, which is placed at\nthe core level in the context of a multilayer ontological architecture called\nFCD-OntoArch (Foundational, Core, and Domain Ontological Architecture for\nSciences). This is a five-layered ontological architecture, which considers\nFoundational, Core, Domain and Instance levels, where the domain level is split\ndown in two sub-levels, namely: Top-domain and Low-domain. Ontologies at the\nsame level can be related to each other, except for the foundational level\nwhere only ThingFO (Thing Foundational Ontology) is found. In addition,\nontologies' terms and relationships at lower levels can be semantically\nenriched by ontologies' terms and relationships from the higher levels. Note\nthat both ThingFO and ontologies at the core level such as ProcessCO,\nSituationCO, among others, are domain independent with respect to their terms.\nStereotypes are the mechanism used for enriching ProcessCO terms mainly from\nthe ThingFO ontology. Note that in the end of this document, we address the\nProcessCO vs. ThingFO non-taxonomic relationship verification matrix.\nAdditionally, note that annotations of updates from the previous version\n(ProcessCO v1.2) to the current one (v1.3) can be found in Appendix A. For\ninstance, 6 axioms were added.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.09443,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"Towards Personalized and Human-in-the-Loop Document Summarization\n\n  The ubiquitous availability of computing devices and the widespread use of\nthe internet have generated a large amount of data continuously. Therefore, the\namount of available information on any given topic is far beyond humans'\nprocessing capacity to properly process, causing what is known as information\noverload. To efficiently cope with large amounts of information and generate\ncontent with significant value to users, we require identifying, merging and\nsummarising information. Data summaries can help gather related information and\ncollect it into a shorter format that enables answering complicated questions,\ngaining new insight and discovering conceptual boundaries.\n  This thesis focuses on three main challenges to alleviate information\noverload using novel summarisation techniques. It further intends to facilitate\nthe analysis of documents to support personalised information extraction. This\nthesis separates the research issues into four areas, covering (i) feature\nengineering in document summarisation, (ii) traditional static and inflexible\nsummaries, (iii) traditional generic summarisation approaches, and (iv) the\nneed for reference summaries. We propose novel approaches to tackle these\nchallenges, by: i)enabling automatic intelligent feature engineering, ii)\nenabling flexible and interactive summarisation, iii) utilising intelligent and\npersonalised summarisation approaches. The experimental results prove the\nefficiency of the proposed approaches compared to other state-of-the-art\nmodels. We further propose solutions to the information overload problem in\ndifferent domains through summarisation, covering network traffic data, health\ndata and business process data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.13063,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000024173,
      "text":"Satisfiability and Containment of Recursive SHACL\n\n  The Shapes Constraint Language (SHACL) is the recent W3C recommendation\nlanguage for validating RDF data, by verifying certain shapes on graphs.\nPrevious work has largely focused on the validation problem and the standard\ndecision problems of satisfiability and containment, crucial for design and\noptimisation purposes, have only been investigated for simplified versions of\nSHACL. Moreover, the SHACL specification does not define the semantics of\nrecursively-defined constraints, which led to several alternative recursive\nsemantics being proposed in the literature. The interaction between these\ndifferent semantics and important decision problems has not been investigated\nyet. In this article we provide a comprehensive study of the different features\nof SHACL, by providing a translation to a new first-order language, called SCL,\nthat precisely captures the semantics of SHACL. We also present MSCL, a\nsecond-order extension of SCL, which allows us to define, in a single formal\nlogic framework, the main recursive semantics of SHACL. Within this language we\nalso provide an effective treatment of filter constraints which are often\nneglected in the related literature. Using this logic we provide a detailed map\nof (un)decidability and complexity results for the satisfiability and\ncontainment decision problems for different SHACL fragments. Notably, we prove\nthat both problems are undecidable for the full language, but we present\ndecidable combinations of interesting features, even in the face of recursion.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.03294,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000028478,
      "text":"A Smart and Defensive Human-Machine Approach to Code Analysis\n\n  Static analysis remains one of the most popular approaches for detecting and\ncorrecting poor or vulnerable program code. It involves the examination of code\nlistings, test results, or other documentation to identify errors, violations\nof development standards, or other problems, with the ultimate goal of fixing\nthese errors so that systems and software are as secure as possible. There\nexists a plethora of static analysis tools, which makes it challenging for\nbusinesses and programmers to select a tool to analyze their program code. It\nis imperative to find ways to improve code analysis so that it can be employed\nby cyber defenders to mitigate security risks. In this research, we propose a\nmethod that employs the use of virtual assistants to work with programmers to\nensure that software are as safe as possible in order to protect\nsafety-critical systems from data breaches and other attacks. The proposed\nmethod employs a recommender system that uses various metrics to help\nprogrammers select the most appropriate code analysis tool for their project\nand guides them through the analysis process. The system further tracks the\nuser's behavior regarding the adoption of the recommended practices.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.11645,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000154641,
      "text":"Robust Model-based Reinforcement Learning for Autonomous Greenhouse\n  Control\n\n  Due to the high efficiency and less weather dependency, autonomous\ngreenhouses provide an ideal solution to meet the increasing demand for fresh\nfood. However, managers are faced with some challenges in finding appropriate\ncontrol strategies for crop growth, since the decision space of the greenhouse\ncontrol problem is an astronomical number. Therefore, an intelligent\nclosed-loop control framework is highly desired to generate an automatic\ncontrol policy. As a powerful tool for optimal control, reinforcement learning\n(RL) algorithms can surpass human beings' decision-making and can also be\nseamlessly integrated into the closed-loop control framework. However, in\ncomplex real-world scenarios such as agricultural automation control, where the\ninteraction with the environment is time-consuming and expensive, the\napplication of RL algorithms encounters two main challenges, i.e., sample\nefficiency and safety. Although model-based RL methods can greatly mitigate the\nefficiency problem of greenhouse control, the safety problem has not got too\nmuch attention. In this paper, we present a model-based robust RL framework for\nautonomous greenhouse control to meet the sample efficiency and safety\nchallenges. Specifically, our framework introduces an ensemble of environment\nmodels to work as a simulator and assist in policy optimization, thereby\naddressing the low sample efficiency problem. As for the safety concern, we\npropose a sample dropout module to focus more on worst-case samples, which can\nhelp improve the adaptability of the greenhouse planting policy in extreme\ncases. Experimental results demonstrate that our approach can learn a more\neffective greenhouse planting policy with better robustness than existing\nmethods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.05872,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000008278,
      "text":"HAC Explore: Accelerating Exploration with Hierarchical Reinforcement\n  Learning\n\n  Sparse rewards and long time horizons remain challenging for reinforcement\nlearning algorithms. Exploration bonuses can help in sparse reward settings by\nencouraging agents to explore the state space, while hierarchical approaches\ncan assist with long-horizon tasks by decomposing lengthy tasks into shorter\nsubtasks. We propose HAC Explore (HACx), a new method that combines these\napproaches by integrating the exploration bonus method Random Network\nDistillation (RND) into the hierarchical approach Hierarchical Actor-Critic\n(HAC). HACx outperforms either component method on its own, as well as an\nexisting approach to combining hierarchy and exploration, in a set of difficult\nsimulated robotics tasks. HACx is the first RL method to solve a sparse reward,\ncontinuous-control task that requires over 1,000 actions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.05165,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000024173,
      "text":"Stable Marriage Problems with Ties and Incomplete Preferences: An\n  Empirical Comparison of ASP, SAT, ILP, CP, and Local Search Methods\n\n  We study a variation of the Stable Marriage problem, where every man and\nevery woman express their preferences as preference lists which may be\nincomplete and contain ties. This problem is called the Stable Marriage problem\nwith Ties and Incomplete preferences (SMTI). We consider three optimization\nvariants of SMTI, Max Cardinality, Sex-Equal and Egalitarian, and empirically\ncompare the following methods to solve them: Answer Set Programming, Constraint\nProgramming, Integer Linear Programming. For Max Cardinality, we compare these\nmethods with Local Search methods as well. We also empirically compare Answer\nSet Programming with Propositional Satisfiability, for SMTI instances. This\npaper is under consideration for acceptance in Theory and Practice of Logic\nProgramming (TPLP).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.09003,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"Explainable Reinforcement Learning for Broad-XAI: A Conceptual Framework\n  and Survey\n\n  Broad Explainable Artificial Intelligence moves away from interpreting\nindividual decisions based on a single datum and aims to provide integrated\nexplanations from multiple machine learning algorithms into a coherent\nexplanation of an agent's behaviour that is aligned to the communication needs\nof the explainee. Reinforcement Learning (RL) methods, we propose, provide a\npotential backbone for the cognitive model required for the development of\nBroad-XAI. RL represents a suite of approaches that have had increasing success\nin solving a range of sequential decision-making problems. However, these\nalgorithms all operate as black-box problem solvers, where they obfuscate their\ndecision-making policy through a complex array of values and functions.\nEXplainable RL (XRL) is relatively recent field of research that aims to\ndevelop techniques to extract concepts from the agent's: perception of the\nenvironment; intrinsic\/extrinsic motivations\/beliefs; Q-values, goals and\nobjectives. This paper aims to introduce a conceptual framework, called the\nCausal XRL Framework (CXF), that unifies the current XRL research and uses RL\nas a backbone to the development of Broad-XAI. Additionally, we recognise that\nRL methods have the ability to incorporate a range of technologies to allow\nagents to adapt to their environment. CXF is designed for the incorporation of\nmany standard RL extensions and integrated with external ontologies and\ncommunication facilities so that the agent can answer questions that explain\noutcomes and justify its decisions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.05428,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000028147,
      "text":"Determining ActionReversibility in STRIPS Using Answer Set and Epistemic\n  Logic Programming\n\n  In the context of planning and reasoning about actions and change, we call an\naction reversible when its effects can be reverted by applying other actions,\nreturning to the original state. Renewed interest in this area has led to\nseveral results in the context of the PDDL language, widely used for describing\nplanning tasks.\n  In this paper, we propose several solutions to the computational problem of\ndeciding the reversibility of an action. In particular, we leverage an existing\ntranslation from PDDL to Answer Set Programming (ASP), and then use several\ndifferent encodings to tackle the problem of action reversibility for the\nSTRIPS fragment of PDDL. For these, we use ASP, as well as Epistemic Logic\nProgramming (ELP), an extension of ASP with epistemic operators, and compare\nand contrast their strengths and weaknesses.\n  Under consideration for acceptance in TPLP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.13744,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000008941,
      "text":"The Horn Non-Clausal Class and its Polynomiality\n\n  The expressiveness of propositional non-clausal (NC) formulas is\nexponentially richer than that of clausal formulas. Yet, clausal efficiency\noutperforms non-clausal one. Indeed, a major weakness of the latter is that,\nwhile Horn clausal formulas, along with Horn algorithms, are crucial for the\nhigh efficiency of clausal reasoning, no Horn-like formulas in non-clausal form\nhad been proposed. To overcome such weakness, we define the hybrid class\n$\\mathbb{H_{NC}}$ of Horn Non-Clausal (Horn-NC) formulas, by adequately lifting\nthe Horn pattern to NC form, and argue that $\\mathbb{H_{NC}}$, along with\nfuture Horn-NC algorithms, shall increase non-clausal efficiency just as the\nHorn class has increased clausal efficiency. Secondly, we: (i) give the\ncompact, inductive definition of $\\mathbb{H_{NC}}$; (ii) prove that\nsyntactically $\\mathbb{H_{NC}}$ subsumes the Horn class but semantically both\nclasses are equivalent, and (iii) characterize the non-clausal formulas\nbelonging to $\\mathbb{H_{NC}}$. Thirdly, we define the Non-Clausal\nUnit-Resolution calculus, $UR_{NC}$, and prove that it checks the\nsatisfiability of $\\mathbb{H_{NC}}$ in polynomial time. This fact, to our\nknowledge, makes $\\mathbb{H_{NC}}$ the first characterized polynomial class in\nNC reasoning. Finally, we prove that $\\mathbb{H_{NC}}$ is linearly\nrecognizable, and also that it is both strictly succincter and exponentially\nricher than the Horn class. We discuss that in NC automated reasoning, e.g.\nsatisfiability solving, theorem proving, logic programming, etc., can directly\nbenefit from $\\mathbb{H_{NC}}$ and $UR_{NC}$ and that, as a by-product of its\nproved properties, $\\mathbb{H_{NC}}$ arises as a new alternative to analyze\nHorn functions and implication systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.03988,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000019206,
      "text":"Knowledge accumulating: The general pattern of learning\n\n  Artificial Intelligence has been developed for decades with the achievement\nof great progress. Recently, deep learning shows its ability to solve many real\nworld problems, e.g. image classification and detection, natural language\nprocessing, playing GO. Theoretically speaking, an artificial neural network\ncan fit any function and reinforcement learning can learn from any delayed\nreward. But in solving real world tasks, we still need to spend a lot of effort\nto adjust algorithms to fit task unique features. This paper proposes that the\nreason of this phenomenon is the sparse feedback feature of the nature, and a\nsingle algorithm, no matter how we improve it, can only solve dense feedback\ntasks or specific sparse feedback tasks. This paper first analyses how sparse\nfeedback affects algorithm perfomance, and then proposes a pattern that\nexplains how to accumulate knowledge to solve sparse feedback problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.03903,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000081791,
      "text":"Sinogram Denoise Based on Generative Adversarial Networks\n\n  A novel method for sinogram denoise based on Generative Adversarial Networks\n(GANs) in the field of SPECT imaging is presented. Projection data from\nsoftware phantoms were used to train the proposed model. For evaluation of the\nefficacy of the method Shepp Logan based phantom, with various noise levels\nadded where used. The resulting denoised sinograms are reconstructed using\nOrdered Subset Expectation Maximization (OSEM) and compared to the\nreconstructions of the original noised sinograms. As the results show, the\nproposed method significantly denoise the sinograms and significantly improves\nthe reconstructions. Finally, to demonstrate the efficacy and capability of the\nproposed method results from real-world DAT-SPECT sinograms are presented.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.03414,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.000001755,
      "text":"Vision Transformer for femur fracture classification\n\n  In recent years, the scientific community has focused on the development of\nCAD tools that could improve bone fractures' classification, mostly based on\nConvolutional Neural Network (CNN). However, the discerning accuracy of\nfractures' subtypes was far from optimal. This paper proposes a modified\nversion of a very recent and powerful deep learning technique, the Vision\nTransformer (ViT), outperforming CNNs based approaches and consequently\nincreasing specialists' diagnosis accuracy. 4207 manually annotated images were\nused and distributed, by following the AO\/OTA classification, in different\nfracture types, the largest labeled dataset of proximal femur fractures used in\nliterature. The ViT architecture was used and compared with a classic CNN and a\nmultistage architecture composed of successive CNNs in cascade. To demonstrate\nthe reliability of this approach, 1) the attention maps were used to visualize\nthe most relevant areas of the images, 2) the performance of a generic CNN and\nViT was compared through unsupervised learning techniques, and 3) 11\nspecialists were asked to evaluate and classify 150 proximal femur fractures'\nimages with and without the help of the ViT, then results were compared for\npotential improvement. The ViT was able to correctly predict 83% of the test\nimages. Precision, recall and F1-score were 0.77 (CI 0.64-0.90), 0.76 (CI\n0.62-0.91) and 0.77 (CI 0.64-0.89), respectively. The average specialists'\ndiagnostic improvement was 29% when supported by ViT's predictions,\noutperforming the algorithm alone. This paper showed the potential of Vision\nTransformers in bone fracture classification. For the first time, good results\nwere obtained in sub-fractures classification, with the largest and richest\ndataset ever. Accordingly, the assisted diagnosis yielded the best results,\nproving once again the effectiveness of a coordinated work between neural\nnetworks and specialists.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.05436,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000062254,
      "text":"Friddy multiagent price stabilization model\n\n  In a multiagent network model consisting of nodes, each network node has an\nagent and priced Friddy coins, and the agent can buy or sell Friddy coins in\nthe marketplace. Though every node may not effectively have an equal price\nduring the transaction time, the prices have to reach equilibrium by iterating\nbuy and sell transactions on a macro level.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.05412,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000046028,
      "text":"Analyzing Race and Country of Citizenship Bias in Wikidata\n\n  As an open and collaborative knowledge graph created by users and bots, it is\npossible that the knowledge in Wikidata is biased in regards to multiple\nfactors such as gender, race, and country of citizenship. Previous work has\nmostly studied the representativeness of Wikidata knowledge in terms of genders\nof people. In this paper, we examine the race and citizenship bias in general\nand in regards to STEM representation for scientists, software developers, and\nengineers. By comparing Wikidata queries to real-world datasets, we identify\nthe differences in representation to characterize the biases present in\nWikidata. Through this analysis, we discovered that there is an\noverrepresentation of white individuals and those with citizenship in Europe\nand North America; the rest of the groups are generally underrepresented. Based\non these findings, we have found and linked to Wikidata additional data about\nSTEM scientists from the minorities. This data is ready to be inserted into\nWikidata with a bot. Increasing representation of minority race and country of\ncitizenship groups can create a more accurate portrayal of individuals in STEM.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.00633,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000050002,
      "text":"Planning with Learned Binarized Neural Networks Benchmarks for MaxSAT\n  Evaluation 2021\n\n  This document provides a brief introduction to learned automated planning\nproblem where the state transition function is in the form of a binarized\nneural network (BNN), presents a general MaxSAT encoding for this problem, and\ndescribes the four domains, namely: Navigation, Inventory Control, System\nAdministrator and Cellda, that are submitted as benchmarks for MaxSAT\nEvaluation 2021.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.1233,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000053975,
      "text":"SMT-Based Safety Verification of Data-Aware Processes under Ontologies\n  (Extended Version)\n\n  In the context of verification of data-aware processes (DAPs), a formal\napproach based on satisfiability modulo theories (SMT) has been considered to\nverify parameterised safety properties of so-called artifact-centric systems.\nThis approach requires a combination of model-theoretic notions and algorithmic\ntechniques based on backward reachability. We introduce here a variant of one\nof the most investigated models in this spectrum, namely simple artifact\nsystems (SASs), where, instead of managing a database, we operate over a\ndescription logic (DL) ontology expressed in (a slight extension of) RDFS. This\nDL, enjoying suitable model-theoretic properties, allows us to define DL-based\nSASs to which backward reachability can still be applied, leading to\ndecidability in PSPACE of the corresponding safety problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.04555,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"Deep Joint Learning of Pathological Region Localization and Alzheimer's\n  Disease Diagnosis\n\n  The identification of Alzheimer's disease (AD) and its early stages using\nstructural magnetic resonance imaging (MRI) has been attracting the attention\nof researchers. Various data-driven approaches have been introduced to capture\nsubtle and local morphological changes of the brain accompanied by the disease\nprogression. One of the typical approaches for capturing subtle changes is\npatch-level feature representation. However, the predetermined regions to\nextract patches can limit classification performance by interrupting the\nexploration of potential biomarkers. In addition, the existing patch-level\nanalyses have difficulty explaining their decision-making. To address these\nproblems, we propose the BrainBagNet with a position-based gate\n(PG-BrainBagNet), a framework for jointly learning pathological region\nlocalization and AD diagnosis in an end-to-end manner. In advance, as all scans\nare aligned to a template in image processing, the position of brain images can\nbe represented through the 3D Cartesian space shared by the overall MRI scans.\nThe proposed method represents the patch-level response from whole-brain MRI\nscans and discriminative brain-region from position information. Based on the\noutcomes, the patch-level class evidence is calculated, and then the\nimage-level prediction is inferred by a transparent aggregation. The proposed\nmodels were evaluated on the ADNI datasets. In five-fold cross-validation, the\nclassification performance of the proposed method outperformed that of the\nstate-of-the-art methods in both AD diagnosis (AD vs. normal control) and mild\ncognitive impairment (MCI) conversion prediction (progressive MCI vs. stable\nMCI) tasks. In addition, changes in the identified discriminant regions and\npatch-level class evidence according to the patch size used for model training\nare presented and analyzed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.06405,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000017881,
      "text":"Planning with Incomplete Information in Quantified Answer Set\n  Programming\n\n  We present a general approach to planning with incomplete information in\nAnswer Set Programming (ASP). More precisely, we consider the problems of\nconformant and conditional planning with sensing actions and assumptions. We\nrepresent planning problems using a simple formalism where logic programs\ndescribe the transition function between states, the initial states and the\ngoal states. For solving planning problems, we use Quantified Answer Set\nProgramming (QASP), an extension of ASP with existential and universal\nquantifiers over atoms that is analogous to Quantified Boolean Formulas (QBFs).\nWe define the language of quantified logic programs and use it to represent the\nsolutions to different variants of conformant and conditional planning. On the\npractical side, we present a translation-based QASP solver that converts\nquantified logic programs into QBFs and then executes a QBF solver, and we\nevaluate experimentally the approach on conformant and conditional planning\nbenchmarks. Under consideration for acceptance in TPLP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2108.05525,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000021524,
      "text":"Clustering with UMAP: Why and How Connectivity Matters\n\n  Topology based dimensionality reduction methods such as t-SNE and UMAP have\nseen increasing success and popularity in high-dimensional data. These methods\nhave strong mathematical foundations and are based on the intuition that the\ntopology in low dimensions should be close to that of high dimensions. Given\nthat the initial topological structure is a precursor to the success of the\nalgorithm, this naturally raises the question: What makes a \"good\" topological\nstructure for dimensionality reduction? Insight into this will enable us to\ndesign better algorithms which take into account both local and global\nstructure. In this paper which focuses on UMAP, we study the effects of node\nconnectivity (k-Nearest Neighbors vs mutual k-Nearest Neighbors) and relative\nneighborhood (Adjacent via Path Neighbors) on dimensionality reduction. We\nexplore these concepts through extensive ablation studies on 4 standard image\nand text datasets; MNIST, FMNIST, 20NG, AG, reducing to 2 and 64 dimensions.\nOur findings indicate that a more refined notion of connectivity (mutual\nk-Nearest Neighbors with minimum spanning tree) together with a flexible method\nof constructing the local neighborhood (Path Neighbors), can achieve a much\nbetter representation than default UMAP, as measured by downstream clustering\nperformance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.00318,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000006623,
      "text":"Intrinsic Argument Strength in Structured Argumentation: a Principled\n  Approach\n\n  Abstract argumentation provides us with methods such as gradual and Dung\nsemantics with which to evaluate arguments after potential attacks by other\narguments. Some of these methods can take intrinsic strengths of arguments as\ninput, with which to modulate the effects of attacks between arguments. Coming\nfrom abstract argumentation, these methods look only at the relations between\narguments and not at the structure of the arguments themselves. In structured\nargumentation the way an argument is constructed, by chaining inference rules\nstarting from premises, is taken into consideration. In this paper we study\nmethods for assigning an argument its intrinsic strength, based on the\nstrengths of the premises and inference rules used to form said argument. We\nfirst define a set of principles, which are properties that strength assigning\nmethods might satisfy. We then propose two such methods and analyse which\nprinciples they satisfy. Finally, we present a generalised system for creating\nnovel strength assigning methods and speak to the properties of this system\nregarding the proposed principles.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.10547,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.000007285,
      "text":"K-AID: Enhancing Pre-trained Language Models with Domain Knowledge for\n  Question Answering\n\n  Knowledge enhanced pre-trained language models (K-PLMs) are shown to be\neffective for many public tasks in the literature but few of them have been\nsuccessfully applied in practice. To address this problem, we propose K-AID, a\nsystematic approach that includes a low-cost knowledge acquisition process for\nacquiring domain knowledge, an effective knowledge infusion module for\nimproving model performance, and a knowledge distillation component for\nreducing the model size and deploying K-PLMs on resource-restricted devices\n(e.g., CPU) for real-world application. Importantly, instead of capturing\nentity knowledge like the majority of existing K-PLMs, our approach captures\nrelational knowledge, which contributes to better-improving sentence-level text\nclassification and text matching tasks that play a key role in question\nanswering (QA). We conducted a set of experiments on five text classification\ntasks and three text matching tasks from three domains, namely E-commerce,\nGovernment, and Film&TV, and performed online A\/B tests in E-commerce.\nExperimental results show that our approach is able to achieve substantial\nimprovement on sentence-level question answering tasks and bring beneficial\nbusiness value in industrial settings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.14381,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"From Organisational Structure to Organisational Behaviour Formalisation\n\n  To understand how an organisational structure relates to organisational\nbehaviour is an interesting fundamental challenge in the area of organisation\nmodelling. Specifications of organisational structure usually have a\ndiagrammatic form that abstracts from more detailed dynamics. Dynamic\nproperties of agent systems, on the other hand, are often specified in the form\nof a set of logical formulae in some temporal language. This paper addresses\nthe question how these two perspectives can be combined in one framework. It is\nshown how for different aggregation levels and other elements within an\norganisation structure, sets of dynamic properties can be specified.\nOrganisational structure provides a structure of (interlevel) relationships\nbetween these multiple sets of dynamic properties. Thus organisational\nstructure is reflected in the formalisation of the dynamics of organisational\nbehaviour. To illustrate the effectiveness of the approach a formal foundation\nis presented for the integrated specification of both structure and behaviour\nof an AGR organisation model.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.0483,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000004636,
      "text":"Solving the Extended Job Shop Scheduling Problem with AGVs -- Classical\n  and Quantum Approaches\n\n  The subject of Job Scheduling Optimisation (JSO) deals with the scheduling of\njobs in an organization, so that the single working steps are optimally\norganized regarding the postulated targets. In this paper a use case is\nprovided which deals with a sub-aspect of JSO, the Job Shop Scheduling Problem\n(JSSP or JSP). As many optimization problems JSSP is NP-complete, which means\nthe complexity increases with every node in the system exponentially. The goal\nof the use case is to show how to create an optimized duty rooster for certain\nworkpieces in a flexible organized machinery, combined with an Autonomous\nGround Vehicle (AGV), using Constraint Programming (CP) and Quantum Computing\n(QC) alternatively. The results of a classical solution based on CP and on a\nQuantum Annealing model are presented and discussed. All presented results have\nbeen elaborated in the research project PlanQK.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.01797,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000055631,
      "text":"Hybrid Contrastive Learning of Tri-Modal Representation for Multimodal\n  Sentiment Analysis\n\n  The wide application of smart devices enables the availability of multimodal\ndata, which can be utilized in many tasks. In the field of multimodal sentiment\nanalysis (MSA), most previous works focus on exploring intra- and inter-modal\ninteractions. However, training a network with cross-modal information\n(language, visual, audio) is still challenging due to the modality gap, and\nexisting methods still cannot ensure to sufficiently learn intra-\/inter-modal\ndynamics. Besides, while learning dynamics within each sample draws great\nattention, the learning of inter-class relationships is neglected. Moreover,\nthe size of datasets limits the generalization ability of existing methods. To\naddress the afore-mentioned issues, we propose a novel framework HyCon for\nhybrid contrastive learning of tri-modal representation. Specifically, we\nsimultaneously perform intra-\/inter-modal contrastive learning and\nsemi-contrastive learning (that is why we call it hybrid contrastive learning),\nwith which the model can fully explore cross-modal interactions, preserve\ninter-class relationships and reduce the modality gap. Besides, a refinement\nterm is devised to prevent the model falling into a sub-optimal solution.\nMoreover, HyCon can naturally generate a large amount of training pairs for\nbetter generalization and reduce the negative effect of limited datasets.\nExtensive experiments on public datasets demonstrate that our proposed method\noutperforms existing works.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.0122,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000054969,
      "text":"An Oracle and Observations for the OpenAI Gym \/ ALE Freeway Environment\n\n  The OpenAI Gym project contains hundreds of control problems whose goal is to\nprovide a testbed for reinforcement learning algorithms. One such problem is\nFreeway-ram-v0, where the observations presented to the agent are 128 bytes of\nRAM. While the goals of the project are for non-expert AI agents to solve the\ncontrol problems with general training, in this work, we seek to learn more\nabout the problem, so that we can better evaluate solutions. In particular, we\ndevelop on oracle to play the game, so that we may have baselines for success.\nWe present details of the oracle, plus optimal game-playing situations that can\nbe used for training and testing AI agents.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.09478,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000029802,
      "text":"A Survey of Text Games for Reinforcement Learning informed by Natural\n  Language\n\n  Reinforcement Learning has shown success in a number of complex virtual\nenvironments. However, many challenges still exist towards solving problems\nwith natural language as a core component. Interactive Fiction Games (or Text\nGames) are one such problem type that offer a set of partially observable\nenvironments where natural language is required as part of the reinforcement\nlearning solutions.\n  Therefore, this survey's aim is to assist in the development of new Text Game\nproblem settings and solutions for Reinforcement Learning informed by natural\nlanguage. Specifically, this survey summarises: 1) the challenges introduced in\nText Game Reinforcement Learning problems, 2) the generation tools for\nevaluating Text Games and the subsequent environments generated and, 3) the\nagent architectures currently applied are compared to provide a systematic\nreview of benchmark methodologies and opportunities for future researchers.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.11223,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000044703,
      "text":"Individual and Collective Autonomous Development\n\n  The increasing complexity and unpredictability of many ICT scenarios let us\nenvision that future systems will have to dynamically learn how to act and\nadapt to face evolving situations with little or no a priori knowledge, both at\nthe level of individual components and at the collective level. In other words,\nsuch systems should become able to autonomously develop models of themselves\nand of their environment. Autonomous development includes: learning models of\nown capabilities; learning how to act purposefully towards the achievement of\nspecific goals; and learning how to act collectively, i.e., accounting for the\npresence of others. In this paper, we introduce the vision of autonomous\ndevelopment in ICT systems, by framing its key concepts and by illustrating\nsuitable application domains. Then, we overview the many research areas that\nare contributing or can potentially contribute to the realization of the\nvision, and identify some key research challenges.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.01634,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000028478,
      "text":"AI Descartes: Combining Data and Theory for Derivable Scientific\n  Discovery\n\n  Scientists have long aimed to discover meaningful formulae which accurately\ndescribe experimental data. A common approach is to manually create\nmathematical models of natural phenomena using domain knowledge, and then fit\nthese models to data. In contrast, machine-learning algorithms automate the\nconstruction of accurate data-driven models while consuming large amounts of\ndata. The problem of incorporating prior knowledge in the form of constraints\non the functional form of a learned model (e.g., nonnegativity) has been\nexplored in the literature. However, finding models that are consistent with\nprior knowledge expressed in the form of general logical axioms (e.g.,\nconservation of energy) is an open problem. We develop a method to enable\nprincipled derivations of models of natural phenomena from axiomatic knowledge\nand experimental data by combining logical reasoning with symbolic regression.\nWe demonstrate these concepts for Kepler's third law of planetary motion,\nEinstein's relativistic time-dilation law, and Langmuir's theory of adsorption,\nautomatically connecting experimental data with background theory in each case.\nWe show that laws can be discovered from few data points when using formal\nlogical reasoning to distinguish the correct formula from a set of plausible\nformulas that have similar error on the data. The combination of reasoning with\nmachine learning provides generalizeable insights into key aspects of natural\nphenomena. We envision that this combination will enable derivable discovery of\nfundamental laws of science and believe that our work is an important step\ntowards automating the scientific method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.10716,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000005298,
      "text":"A formalisation of BPMN in Description Logics\n\n  In this paper we present a textual description, in terms of Description\nLogics, of the BPMN Ontology, which provides a clear semantic formalisation of\nthe structural components of the Business Process Modelling Notation (BPMN),\nbased on the latest stable BPMN specifications from OMG [BPMN Version 1.1 --\nJanuary 2008]. The development of the ontology was guided by the description of\nthe complete set of BPMN Element Attributes and Types contained in Annex B of\nthe BPMN specifications.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.03166,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000068876,
      "text":"Aspartix-V21\n\n  In this solver description we present ASPARTIX-V, in its 2021 edition, which\nparticipates in the International Competition on Computational Models of\nArgumentation (ICCMA) 2021. ASPARTIX-V is capable of solving all classical\n(static) reasoning tasks part of ICCMA'21 and extends the ASPARTIX system suite\nby incorporation of recent ASP language constructs (e.g. conditional literals),\ndomain heuristics within ASP, and multi-shot methods. In this light ASPARTIX-V\ndeviates from the traditional focus of ASPARTIX on monolithic approaches (i.e.,\none-shot solving via a single ASP encoding) to further enhance performance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.09696,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000080135,
      "text":"Configuring Multiple Instances with Multi-Configuration\n\n  Configuration is a successful application area of Artificial Intelligence. In\nthe majority of the cases, configuration systems focus on configuring one\nsolution (configuration) that satisfies the preferences of a single user or a\ngroup of users. In this paper, we introduce a new configuration approach -\nmulti-configuration - that focuses on scenarios where the outcome of a\nconfiguration process is a set of configurations. Example applications thereof\nare the configuration of personalized exams for individual students, the\nconfiguration of project teams, reviewer-to-paper assignment, and hotel room\nassignments including individualized city trips for tourist groups. For\nmulti-configuration scenarios, we exemplify a constraint satisfaction problem\nrepresentation in the context of configuring exams. The paper is concluded with\na discussion of open issues for future work.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.12755,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"Abstraction, Reasoning and Deep Learning: A Study of the \"Look and Say\"\n  Sequence\n\n  The ability to abstract, count, and use System~2 reasoning are well-known\nmanifestations of intelligence and understanding. In this paper, we argue,\nusing the example of the ``Look and Say\" puzzle, that although deep neural\nnetworks can exhibit high `competence' (as measured by accuracy) when trained\non large data sets (2 million examples in our case), they do not show any sign\non the deeper understanding of the problem, or what D. Dennett calls\n`comprehension'. We report on two sets experiments: first, computing the next\nelement of the sequence, and ,then, the previous element. We view both problems\nas building a translator from one set of tokens to another. We apply both\nstandard LSTMs and Transformer\/Attention-based neural networks, using publicly\navailable machine translation software. We observe that despite the amazing\naccuracy, the performance of the trained programs on the actual L\\&S sequence\nis bad, and shows no understanding of the principles behind the sequences. The\nramifications of this finding include: (1) from the cognitive science\nperspective, we argue that we need better mathematical models of abstraction;\n(2) the universality of neural networks should be re-examined for functions\nacting on discrete data sets; (3) we hypothesize topology can provide a\ndefinition of without the reference to the concept of distance.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.03202,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"On the impact of MDP design for Reinforcement Learning agents in\n  Resource Management\n\n  The recent progress in Reinforcement Learning applications to Resource\nManagement presents MDPs without a deeper analysis of the impacts of design\ndecisions on agent performance. In this paper, we compare and contrast four\ndifferent MDP variations, discussing their computational requirements and\nimpacts on agent performance by means of an empirical analysis. We conclude by\nshowing that, in our experiments, when using Multi-Layer Perceptrons as\napproximation function, a compact state representation allows transfer of\nagents between environments, and that transferred agents have good performance\nand outperform specialized agents in 80\\% of the tested scenarios, even without\nretraining.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.13893,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Explainable Machine Larning for liver transplantation\n\n  In this work, we present a flexible method for explaining, in human readable\nterms, the predictions made by decision trees used as decision support in liver\ntransplantation. The decision trees have been obtained through machine learning\napplied on a dataset collected at the liver transplantation unit at the\nCoru\\~na University Hospital Center and are used to predict long term (five\nyears) survival after transplantation. The method we propose is based on the\nrepresentation of the decision tree as a set of rules in a logic program (LP)\nthat is further annotated with text messages. This logic program is then\nprocessed using the tool xclingo (based on Answer Set Programming) that allows\nbuilding compound explanations depending on the annotation text and the rules\neffectively fired when a given input is provided. We explore two alternative LP\nencodings: one in which rules respect the tree structure (more convenient to\nreflect the learning process) and one where each rule corresponds to a\n(previously simplified) tree path (more readable for decision making).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.07827,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0,
      "text":"Enabling risk-aware Reinforcement Learning for medical interventions\n  through uncertainty decomposition\n\n  Reinforcement Learning (RL) is emerging as tool for tackling complex control\nand decision-making problems. However, in high-risk environments such as\nhealthcare, manufacturing, automotive or aerospace, it is often challenging to\nbridge the gap between an apparently optimal policy learnt by an agent and its\nreal-world deployment, due to the uncertainties and risk associated with it.\nBroadly speaking RL agents face two kinds of uncertainty, 1. aleatoric\nuncertainty, which reflects randomness or noise in the dynamics of the world,\nand 2. epistemic uncertainty, which reflects the bounded knowledge of the agent\ndue to model limitations and finite amount of information\/data the agent has\nacquired about the world. These two types of uncertainty carry fundamentally\ndifferent implications for the evaluation of performance and the level of risk\nor trust. Yet these aleatoric and epistemic uncertainties are generally\nconfounded as standard and even distributional RL is agnostic to this\ndifference. Here we propose how a distributional approach (UA-DQN) can be\nrecast to render uncertainties by decomposing the net effects of each\nuncertainty. We demonstrate the operation of this method in grid world examples\nto build intuition and then show a proof of concept application for an RL agent\noperating as a clinical decision support system in critical care\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.10144,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000030133,
      "text":"FaxPlainAC: A Fact-Checking Tool Based on EXPLAINable Models with HumAn\n  Correction in the Loop\n\n  Fact-checking on the Web has become the main mechanism through which we\ndetect the credibility of the news or information. Existing fact-checkers\nverify the authenticity of the information (support or refute the claim) based\non secondary sources of information. However, existing approaches do not\nconsider the problem of model updates due to constantly increasing training\ndata due to user feedback. It is therefore important to conduct user studies to\ncorrect models' inference biases and improve the model in a life-long learning\nmanner in the future according to the user feedback. In this paper, we present\nFaxPlainAC, a tool that gathers user feedback on the output of explainable\nfact-checking models. FaxPlainAC outputs both the model decision, i.e., whether\nthe input fact is true or not, along with the supporting\/refuting evidence\nconsidered by the model. Additionally, FaxPlainAC allows for accepting user\nfeedback both on the prediction and explanation. Developed in Python,\nFaxPlainAC is designed as a modular and easily deployable tool. It can be\nintegrated with other downstream tasks and allowing for fact-checking human\nannotation gathering and life-long learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.08149,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000536442,
      "text":"Karpov's Queen Sacrifices and AI\n\n  Anatoly Karpov's Queen sacrifices are analyzed. Stockfish 14 NNUE -- an AI\nchess engine -- evaluates how efficient Karpov's sacrifices are. For\ncomparative purposes, we provide a dataset on Karpov's Rook and Knight\nsacrifices to test whether Karpov achieves a similar level of accuracy. Our\nstudy has implications for human-AI interaction and how humans can better\nunderstand the strategies employed by black-box AI algorithms. Finally, we\nconclude with implications for human study in. chess with computer engines.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.03813,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Video2Skill: Adapting Events in Demonstration Videos to Skills in an\n  Environment using Cyclic MDP Homomorphisms\n\n  Humans excel at learning long-horizon tasks from demonstrations augmented\nwith textual commentary, as evidenced by the burgeoning popularity of tutorial\nvideos online. Intuitively, this capability can be separated into 2 distinct\nsubtasks - first, dividing a long-horizon demonstration sequence into\nsemantically meaningful events; second, adapting such events into meaningful\nbehaviors in one's own environment. Here, we present Video2Skill (V2S), which\nattempts to extend this capability to artificial agents by allowing a robot arm\nto learn from human cooking videos. We first use sequence-to-sequence\nAuto-Encoder style architectures to learn a temporal latent space for events in\nlong-horizon demonstrations. We then transfer these representations to the\nrobotic target domain, using a small amount of offline and unrelated\ninteraction data (sequences of state-action pairs of the robot arm controlled\nby an expert) to adapt these events into actionable representations, i.e.,\nskills. Through experiments, we demonstrate that our approach results in\nself-supervised analogy learning, where the agent learns to draw analogies\nbetween motions in human demonstration data and behaviors in the robotic\nenvironment. We also demonstrate the efficacy of our approach on model learning\n- demonstrating how Video2Skill utilizes prior knowledge from human\ndemonstration to outperform traditional model learning of long-horizon\ndynamics. Finally, we demonstrate the utility of our approach for non-tabula\nrasa decision-making, i.e, utilizing video demonstration for zero-shot skill\ngeneration.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2109.03391,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.000025034,
      "text":"Visual Sensation and Perception Computational Models for Deep Learning:\n  State of the art, Challenges and Prospects\n\n  Visual sensation and perception refers to the process of sensing, organizing,\nidentifying, and interpreting visual information in environmental awareness and\nunderstanding. Computational models inspired by visual perception have the\ncharacteristics of complexity and diversity, as they come from many subjects\nsuch as cognition science, information science, and artificial intelligence. In\nthis paper, visual perception computational models oriented deep learning are\ninvestigated from the biological visual mechanism and computational vision\ntheory systematically. Then, some points of view about the prospects of the\nvisual perception computational models are presented. Finally, this paper also\nsummarizes the current challenges of visual perception and predicts its future\ndevelopment trends. Through this survey, it will provide a comprehensive\nreference for research in this direction.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.0248,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000096361,
      "text":"Efficient Multi-agent Epistemic Planning: Teaching Planners About Nested\n  Belief\n\n  Many AI applications involve the interaction of multiple autonomous agents,\nrequiring those agents to reason about their own beliefs, as well as those of\nother agents. However, planning involving nested beliefs is known to be\ncomputationally challenging. In this work, we address the task of synthesizing\nplans that necessitate reasoning about the beliefs of other agents. We plan\nfrom the perspective of a single agent with the potential for goals and actions\nthat involve nested beliefs, non-homogeneous agents, co-present observations,\nand the ability for one agent to reason as if it were another. We formally\ncharacterize our notion of planning with nested belief, and subsequently\ndemonstrate how to automatically convert such problems into problems that\nappeal to classical planning technology for solving efficiently. Our approach\nrepresents an important step towards applying the well-established field of\nautomated planning to the challenging task of planning involving nested beliefs\nof multiple agents.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.04041,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Pick Your Battles: Interaction Graphs as Population-Level Objectives for\n  Strategic Diversity\n\n  Strategic diversity is often essential in games: in multi-player games, for\nexample, evaluating a player against a diverse set of strategies will yield a\nmore accurate estimate of its performance. Furthermore, in games with\nnon-transitivities diversity allows a player to cover several winning\nstrategies. However, despite the significance of strategic diversity, training\nagents that exhibit diverse behaviour remains a challenge. In this paper we\nstudy how to construct diverse populations of agents by carefully structuring\nhow individuals within a population interact. Our approach is based on\ninteraction graphs, which control the flow of information between agents during\ntraining and can encourage agents to specialise on different strategies,\nleading to improved overall performance. We provide evidence for the importance\nof diversity in multi-agent training and analyse the effect of applying\ndifferent interaction graphs on the training trajectories, diversity and\nperformance of populations in a range of games. This is an extended version of\nthe long abstract published at AAMAS.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.1487,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"A Scenario-Based Platform for Testing Autonomous Vehicle Behavior\n  Prediction Models in Simulation\n\n  Behavior prediction remains one of the most challenging tasks in the\nautonomous vehicle (AV) software stack. Forecasting the future trajectories of\nnearby agents plays a critical role in ensuring road safety, as it equips AVs\nwith the necessary information to plan safe routes of travel. However, these\nprediction models are data-driven and trained on data collected in real life\nthat may not represent the full range of scenarios an AV can encounter. Hence,\nit is important that these prediction models are extensively tested in various\ntest scenarios involving interactive behaviors prior to deployment. To support\nthis need, we present a simulation-based testing platform which supports (1)\nintuitive scenario modeling with a probabilistic programming language called\nScenic, (2) specifying a multi-objective evaluation metric with a partial\npriority ordering, (3) falsification of the provided metric, and (4)\nparallelization of simulations for scalable testing. As a part of the platform,\nwe provide a library of 25 Scenic programs that model challenging test\nscenarios involving interactive traffic participant behaviors. We demonstrate\nthe effectiveness and the scalability of our platform by testing a trained\nbehavior prediction model and searching for failure scenarios.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.0245,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000046028,
      "text":"Reward-Punishment Symmetric Universal Intelligence\n\n  Can an agent's intelligence level be negative? We extend the Legg-Hutter\nagent-environment framework to include punishments and argue for an affirmative\nanswer to that question. We show that if the background encodings and Universal\nTuring Machine (UTM) admit certain Kolmogorov complexity symmetries, then the\nresulting Legg-Hutter intelligence measure is symmetric about the origin. In\nparticular, this implies reward-ignoring agents have Legg-Hutter intelligence 0\naccording to such UTMs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.03939,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000111924,
      "text":"Ranking Cost: Building An Efficient and Scalable Circuit Routing Planner\n  with Evolution-Based Optimization\n\n  Circuit routing has been a historically challenging problem in designing\nelectronic systems such as very large-scale integration (VLSI) and printed\ncircuit boards (PCBs). The main challenge is that connecting a large number of\nelectronic components under specific design rules involves a very large search\nspace. Early solutions are typically designed with hard-coded heuristics, which\nsuffer from problems of non-optimal solutions and lack of flexibility for new\ndesign needs. Although a few learning-based methods have been proposed\nrecently, they are typically cumbersome and hard to extend to large-scale\napplications. In this work, we propose a new algorithm for circuit routing,\nnamed Ranking Cost, which innovatively combines search-based methods (i.e., A*\nalgorithm) and learning-based methods (i.e., Evolution Strategies) to form an\nefficient and trainable router. In our method, we introduce a new set of\nvariables called cost maps, which can help the A* router to find out proper\npaths to achieve the global objective. We also train a ranking parameter, which\ncan produce the ranking order and further improve the performance of our\nmethod. Our algorithm is trained in an end-to-end manner and does not use any\nartificial data or human demonstration. In the experiments, we compare with the\nsequential A* algorithm and a canonical reinforcement learning approach, and\nresults show that our method outperforms these baselines with higher\nconnectivity rates and better scalability.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.0264,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000041061,
      "text":"Bach Style Music Authoring System based on Deep Learning\n\n  With the continuous improvement in various aspects in the field of artificial\nintelligence, the momentum of artificial intelligence with deep learning\ncapabilities into the field of music is coming. The research purpose of this\npaper is to design a Bach style music authoring system based on deep learning.\nWe use a LSTM neural network to train serialized and standardized music feature\ndata. By repeated experiments, we find the optimal LSTM model which can\ngenerate imitation of Bach music. Finally the generated music is\ncomprehensively evaluated in the form of online audition and Turing test. The\nrepertoires which the music generation system constructed in this article are\nvery close to the style of Bach's original music, and it is relatively\ndifficult for ordinary people to distinguish the musics Bach authored and AI\ncreated.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.0771,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000024504,
      "text":"Semi-automated checking for regulatory compliance in e-Health\n\n  One of the main issues of every business process is to be compliant with\nlegal rules. This work presents a methodology to check in a semi-automated way\nthe regulatory compliance of a business process. We analyse an e-Health\nhospital service in particular: the Hospital at Home (HaH) service. The paper\nshows, at first, the analysis of the hospital business using the Business\nProcess Management and Notation (BPMN) standard language, then, the\nformalization in Defeasible Deontic Logic (DDL) of some rules of the European\nGeneral Data Protection Regulation (GDPR). The aim is to show how to combine a\nset of tasks of a business with a set of rules to be compliant with, using a\ntool.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.03223,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000032783,
      "text":"Goal-Directed Design Agents: Integrating Visual Imitation with One-Step\n  Lookahead Optimization for Generative Design\n\n  Engineering design problems often involve large state and action spaces along\nwith highly sparse rewards. Since an exhaustive search of those spaces is not\nfeasible, humans utilize relevant domain knowledge to condense the search\nspace. Previously, deep learning agents (DLAgents) were introduced to use\nvisual imitation learning to model design domain knowledge. This note builds on\nDLAgents and integrates them with one-step lookahead search to develop\ngoal-directed agents capable of enhancing learned strategies for sequentially\ngenerating designs. Goal-directed DLAgents can employ human strategies learned\nfrom data along with optimizing an objective function. The visual imitation\nnetwork from DLAgents is composed of a convolutional encoder-decoder network,\nacting as a rough planning step that is agnostic to feedback. Meanwhile, the\nlookahead search identifies the fine-tuned design action guided by an\nobjective. These design agents are trained on an unconstrained truss design\nproblem that is modeled as a sequential, action-based configuration design\nproblem. The agents are then evaluated on two versions of the problem: the\noriginal version used for training and an unseen constrained version with an\nobstructed construction space. The goal-directed agents outperform the human\ndesigners used to train the network as well as the previous objective-agnostic\nversions of the agent in both scenarios. This illustrates a design agent\nframework that can efficiently use feedback to not only enhance learned design\nstrategies but also adapt to unseen design problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.15058,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"cgSpan: Pattern Mining in Conceptual Graphs\n\n  Conceptual Graphs (CGs) are a graph-based knowledge representation formalism.\nIn this paper we propose cgSpan a CG frequent pattern mining algorithm. It\nextends the DMGM-GSM algorithm that takes taxonomy-based labeled graphs as\ninput; it includes three more kinds of knowledge of the CG formalism: (a) the\nfixed arity of relation nodes, handling graphs of neighborhoods centered on\nrelations rather than graphs of nodes, (b) the signatures, avoiding patterns\nwith concept types more general than the maximal types specified in signatures\nand (c) the inference rules, applying them during the pattern mining process.\nThe experimental study highlights that cgSpan is a functional CG Frequent\nPattern Mining algorithm and that including CGs specificities results in a\nfaster algorithm with more expressive results and less redundancy with\nvocabulary.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.14535,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"Comparing Heuristics, Constraint Optimization, and Reinforcement\n  Learning for an Industrial 2D Packing Problem\n\n  Cutting and Packing problems are occurring in different industries with a\ndirect impact on the revenue of businesses. Generally, the goal in Cutting and\nPacking is to assign a set of smaller objects to a set of larger objects. To\nsolve Cutting and Packing problems, practitioners can resort to heuristic and\nexact methodologies. Lately, machine learning is increasingly used for solving\nsuch problems. This paper considers a 2D packing problem from the furniture\nindustry, where a set of wooden workpieces must be assigned to different\nmodules of a trolley in the most space-saving way. We present an experimental\nsetup to compare heuristics, constraint optimization, and deep reinforcement\nlearning for the given problem. The used methodologies and their results get\ncollated in terms of their solution quality and runtime. In the given use case\na greedy heuristic produces optimal results and outperforms the other\napproaches in terms of runtime. Constraint optimization also produces optimal\nresults but requires more time to perform. The deep reinforcement learning\napproach did not always produce optimal or even feasible solutions. While we\nassume this could be remedied with more training, considering the good results\nwith the heuristic, deep reinforcement learning seems to be a bad fit for the\ngiven use case.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.03754,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Process Extraction from Text: Benchmarking the State of the Art and\n  Paving the Way for Future Challenges\n\n  The extraction of process models from text refers to the problem of turning\nthe information contained in an unstructured textual process descriptions into\na formal representation,i.e.,a process model. Several automated approaches have\nbeen proposed to tackle this problem, but they are highly heterogeneous in\nscope and underlying assumptions,i.e., differences in input, target output, and\ndata used in their evaluation.As a result, it is currently unclear how well\nexisting solutions are able to solve the model-extraction problem and how they\ncompare to each other.We overcome this issue by comparing 10 state-of-the-art\napproaches for model extraction in a systematic manner, covering both\nqualitative and quantitative aspects.The qualitative evaluation compares the\nanalysis of the primary studies on: 1 the main characteristics of each\nsolution;2 the type of process model elements extracted from the input data;3\nthe experimental evaluation performed to evaluate the proposed framework.The\nresults show a heterogeneity of techniques, elements extracted and evaluations\nconducted, that are often impossible to compare.To overcome this difficulty we\npropose a quantitative comparison of the tools proposed by the papers on the\nunifying task of process model entity and relation extraction so as to be able\nto compare them directly.The results show three distinct groups of tools in\nterms of performance, with no tool obtaining very good scores and also serious\nlimitations.Moreover, the proposed evaluation pipeline can be considered a\nreference task on a well-defined dataset and metrics that can be used to\ncompare new tools. The paper also presents a reflection on the results of the\nqualitative and quantitative evaluation on the limitations and challenges that\nthe community needs to address in the future to produce significant advances in\nthis area.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.1445,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000070863,
      "text":"Rot-Pro: Modeling Transitivity by Projection in Knowledge Graph\n  Embedding\n\n  Knowledge graph embedding models learn the representations of entities and\nrelations in the knowledge graphs for predicting missing links (relations)\nbetween entities. Their effectiveness are deeply affected by the ability of\nmodeling and inferring different relation patterns such as symmetry, asymmetry,\ninversion, composition and transitivity. Although existing models are already\nable to model many of these relations patterns, transitivity, a very common\nrelation pattern, is still not been fully supported. In this paper, we first\ntheoretically show that the transitive relations can be modeled with\nprojections. We then propose the Rot-Pro model which combines the projection\nand relational rotation together. We prove that Rot-Pro can infer all the above\nrelation patterns. Experimental results show that the proposed Rot-Pro model\neffectively learns the transitivity pattern and achieves the state-of-the-art\nresults on the link prediction task in the datasets containing transitive\nrelations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.01232,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000043048,
      "text":"Benchmarking Safety Monitors for Image Classifiers with Machine Learning\n\n  High-accurate machine learning (ML) image classifiers cannot guarantee that\nthey will not fail at operation. Thus, their deployment in safety-critical\napplications such as autonomous vehicles is still an open issue. The use of\nfault tolerance mechanisms such as safety monitors is a promising direction to\nkeep the system in a safe state despite errors of the ML classifier. As the\nprediction from the ML is the core information directly impacting safety, many\nworks are focusing on monitoring the ML model itself. Checking the efficiency\nof such monitors in the context of safety-critical applications is thus a\nsignificant challenge. Therefore, this paper aims at establishing a baseline\nframework for benchmarking monitors for ML image classifiers. Furthermore, we\npropose a framework covering the entire pipeline, from data generation to\nevaluation. Our approach measures monitor performance with a broader set of\nmetrics than usually proposed in the literature. Moreover, we benchmark three\ndifferent monitor approaches in 79 benchmark datasets containing five\ncategories of out-of-distribution data for image classifiers: class novelty,\nnoise, anomalies, distributional shifts, and adversarial attacks. Our results\nindicate that these monitors are no more accurate than a random monitor. We\nalso release the code of all experiments for reproducibility.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.03468,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000184112,
      "text":"Belief Evolution Network-based Probability Transformation and Fusion\n\n  Smets proposes the Pignistic Probability Transformation (PPT) as the decision\nlayer in the Transferable Belief Model (TBM), which argues when there is no\nmore information, we have to make a decision using a Probability Mass Function\n(PMF). In this paper, the Belief Evolution Network (BEN) and the full causality\nfunction are proposed by introducing causality in Hierarchical Hypothesis Space\n(HHS). Based on BEN, we interpret the PPT from an information fusion view and\npropose a new Probability Transformation (PT) method called Full Causality\nProbability Transformation (FCPT), which has better performance under\nBi-Criteria evaluation. Besides, we heuristically propose a new probability\nfusion method based on FCPT. Compared with Dempster Rule of Combination (DRC),\nthe proposed method has more reasonable result when fusing same evidence.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.05028,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"The CaLiGraph Ontology as a Challenge for OWL Reasoners\n\n  CaLiGraph is a large-scale cross-domain knowledge graph generated from\nWikipedia by exploiting the category system, list pages, and other list\nstructures in Wikipedia, containing more than 15 million typed entities and\naround 10 million relation assertions. Other than knowledge graphs such as\nDBpedia and YAGO, whose ontologies are comparably simplistic, CaLiGraph also\nhas a rich ontology, comprising more than 200,000 class restrictions. Those two\nproperties - a large A-box and a rich ontology - make it an interesting\nchallenge for benchmarking reasoners. In this paper, we show that a reasoning\ntask which is particularly relevant for CaLiGraph, i.e., the materialization of\nowl:hasValue constraints into assertions between individuals and between\nindividuals and literals, is insufficiently supported by available reasoning\nsystems. We provide differently sized benchmark subsets of CaLiGraph, which can\nbe used for performance analysis of reasoning systems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.05743,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000072519,
      "text":"Program Transfer for Answering Complex Questions over Knowledge Bases\n\n  Program induction for answering complex questions over knowledge bases (KBs)\naims to decompose a question into a multi-step program, whose execution against\nthe KB produces the final answer. Learning to induce programs relies on a large\nnumber of parallel question-program pairs for the given KB. However, for most\nKBs, the gold program annotations are usually lacking, making learning\ndifficult. In this paper, we propose the approach of program transfer, which\naims to leverage the valuable program annotations on the rich-resourced KBs as\nexternal supervision signals to aid program induction for the low-resourced KBs\nthat lack program annotations. For program transfer, we design a novel\ntwo-stage parsing framework with an efficient ontology-guided pruning strategy.\nFirst, a sketch parser translates the question into a high-level program\nsketch, which is the composition of functions. Second, given the question and\nsketch, an argument parser searches the detailed arguments from the KB for\nfunctions. During the searching, we incorporate the KB ontology to prune the\nsearch space. The experiments on ComplexWebQuestions and WebQuestionSP show\nthat our method outperforms SOTA methods significantly, demonstrating the\neffectiveness of program transfer and our framework. Our codes and datasets can\nbe obtained from https:\/\/github.com\/THU-KEG\/ProgramTransfer.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.0569,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000028147,
      "text":"Partial Counterfactual Identification from Observational and\n  Experimental Data\n\n  This paper investigates the problem of bounding counterfactual queries from\nan arbitrary collection of observational and experimental distributions and\nqualitative knowledge about the underlying data-generating model represented in\nthe form of a causal diagram. We show that all counterfactual distributions in\nan arbitrary structural causal model (SCM) could be generated by a canonical\nfamily of SCMs with the same causal diagram where unobserved (exogenous)\nvariables are discrete with a finite domain. Utilizing the canonical SCMs, we\ntranslate the problem of bounding counterfactuals into that of polynomial\nprogramming whose solution provides optimal bounds for the counterfactual\nquery. Solving such polynomial programs is in general computationally\nexpensive. We therefore develop effective Monte Carlo algorithms to approximate\nthe optimal bounds from an arbitrary combination of observational and\nexperimental data. Our algorithms are validated extensively on synthetic and\nreal-world datasets.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.03613,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000093049,
      "text":"A Data-Centric Approach for Training Deep Neural Networks with Less Data\n\n  While the availability of large datasets is perceived to be a key requirement\nfor training deep neural networks, it is possible to train such models with\nrelatively little data. However, compensating for the absence of large datasets\ndemands a series of actions to enhance the quality of the existing samples and\nto generate new ones. This paper summarizes our winning submission to the\n\"Data-Centric AI\" competition. We discuss some of the challenges that arise\nwhile training with a small dataset, offer a principled approach for systematic\ndata quality enhancement, and propose a GAN-based solution for synthesizing new\ndata points. Our evaluations indicate that the dataset generated by the\nproposed pipeline offers 5% accuracy improvement while being significantly\nsmaller than the baseline.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.09624,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Ideal Partition of Resources for Metareasoning\n\n  We can achieve significant gains in the value of computation by metareasoning\nabout the nature or extent of base-level problem solving before executing a\nsolution. However, resources that are irrevocably committed to metareasoning\nare not available for executing a solution. Thus, it is important to determine\nthe portion of resources we wish to apply to metareasoning and control versus\nto the execution of a solution plan. Recent research on rational agency has\nhighlighted the importance of limiting the consumption of resources by\nmetareasoning machinery. We shall introduce the metareasoning-partition\nproblem--the problem of ideally apportioning costly reasoning resources to\nplanning a solution versus applying resource to executing a solution to a\nproblem. We exercise prototypical metareasoning-partition models to probe the\nrelationships between time allocated to metareasoning and to execution for\ndifferent problem classes. Finally, we examine the value of metareasoning in\nthe context of our functional analyses.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2110.09197,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"On the Completeness and Complexity of the Lifted Dynamic Junction Tree\n  Algorithm\n\n  For static lifted inference algorithms, completeness, i.e., domain\nliftability, is extensively studied. However, so far no domain liftability\nresults for temporal lifted inference algorithms exist. In this paper, we close\nthis gap. More precisely, we contribute the first completeness and complexity\nanalysis for a temporal lifted algorithm, the socalled lifted dynamic junction\ntree algorithm (LDJT), which is the only exact lifted temporal inference\nalgorithm out there. To handle temporal aspects efficiently, LDJT uses\nconditional independences to proceed in time, leading to restrictions w.r.t.\nelimination orders. We show that these restrictions influence the domain\nliftability results and show that one particular case while proceeding in time,\nhas to be excluded from FO12 . Additionally, for the complexity of LDJT, we\nprove that the lifted width is in even more cases smaller than the\ncorresponding treewidth in comparison to static inference.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.03059,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000053975,
      "text":"Engagement Decision Support for Beyond Visual Range Air Combat\n\n  This work aims to provide an engagement decision support tool for Beyond\nVisual Range (BVR) air combat in the context of Defensive Counter Air (DCA)\nmissions. In BVR air combat, engagement decision refers to the choice of the\nmoment the pilot engages a target by assuming an offensive stance and executing\ncorresponding maneuvers. To model this decision, we use the Brazilian Air\nForce's Aerospace Simulation Environment (Ambiente de Simula\\c{c}\\~ao\nAeroespacial - ASA in Portuguese), which generated 3,729 constructive\nsimulations lasting 12 minutes each and a total of 10,316 engagements. We\nanalyzed all samples by an operational metric called the DCA index, which\nrepresents, based on the experience of subject matter experts, the degree of\nsuccess in this type of mission. This metric considers the distances of the\naircraft of the same team and the opposite team, the point of Combat Air\nPatrol, and the number of missiles used. By defining the engagement status\nright before it starts and the average of the DCA index throughout the\nengagement, we create a supervised learning model to determine the quality of a\nnew engagement. An algorithm based on decision trees, working with the XGBoost\nlibrary, provides a regression model to predict the DCA index with a\ncoefficient of determination close to 0.8 and a Root Mean Square Error of 0.05\nthat can furnish parameters to the BVR pilot to decide whether or not to\nengage. Thus, using data obtained through simulations, this work contributes by\nbuilding a decision support system based on machine learning for BVR air\ncombat.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.01364,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000088082,
      "text":"Learning to Explore by Reinforcement over High-Level Options\n\n  Autonomous 3D environment exploration is a fundamental task for various\napplications such as navigation. The goal of exploration is to investigate a\nnew environment and build its occupancy map efficiently. In this paper, we\npropose a new method which grants an agent two intertwined options of\nbehaviors: \"look-around\" and \"frontier navigation\". This is implemented by an\noption-critic architecture and trained by reinforcement learning algorithms. In\neach timestep, an agent produces an option and a corresponding action according\nto the policy. We also take advantage of macro-actions by incorporating classic\npath-planning techniques to increase training efficiency. We demonstrate the\neffectiveness of the proposed method on two publicly available 3D environment\ndatasets and the results show our method achieves higher coverage than\ncompeting techniques with better efficiency.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.11871,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Solve Optimization Problems with Unknown Constraint Networks\n\n  In most optimization problems, users have a clear understanding of the\nfunction to optimize (e.g., minimize the makespan for scheduling problems).\nHowever, the constraints may be difficult to state and their modelling often\nrequires expertise in Constraint Programming. Active constraint acquisition has\nbeen successfully used to support non-experienced users in learning constraint\nnetworks through the generation of a sequence of queries. In this paper, we\npropose Learn&Optimize, a method to solve optimization problems with known\nobjective function and unknown constraint network. It uses an active constraint\nacquisition algorithm which learns the unknown constraints and computes\nboundaries for the optimal solution during the learning process. As a result,\nour method allows users to solve optimization problems without learning the\noverall constraint network.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.00783,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.000000861,
      "text":"An AI-powered Smart Routing Solution for Payment Systems\n\n  In the current era of digitization, online payment systems are attracting\nconsiderable interest. Improving the efficiency of a payment system is\nimportant since it has a substantial impact on revenues for businesses. A\ngateway is an integral component of a payment system through which every\ntransaction is routed. In an online payment system, payment processors\nintegrate with these gateways by means of various configurations such as\npricing, methods, risk checks, etc. These configurations are called terminals.\nEach gateway can have multiple terminals associated with it. Routing a payment\ntransaction through the best terminal is crucial to increase the probability of\na payment transaction being successful. Machine learning (ML) and artificial\nintelligence (AI) techniques can be used to accurately predict the best\nterminals based on their previous performance and various payment-related\nattributes. We have devised a pipeline consisting of static and dynamic\nmodules. The static module does the initial filtering of the terminals using\nstatic rules and a logistic regression model that predicts gateway downtimes.\nSubsequently, the dynamic module computes a lot of novel features based on\nsuccess rate, payment attributes, time lag, etc. to model the terminal\nbehaviour accurately. These features are updated using an adaptive time decay\nrate algorithm in real-time using a feedback loop and passed to a random forest\nclassifier to predict the success probabilities for every terminal. This\npipeline is currently in production at Razorpay routing millions of\ntransactions through it in real-time and has given a 4-6\\% improvement in\nsuccess rate across all payment methods (credit card, debit card, UPI, net\nbanking). This has made our payment system more resilient to performance drops,\nwhich has improved the user experience, instilled more trust in the merchants,\nand boosted the revenue of the business.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.12677,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000873539,
      "text":"Topological and Algebraic Structures of Atanassov's Intuitionistic\n  Fuzzy-Values Space\n\n  We prove that the space of intuitionistic fuzzy values (IFVs) with a linear\norder based on a score function and an accuracy function has the same algebraic\nstructure as the one induced by a linear order based on a similarity function\nand an accuracy function. By introducing a new operator for IFVs via the linear\norder based on a score function and an accuracy function, we show that such an\noperator is a strong negation on IFVs. Moreover, we observe that the space of\nIFVs is a complete lattice and a Kleene algebra with the new operator. We also\ndemonstrate that the topological space of IFVs with the order topology induced\nby the above two linear orders is not separable and metrizable but compact and\nconnected. From some new perspectives,our results partially answer three open\nproblems posed by Atanassov [Intuitionistic Fuzzy Sets: Theory and\nApplications, Springer, 1999] and [On Intuitionistic Fuzzy Sets Theory,\nSpringer, 2012]. Furthermore, we construct an isomorphism between the spaces of\nIFVs and q-rung orthopedic fuzzy values (q-ROFVs) under the corresponding\nlinear orders. To this end, we introduce the concept of admissible similarity\nmeasures with particular orders for IFSs, extending the existing definition of\nthe similarity measure for IFSs, and construct an admissible similarity measure\nwith a linear order based on a score function and an accuracy function, which\nis effectively applied to a pattern recognition problem about the\nclassification of building materials.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.08246,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000283122,
      "text":"Self-encoding Barnacle Mating Optimizer Algorithm for Manpower\n  Scheduling in Flow Shop\n\n  Flow Shop Scheduling (FSS) has been widely researched due to its application\nin many types of fields, while the human participant brings great challenges to\nthis problem. Manpower scheduling captures attention for assigning workers with\ndiverse proficiency to the appropriate stages, which is of great significance\nto production efficiency.\n  In this paper, we present a novel algorithm called Self-encoding Barnacle\nMating Optimizer (SBMO), which solves the FSS problem considering worker\nproficiency, defined as a new problem, Flow Shop Manpower Scheduling Problem\n(FSMSP). The highlight of the SBMO algorithm is the combination with the\nencoding method, crossover and mutation operators. Moreover, in order to solve\nthe local optimum problem, we design a neighborhood search scheme. Finally, the\nextensive comparison simulations are conducted to demonstrate the superiority\nof the proposed SBMO. The results indicate the effectiveness of SBMO in\napproximate ratio, powerful stability, and execution time, compared with the\nclassic and popular counterparts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.00797,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000086096,
      "text":"A Feedback Integrated Web-Based Multi-Criteria Group Decision Support\n  Model for Contractor Selection using Fuzzy Analytic Hierarchy Process\n\n  In this paper, a feedback integrated multi-criteria group decision support\nmodel for contractor selection was proposed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.02123,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000015563,
      "text":"Marriage is a Peach and a Chalice: Modelling Cultural Symbolism on the\n  SemanticWeb\n\n  In this work, we fill the gap in the Semantic Web in the context of Cultural\nSymbolism. Building upon earlier work in, we introduce the Simulation Ontology,\nan ontology that models the background knowledge of symbolic meanings,\ndeveloped by combining the concepts taken from the authoritative theory of\nSimulacra and Simulations of Jean Baudrillard with symbolic structures and\ncontent taken from \"Symbolism: a Comprehensive Dictionary\" by Steven Olderr. We\nre-engineered the symbolic knowledge already present in heterogeneous resources\nby converting it into our ontology schema to create HyperReal, the first\nknowledge graph completely dedicated to cultural symbolism. A first experiment\nrun on the knowledge graph is presented to show the potential of quantitative\nresearch on symbolism.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.01726,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000007285,
      "text":"Instructive artificial intelligence (AI) for human training, assistance,\n  and explainability\n\n  We propose a novel approach to explainable AI (XAI) based on the concept of\n\"instruction\" from neural networks. In this case study, we demonstrate how a\nsuperhuman neural network might instruct human trainees as an alternative to\ntraditional approaches to XAI. Specifically, an AI examines human actions and\ncalculates variations on the human strategy that lead to better performance.\nExperiments with a JHU\/APL-developed AI player for the cooperative card game\nHanabi suggest this technique makes unique contributions to explainability\nwhile improving human performance. One area of focus for Instructive AI is in\nthe significant discrepancies that can arise between a human's actual strategy\nand the strategy they profess to use. This inaccurate self-assessment presents\na barrier for XAI, since explanations of an AI's strategy may not be properly\nunderstood or implemented by human recipients. We have developed and are\ntesting a novel, Instructive AI approach that estimates human strategy by\nobserving human actions. With neural networks, this allows a direct calculation\nof the changes in weights needed to improve the human strategy to better\nemulate a more successful AI. Subjected to constraints (e.g. sparsity) these\nweight changes can be interpreted as recommended changes to human strategy\n(e.g. \"value A more, and value B less\"). Instruction from AI such as this\nfunctions both to help humans perform better at tasks, but also to better\nunderstand, anticipate, and correct the actions of an AI. Results will be\npresented on AI instruction's ability to improve human decision-making and\nhuman-AI teaming in Hanabi.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.07779,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.000001457,
      "text":"Overcoming Digital Gravity when using AI in Public Health Decisions\n\n  In popular usage, Data Gravity refers to the ability of a body of data to\nattract applications, services and other data. In this work we introduce a\nbroader concept, \"Digital Gravity\" which includes not just data, but other\nelements of the AI\/ML workflow. This concept is born out of our recent\nexperiences in developing and deploying an AI-based decision support platform\nintended for use in a public health context. In addition to data, examples of\nadditional considerations are compute (infrastructure and software), DevSecOps\n(personnel and practices), algorithms\/programs, control planes, middleware\n(considered separately from programs), and even companies\/service providers. We\ndiscuss the impact of Digital Gravity on the pathway to adoption and suggest\npreliminary approaches to conceptualize and mitigate the friction caused by it.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.08486,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Neural Class Expression Synthesis\n\n  Many applications require explainable node classification in knowledge\ngraphs. Towards this end, a popular ``white-box'' approach is class expression\nlearning: Given sets of positive and negative nodes, class expressions in\ndescription logics are learned that separate positive from negative nodes. Most\nexisting approaches are search-based approaches generating many candidate class\nexpressions and selecting the best one. However, they often take a long time to\nfind suitable class expressions. In this paper, we cast class expression\nlearning as a translation problem and propose a new family of class expression\nlearning approaches which we dub neural class expression synthesizers. Training\nexamples are ``translated'' into class expressions in a fashion akin to machine\ntranslation. Consequently, our synthesizers are not subject to the runtime\nlimitations of search-based approaches. We study three instances of this novel\nfamily of approaches based on LSTMs, GRUs, and set transformers, respectively.\nAn evaluation of our approach on four benchmark datasets suggests that it can\neffectively synthesize high-quality class expressions with respect to the input\nexamples in approximately one second on average. Moreover, a comparison to\nstate-of-the-art approaches suggests that we achieve better F-measures on large\ndatasets. For reproducibility purposes, we provide our implementation as well\nas pretrained models in our public GitHub repository at\nhttps:\/\/github.com\/dice-group\/NeuralClassExpressionSynthesis\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.09475,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000020862,
      "text":"Lifelong Reinforcement Learning with Temporal Logic Formulas and Reward\n  Machines\n\n  Continuously learning new tasks using high-level ideas or knowledge is a key\ncapability of humans. In this paper, we propose Lifelong reinforcement learning\nwith Sequential linear temporal logic formulas and Reward Machines (LSRM),\nwhich enables an agent to leverage previously learned knowledge to fasten\nlearning of logically specified tasks. For the sake of more flexible\nspecification of tasks, we first introduce Sequential Linear Temporal Logic\n(SLTL), which is a supplement to the existing Linear Temporal Logic (LTL)\nformal language. We then utilize Reward Machines (RM) to exploit structural\nreward functions for tasks encoded with high-level events, and propose\nautomatic extension of RM and efficient knowledge transfer over tasks for\ncontinuous learning in lifetime. Experimental results show that LSRM\noutperforms the methods that learn the target tasks from scratch by taking\nadvantage of the task decomposition using SLTL and knowledge transfer over RM\nduring the lifelong learning process.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.11779,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000003974,
      "text":"Answering Fuzzy Queries over Fuzzy DL-Lite Ontologies\n\n  A prominent problem in knowledge representation is how to answer queries\ntaking into account also the implicit consequences of an ontology representing\ndomain knowledge. While this problem has been widely studied within the realm\nof description logic ontologies, it has been surprisingly neglected within the\ncontext of vague or imprecise knowledge, particularly from the point of view of\nmathematical fuzzy logic. In this paper we study the problem of answering\nconjunctive queries and threshold queries w.r.t. ontologies in fuzzy DL-Lite.\nSpecifically, we show through a rewriting approach that threshold query\nanswering w.r.t. consistent ontologies remains in $AC_0$ in data complexity,\nbut that conjunctive query answering is highly dependent on the selected\ntriangular norm, which has an impact on the underlying semantics. For the\nidempodent G\\\"odel t-norm, we provide an effective method based on a reduction\nto the classical case. This paper is under consideration in Theory and Practice\nof Logic Programming (TPLP).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.13271,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000032451,
      "text":"Designing a Trusted Data Brokerage Framework in the Aviation Domain\n\n  In recent years, there is growing interest in the ways the European aviation\nindustry can leverage the multi-source data fusion towards augmented domain\nintelligence. However, privacy, legal and organisational policies together with\ntechnical limitations, hinder data sharing and, thus, its benefits. The current\npaper presents the ICARUS data policy and assets brokerage framework, which\naims to (a) formalise the data attributes and qualities that affect how\naviation data assets can be shared and handled subsequently to their\nacquisition, including licenses, IPR, characterisation of sensitivity and\nprivacy risks, and (b) enable the creation of machine-processable data\ncontracts for the aviation industry. This involves expressing contractual terms\npertaining to data trading agreements into a machine-processable language and\nsupporting the diverse interactions among stakeholders in aviation data sharing\nscenarios through a trusted and robust system based on the Ethereum platform.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.03472,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"Savile Row Manual\n\n  We describe the constraint modelling tool Savile Row, its input language and\nits main features. Savile Row translates a solver-independent constraint\nmodelling language to the input languages for various solvers including\nconstraint, SAT, and SMT solvers. After a brief introduction, the manual\ndescribes the Essence Prime language, which is the input language of Savile\nRow. Then we describe the functions of the tool, its main features and options\nand how to install and use it.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.09078,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.000008146,
      "text":"Green CWS: Extreme Distillation and Efficient Decode Method Towards\n  Industrial Application\n\n  Benefiting from the strong ability of the pre-trained model, the research on\nChinese Word Segmentation (CWS) has made great progress in recent years.\nHowever, due to massive computation, large and complex models are incapable of\nempowering their ability for industrial use. On the other hand, for\nlow-resource scenarios, the prevalent decode method, such as Conditional Random\nField (CRF), fails to exploit the full information of the training data. This\nwork proposes a fast and accurate CWS framework that incorporates a\nlight-weighted model and an upgraded decode method (PCRF) towards industrially\nlow-resource CWS scenarios. First, we distill a Transformer-based student model\nas an encoder, which not only accelerates the inference speed but also combines\nopen knowledge and domain-specific knowledge. Second, the perplexity score to\nevaluate the language model is fused into the CRF module to better identify the\nword boundaries. Experiments show that our work obtains relatively high\nperformance on multiple datasets with as low as 14\\% of time consumption\ncompared with the original BERT-based model. Moreover, under the low-resource\nsetting, we get superior results in comparison with the traditional decoding\nmethods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.06854,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"Time in a Box: Advancing Knowledge Graph Completion with Temporal Scopes\n\n  Almost all statements in knowledge bases have a temporal scope during which\nthey are valid. Hence, knowledge base completion (KBC) on temporal knowledge\nbases (TKB), where each statement \\textit{may} be associated with a temporal\nscope, has attracted growing attention. Prior works assume that each statement\nin a TKB \\textit{must} be associated with a temporal scope. This ignores the\nfact that the scoping information is commonly missing in a KB. Thus prior work\nis typically incapable of handling generic use cases where a TKB is composed of\ntemporal statements with\/without a known temporal scope. In order to address\nthis issue, we establish a new knowledge base embedding framework, called\nTIME2BOX, that can deal with atemporal and temporal statements of different\ntypes simultaneously. Our main insight is that answers to a temporal query\nalways belong to a subset of answers to a time-agnostic counterpart. Put\ndifferently, time is a filter that helps pick out answers to be correct during\ncertain periods. We introduce boxes to represent a set of answer entities to a\ntime-agnostic query. The filtering functionality of time is modeled by\nintersections over these boxes. In addition, we generalize current evaluation\nprotocols on time interval prediction. We describe experiments on two datasets\nand show that the proposed method outperforms state-of-the-art (SOTA) methods\non both link prediction and time prediction.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.07568,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000046028,
      "text":"Can Graph Neural Networks Learn to Solve MaxSAT Problem?\n\n  With the rapid development of deep learning techniques, various recent work\nhas tried to apply graph neural networks (GNNs) to solve NP-hard problems such\nas Boolean Satisfiability (SAT), which shows the potential in bridging the gap\nbetween machine learning and symbolic reasoning. However, the quality of\nsolutions predicted by GNNs has not been well investigated in the literature.\nIn this paper, we study the capability of GNNs in learning to solve Maximum\nSatisfiability (MaxSAT) problem, both from theoretical and practical\nperspectives. We build two kinds of GNN models to learn the solution of MaxSAT\ninstances from benchmarks, and show that GNNs have attractive potential to\nsolve MaxSAT problem through experimental evaluation. We also present a\ntheoretical explanation of the effect that GNNs can learn to solve MaxSAT\nproblem to some extent for the first time, based on the algorithmic alignment\ntheory.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.02244,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000021855,
      "text":"Exploring Explainable AI in the Financial Sector: Perspectives of Banks\n  and Supervisory Authorities\n\n  Explainable artificial intelligence (xAI) is seen as a solution to making AI\nsystems less of a black box. It is essential to ensure transparency, fairness,\nand accountability, which are especially paramount in the financial sector. The\naim of this study was a preliminary investigation of the perspectives of\nsupervisory authorities and regulated entities regarding the application of xAI\nin the fi-nancial sector. Three use cases (consumer credit, credit risk, and\nanti-money laundering) were examined using semi-structured interviews at three\nbanks and two supervisory authorities in the Netherlands. We found that for the\ninvestigated use cases a disparity exists between supervisory authorities and\nbanks regarding the desired scope of explainability of AI systems. We argue\nthat the financial sector could benefit from clear differentiation between\ntechnical AI (model) ex-plainability requirements and explainability\nrequirements of the broader AI system in relation to applicable laws and\nregulations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2111.15108,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"Interval-valued q-Rung Orthopair Fuzzy Choquet Integral Operators and\n  Its Application in Group Decision Making\n\n  It is more flexible for decision makers to evaluate by interval-valued q-rung\northopair fuzzy set (IVq-ROFS),which offers fuzzy decision-making more\napplicational space. Meanwhile, Choquet integralses non-additive set function\n(fuzzy measure) to describe the interaction between attributes directly.In\nparticular, there are a large number of practical issues that have relevance\nbetween attributes.Therefore,this paper proposes the correlation operator and\ngroup decision-making method based on the interval-valued q-rung orthopair\nfuzzy set Choquet integral.First,interval-valued q-rung orthopair fuzzy Choquet\nintegral average operator (IVq-ROFCA) and interval-valued q-rung orthopair\nfuzzy Choquet integral geometric operator (IVq-ROFCG) are inves-tigated,and\ntheir basic properties are proved.Furthermore, several operators based on\nIVq-ROFCA and IVq-ROFCG are developed. Then, a group decision-making method\nbased on IVq-ROFCA is developed,which can solve the decision making problems\nwith interaction between attributes.Finally,through the implementation of the\nwarning management system for hypertension,it is shown that the operator and\ngroup decision-making method proposed in this paper can handle complex\ndecision-making cases in reality, and the decision result is consistent with\nthe doctor's diagnosis result.Moreover,the comparison with the results of other\noperators shows that the proposed operators and group decision-making method\nare correct and effective,and the decision result will not be affected by the\nchange of q value.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.1448,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"On some Foundational Aspects of Human-Centered Artificial Intelligence\n\n  The burgeoning of AI has prompted recommendations that AI techniques should\nbe \"human-centered\". However, there is no clear definition of what is meant by\nHuman Centered Artificial Intelligence, or for short, HCAI. This paper aims to\nimprove this situation by addressing some foundational aspects of HCAI. To do\nso, we introduce the term HCAI agent to refer to any physical or software\ncomputational agent equipped with AI components and that interacts and\/or\ncollaborates with humans. This article identifies five main conceptual\ncomponents that participate in an HCAI agent: Observations, Requirements,\nActions, Explanations and Models. We see the notion of HCAI agent, together\nwith its components and functions, as a way to bridge the technical and\nnon-technical discussions on human-centered AI. In this paper, we focus our\nanalysis on scenarios consisting of a single agent operating in dynamic\nenvironments in presence of humans.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.15221,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Constraint Sampling Reinforcement Learning: Incorporating Expertise For\n  Faster Learning\n\n  Online reinforcement learning (RL) algorithms are often difficult to deploy\nin complex human-facing applications as they may learn slowly and have poor\nearly performance. To address this, we introduce a practical algorithm for\nincorporating human insight to speed learning. Our algorithm, Constraint\nSampling Reinforcement Learning (CSRL), incorporates prior domain knowledge as\nconstraints\/restrictions on the RL policy. It takes in multiple potential\npolicy constraints to maintain robustness to misspecification of individual\nconstraints while leveraging helpful ones to learn quickly. Given a base RL\nlearning algorithm (ex. UCRL, DQN, Rainbow) we propose an upper confidence with\nelimination scheme that leverages the relationship between the constraints, and\ntheir observed performance, to adaptively switch among them. We instantiate our\nalgorithm with DQN-type algorithms and UCRL as base algorithms, and evaluate\nour algorithm in four environments, including three simulators based on real\ndata: recommendations, educational activity sequencing, and HIV treatment\nsequencing. In all cases, CSRL learns a good policy faster than baselines.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.13477,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000004669,
      "text":"A Brief History of Updates of Answer-Set Programs\n\n  Over the last couple of decades, there has been a considerable effort devoted\nto the problem of updating logic programs under the stable model semantics\n(a.k.a. answer-set programs) or, in other words, the problem of characterising\nthe result of bringing up-to-date a logic program when the world it describes\nchanges. Whereas the state-of-the-art approaches are guided by the same basic\nintuitions and aspirations as belief updates in the context of classical logic,\nthey build upon fundamentally different principles and methods, which have\nprevented a unifying framework that could embrace both belief and rule updates.\nIn this paper, we will overview some of the main approaches and results related\nto answer-set programming updates, while pointing out some of the main\nchallenges that research in this topic has faced.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.04286,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000293718,
      "text":"TempAMLSI : Temporal Action Model Learning based on Grammar Induction\n\n  Hand-encoding PDDL domains is generally accepted as difficult, tedious and\nerror-prone. The difficulty is even greater when temporal domains have to be\nencoded. Indeed, actions have a duration and their effects are not\ninstantaneous. In this paper, we present TempAMLSI, an algorithm based on the\nAMLSI approach able to learn temporal domains. TempAMLSI is based on the\nclassical assumption done in temporal planning that it is possible to convert a\nnon-temporal domain into a temporal domain. TempAMLSI is the first approach\nable to learn temporal domain with single hard envelope and Cushing's\nintervals. We show experimentally that TempAMLSI is able to learn accurate\ntemporal domains, i.e., temporal domain that can be used directly to solve new\nplanning problem, with different forms of action concurrency.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.05638,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000001755,
      "text":"DistilCSE: Effective Knowledge Distillation For Contrastive Sentence\n  Embeddings\n\n  Large-scale contrastive learning models can learn very informative sentence\nembeddings, but are hard to serve online due to the huge model size. Therefore,\nthey often play the role of \"teacher\", transferring abilities to small\n\"student\" models through knowledge distillation. However, knowledge\ndistillation inevitably brings some drop in embedding effect. To tackle that,\nwe propose an effective knowledge distillation framework for contrastive\nsentence embeddings, termed DistilCSE. It first applies knowledge distillation\non a large amount of unlabeled data, and then fine-tunes student models through\ncontrastive learning on limited labeled data. To achieve better distillation\nresults, we further propose Contrastive Knowledge Distillation (CKD). CKD uses\nInfoNCE as the loss function in knowledge distillation, enhancing the objective\nconsistency among teacher model training, knowledge distillation, and student\nmodel fine-tuning. Extensive experiments show that student models trained with\nthe proposed DistilCSE and CKD suffer from little or even no performance\ndecrease and consistently outperform the corresponding counterparts of the same\nparameter size. Impressively, our 110M student model outperforms the latest\nstate-of-the-art model, i.e., Sentence-T5 (11B), with only 1% parameters and\n0.25% unlabeled data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.03168,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000068545,
      "text":"Tele-EvalNet: A Low-cost, Teleconsultation System for Home based\n  Rehabilitation of Stroke Survivors using Multiscale CNN-LSTM Architecture\n\n  Technology has an important role to play in the field of Rehabilitation,\nimproving patient outcomes and reducing healthcare costs. However, existing\napproaches lack clinical validation, robustness and ease of use. We propose\nTele-EvalNet, a novel system consisting of two components: a live feedback\nmodel and an overall performance evaluation model. The live feedback model\ndemonstrates feedback on exercise correctness with easy to understand\ninstructions highlighted using color markers. The overall performance\nevaluation model learns a mapping of joint data to scores, given to the\nperformance by clinicians. The model does this by extracting clinically\napproved features from joint data. Further, these features are encoded to a\nlower dimensional space with an autoencoder. A novel multi-scale CNN-LSTM\nnetwork is proposed to learn a mapping of performance data to the scores by\nleveraging features extracted at multiple scales. The proposed system shows a\nhigh degree of improvement in score predictions and outperforms the\nstate-of-the-art rehabilitation models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.07867,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000045035,
      "text":"Interscript: A dataset for interactive learning of scripts through error\n  feedback\n\n  How can an end-user provide feedback if a deployed structured prediction\nmodel generates inconsistent output, ignoring the structural complexity of\nhuman language? This is an emerging topic with recent progress in synthetic or\nconstrained settings, and the next big leap would require testing and tuning\nmodels in real-world settings. We present a new dataset, Interscript,\ncontaining user feedback on a deployed model that generates complex everyday\ntasks. Interscript contains 8,466 data points -- the input is a possibly\nerroneous script and a user feedback, and the output is a modified script. We\nposit two use-cases of \\ours that might significantly advance the\nstate-of-the-art in interactive learning. The dataset is available at:\nhttps:\/\/github.com\/allenai\/interscript.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.04751,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000101659,
      "text":"Co-evolutionary hybrid intelligence\n\n  Artificial intelligence is one of the drivers of modern technological\ndevelopment. The current approach to the development of intelligent systems is\ndata-centric. It has several limitations: it is fundamentally impossible to\ncollect data for modeling complex objects and processes; training neural\nnetworks requires huge computational and energy resources; solutions are not\nexplainable. The article discusses an alternative approach to the development\nof artificial intelligence systems based on human-machine hybridization and\ntheir co-evolution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.04145,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000035432,
      "text":"A Review for Deep Reinforcement Learning in Atari:Benchmarks,\n  Challenges, and Solutions\n\n  The Arcade Learning Environment (ALE) is proposed as an evaluation platform\nfor empirically assessing the generality of agents across dozens of Atari 2600\ngames. ALE offers various challenging problems and has drawn significant\nattention from the deep reinforcement learning (RL) community. From Deep\nQ-Networks (DQN) to Agent57, RL agents seem to achieve superhuman performance\nin ALE. However, is this the case? In this paper, to explore this problem, we\nfirst review the current evaluation metrics in the Atari benchmarks and then\nreveal that the current evaluation criteria of achieving superhuman performance\nare inappropriate, which underestimated the human performance relative to what\nis possible. To handle those problems and promote the development of RL\nresearch, we propose a novel Atari benchmark based on human world records\n(HWR), which puts forward higher requirements for RL agents on both final\nperformance and learning efficiency. Furthermore, we summarize the\nstate-of-the-art (SOTA) methods in Atari benchmarks and provide benchmark\nresults over new evaluation metrics based on human world records. We concluded\nthat at least four open challenges hinder RL agents from achieving superhuman\nperformance from those new benchmark results. Finally, we also discuss some\npromising ways to handle those problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.01451,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000020199,
      "text":"Architecting and Visualizing Deep Reinforcement Learning Models\n\n  To meet the growing interest in Deep Reinforcement Learning (DRL), we sought\nto construct a DRL-driven Atari Pong agent and accompanying visualization tool.\nExisting approaches do not support the flexibility required to create an\ninteractive exhibit with easily-configurable physics and a human-controlled\nplayer. Therefore, we constructed a new Pong game environment, discovered and\naddressed a number of unique data deficiencies that arise when applying DRL to\na new environment, architected and tuned a policy gradient based DRL model,\ndeveloped a real-time network visualization, and combined these elements into\nan interactive display to help build intuition and awareness of the mechanics\nof DRL inference.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.02333,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"LoNLI: An Extensible Framework for Testing Diverse Logical Reasoning\n  Capabilities for NLI\n\n  Natural Language Inference (NLI) is considered a representative task to test\nnatural language understanding (NLU). In this work, we propose an extensible\nframework to collectively yet categorically test diverse Logical reasoning\ncapabilities required for NLI (and, by extension, NLU). Motivated by behavioral\ntesting, we create a semi-synthetic large test bench (363 templates, 363k\nexamples) and an associated framework that offers the following utilities: 1)\nindividually test and analyze reasoning capabilities along 17 reasoning\ndimensions (including pragmatic reasoning); 2) design experiments to study\ncross-capability information content (leave one out or bring one in); and 3)\nthe synthetic nature enables us to control for artifacts and biases. We extend\na publicly available framework of automated test case instantiation from\nfree-form natural language templates (CheckList) and a well-defined taxonomy of\ncapabilities to cover a wide range of increasingly harder test cases while\nvarying the complexity of natural language. Through our analysis of\nstate-of-the-art NLI systems, we observe that our benchmark is indeed hard (and\nnon-trivial even with training on additional resources). Some capabilities\nstand out as harder. Further, fine-grained analysis and fine-tuning experiments\nreveal more insights about these capabilities and the models -- supporting and\nextending previous observations; thus showing the utility of the proposed\ntestbench.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.05434,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"A Reinforcement Learning-based Adaptive Control Model for Future Street\n  Planning, An Algorithm and A Case Study\n\n  With the emerging technologies in Intelligent Transportation System (ITS),\nthe adaptive operation of road space is likely to be realised within decades.\nAn intelligent street can learn and improve its decision-making on the\nright-of-way (ROW) for road users, liberating more active pedestrian space\nwhile maintaining traffic safety and efficiency. However, there is a lack of\neffective controlling techniques for these adaptive street infrastructures. To\nfill this gap in existing studies, we formulate this control problem as a\nMarkov Game and develop a solution based on the multi-agent Deep Deterministic\nPolicy Gradient (MADDPG) algorithm. The proposed model can dynamically assign\nROW for sidewalks, autonomous vehicles (AVs) driving lanes and on-street\nparking areas in real-time. Integrated with the SUMO traffic simulator, this\nmodel was evaluated using the road network of the South Kensington District\nagainst three cases of divergent traffic conditions: pedestrian flow rates, AVs\ntraffic flow rates and parking demands. Results reveal that our model can\nachieve an average reduction of 3.87% and 6.26% in street space assigned for\non-street parking and vehicular operations. Combined with space gained by\nlimiting the number of driving lanes, the average proportion of sidewalks to\ntotal widths of streets can significantly increase by 10.13%.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.12754,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000008278,
      "text":"Toward a New Science of Common Sense\n\n  Common sense has always been of interest in Artificial Intelligence, but has\nrarely taken center stage. Despite its mention in one of John McCarthy's\nearliest papers and years of work by dedicated researchers, arguably no AI\nsystem with a serious amount of general common sense has ever emerged. Why is\nthat? What's missing? Examples of AI systems' failures of common sense abound,\nand they point to AI's frequent focus on expertise as the cause. Those\nattempting to break the resulting brittleness barrier, even in the context of\nmodern deep learning, have tended to invest their energy in large numbers of\nsmall bits of commonsense knowledge. While important, all the commonsense\nknowledge fragments in the world don't add up to a system that actually\ndemonstrates common sense in a human-like way. We advocate examining common\nsense from a broader perspective than in the past. Common sense should be\nconsidered in the context of a full cognitive system with history, goals,\ndesires, and drives, not just in isolated circumscribed examples. A fresh look\nis needed: common sense is worthy of its own dedicated scientific exploration.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.06917,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000088082,
      "text":"Branching Strategy Selection Approach Based on Vivification Ratio\n\n  The two most effective branching strategies LRB and VSIDS perform differently\non different types of instances. Generally, LRB is more effective on crafted\ninstances, while VSIDS is more effective on application ones. However,\ndistinguishing the types of instances is difficult. To overcome this drawback,\nwe propose a branching strategy selection approach based on the vivification\nratio. This approach uses the LRB branching strategy more to solve the\ninstances with a very low vivification ratio. We tested the instances from the\nmain track of SAT competitions in recent years. The results show that the\nproposed approach is robust and it significantly increases the number of solved\ninstances. It is worth mentioning that, with the help of our approach, the\nsolver Maple\\_CM can solve more than 16 instances for the benchmark from the\n2020 SAT competition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.00848,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000014901,
      "text":"First Steps of an Approach to the ARC Challenge based on Descriptive\n  Grid Models and the Minimum Description Length Principle\n\n  The Abstraction and Reasoning Corpus (ARC) was recently introduced by\nFran\\c{c}ois Chollet as a tool to measure broad intelligence in both humans and\nmachines. It is very challenging, and the best approach in a Kaggle competition\ncould only solve 20% of the tasks, relying on brute-force search for chains of\nhand-crafted transformations. In this paper, we present the first steps\nexploring an approach based on descriptive grid models and the Minimum\nDescription Length (MDL) principle. The grid models describe the contents of a\ngrid, and support both parsing grids and generating grids. The MDL principle is\nused to guide the search for good models, i.e. models that compress the grids\nthe most. We report on our progress over a year, improving on the general\napproach and the models. Out of the 400 training tasks, our performance\nincreased from 5 to 29 solved tasks, only using 30s computation time per task.\nOur approach not only predicts the output grids, but also outputs an\nintelligible model and explanations for how the model was incrementally built.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.05742,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000010928,
      "text":"A Puzzle-Based Dataset for Natural Language Inference\n\nWe provide here a dataset for tasks related to natural language understanding and natural language inference. The dataset contains logical puzzles in natural language from three domains: comparing puzzles, knighs and knaves, and zebra puzzles. Each puzzle is associated with the entire set of atomic questions that can be generated based on the relations and individuals occurring in the text. For each question we provide the correct answer: entailment, contradiction or ambiguity. The answer's correctness is verified against theorem provers. Good puzzles have two properties: (i) each piece of information is necessary and (ii) no unnecessary information is provided. These properties make puzzles interesting candidates for machine comprehension tasks.",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.01671,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000033114,
      "text":"An Automatic Approach for Generating Rich, Linked Geo-Metadata from\n  Historical Map Images\n\n  Historical maps contain detailed geographic information difficult to find\nelsewhere covering long-periods of time (e.g., 125 years for the historical\ntopographic maps in the US). However, these maps typically exist as scanned\nimages without searchable metadata. Existing approaches making historical maps\nsearchable rely on tedious manual work (including crowd-sourcing) to generate\nthe metadata (e.g., geolocations and keywords). Optical character recognition\n(OCR) software could alleviate the required manual work, but the recognition\nresults are individual words instead of location phrases (e.g., \"Black\" and\n\"Mountain\" vs. \"Black Mountain\"). This paper presents an end-to-end approach to\naddress the real-world problem of finding and indexing historical map images.\nThis approach automatically processes historical map images to extract their\ntext content and generates a set of metadata that is linked to large external\ngeospatial knowledge bases. The linked metadata in the RDF (Resource\nDescription Framework) format support complex queries for finding and indexing\nhistorical maps, such as retrieving all historical maps covering mountain peaks\nhigher than 1,000 meters in California. We have implemented the approach in a\nsystem called mapKurator. We have evaluated mapKurator using historical maps\nfrom several sources with various map styles, scales, and coverage. Our results\nshow significant improvement over the state-of-the-art methods. The code has\nbeen made publicly available as modules of the Kartta Labs project at\nhttps:\/\/github.com\/kartta-labs\/Project.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.0678,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000470214,
      "text":"Explanation Container in Case-Based Biomedical Question-Answering\n\n  The National Center for Advancing Translational Sciences(NCATS) Biomedical\nData Translator (Translator) aims to attenuate problems faced by translational\nscientists. Translator is a multi-agent architecture consisting of six\nautonomous relay agents (ARAs) and eight knowledge providers (KPs). In this\npaper, we present the design of the Explanatory Agent (xARA), a case-based ARA\nthat answers biomedical queries by accessing multiple KPs, ranking results, and\nexplaining the ranking of results. The Explanatory Agent is designed with five\nknowledge containers that include the four original knowledge containers and\none additional container for explanation - the Explanation Container. The\nExplanation Container is case-based and designed with its own knowledge\ncontainers.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.12876,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000020862,
      "text":"Learning to Walk with Dual Agents for Knowledge Graph Reasoning\n\n  Graph walking based on reinforcement learning (RL) has shown great success in\nnavigating an agent to automatically complete various reasoning tasks over an\nincomplete knowledge graph (KG) by exploring multi-hop relational paths.\nHowever, existing multi-hop reasoning approaches only work well on short\nreasoning paths and tend to miss the target entity with the increasing path\nlength. This is undesirable for many reason-ing tasks in real-world scenarios,\nwhere short paths connecting the source and target entities are not available\nin incomplete KGs, and thus the reasoning performances drop drastically unless\nthe agent is able to seek out more clues from longer paths. To address the\nabove challenge, in this paper, we propose a dual-agent reinforcement learning\nframework, which trains two agents (GIANT and DWARF) to walk over a KG jointly\nand search for the answer collaboratively. Our approach tackles the reasoning\nchallenge in long paths by assigning one of the agents (GIANT) searching on\ncluster-level paths quickly and providing stage-wise hints for another agent\n(DWARF). Finally, experimental results on several KG reasoning benchmarks show\nthat our approach can search answers more accurately and efficiently, and\noutperforms existing RL-based methods for long path queries by a large margin.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2112.14243,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2021,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000116229,
      "text":"An AGM Approach to Revising Preferences\n\n  We look at preference change arising out of an interaction between two\nelements: the first is an initial preference ranking encoding a pre-existing\nattitude; the second element is new preference information signaling input from\nan authoritative source, which may come into conflict with the initial\npreference. The aim is to adjust the initial preference and bring it in line\nwith the new preference, without having to give up more information than\nnecessary. We model this process using the formal machinery of belief change,\nalong the lines of the well-known AGM approach. We propose a set of fundamental\nrationality postulates, and derive the main results of the paper: a set of\nrepresentation theorems showing that preference change according to these\npostulates can be rationalized as a choice function guided by a ranking on the\ncomparisons in the initial preference order. We conclude by presenting\noperators satisfying our proposed postulates. Our approach thus allows us to\nsituate preference revision within the larger family of belief change\noperators.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.0976,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000497699,
      "text":"Multi-Graph Fusion Networks for Urban Region Embedding\n\n  Learning the embeddings for urban regions from human mobility data can reveal\nthe functionality of regions, and then enables the correlated but distinct\ntasks such as crime prediction. Human mobility data contains rich but abundant\ninformation, which yields to the comprehensive region embeddings for cross\ndomain tasks. In this paper, we propose multi-graph fusion networks (MGFN) to\nenable the cross domain prediction tasks. First, we integrate the graphs with\nspatio-temporal similarity as mobility patterns through a mobility graph fusion\nmodule. Then, in the mobility pattern joint learning module, we design the\nmulti-level cross-attention mechanism to learn the comprehensive embeddings\nfrom multiple mobility patterns based on intra-pattern and inter-pattern\nmessages. Finally, we conduct extensive experiments on real-world urban\ndatasets. Experimental results demonstrate that the proposed MGFN outperforms\nthe state-of-the-art methods by up to 12.35% improvement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.08017,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000088082,
      "text":"Fine-Grained Trajectory-based Travel Time Estimation for Multi-city\n  Scenarios Based on Deep Meta-Learning\n\n  Travel Time Estimation (TTE) is indispensable in intelligent transportation\nsystem (ITS). It is significant to achieve the fine-grained Trajectory-based\nTravel Time Estimation (TTTE) for multi-city scenarios, namely to accurately\nestimate travel time of the given trajectory for multiple city scenarios.\nHowever, it faces great challenges due to complex factors including dynamic\ntemporal dependencies and fine-grained spatial dependencies. To tackle these\nchallenges, we propose a meta learning based framework, MetaTTE, to\ncontinuously provide accurate travel time estimation over time by leveraging\nwell-designed deep neural network model called DED, which consists of Data\npreprocessing module and Encoder-Decoder network module. By introducing meta\nlearning techniques, the generalization ability of MetaTTE is enhanced using\nsmall amount of examples, which opens up new opportunities to increase the\npotential of achieving consistent performance on TTTE when traffic conditions\nand road networks change over time in the future. The DED model adopts an\nencoder-decoder network to capture fine-grained spatial and temporal\nrepresentations. Extensive experiments on two real-world datasets are conducted\nto confirm that our MetaTTE outperforms six state-of-art baselines, and improve\n29.35% and 25.93% accuracy than the best baseline on Chengdu and Porto\ndatasets, respectively.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.06692,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Explainable Decision Making with Lean and Argumentative Explanations\n\n  It is widely acknowledged that transparency of automated decision making is\ncrucial for deployability of intelligent systems, and explaining the reasons\nwhy some decisions are \"good\" and some are not is a way to achieving this\ntransparency. We consider two variants of decision making, where \"good\"\ndecisions amount to alternatives (i) meeting \"most\" goals, and (ii) meeting\n\"most preferred\" goals. We then define, for each variant and notion of\n\"goodness\" (corresponding to a number of existing notions in the literature),\nexplanations in two formats, for justifying the selection of an alternative to\naudiences with differing needs and competences: lean explanations, in terms of\ngoals satisfied and, for some notions of \"goodness\", alternative decisions, and\nargumentative explanations, reflecting the decision process leading to the\nselection, while corresponding to the lean explanations. To define\nargumentative explanations, we use assumption-based argumentation (ABA), a\nwell-known form of structured argumentation. Specifically, we define ABA\nframeworks such that \"good\" decisions are admissible ABA arguments and draw\nargumentative explanations from dispute trees sanctioning this admissibility.\nFinally, we instantiate our overall framework for explainable decision-making\nto accommodate connections between goals and decisions in terms of decision\ngraphs incorporating defeasible and non-defeasible information.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.06254,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000012583,
      "text":"Exploit Customer Life-time Value with Memoryless Experiments\n\n  As a measure of the long-term contribution produced by customers in a service\nor product relationship, life-time value, or LTV, can more comprehensively find\nthe optimal strategy for service delivery. However, it is challenging to\naccurately abstract the LTV scene, model it reasonably, and find the optimal\nsolution. The current theories either cannot precisely express LTV because of\nthe single modeling structure, or there is no efficient solution. We propose a\ngeneral LTV modeling method, which solves the problem that customers' long-term\ncontribution is difficult to quantify while existing methods, such as modeling\nthe click-through rate, only pursue the short-term contribution. At the same\ntime, we also propose a fast dynamic programming solution based on a mutated\nbisection method and the memoryless repeated experiments assumption. The model\nand method can be applied to different service scenarios, such as the\nrecommendation system. Experiments on real-world datasets confirm the\neffectiveness of the proposed model and optimization method. In addition, this\nwhole LTV structure was deployed at a large E-commerce mobile phone\napplication, where it managed to select optimal push message sending time and\nachieved a 10\\% LTV improvement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.0591,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000062585,
      "text":"An Automatic Ontology Generation Framework with An Organizational\n  Perspective\n\n  Ontologies have been known for their semantic representation of knowledge.\nontologies cannot automatically evolve to reflect updates that occur in\nrespective domains. To address this limitation, researchers have called for\nautomatic ontology generation from unstructured text corpus. Unfortunately,\nsystems that aim to generate ontologies from unstructured text corpus are\ndomain-specific and require manual intervention. In addition, they suffer from\nuncertainty in creating concept linkages and difficulty in finding axioms for\nthe same concept. Knowledge Graphs (KGs) has emerged as a powerful model for\nthe dynamic representation of knowledge. However, KGs have many quality\nlimitations and need extensive refinement. This research aims to develop a\nnovel domain-independent automatic ontology generation framework that converts\nunstructured text corpus into domain consistent ontological form. The framework\ngenerates KGs from unstructured text corpus as well as refine and correct them\nto be consistent with domain ontologies. The power of the proposed\nautomatically generated ontology is that it integrates the dynamic features of\nKGs and the quality features of ontologies.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.07125,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000032783,
      "text":"WATCH: Wasserstein Change Point Detection for High-Dimensional Time\n  Series Data\n\n  Detecting relevant changes in dynamic time series data in a timely manner is\ncrucially important for many data analysis tasks in real-world settings. Change\npoint detection methods have the ability to discover changes in an unsupervised\nfashion, which represents a desirable property in the analysis of unbounded and\nunlabeled data streams. However, one limitation of most of the existing\napproaches is represented by their limited ability to handle multivariate and\nhigh-dimensional data, which is frequently observed in modern applications such\nas traffic flow prediction, human activity recognition, and smart grids\nmonitoring. In this paper, we attempt to fill this gap by proposing WATCH, a\nnovel Wasserstein distance-based change point detection approach that models an\ninitial distribution and monitors its behavior while processing new data\npoints, providing accurate and robust detection of change points in dynamic\nhigh-dimensional data. An extensive experimental evaluation involving a large\nnumber of benchmark datasets shows that WATCH is capable of accurately\nidentifying change points and outperforming state-of-the-art methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.11691,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Recursive Binding for Similarity-Preserving Hypervector Representations\n  of Sequences\n\n  Hyperdimensional computing (HDC), also known as vector symbolic architectures\n(VSA), is a computing framework used within artificial intelligence and\ncognitive computing that operates with distributed vector representations of\nlarge fixed dimensionality. A critical step for designing the HDC\/VSA solutions\nis to obtain such representations from the input data. Here, we focus on\nsequences and propose their transformation to distributed representations that\nboth preserve the similarity of identical sequence elements at nearby positions\nand are equivariant to the sequence shift. These properties are enabled by\nforming representations of sequence positions using recursive binding and\nsuperposition operations. The proposed transformation was experimentally\ninvestigated with symbolic strings used for modeling human perception of word\nsimilarity. The obtained results are on a par with more sophisticated\napproaches from the literature. The proposed transformation was designed for\nthe HDC\/VSA model known as Fourier Holographic Reduced Representations.\nHowever, it can be adapted to some other HDC\/VSA models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.09305,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000069208,
      "text":"An Analysis and Comparison of ACT-R and Soar\n\n  This is a detailed analysis and comparison of the ACT-R and Soar cognitive\narchitectures, including their overall structure, their representations of\nagent data and metadata, and their associated processing. It focuses on working\nmemory, procedural memory, and long-term declarative memory. I emphasize the\ncommonalities, which are many, but also highlight the differences. I identify\nthe processes and distinct classes of information used by these architectures,\nincluding agent data, metadata, and meta-process data, and explore the roles\nthat metadata play in decision making, memory retrievals, and learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.10334,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000015563,
      "text":"Towards Objective Metrics for Procedurally Generated Video Game Levels\n\n  With increasing interest in procedural content generation by academia and\ngame developers alike, it is vital that different approaches can be compared\nfairly. However, evaluating procedurally generated video game levels is often\ndifficult, due to the lack of standardised, game-independent metrics. In this\npaper, we introduce two simulation-based evaluation metrics that involve\nanalysing the behaviour of an A* agent to measure the diversity and difficulty\nof generated levels in a general, game-independent manner. Diversity is\ncalculated by comparing action trajectories from different levels using the\nedit distance, and difficulty is measured as how much exploration and expansion\nof the A* search tree is necessary before the agent can solve the level. We\ndemonstrate that our diversity metric is more robust to changes in level size\nand representation than current methods and additionally measures factors that\ndirectly affect playability, instead of focusing on visual information. The\ndifficulty metric shows promise, as it correlates with existing estimates of\ndifficulty in one of the tested domains, but it does face some challenges in\nthe other domain. Finally, to promote reproducibility, we publicly release our\nevaluation framework.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.0018,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000006987,
      "text":"IoT-based Route Recommendation for an Intelligent Waste Management\n  System\n\n  The Internet of Things (IoT) is a paradigm characterized by a network of\nembedded sensors and services. These sensors are incorporated to collect\nvarious information, track physical conditions, e.g., waste bins' status, and\nexchange data with different centralized platforms. The need for such sensors\nis increasing; however, proliferation of technologies comes with various\nchallenges. For example, how can IoT and its associated data be used to enhance\nwaste management? In smart cities, an efficient waste management system is\ncrucial. Artificial Intelligence (AI) and IoT-enabled approaches can empower\ncities to manage the waste collection. This work proposes an intelligent\napproach to route recommendation in an IoT-enabled waste management system\ngiven spatial constraints. It performs a thorough analysis based on AI-based\nmethods and compares their corresponding results. Our solution is based on a\nmultiple-level decision-making process in which bins' status and coordinates\nare taken into account to address the routing problem. Such AI-based models can\nhelp engineers design a sustainable infrastructure system.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.1158,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000083447,
      "text":"DecisionHoldem: Safe Depth-Limited Solving With Diverse Opponents for\n  Imperfect-Information Games\n\n  An imperfect-information game is a type of game with asymmetric information.\nIt is more common in life than perfect-information game. Artificial\nintelligence (AI) in imperfect-information games, such like poker, has made\nconsiderable progress and success in recent years. The great success of\nsuperhuman poker AI, such as Libratus and Deepstack, attracts researchers to\npay attention to poker research. However, the lack of open-source code limits\nthe development of Texas hold'em AI to some extent. This article introduces\nDecisionHoldem, a high-level AI for heads-up no-limit Texas hold'em with safe\ndepth-limited subgame solving by considering possible ranges of opponent's\nprivate hands to reduce the exploitability of the strategy. Experimental\nresults show that DecisionHoldem defeats the strongest openly available agent\nin heads-up no-limit Texas hold'em poker, namely Slumbot, and a high-level\nreproduction of Deepstack, viz, Openstack, by more than 730 mbb\/h\n(one-thousandth big blind per round) and 700 mbb\/h. Moreover, we release the\nsource codes and tools of DecisionHoldem to promote AI development in\nimperfect-information games.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.12885,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000011921,
      "text":"Computational Metacognition\n\n  Computational metacognition represents a cognitive systems perspective on\nhigh-order reasoning in integrated artificial systems that seeks to leverage\nideas from human metacognition and from metareasoning approaches in artificial\nintelligence. The key characteristic is to declaratively represent and then\nmonitor traces of cognitive activity in an intelligent system in order to\nmanage the performance of cognition itself. Improvements in cognition then lead\nto improvements in behavior and thus performance. We illustrate these concepts\nwith an agent implementation in a cognitive architecture called MIDCA and show\nthe value of metacognition in problem-solving. The results illustrate how\ncomputational metacognition improves performance by changing cognition through\nmeta-level goal operations and learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.08032,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Combining Machine Learning with Knowledge Engineering to detect Fake\n  News in Social Networks-a survey\n\n  Due to extensive spread of fake news on social and news media it became an\nemerging research topic now a days that gained attention. In the news media and\nsocial media the information is spread highspeed but without accuracy and hence\ndetection mechanism should be able to predict news fast enough to tackle the\ndissemination of fake news. It has the potential for negative impacts on\nindividuals and society. Therefore, detecting fake news on social media is\nimportant and also a technically challenging problem these days. We knew that\nMachine learning is helpful for building Artificial intelligence systems based\non tacit knowledge because it can help us to solve complex problems due to real\nword data. On the other side we knew that Knowledge engineering is helpful for\nrepresenting experts knowledge which people aware of that knowledge. Due to\nthis we proposed that integration of Machine learning and knowledge engineering\ncan be helpful in detection of fake news. In this paper we present what is fake\nnews, importance of fake news, overall impact of fake news on different areas,\ndifferent ways to detect fake news on social media, existing detections\nalgorithms that can help us to overcome the issue, similar application areas\nand at the end we proposed combination of data driven and engineered knowledge\nto combat fake news. We studied and compared three different modules text\nclassifiers, stance detection applications and fact checking existing\ntechniques that can help to detect fake news. Furthermore, we investigated the\nimpact of fake news on society. Experimental evaluation of publically available\ndatasets and our proposed fake news detection combination can serve better in\ndetection of fake news.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.05544,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000120203,
      "text":"BandMaxSAT: A Local Search MaxSAT Solver with Multi-armed Bandit\n\n  We address Partial MaxSAT (PMS) and Weighted PMS (WPMS), two practical\ngeneralizations of the MaxSAT problem, and propose a local search algorithm for\nthese problems, called BandMaxSAT, that applies a multi-armed bandit model to\nguide the search direction. The bandit in our method is associated with all the\nsoft clauses in the input (W)PMS instance. Each arm corresponds to a soft\nclause. The bandit model can help BandMaxSAT to select a good direction to\nescape from local optima by selecting a soft clause to be satisfied in the\ncurrent step, that is, selecting an arm to be pulled. We further propose an\ninitialization method for (W)PMS that prioritizes both unit and binary clauses\nwhen producing the initial solutions. Extensive experiments demonstrate that\nBandMaxSAT significantly outperforms the state-of-the-art (W)PMS local search\nalgorithm SATLike3.0. Specifically, the number of instances in which BandMaxSAT\nobtains better results is about twice that obtained by SATLike3.0. Moreover, we\ncombine BandMaxSAT with the complete solver TT-Open-WBO-Inc. The resulting\nsolver BandMaxSAT-c also outperforms some of the best state-of-the-art complete\n(W)PMS solvers, including SATLike-c, Loandra and TT-Open-WBO-Inc.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.01027,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000456969,
      "text":"A integrating critic-waspas group decision making method under\n  interval-valued q-rung orthogonal fuzzy enviroment\n\n  This paper provides a new tool for multi-attribute multi-objective group\ndecision-making with unknown weights and attributes' weights. An\ninterval-valued generalized orthogonal fuzzy group decision-making method is\nproposed based on the Yager operator and CRITIC-WASPAS method with unknown\nweights. The method integrates Yager operator, CRITIC, WASPAS, and interval\nvalue generalized orthogonal fuzzy group. Its merits lie in allowing\ndecision-makers greater freedom, avoiding bias due to decision-makers' weight,\nand yielding accurate evaluation. The research includes: expanding the interval\nvalue generalized distance measurement method for comparison and application of\nsimilarity measurement and decision-making methods; developing a new scoring\nfunction for comparing the size of interval value generalized orthogonal fuzzy\nnumbers,and further existing researches. The proposed interval-valued Yager\nweighted average operator (IVq-ROFYWA) and Yager weighted geometric average\noperator (IVq-ROFYWG) are used for information aggregation. The CRITIC-WASPAS\ncombines the advantages of CRITIC and WASPAS, which not only work in the single\ndecision but also serve as the basis of the group decision. The in-depth study\nof the decision-maker's weight matrix overcomes the shortcomings of taking the\ndecision as a whole, and weighs the decision-maker's information aggregation.\nFinally, the group decision algorithm is used for hypertension risk management.\nThe results are consistent with decision-makers' opinions. Practice and case\nanalysis have proved the effectiveness of the method proposed in this paper. At\nthe same time, it is compared with other operators and decision-making methods,\nwhich proves the method effective and feasible.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.10453,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.000018047,
      "text":"The First AI4TSP Competition: Learning to Solve Stochastic Routing\n  Problems\n\n  This paper reports on the first international competition on AI for the\ntraveling salesman problem (TSP) at the International Joint Conference on\nArtificial Intelligence 2021 (IJCAI-21). The TSP is one of the classical\ncombinatorial optimization problems, with many variants inspired by real-world\napplications. This first competition asked the participants to develop\nalgorithms to solve a time-dependent orienteering problem with stochastic\nweights and time windows (TD-OPSWTW). It focused on two types of learning\napproaches: surrogate-based optimization and deep reinforcement learning. In\nthis paper, we describe the problem, the setup of the competition, the winning\nmethods, and give an overview of the results. The winning methods described in\nthis work have advanced the state-of-the-art in using AI for stochastic routing\nproblems. Overall, by organizing this competition we have introduced routing\nproblems as an interesting problem setting for AI researchers. The simulator of\nthe problem has been made open-source and can be used by other researchers as a\nbenchmark for new AI methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.0704,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"Benchmark datasets driving artificial intelligence development fail to\n  capture the needs of medical professionals\n\n  Publicly accessible benchmarks that allow for assessing and comparing model\nperformances are important drivers of progress in artificial intelligence (AI).\nWhile recent advances in AI capabilities hold the potential to transform\nmedical practice by assisting and augmenting the cognitive processes of\nhealthcare professionals, the coverage of clinically relevant tasks by AI\nbenchmarks is largely unclear. Furthermore, there is a lack of systematized\nmeta-information that allows clinical AI researchers to quickly determine\naccessibility, scope, content and other characteristics of datasets and\nbenchmark datasets relevant to the clinical domain.\n  To address these issues, we curated and released a comprehensive catalogue of\ndatasets and benchmarks pertaining to the broad domain of clinical and\nbiomedical natural language processing (NLP), based on a systematic review of\nliterature and online resources. A total of 450 NLP datasets were manually\nsystematized and annotated with rich metadata, such as targeted tasks, clinical\napplicability, data types, performance metrics, accessibility and licensing\ninformation, and availability of data splits. We then compared tasks covered by\nAI benchmark datasets with relevant tasks that medical practitioners reported\nas highly desirable targets for automation in a previous empirical study.\n  Our analysis indicates that AI benchmarks of direct clinical relevance are\nscarce and fail to cover most work activities that clinicians want to see\naddressed. In particular, tasks associated with routine documentation and\npatient data administration workflows are not represented despite significant\nassociated workloads. Thus, currently available AI benchmarks are improperly\naligned with desired targets for AI automation in clinical settings, and novel\nbenchmarks should be created to fill these gaps.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.04349,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Video Intelligence as a component of a Global Security system\n\n  This paper describes the evolution of our research from video analytics to a\nglobal security system with focus on the video surveillance component. Indeed\nvideo surveillance has evolved from a commodity security tool up to the most\nefficient way of tracking perpetrators when terrorism hits our modern urban\ncenters. As number of cameras soars, one could expect the system to leverage\nthe huge amount of data carried through the video streams to provide fast\naccess to video evidences, actionable intelligence for monitoring real-time\nevents and enabling predictive capacities to assist operators in their\nsurveillance tasks. This research explores a hybrid platform for video\nintelligence capture, automated data extraction, supervised Machine Learning\nfor intelligently assisted urban video surveillance; Extension to other\ncomponents of a global security system are discussed. Applying Knowledge\nManagement principles in this research helps with deep problem understanding\nand facilitates the implementation of efficient information and experience\nsharing decision support systems providing assistance to people on the field as\nwell as in operations centers. The originality of this work is also the\ncreation of \"common\" human-machine and machine to machine language and a\nsecurity ontology.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.05528,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"Reinforcement Learning based Air Combat Maneuver Generation\n\n  The advent of artificial intelligence technology paved the way of many\nresearches to be made within air combat sector. Academicians and many other\nresearchers did a research on a prominent research direction called autonomous\nmaneuver decision of UAV. Elaborative researches produced some outcomes, but\ndecisions that include Reinforcement Learning(RL) came out to be more\nefficient. There have been many researches and experiments done to make an\nagent reach its target in an optimal way, most prominent are Genetic\nAlgorithm(GA) , A star, RRT and other various optimization techniques have been\nused. But Reinforcement Learning is the well known one for its success. In\nDARPHA Alpha Dogfight Trials, reinforcement learning prevailed against a real\nveteran F16 human pilot who was trained by Boeing. This successor model was\ndeveloped by Heron Systems. After this accomplishment, reinforcement learning\nbring tremendous attention on itself. In this research we aimed our UAV which\nhas a dubin vehicle dynamic property to move to the target in two dimensional\nspace in an optimal path using Twin Delayed Deep Deterministic Policy Gradients\n(TD3) and used in experience replay Hindsight Experience Replay(HER).We did\ntests on two different environments and used simulations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2201.0381,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":1,
    "pangram_prediction":{
      "ai_likelihood":0.0000015232,
      "text":"Ancestral Instrument Method for Causal Inference without Complete\n  Knowledge\n\n  Unobserved confounding is the main obstacle to causal effect estimation from\nobservational data. Instrumental variables (IVs) are widely used for causal\neffect estimation when there exist latent confounders. With the standard IV\nmethod, when a given IV is valid, unbiased estimation can be obtained, but the\nvalidity requirement on a standard IV is strict and untestable. Conditional IVs\nhave been proposed to relax the requirement of standard IVs by conditioning on\na set of observed variables (known as a conditioning set for a conditional IV).\nHowever, the criterion for finding a conditioning set for a conditional IV\nneeds a directed acyclic graph (DAG) representing the causal relationships of\nboth observed and unobserved variables. This makes it challenging to discover a\nconditioning set directly from data. In this paper, by leveraging maximal\nancestral graphs (MAGs) for causal inference with latent variables, we study\nthe graphical properties of ancestral IVs, a type of conditional IVs using\nMAGs, and develop the theory to support data-driven discovery of the\nconditioning set for a given ancestral IV in data under the pretreatment\nvariable assumption. Based on the theory, we develop an algorithm for unbiased\ncausal effect estimation with a given ancestral IV and observational data.\nExtensive experiments on synthetic and real-world datasets demonstrate the\nperformance of the algorithm in comparison with existing IV methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.11958,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.00001659,
      "text":"Cognitive Semantic Communication Systems Driven by Knowledge Graph\n\n  Semantic communication is envisioned as a promising technique to break\nthrough the Shannon limit. However, the existing semantic communication\nframeworks do not involve inference and error correction, which limits the\nachievable performance. In this paper, in order to tackle this issue, a\ncognitive semantic communication framework is proposed by exploiting knowledge\ngraph. Moreover, a simple, general and interpretable solution for semantic\ninformation detection is developed by exploiting triples as semantic symbols.\nIt also allows the receiver to correct errors occurring at the symbolic level.\nFurthermore, the pre-trained model is fine-tuned to recover semantic\ninformation, which overcomes the drawback that a fixed bit length coding is\nused to encode sentences of different lengths. Simulation results on the public\nWebNLG corpus show that our proposed system is superior to other benchmark\nsystems in terms of the data compression rate and the reliability of\ncommunication.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.12622,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000013908,
      "text":"Towards neoRL networks; the emergence of purposive graphs\n\n  The neoRL framework for purposive AI implements latent learning by emulated\ncognitive maps, with general value functions (GVF) expressing operant desires\ntoward separate states. The agent's expectancy of reward, expressed as learned\nprojections in the considered space, allows the neoRL agent to extract\npurposive behavior from the learned map according to the reward hypothesis. We\nexplore this allegory further, considering neoRL modules as nodes in a network\nwith desire as input and state-action Q-value as output; we see that action\nsets with Euclidean significance imply an interpretation of state-action\nvectors as Euclidean projections of desire. Autonomous desire from neoRL nodes\nwithin the agent allows for deeper neoRL behavioral graphs. Experiments confirm\nthe effect of neoRL networks governed by autonomous desire, verifying the four\nprinciples for purposive networks. A neoRL agent governed by purposive networks\ncan navigate Euclidean spaces in real-time while learning, exemplifying how\nmodern AI still can profit from inspiration from early psychology.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.13101,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000050995,
      "text":"Sustainability using Renewable Electricity (SuRE) towards NetZero\n  Emissions\n\n  Demand for energy has increased significantly across the globe due to\nincrease in population and economic growth. Growth in energy demand poses\nserious threat to the environment since majority of the energy sources are\nnon-renewable and based on fossil fuels, which leads to emission of harmful\ngreenhouse gases. Organizations across the world are facing challenges in\ntransitioning from fossil fuels-based sources to greener sources to reduce\ntheir carbon footprint. As a step towards achieving Net-Zero emission target,\nwe present a scalable AI based solution that can be used by organizations to\nincrease their overall renewable electricity share in total energy consumption.\nOur solution provides facilities with accurate energy demand forecast,\nrecommendation for procurement of renewable electricity to optimize cost and\ncarbon offset recommendations to compensate for Greenhouse Gas (GHG) emissions.\nThis solution has been used in production for more than a year for four\nfacilities and has increased their renewable electricity share significantly.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.14018,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000066559,
      "text":"Description Logic EL++ Embeddings with Intersectional Closure\n\n  Many ontologies, in particular in the biomedical domain, are based on the\nDescription Logic EL++. Several efforts have been made to interpret and exploit\nEL++ ontologies by distributed representation learning. Specifically, concepts\nwithin EL++ theories have been represented as n-balls within an n-dimensional\nembedding space. However, the intersectional closure is not satisfied when\nusing n-balls to represent concepts because the intersection of two n-balls is\nnot an n-ball. This leads to challenges when measuring the distance between\nconcepts and inferring equivalence between concepts. To this end, we developed\nEL Box Embedding (ELBE) to learn Description Logic EL++ embeddings using\naxis-parallel boxes. We generate specially designed box-based geometric\nconstraints from EL++ axioms for model training. Since the intersection of\nboxes remains as a box, the intersectional closure is satisfied. We report\nextensive experimental results on three datasets and present a case study to\ndemonstrate the effectiveness of the proposed method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.13746,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Solving The Travelling Salesmen Problem using HNN and HNN-SA algorithms\n\n  In this case study, the renowned Travelling Salesmen problem has been\nstudied. Travelling Salesman problem is a most demanding computational problem\nin Computer Science. The Travelling Salesmen problem has been solved by two\ndifferent ways using Hopfield Network. The main theory of the problem is to\nfind distance and connectedness between nodes in a graph having edges between\nthe nodes. The basic algorithm used for this problem is Djikstra's Algorithm.\nBut till now , a number of such algorithms have evolved. Among them(some other\nalgorithms) , are distinct and have been proved to solve the travelling\nsalesmen problem by graph theory.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.13985,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000004636,
      "text":"The dangers in algorithms learning humans' values and irrationalities\n\n  For an artificial intelligence (AI) to be aligned with human values (or human\npreferences), it must first learn those values. AI systems that are trained on\nhuman behavior, risk miscategorising human irrationalities as human values --\nand then optimising for these irrationalities. Simply learning human values\nstill carries risks: AI learning them will inevitably also gain information on\nhuman irrationalities and human behaviour\/policy. Both of these can be\ndangerous: knowing human policy allows an AI to become generically more\npowerful (whether it is partially aligned or not aligned at all), while\nlearning human irrationalities allows it to exploit humans without needing to\nprovide value in return. This paper analyses the danger in developing\nartificial intelligence that learns about human irrationalities and human\npolicy, and constructs a model recommendation system with various levels of\ninformation about human biases, human policy, and human values. It concludes\nthat, whatever the power and knowledge of the AI, it is more dangerous for it\nto know human irrationalities than human values. Thus it is better for the AI\nto learn human values directly, rather than learning human biases and then\ndeducing values from behaviour.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.04411,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"A.I. and Data-Driven Mobility at Volkswagen Financial Services AG\n\n  Machine learning is being widely adapted in industrial applications owing to\nthe capabilities of commercially available hardware and rapidly advancing\nresearch. Volkswagen Financial Services (VWFS), as a market leader in vehicle\nleasing services, aims to leverage existing proprietary data and the latest\nresearch to enhance existing and derive new business processes. The\ncollaboration between Information Systems and Machine Learning Lab (ISMLL) and\nVWFS serves to realize this goal. In this paper, we propose methods in the\nfields of recommender systems, object detection, and forecasting that enable\ndata-driven decisions for the vehicle life-cycle at VWFS.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.05793,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000205967,
      "text":"Answer Set Planning: A Survey\n\n  Answer Set Planning refers to the use of Answer Set Programming (ASP) to\ncompute plans, i.e., solutions to planning problems, that transform a given\nstate of the world to another state. The development of efficient and scalable\nanswer set solvers has provided a significant boost to the development of\nASP-based planning systems. This paper surveys the progress made during the\nlast two and a half decades in the area of answer set planning, from its\nfoundations to its use in challenging planning domains. The survey explores the\nadvantages and disadvantages of answer set planning. It also discusses typical\napplications of answer set planning and presents a set of challenges for future\nresearch.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.07065,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Automatic Generation of Individual Fuzzy Cognitive Maps from\n  Longitudinal Data\n\n  Fuzzy Cognitive Maps (FCMs) are computational models that represent how\nfactors (nodes) change over discrete interactions based on causal impacts\n(weighted directed edges) from other factors. This approach has traditionally\nbeen used as an aggregate, similarly to System Dynamics, to depict the\nfunctioning of a system. There has been a growing interest in taking this\naggregate approach at the individual-level, for example by equipping each agent\nof an Agent-Based Model with its own FCM to express its behavior. Although\nframeworks and studies have already taken this approach, an ongoing limitation\nhas been the difficulty of creating as many FCMs as there are individuals.\nIndeed, current studies have been able to create agents whose traits are\ndifferent, but whose decision-making modules are often identical, thus limiting\nthe behavioral heterogeneity of the simulated population. In this paper, we\naddress this limitation by using Genetic Algorithms to create one FCM for each\nagent, thus providing the means to automatically create a virtual population\nwith heterogeneous behaviors. Our algorithm builds on prior work from Stach and\ncolleagues by introducing additional constraints into the process and applying\nit over longitudinal, individual-level data. A case study from a real-world\nintervention on nutrition confirms that our approach can generate heterogeneous\nagents that closely follow the trajectories of their real-world human\ncounterparts. Future works include technical improvements such as lowering the\ncomputational time of the approach, or case studies in computational\nintelligence that use our virtual populations to test new behavior change\ninterventions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.03196,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"A Conditional Perspective on the Logic of Iterated Belief Contraction\n\n  In this article, we consider iteration principles for contraction, with the\ngoal of identifying properties for contractions that respect conditional\nbeliefs. Therefore, we investigate and evaluate four groups of iteration\nprinciples for contraction which consider the dynamics of conditional beliefs.\nFor all these principles, we provide semantic characterization theorems and\nprovide formulations by postulates which highlight how the change of beliefs\nand of conditional beliefs is constrained, whenever that is possible. The first\ngroup is similar to the syntactic Darwiche-Pearl postulates. As a second group,\nwe consider semantic postulates for iteration of contraction by Chopra, Ghose,\nMeyer and Wong, and by Konieczny and Pino P\\'erez, respectively, and we provide\nnovel syntactic counterparts. Third, we propose a contraction analogue of the\nindependence condition by Jin and Thielscher. For the fourth group, we consider\nnatural and moderate contraction by Nayak. Methodically, we make use of\nconditionals for contractions, so-called contractionals and furthermore, we\npropose and employ the novel notion of $ \\alpha $-equivalence for formulating\nsome of the new postulates.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.07412,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.000007285,
      "text":"Knowledge Graph Reasoning with Logics and Embeddings: Survey and\n  Perspective\n\n  Knowledge graph (KG) reasoning is becoming increasingly popular in both\nacademia and industry. Conventional KG reasoning based on symbolic logic is\ndeterministic, with reasoning results being explainable, while modern\nembedding-based reasoning can deal with uncertainty and predict plausible\nknowledge, often with high efficiency via vector computation. A promising\ndirection is to integrate both logic-based and embedding-based methods, with\nthe vision to have advantages of both. It has attracted wide research attention\nwith more and more works published in recent years. In this paper, we\ncomprehensively survey these works, focusing on how logics and embeddings are\nintegrated. We first briefly introduce preliminaries, then systematically\ncategorize and discuss works of logic and embedding-aware KG reasoning from\ndifferent perspectives, and finally conclude and discuss the challenges and\nfurther directions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.00083,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000019537,
      "text":"Sampling-Based Winner Prediction in District-Based Elections\n\n  In a district-based election, we apply a voting rule $r$ to decide the\nwinners in each district, and a candidate who wins in a maximum number of\ndistricts is the winner of the election. We present efficient sampling-based\nalgorithms to predict the winner of such district-based election systems in\nthis paper. When $r$ is plurality and the margin of victory is known to be at\nleast $\\varepsilon$ fraction of the total population, we present an algorithm\nto predict the winner. The sample complexity of our algorithm is\n$\\mathcal{O}\\left(\\frac{1}{\\varepsilon^4}\\log\n\\frac{1}{\\varepsilon}\\log\\frac{1}{\\delta}\\right)$. We complement this result by\nproving that any algorithm, from a natural class of algorithms, for predicting\nthe winner in a district-based election when $r$ is plurality, must sample at\nleast $\\Omega\\left(\\frac{1}{\\varepsilon^4}\\log\\frac{1}{\\delta}\\right)$ votes.\nWe then extend this result to any voting rule $r$. Loosely speaking, we show\nthat we can predict the winner of a district-based election with an extra\noverhead of\n$\\mathcal{O}\\left(\\frac{1}{\\varepsilon^2}\\log\\frac{1}{\\delta}\\right)$ over the\nsample complexity of predicting the single-district winner under $r$. We\nfurther extend our algorithm for the case when the margin of victory is\nunknown, but we have only two candidates. We then consider the median voting\nrule when the set of preferences in each district is single-peaked. We show\nthat the winner of a district-based election can be predicted with\n$\\mathcal{O}\\left(\\frac{1}{\\varepsilon^4}\\log\\frac{1}{\\varepsilon}\\log\\frac{1}{\\delta}\\right)$\nsamples even when the harmonious order in different districts can be different\nand even unknown. Finally, we also show some results for estimating the margin\nof victory of a district-based election within both additive and multiplicative\nerror bounds.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.03246,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0002484851,
      "text":"AI-based artistic representation of emotions from EEG signals: a\n  discussion on fairness, inclusion, and aesthetics\n\n  While Artificial Intelligence (AI) technologies are being progressively\ndeveloped, artists and researchers are investigating their role in artistic\npractices. In this work, we present an AI-based Brain-Computer Interface (BCI)\nin which humans and machines interact to express feelings artistically. This\nsystem and its production of images give opportunities to reflect on the\ncomplexities and range of human emotions and their expressions. In this\ndiscussion, we seek to understand the dynamics of this interaction to reach\nbetter co-existence in fairness, inclusion, and aesthetics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.13794,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"Inkorrect: Online Handwriting Spelling Correction\n\n  We introduce Inkorrect, a data- and label-efficient approach for online\nhandwriting (Digital Ink) spelling correction - DISC. Unlike previous work, the\nproposed method does not require multiple samples from the same writer, or\naccess to character level segmentation. We show that existing automatic\nevaluation metrics do not fully capture and are not correlated with the human\nperception of the quality of the spelling correction, and propose new ones that\ncorrelate with human perception. We additionally surface an interesting\nphenomenon: a trade-off between the similarity and recognizability of the\nspell-corrected inks. We further create a family of models corresponding to\ndifferent points on the Pareto frontier between those two axes. We show that\nInkorrect's Pareto frontier dominates the points that correspond to prior work.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.04954,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"D2A-BSP: Distilled Data Association Belief Space Planning with\n  Performance Guarantees Under Budget Constraints\n\n  Unresolved data association in ambiguous and perceptually aliased\nenvironments leads to multi-modal hypotheses on both the robot's and the\nenvironment state. To avoid catastrophic results, when operating in such\nambiguous environments, it is crucial to reason about data association within\nBelief Space Planning (BSP). However, explicitly considering all possible data\nassociations, the number of hypotheses grows exponentially with the planning\nhorizon and determining the optimal action sequence quickly becomes\nintractable. Moreover, with hard budget constraints where some non-negligible\nhypotheses must be pruned, achieving performance guarantees is crucial. In this\nwork we present a computationally efficient novel approach that utilizes only a\ndistilled subset of hypotheses to solve BSP problems while reasoning about data\nassociation. Furthermore, to provide performance guarantees, we derive error\nbounds with respect to the optimal solution. We then demonstrate our approach\nin an extremely aliased environment, where we manage to significantly reduce\ncomputation time without compromising on the quality of the solution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.13196,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.000002053,
      "text":"Toward Interpretable Semantic Textual Similarity via Optimal\n  Transport-based Contrastive Sentence Learning\n\n  Recently, finetuning a pretrained language model to capture the similarity\nbetween sentence embeddings has shown the state-of-the-art performance on the\nsemantic textual similarity (STS) task. However, the absence of an\ninterpretation method for the sentence similarity makes it difficult to explain\nthe model output. In this work, we explicitly describe the sentence distance as\nthe weighted sum of contextualized token distances on the basis of a\ntransportation problem, and then present the optimal transport-based distance\nmeasure, named RCMD; it identifies and leverages semantically-aligned token\npairs. In the end, we propose CLRCMD, a contrastive learning framework that\noptimizes RCMD of sentence pairs, which enhances the quality of sentence\nsimilarity and their interpretation. Extensive experiments demonstrate that our\nlearning framework outperforms other baselines on both STS and\ninterpretable-STS benchmarks, indicating that it computes effective sentence\nsimilarity and also provides interpretation consistent with human judgement.\nThe code and checkpoint are publicly available at\nhttps:\/\/github.com\/sh0416\/clrcmd.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.04787,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000077817,
      "text":"Proceedings of the Robust Artificial Intelligence System Assurance\n  (RAISA) Workshop 2022\n\n  The Robust Artificial Intelligence System Assurance (RAISA) workshop will\nfocus on research, development and application of robust artificial\nintelligence (AI) and machine learning (ML) systems. Rather than studying\nrobustness with respect to particular ML algorithms, our approach will be to\nexplore robustness assurance at the system architecture level, during both\ndevelopment and deployment, and within the human-machine teaming context. While\nthe research community is converging on robust solutions for individual AI\nmodels in specific scenarios, the problem of evaluating and assuring the\nrobustness of an AI system across its entire life cycle is much more complex.\nMoreover, the operational context in which AI systems are deployed necessitates\nconsideration of robustness and its relation to principles of fairness,\nprivacy, and explainability.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.1375,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000000662,
      "text":"A Minimal Deductive System for RDFS with Negative Statements\n\n  The triple language RDFS is designed to represent and reason with\n\\emph{positive} statements only (e.g.\"antipyretics are drugs\").\n  In this paper we show how to extend RDFS to express and reason with various\nforms of negative statements under the Open World Assumption (OWA). To do so,\nwe start from $\\rho df$, a minimal, but significant RDFS fragment that covers\nall essential features of RDFS, and then extend it to $\\rho df_\\bot^\\neg$,\nallowing express also statements such as \"radio therapies are non drug\ntreatments\", \"Ebola has no treatment\", or \"opioids and antipyretics are\ndisjoint classes\". The main and, to the best of our knowledge, unique features\nof our proposal are: (i) $\\rho df_\\bot^\\neg$ remains syntactically a triple\nlanguage by extending $\\rho df$ with new symbols with specific semantics and\nthere is no need to revert to the reification method to represent negative\ntriples; (ii) the logic is defined in such a way that any RDFS reasoner\/store\nmay handle the new predicates as ordinary terms if it does not want to take\naccount of the extra capabilities; (iii) despite negated statements, every\n$\\rho df_\\bot^\\neg$ knowledge base is satisfiable; (iv) the $\\rho df_\\bot^\\neg$\nentailment decision procedure is obtained from $\\rho df$ via additional\ninference rules favouring a potential implementation; and (v) deciding\nentailment in $\\rho df_\\bot^\\neg$ ranges from P to NP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.02879,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"An Empirical Analysis of AI Contributions to Sustainable Cities (SDG11)\n\n  Artificial Intelligence (AI) presents opportunities to develop tools and\ntechniques for addressing some of the major global challenges and deliver\nsolutions with significant social and economic impacts. The application of AI\nhas far-reaching implications for the 17 Sustainable Development Goals (SDGs)\nin general, and sustainable urban development in particular. However, existing\nattempts to understand and use the opportunities offered by AI for SDG 11 have\nbeen explored sparsely, and the shortage of empirical evidence about the\npractical application of AI remains. In this chapter, we analyze the\ncontribution of AI to support the progress of SDG 11 (Sustainable Cities and\nCommunities). We address the knowledge gap by empirically analyzing the AI\nsystems (N = 29) from the AIxSDG database and the Community Research and\nDevelopment Information Service (CORDIS) database. Our analysis revealed that\nAI systems have indeed contributed to advancing sustainable cities in several\nways (e.g., waste management, air quality monitoring, disaster response\nmanagement, transportation management), but many projects are still working for\ncitizens and not with them. This snapshot of AI's impact on SDG11 is inherently\npartial, yet useful to advance our understanding as we move towards more mature\nsystems and research on the impact of AI systems for social good.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2202.03192,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":2,
    "pangram_prediction":{
      "ai_likelihood":0.0,
      "text":"Reward is not enough: can we liberate AI from the reinforcement learning\n  paradigm?\n\n  I present arguments against the hypothesis put forward by Silver, Singh,\nPrecup, and Sutton (\nhttps:\/\/www.sciencedirect.com\/science\/article\/pii\/S0004370221000862 ) : reward\nmaximization is not enough to explain many activities associated with natural\nand artificial intelligence including knowledge, learning, perception, social\nintelligence, evolution, language, generalisation and imitation. I show such\nreductio ad lucrum has its intellectual origins in the political economy of\nHomo economicus and substantially overlaps with the radical version of\nbehaviourism. I show why the reinforcement learning paradigm, despite its\ndemonstrable usefulness in some practical application, is an incomplete\nframework for intelligence -- natural and artificial. Complexities of\nintelligent behaviour are not simply second-order complications on top of\nreward maximisation. This fact has profound implications for the development of\npractically usable, smart, safe and robust artificially intelligent agents.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.13929,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000001755,
      "text":"A Meta Survey of Quality Evaluation Criteria in Explanation Methods\n\n  Explanation methods and their evaluation have become a significant issue in\nexplainable artificial intelligence (XAI) due to the recent surge of opaque AI\nmodels in decision support systems (DSS). Since the most accurate AI models are\nopaque with low transparency and comprehensibility, explanations are essential\nfor bias detection and control of uncertainty. There are a plethora of criteria\nto choose from when evaluating explanation method quality. However, since\nexisting criteria focus on evaluating single explanation methods, it is not\nobvious how to compare the quality of different methods. This lack of consensus\ncreates a critical shortage of rigour in the field, although little is written\nabout comparative evaluations of explanation methods. In this paper, we have\nconducted a semi-systematic meta-survey over fifteen literature surveys\ncovering the evaluation of explainability to identify existing criteria usable\nfor comparative evaluations of explanation methods. The main contribution in\nthe paper is the suggestion to use appropriate trust as a criterion to measure\nthe outcome of the subjective evaluation criteria and consequently make\ncomparative evaluations possible. We also present a model of explanation\nquality aspects. In the model, criteria with similar definitions are grouped\nand related to three identified aspects of quality; model, explanation, and\nuser. We also notice four commonly accepted criteria (groups) in the\nliterature, covering all aspects of explanation quality: Performance,\nappropriate trust, explanation satisfaction, and fidelity. We suggest the model\nbe used as a chart for comparative evaluations to create more generalisable\nresearch in explanation quality.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.16289,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000038743,
      "text":"Reducing Learning Difficulties: One-Step Two-Critic Deep Reinforcement\n  Learning for Inverter-based Volt-Var Control\n\n  A one-step two-critic deep reinforcement learning (OSTC-DRL) approach for\ninverter-based volt-var control (IB-VVC) in active distribution networks is\nproposed in this paper. Firstly, considering IB-VVC can be formulated as a\nsingle-period optimization problem, we formulate the IB-VVC as a one-step\nMarkov decision process rather than the standard Markov decision process, which\nsimplifies the DRL learning task. Then we design the one-step actor-critic DRL\nscheme which is a simplified version of recent DRL algorithms, and it avoids\nthe issue of Q value overestimation successfully. Furthermore, considering two\nobjectives of VVC: minimizing power loss and eliminating voltage violation, we\nutilize two critics to approximate the rewards of two objectives separately. It\nsimplifies the approximation tasks of each critic, and avoids the interaction\neffect between two objectives in the learning process of critic. The OSTC-DRL\napproach integrates the one-step actor-critic DRL scheme and the two-critic\ntechnology. Based on the OSTC-DRL, we design two centralized DRL algorithms.\nFurther, we extend the OSTC-DRL to multi-agent OSTC-DRL for decentralized\nIB-VVC and design two multi-agent DRL algorithms. Simulations demonstrate that\nthe proposed OSTC-DRL has a faster convergence rate and a better control\nperformance, and the multi-agent OSTC-DRL works well for decentralized IB-VVC\nproblems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.13965,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000222855,
      "text":"Augmenting Knowledge Graphs for Better Link Prediction\n\n  Embedding methods have demonstrated robust performance on the task of link\nprediction in knowledge graphs, by mostly encoding entity relationships. Recent\nmethods propose to enhance the loss function with a literal-aware term. In this\npaper, we propose KGA: a knowledge graph augmentation method that incorporates\nliterals in an embedding model without modifying its loss function. KGA\ndiscretizes quantity and year values into bins, and chains these bins both\nhorizontally, modeling neighboring values, and vertically, modeling multiple\nlevels of granularity. KGA is scalable and can be used as a pre-processing step\nfor any existing knowledge graph embedding model. Experiments on legacy\nbenchmarks and a new large benchmark, DWD, show that augmenting the knowledge\ngraph with quantities and years is beneficial for predicting both entities and\nnumbers, as KGA outperforms the vanilla models and other relevant baselines.\nOur ablation studies confirm that both quantities and years contribute to KGA's\nperformance, and that its performance depends on the discretization and binning\nsettings. We make the code, models, and the DWD benchmark publicly available to\nfacilitate reproducibility and future research.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.12955,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000009272,
      "text":"Onto4MAT: A Swarm Shepherding Ontology for Generalised Multi-Agent\n  Teaming\n\n  Research in multi-agent teaming has increased substantially over recent\nyears, with knowledge-based systems to support teaming processes typically\nfocused on delivering functional (communicative) solutions for a team to act\nmeaningfully in response to direction. Enabling humans to effectively interact\nand team with a swarm of autonomous cognitive agents is an open research\nchallenge in Human-Swarm Teaming research, partially due to the focus on\ndeveloping the enabling architectures to support these systems. Typically,\nbi-directional transparency and shared semantic understanding between agents\nhas not prioritised a designed mechanism in Human-Swarm Teaming, potentially\nlimiting how a human and a swarm team can share understanding and\ninformation\\textemdash data through concepts and contexts\\textemdash to achieve\na goal. To address this, we provide a formal knowledge representation design\nthat enables the swarm Artificial Intelligence to reason about its environment\nand system, ultimately achieving a shared goal. We propose the Ontology for\nGeneralised Multi-Agent Teaming, Onto4MAT, to enable more effective teaming\nbetween humans and teams through the biologically-inspired approach of\nshepherding.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.02696,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000022517,
      "text":"Boosting the Learning for Ranking Patterns\n\n  Discovering relevant patterns for a particular user remains a challenging\ntasks in data mining. Several approaches have been proposed to learn\nuser-specific pattern ranking functions. These approaches generalize well, but\nat the expense of the running time. On the other hand, several measures are\noften used to evaluate the interestingness of patterns, with the hope to reveal\na ranking that is as close as possible to the user-specific ranking. In this\npaper, we formulate the problem of learning pattern ranking functions as a\nmulticriteria decision making problem. Our approach aggregates different\ninterestingness measures into a single weighted linear ranking function, using\nan interactive learning procedure that operates in either passive or active\nmodes. A fast learning step is used for eliciting the weights of all the\nmeasures by mean of pairwise comparisons.\n  This approach is based on Analytic Hierarchy Process (AHP), and a set of\nuser-ranked patterns to build a preference matrix, which compares the\nimportance of measures according to the user-specific interestingness. A\nsensitivity based heuristic is proposed for the active learning mode, in order\nto insure high quality results with few user ranking queries. Experiments\nconducted on well-known datasets show that our approach significantly reduces\nthe running time and returns precise pattern ranking, while being robust to\nuser-error compared with state-of-the-art approaches.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.01654,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0,
      "text":"Optimized cost function for demand response coordination of multiple EV\n  charging stations using reinforcement learning\n\n  Electric vehicle (EV) charging stations represent a substantial load with\nsignificant flexibility. The exploitation of that flexibility in demand\nresponse (DR) algorithms becomes increasingly important to manage and balance\ndemand and supply in power grids. Model-free DR based on reinforcement learning\n(RL) is an attractive approach to balance such EV charging load. We build on\nprevious research on RL, based on a Markov decision process (MDP) to\nsimultaneously coordinate multiple charging stations. However, we note that the\ncomputationally expensive cost function adopted in the previous research leads\nto large training times, which limits the feasibility and practicality of the\napproach. We, therefore, propose an improved cost function that essentially\nforces the learned control policy to always fulfill any charging demand that\ndoes not offer any flexibility. We rigorously compare the newly proposed batch\nRL fitted Q-iteration implementation with the original (costly) one, using\nreal-world data. Specifically, for the case of load flattening, we compare the\ntwo approaches in terms of (i) the processing time to learn the RL-based\ncharging policy, as well as (ii) the overall performance of the policy\ndecisions in terms of meeting the target load for unseen test data. The\nperformance is analyzed for different training periods and varying training\nsample sizes. In addition to both RL policies performance results, we provide\nperformance bounds in terms of both (i) an optimal all-knowing strategy, and\n(ii) a simple heuristic spreading individual EV charging uniformly over time\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.0131,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000037418,
      "text":"Counterfactually Evaluating Explanations in Recommender Systems\n\n  Modern recommender systems face an increasing need to explain their\nrecommendations. Despite considerable progress in this area, evaluating the\nquality of explanations remains a significant challenge for researchers and\npractitioners. Prior work mainly conducts human study to evaluate explanation\nquality, which is usually expensive, time-consuming, and prone to human bias.\nIn this paper, we propose an offline evaluation method that can be computed\nwithout human involvement. To evaluate an explanation, our method quantifies\nits counterfactual impact on the recommendation. To validate the effectiveness\nof our method, we carry out an online user study. We show that, compared to\nconventional methods, our method can produce evaluation scores more correlated\nwith the real human judgments, and therefore can serve as a better proxy for\nhuman evaluation. In addition, we show that explanations with high evaluation\nscores are considered better by humans. Our findings highlight the promising\ndirection of using the counterfactual approach as one possible way to evaluate\nrecommendation explanations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.17109,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000006292,
      "text":"A Rich Recipe Representation as Plan to Support Expressive Multi Modal\n  Queries on Recipe Content and Preparation Process\n\n  Food is not only a basic human necessity but also a key factor driving a\nsociety's health and economic well-being. As a result, the cooking domain is a\npopular use-case to demonstrate decision-support (AI) capabilities in service\nof benefits like precision health with tools ranging from information retrieval\ninterfaces to task-oriented chatbots. An AI here should understand concepts in\nthe food domain (e.g., recipes, ingredients), be tolerant to failures\nencountered while cooking (e.g., browning of butter), handle allergy-based\nsubstitutions, and work with multiple data modalities (e.g. text and images).\nHowever, the recipes today are handled as textual documents which makes it\ndifficult for machines to read, reason and handle ambiguity. This demands a\nneed for better representation of the recipes, overcoming the ambiguity and\nsparseness that exists in the current textual documents. In this paper, we\ndiscuss the construction of a machine-understandable rich recipe representation\n(R3), in the form of plans, from the recipes available in natural language. R3\nis infused with additional knowledge such as information about allergens and\nimages of ingredients, possible failures and tips for each atomic cooking step.\nTo show the benefits of R3, we also present TREAT, a tool for recipe retrieval\nwhich uses R3 to perform multi-modal reasoning on the recipe's content (plan\nobjects - ingredients and cooking tools), food preparation process (plan\nactions and time), and media type (image, text). R3 leads to improved retrieval\nefficiency and new capabilities that were hither-to not possible in textual\nrepresentation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.12673,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000097023,
      "text":"Decision-making of Emergent Incident based on P-MADDPG\n\n  In recent years, human casualties and damage to resources caused by emergent\nincidents have become a serious problem worldwide. In this paper, we model the\nemergency decision-making problem and use Multi-agent System (MAS) to solve the\nproblem that the decision speed cannot keep up with the spreading speed. MAS\ncan play an important role in the automated execution of these tasks to reduce\nmission completion time. In this paper, we propose a P-MADDPG algorithm to\nsolve the emergency decision-making problem of emergent incidents, which\npredicts the nodes where an incident may occur in the next time by GRU model\nand makes decisions before the incident occurs, thus solving the problem that\nthe decision speed cannot keep up with the spreading speed. A simulation\nenvironment was established for realistic scenarios, and three scenarios were\nselected to test the performance of P-MADDPG in emergency decision-making\nproblems for emergent incidents: unmanned storage, factory assembly line, and\ncivil airport baggage transportation. Simulation results using the P-MADDPG\nalgorithm are compared with the greedy algorithm and the MADDPG algorithm, and\nthe final experimental results show that the P-MADDPG algorithm converges\nfaster and better than the other algorithms in scenarios of different sizes.\nThis shows that the P-MADDP algorithm is effective for emergency\ndecision-making in emergent incident.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.1305,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000005629,
      "text":"Evolved Open-Endedness in Cultural Evolution: A New Dimension in\n  Open-Ended Evolution Research\n\n  The goal of Artificial Life research, as articulated by Chris Langton, is \"to\ncontribute to theoretical biology by locating life-as-we-know-it within the\nlarger picture of life-as-it-could-be\" (1989, p.1). The study and pursuit of\nopen-ended evolution in artificial evolutionary systems exemplifies this goal.\nHowever, open-ended evolution research is hampered by two fundamental issues;\nthe struggle to replicate open-endedness in an artificial evolutionary system,\nand the fact that we only have one system (genetic evolution) from which to\ndraw inspiration. Here we argue that cultural evolution should be seen not only\nas another real-world example of an open-ended evolutionary system, but that\nthe unique qualities seen in cultural evolution provide us with a new\nperspective from which we can assess the fundamental properties of, and ask new\nquestions about, open-ended evolutionary systems, especially in regard to\nevolved open-endedness and transitions from bounded to unbounded evolution.\nHere we provide an overview of culture as an evolutionary system, highlight the\ninteresting case of human cultural evolution as an open-ended evolutionary\nsystem, and contextualise cultural evolution under the framework of (evolved)\nopen-ended evolution. We go on to provide a set of new questions that can be\nasked once we consider cultural evolution within the framework of open-ended\nevolution, and introduce new insights that we may be able to gain about evolved\nopen-endedness as a result of asking these questions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.01146,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000068545,
      "text":"Controlling the Focus of Pretrained Language Generation Models\n\n  The finetuning of pretrained transformer-based language generation models are\ntypically conducted in an end-to-end manner, where the model learns to attend\nto relevant parts of the input by itself. However, there does not exist a\nmechanism to directly control the model's focus. This work aims to develop a\ncontrol mechanism by which a user can select spans of context as \"highlights\"\nfor the model to focus on, and generate relevant output. To achieve this goal,\nwe augment a pretrained model with trainable \"focus vectors\" that are directly\napplied to the model's embeddings, while the model itself is kept fixed. These\nvectors, trained on automatic annotations derived from attribution methods, act\nas indicators for context importance. We test our approach on two core\ngeneration tasks: dialogue response generation and abstractive summarization.\nWe also collect evaluation data where the highlight-generation pairs are\nannotated by humans. Our experiments show that the trained focus vectors are\neffective in steering the model to generate outputs that are relevant to\nuser-selected highlights.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.02217,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000052651,
      "text":"Quantification of emotions in decision making\n\n  The problem of quantification of emotions in the choice between alternatives\nis considered. The alternatives are evaluated in a dual manner. From one side,\nthey are characterized by rational features defining the utility of each\nalternative. From the other side, the choice is affected by emotions labeling\nthe alternatives as attractive or repulsive, pleasant or unpleasant. A decision\nmaker needs to make a choice taking into account both these features, the\nutility of alternatives and their attractiveness. The notion of utility is\nbased on rational grounds, while the notion of attractiveness is vague and\nrather is based on irrational feelings. A general method, allowing for the\nquantification of the choice combining rational and emotional features is\ndescribed. Despite that emotions seem to avoid precise quantification, their\nquantitative evaluation is possible at the aggregate level. The analysis of a\nseries of empirical data demonstrates the efficiency of the approach, including\nthe realistic behavioral problems that cannot be treated by the standard\nexpected utility theory.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.10794,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000150005,
      "text":"Human-Centric Artificial Intelligence Architecture for Industry 5.0\n  Applications\n\n  Human-centricity is the core value behind the evolution of manufacturing\ntowards Industry 5.0. Nevertheless, there is a lack of architecture that\nconsiders safety, trustworthiness, and human-centricity at its core. Therefore,\nwe propose an architecture that integrates Artificial Intelligence (Active\nLearning, Forecasting, Explainable Artificial Intelligence), simulated reality,\ndecision-making, and users' feedback, focusing on synergies between humans and\nmachines. Furthermore, we align the proposed architecture with the Big Data\nValue Association Reference Architecture Model. Finally, we validate it on\nthree use cases from real-world case studies.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.12817,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Continual Learning and Private Unlearning\n\n  As intelligent agents become autonomous over longer periods of time, they may\neventually become lifelong counterparts to specific people. If so, it may be\ncommon for a user to want the agent to master a task temporarily but later on\nto forget the task due to privacy concerns. However enabling an agent to\n\\emph{forget privately} what the user specified without degrading the rest of\nthe learned knowledge is a challenging problem. With the aim of addressing this\nchallenge, this paper formalizes this continual learning and private unlearning\n(CLPU) problem. The paper further introduces a straightforward but exactly\nprivate solution, CLPU-DER++, as the first step towards solving the CLPU\nproblem, along with a set of carefully designed benchmark problems to evaluate\nthe effectiveness of the proposed solution. The code is available at\nhttps:\/\/github.com\/Cranial-XIX\/Continual-Learning-Private-Unlearning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.15274,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"Finding Structure and Causality in Linear Programs\n\n  Linear Programs (LP) are celebrated widely, particularly so in machine\nlearning where they have allowed for effectively solving probabilistic\ninference tasks or imposing structure on end-to-end learning systems. Their\npotential might seem depleted but we propose a foundational, causal perspective\nthat reveals intriguing intra- and inter-structure relations for LP components.\nWe conduct a systematic, empirical investigation on general-, shortest path-\nand energy system LPs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.00183,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000032451,
      "text":"$ \\text{T}^3 $OMVP: A Transformer-based Time and Team Reinforcement\n  Learning Scheme for Observation-constrained Multi-Vehicle Pursuit in Urban\n  Area\n\n  Smart Internet of Vehicles (IoVs) combined with Artificial Intelligence (AI)\nwill contribute to vehicle decision-making in the Intelligent Transportation\nSystem (ITS). Multi-Vehicle Pursuit games (MVP), a multi-vehicle cooperative\nability to capture mobile targets, is becoming a hot research topic gradually.\nAlthough there are some achievements in the field of MVP in the open space\nenvironment, the urban area brings complicated road structures and restricted\nmoving spaces as challenges to the resolution of MVP games. We define an\nObservation-constrained MVP (OMVP) problem in this paper and propose a\nTransformer-based Time and Team Reinforcement Learning scheme ($ \\text{T}^3\n$OMVP) to address the problem. First, a new multi-vehicle pursuit model is\nconstructed based on decentralized partially observed Markov decision processes\n(Dec-POMDP) to instantiate this problem. Second, by introducing and modifying\nthe transformer-based observation sequence, QMIX is redefined to adapt to the\ncomplicated road structure, restricted moving spaces and constrained\nobservations, so as to control vehicles to pursue the target combining the\nvehicle's observations. Third, a multi-intersection urban environment is built\nto verify the proposed scheme. Extensive experimental results demonstrate that\nthe proposed $ \\text{T}^3 $OMVP scheme achieves significant improvements\nrelative to state-of-the-art QMIX approaches by 9.66%~106.25%. Code is\navailable at https:\/\/github.com\/pipihaiziguai\/T3OMVP.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.09952,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000012583,
      "text":"Conquering Ghosts: Relation Learning for Information Reliability Representation and End-to-End Robust Navigation\n\nEnvironmental disturbances, such as sensor data noises, various lighting conditions, challenging weathers and external adversarial perturbations, are inevitable in real self-driving applications. Existing researches and testings have shown that they can severely influence the vehicles perception ability and performance, one of the main issue is the false positive detection, i.e., the ghost object which is not real existed or occurs in the wrong position (such as a non-existent vehicle). Traditional navigation methods tend to avoid every detected objects for safety, however, avoiding a ghost object may lead the vehicle into a even more dangerous situation, such as a sudden break on the highway. Considering the various disturbance types, it is difficult to address this issue at the perceptual aspect. A potential solution is to detect the ghost through relation learning among the whole scenario and develop an integrated end-to-end navigation system. Our underlying logic is that the behavior of all vehicles in the scene is influenced by their neighbors, and normal vehicles behave in a logical way, while ghost vehicles do not. By learning the spatio-temporal relation among surrounding vehicles, an information reliability representation is learned for each detected vehicle and then a robot navigation network is developed. In contrast to existing works, we encourage the network to learn how to represent the reliability and how to aggregate all the information with uncertainties by itself, thus increasing the efficiency and generalizability. To the best of the authors knowledge, this paper provides the first work on using graph relation learning to achieve end-to-end robust navigation in the presence of ghost vehicles. Simulation results in the CARLA platform demonstrate the feasibility and effectiveness of the proposed method in various scenarios.",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.01201,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"Analytical Solutions for the Inverse Problem within Gradual Semantics\n\n  Gradual semantics within abstract argumentation associate a numeric score\nwith every argument in a system, which represents the level of acceptability of\nthis argument, and from which a preference ordering over arguments can be\nderived. While some semantics operate over standard argumentation frameworks,\nmany utilise a weighted framework, where a numeric initial weight is associated\nwith each argument. Recent work has examined the inverse problem within gradual\nsemantics. Rather than determining a preference ordering given an argumentation\nframework and a semantics, the inverse problem takes an argumentation\nframework, a gradual semantics, and a preference ordering as inputs, and\nidentifies what weights are needed to over arguments in the framework to obtain\nthe desired preference ordering. Existing work has attacked the inverse problem\nnumerically, using a root finding algorithm (the bisection method) to identify\nappropriate initial weights. In this paper we demonstrate that for a class of\ngradual semantics, an analytical approach can be used to solve the inverse\nproblem. Unlike the current state-of-the-art, such an analytic approach can\nrapidly find a solution, and is guaranteed to do so. In obtaining this result,\nwe are able to prove several important properties which previous work had posed\nas conjectures.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.13351,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.0000012914,
      "text":"Predicting Personas Using Mechanic Frequencies and Game State Traces\n\n  We investigate how to efficiently predict play personas based on playtraces.\nPlay personas can be computed by calculating the action agreement ratio between\na player and a generative model of playing behavior, a so-called procedural\npersona. But this is computationally expensive and assumes that appropriate\nprocedural personas are readily available. We present two methods for\nestimating player persona, one using regular supervised learning and aggregate\nmeasures of game mechanics initiated, and another based on sequence learning on\na trace of closely cropped gameplay observations. While both of these methods\nachieve high accuracy when predicting play personas defined by agreement with\nprocedural personas, they utterly fail to predict play style as defined by the\nplayers themselves using a questionnaire. This interesting result highlights\nthe value of using computational methods in defining play personas.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2203.16171,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":3,
    "pangram_prediction":{
      "ai_likelihood":0.000036988,
      "text":"Anticipatory Counterplanning\n\n  In competitive environments, commonly agents try to prevent opponents from\nachieving their goals. Most previous preventing approaches assume the\nopponent's goal is known a priori. Others only start executing actions once the\nopponent's goal has been inferred. In this work we introduce a novel\ndomain-independent algorithm called Anticipatory Counterplanning. It combines\ninference of opponent's goals with computation of planning centroids to yield\nproactive counter strategies in problems where the opponent's goal is unknown.\nExperimental results show how this novel technique outperforms reactive\ncounterplanning, increasing the chances of stopping the opponent from achieving\nits goals.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.00755,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000005298,
      "text":"Safe Reinforcement Learning via Shielding under Partial Observability\n\n  Safe exploration is a common problem in reinforcement learning (RL) that aims\nto prevent agents from making disastrous decisions while exploring their\nenvironment. A family of approaches to this problem assume domain knowledge in\nthe form of a (partial) model of this environment to decide upon the safety of\nan action. A so-called shield forces the RL agent to select only safe actions.\nHowever, for adoption in various applications, one must look beyond enforcing\nsafety and also ensure the applicability of RL with good performance. We extend\nthe applicability of shields via tight integration with state-of-the-art deep\nRL, and provide an extensive, empirical study in challenging, sparse-reward\nenvironments under partial observability. We show that a carefully integrated\nshield ensures safety and can improve the convergence rate and final\nperformance of RL agents. We furthermore show that a shield can be used to\nbootstrap state-of-the-art RL agents: they remain safe after initial learning\nin a shielded setting, allowing us to disable a potentially too conservative\nshield eventually.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.06076,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000035432,
      "text":"Hybrid Feature- and Similarity-Based Models for Joint Prediction and\n  Interpretation\n\n  Electronic health records (EHRs) include simple features like patient age\ntogether with more complex data like care history that are informative but not\neasily represented as individual features. To better harness such data, we\ndeveloped an interpretable hybrid feature- and similarity-based model for\nsupervised learning that combines feature and kernel learning for prediction\nand for investigation of causal relationships. We fit our hybrid models by\nconvex optimization with a sparsity-inducing penalty on the kernel. Depending\non the desired model interpretation, the feature and kernel coefficients can be\nlearned sequentially or simultaneously. The hybrid models showed comparable or\nbetter predictive performance than solely feature- or similarity-based\napproaches in a simulation study and in a case study to predict two-year risk\nof loneliness or social isolation with EHR data from a complex primary health\ncare population. Using the case study we also present new kernels for\nhigh-dimensional indicator-coded EHR data that are based on deviations from\npopulation-level expectations, and we identify considerations for causal\ninterpretations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.00299,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000018875,
      "text":"A Survey of Machine Narrative Reading Comprehension Assessments\n\n  As the body of research on machine narrative comprehension grows, there is a\ncritical need for consideration of performance assessment strategies as well as\nthe depth and scope of different benchmark tasks. Based on narrative theories,\nreading comprehension theories, as well as existing machine narrative reading\ncomprehension tasks and datasets, we propose a typology that captures the main\nsimilarities and differences among assessment tasks; and discuss the\nimplications of our typology for new task design and the challenges of\nnarrative reading comprehension.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.05206,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000127819,
      "text":"Access to care: analysis of the geographical distribution of healthcare\n  using Linked Open Data\n\n  Background: Access to medical care is strongly dependent on resource\nallocation, such as the geographical distribution of medical facilities.\nNevertheless, this data is usually restricted to country official\ndocumentation, not available to the public. While some medical facilities' data\nis accessible as semantic resources on the Web, it is not consistent in its\nmodeling and has yet to be integrated into a complete, open, and specialized\nrepository. This work focuses on generating a comprehensive semantic dataset of\nmedical facilities worldwide containing extensive information about such\nfacilities' geo-location.\n  Results: For this purpose, we collect, align, and link various open-source\ndatabases where medical facilities' information may be present. This work\nallows us to evaluate each data source along various dimensions, such as\ncompleteness, correctness, and interlinking with other sources, all critical\naspects of current knowledge representation technologies.\n  Conclusions: Our contributions directly benefit stakeholders in the\nbiomedical and health domain (patients, healthcare professionals, companies,\nregulatory authorities, and researchers), who will now have a better overview\nof the access to and distribution of medical facilities.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.05576,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Multi-agent Actor-Critic with Time Dynamical Opponent Model\n\n  In multi-agent reinforcement learning, multiple agents learn simultaneously\nwhile interacting with a common environment and each other. Since the agents\nadapt their policies during learning, not only the behavior of a single agent\nbecomes non-stationary, but also the environment as perceived by the agent.\nThis renders it particularly challenging to perform policy improvement. In this\npaper, we propose to exploit the fact that the agents seek to improve their\nexpected cumulative reward and introduce a novel \\textit{Time Dynamical\nOpponent Model} (TDOM) to encode the knowledge that the opponent policies tend\nto improve over time. We motivate TDOM theoretically by deriving a lower bound\nof the log objective of an individual agent and further propose\n\\textit{Multi-Agent Actor-Critic with Time Dynamical Opponent Model} (TDOM-AC).\nWe evaluate the proposed TDOM-AC on a differential game and the Multi-agent\nParticle Environment. We show empirically that TDOM achieves superior opponent\nbehavior prediction during test time. The proposed TDOM-AC methodology\noutperforms state-of-the-art Actor-Critic methods on the performed experiments\nin cooperative and \\textbf{especially} in mixed cooperative-competitive\nenvironments. TDOM-AC results in a more stable training and a faster\nconvergence.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.06403,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0001209974,
      "text":"Efficient Re-parameterization Operations Search for Easy-to-Deploy\n  Network Based on Directional Evolutionary Strategy\n\n  Structural re-parameterization (Rep) methods has achieved significant\nperformance improvement on traditional convolutional network. Most current Rep\nmethods rely on prior knowledge to select the reparameterization operations.\nHowever, the performance of architecture is limited by the type of operations\nand prior knowledge. To break this restriction, in this work, an improved\nre-parameterization search space is designed, which including more type of\nre-parameterization operations. Concretely, the performance of convolutional\nnetworks can be further improved by the search space. To effectively explore\nthis search space, an automatic re-parameterization enhancement strategy is\ndesigned based on neural architecture search (NAS), which can search a\nexcellent re-parameterization architecture. Besides, we visualize the output\nfeatures of the architecture to analyze the reasons for the formation of the\nre-parameterization architecture. On public datasets, we achieve better\nresults. Under the same training conditions as ResNet, we improve the accuracy\nof ResNet-50 by 1.82% on ImageNet-1k.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.11902,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000005298,
      "text":"Learning First-Order Symbolic Planning Representations That Are Grounded\n\n  Two main approaches have been developed for learning first-order planning\n(action) models from unstructured data: combinatorial approaches that yield\ncrisp action schemas from the structure of the state space, and deep learning\napproaches that produce action schemas from states represented by images. A\nbenefit of the former approach is that the learned action schemas are similar\nto those that can be written by hand; a benefit of the latter is that the\nlearned representations (predicates) are grounded on the images, and as a\nresult, new instances can be given in terms of images. In this work, we develop\na new formulation for learning crisp first-order planning models that are\ngrounded on parsed images, a step to combine the benefits of the two\napproaches. Parsed images are assumed to be given in a simple O2D language\n(objects in 2D) that involves a small number of unary and binary predicates\nlike \"left\", \"above\", \"shape\", etc. After learning, new planning instances can\nbe given in terms of pairs of parsed images, one for the initial situation and\nthe other for the goal. Learning and planning experiments are reported for\nseveral domains including Blocks, Sokoban, IPC Grid, and Hanoi.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.00302,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000035101,
      "text":"Actual Causality and Responsibility Attribution in Decentralized\n  Partially Observable Markov Decision Processes\n\n  Actual causality and a closely related concept of responsibility attribution\nare central to accountable decision making. Actual causality focuses on\nspecific outcomes and aims to identify decisions (actions) that were critical\nin realizing an outcome of interest. Responsibility attribution is\ncomplementary and aims to identify the extent to which decision makers (agents)\nare responsible for this outcome. In this paper, we study these concepts under\na widely used framework for multi-agent sequential decision making under\nuncertainty: decentralized partially observable Markov decision processes\n(Dec-POMDPs). Following recent works in RL that show correspondence between\nPOMDPs and Structural Causal Models (SCMs), we first establish a connection\nbetween Dec-POMDPs and SCMs. This connection enables us to utilize a language\nfor describing actual causality from prior work and study existing definitions\nof actual causality in Dec-POMDPs. Given that some of the well-known\ndefinitions may lead to counter-intuitive actual causes, we introduce a novel\ndefinition that more explicitly accounts for causal dependencies between\nagents' actions. We then turn to responsibility attribution based on actual\ncausality, where we argue that in ascribing responsibility to an agent it is\nimportant to consider both the number of actual causes in which the agent\nparticipates, as well as its ability to manipulate its own degree of\nresponsibility. Motivated by these arguments we introduce a family of\nresponsibility attribution methods that extends prior work, while accounting\nfor the aforementioned considerations. Finally, through a simulation-based\nexperiment, we compare different definitions of actual causality and\nresponsibility attribution methods. The empirical results demonstrate the\nqualitative difference between the considered definitions of actual causality\nand their impact on attributed responsibility.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.02495,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000373522,
      "text":"Efficient Pragmatic Program Synthesis with Informative Specifications\n\n  Providing examples is one of the most common way for end-users to interact\nwith program synthesizers. However, program synthesis systems assume that\nexamples consistent with the program are chosen at random, and do not exploit\nthe fact that users choose examples pragmatically. Prior work modeled program\nsynthesis as pragmatic communication, but required an inefficient enumeration\nof the entire program space. In this paper, we show that it is possible to\nbuild a program synthesizer that is both pragmatic and efficient by\napproximating the joint distribution of programs with a product of independent\nfactors, and performing pragmatic inference on each factor separately. This\nfactored distribution approximates the exact joint distribution well when the\nexamples are given pragmatically, and is compatible with a basic neuro-symbolic\nprogram synthesis algorithm. Surprisingly, we find that the synthesizer\nassuming a factored approximation performs better than a synthesizer assuming\nan exact joint distribution when evaluated on natural human inputs. This\nsuggests that humans may be assuming a factored distribution while\ncommunicating programs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.05545,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"A Reinforcement Learning Approach for Electric Vehicle Routing Problem\n  with Vehicle-to-Grid Supply\n\n  The use of electric vehicles (EV) in the last mile is appealing from both\nsustainability and operational cost perspectives. In addition to the inherent\ncost efficiency of EVs, selling energy back to the grid during peak grid\ndemand, is a potential source of additional revenue to a fleet operator. To\nachieve this, EVs have to be at specific locations (discharge points) during\nspecific points in time (peak period), even while meeting their core purpose of\ndelivering goods to customers. In this work, we consider the problem of EV\nrouting with constraints on loading capacity; time window; vehicle-to-grid\nenergy supply (CEVRPTW-D); which not only satisfy multiple system objectives,\nbut also scale efficiently to large problem sizes involving hundreds of\ncustomers and discharge stations. We present QuikRouteFinder that uses\nreinforcement learning (RL) for EV routing to overcome these challenges. Using\nSolomon datasets, results from RL are compared against exact formulations based\non mixed-integer linear program (MILP) and genetic algorithm (GA)\nmetaheuristics. On an average, the results show that RL is 24 times faster than\nMILP and GA, while being close in quality (within 20%) to the optimal.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.07123,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000080466,
      "text":"Retrospective on the 2021 BASALT Competition on Learning from Human\n  Feedback\n\n  We held the first-ever MineRL Benchmark for Agents that Solve Almost-Lifelike\nTasks (MineRL BASALT) Competition at the Thirty-fifth Conference on Neural\nInformation Processing Systems (NeurIPS 2021). The goal of the competition was\nto promote research towards agents that use learning from human feedback (LfHF)\ntechniques to solve open-world tasks. Rather than mandating the use of LfHF\ntechniques, we described four tasks in natural language to be accomplished in\nthe video game Minecraft, and allowed participants to use any approach they\nwanted to build agents that could accomplish the tasks. Teams developed a\ndiverse range of LfHF algorithms across a variety of possible human feedback\ntypes. The three winning teams implemented significantly different approaches\nwhile achieving similar performance. Interestingly, their approaches performed\nwell on different tasks, validating our choice of tasks to include in the\ncompetition. While the outcomes validated the design of our competition, we did\nnot get as many participants and submissions as our sister competition, MineRL\nDiamond. We speculate about the causes of this problem and suggest improvements\nfor future iterations of the competition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.04938,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"Value-based Practical Reasoning: Modal Logic + Argumentation\n\n  Autonomous agents are supposed to be able to finish tasks or achieve goals\nthat are assigned by their users through performing a sequence of actions.\nSince there might exist multiple plans that an agent can follow and each plan\nmight promote or demote different values along each action, the agent should be\nable to resolve the conflicts between them and evaluate which plan he should\nfollow. In this paper, we develop a logic-based framework that combines modal\nlogic and argumentation for value-based practical reasoning with plans. Modal\nlogic is used as a technique to represent and verify whether a plan with its\nlocal properties of value promotion or demotion can be followed to achieve an\nagent's goal. We then propose an argumentation-based approach that allows an\nagent to reason about his plans in the form of supporting or objecting to a\nplan using the verification results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.05217,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000022848,
      "text":"Persona-driven Dominant\/Submissive Map (PDSM) Generation for Tutorials\n\n  In this paper, we present a method for automated persona-driven video game\ntutorial level generation. Tutorial levels are scenarios in which the player\ncan explore and discover different rules and game mechanics. Procedural\npersonas can guide generators to create content which encourages or discourages\ncertain playstyle behaviors. In this system, we use procedural personas to\ncalculate the behavioral characteristics of levels which are evolved using the\nquality-diversity algorithm known as Constrained MAP-Elites. An evolved map's\nquality is determined by its simplicity: the simpler it is, the better it is.\nWithin this work, we show that the generated maps can strongly encourage or\ndiscourage different persona-like behaviors and range from simple solutions to\ncomplex puzzle-levels, making them perfect candidates for a tutorial generative\nsystem.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.04918,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000021524,
      "text":"When NAS Meets Trees: An Efficient Algorithm for Neural Architecture\n  Search\n\n  The key challenge in neural architecture search (NAS) is designing how to\nexplore wisely in the huge search space. We propose a new NAS method called\nTNAS (NAS with trees), which improves search efficiency by exploring only a\nsmall number of architectures while also achieving a higher search accuracy.\nTNAS introduces an architecture tree and a binary operation tree, to factorize\nthe search space and substantially reduce the exploration size. TNAS performs a\nmodified bi-level Breadth-First Search in the proposed trees to discover a\nhigh-performance architecture. Impressively, TNAS finds the global optimal\narchitecture on CIFAR-10 with test accuracy of 94.37\\% in four GPU hours in\nNAS-Bench-201. The average test accuracy is 94.35\\%, which outperforms the\nstate-of-the-art. Code is available at:\n\\url{https:\/\/github.com\/guochengqian\/TNAS}.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.10856,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000509951,
      "text":"New Core-Guided and Hitting Set Algorithms for Multi-Objective\n  Combinatorial Optimization\n\n  In the last decade, a plethora of algorithms for single-objective Boolean\noptimization has been proposed that rely on the iterative usage of a highly\neffective Propositional Satisfiability (SAT) solver. But the use of SAT solvers\nin Multi-Objective Combinatorial Optimization (MOCO) algorithms is still\nscarce. Due to this shortage of efficient tools for MOCO, many real-world\napplications formulated as multi-objective are simplified to single-objective,\nusing either a linear combination or a lexicographic ordering of the objective\nfunctions to optimize. In this paper, we extend the state of the art of MOCO\nsolvers with two novel unsatisfiability-based algorithms. The first is a\ncore-guided MOCO solver. The second is a hitting set-based MOCO solver.\nExperimental results obtained in a wide range of benchmark instances show that\nour new unsatisfiability-based algorithms can outperform state-of-the-art\nSAT-based algorithms for MOCO.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.13775,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000078479,
      "text":"CKH: Causal Knowledge Hierarchy for Estimating Structural Causal Models\n  from Data and Priors\n\n  Structural causal models (SCMs) provide a principled approach to identifying\ncausation from observational and experimental data in disciplines ranging from\neconomics to medicine. However, SCMs, which is typically represented as\ngraphical models, cannot rely only on data, rather require support of domain\nknowledge. A key challenge in this context is the absence of a methodological\nframework for encoding priors (background knowledge) into causal models in a\nsystematic manner. We propose an abstraction called causal knowledge hierarchy\n(CKH) for encoding priors into causal models. Our approach is based on the\nfoundation of \"levels of evidence\" in medicine, with a focus on confidence in\ncausal information. Using CKH, we present a methodological framework for\nencoding causal priors from various information sources and combining them to\nderive an SCM. We evaluate our approach on a simulated dataset and demonstrate\noverall performance compared to the ground truth causal model with sensitivity\nanalysis.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.05148,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Speech Sequence Embeddings using Nearest Neighbors Contrastive Learning\n\n  We introduce a simple neural encoder architecture that can be trained using\nan unsupervised contrastive learning objective which gets its positive samples\nfrom data-augmented k-Nearest Neighbors search. We show that when built on top\nof recent self-supervised audio representations, this method can be applied\niteratively and yield competitive SSE as evaluated on two tasks:\nquery-by-example of random sequences of speech, and spoken term discovery. On\nboth tasks our method pushes the state-of-the-art by a significant margin\nacross 5 different languages. Finally, we establish a benchmark on a\nquery-by-example task on the LibriSpeech dataset to monitor future improvements\nin the field.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.04071,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000012914,
      "text":"Utility Functions for Human\/Robot Interaction\n\n  In this paper, we place ourselves in the context of human robot interaction\nand address the problem of cognitive robot modelling. More precisely we are\ninvestigating properties of a utility-based model that will govern a robot's\nactions. The novelty of this approach lies in embedding the responsibility of\nthe robot over the state of affairs into the utility model via a utility\naggregation function. We describe desiderata for such a function and consider\nrelated properties.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2204.08687,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.000000298,
      "text":"Many Episode Learning in a Modular Embodied Agent via End-to-End\n  Interaction\n\n  In this work we give a case study of an embodied machine-learning (ML)\npowered agent that improves itself via interactions with crowd-workers. The\nagent consists of a set of modules, some of which are learned, and others\nheuristic. While the agent is not \"end-to-end\" in the ML sense, end-to-end\ninteraction is a vital part of the agent's learning mechanism. We describe how\nthe design of the agent works together with the design of multiple annotation\ninterfaces to allow crowd-workers to assign credit to module errors from\nend-to-end interactions, and to label data for individual modules. Over\nmultiple automated human-agent interaction, credit assignment, data annotation,\nand model re-training and re-deployment, rounds we demonstrate agent\nimprovement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.00077,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":4,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"Who's the Expert? On Multi-source Belief Change\n\n  Consider the following belief change\/merging scenario. A group of information\nsources gives a sequence of reports about the state of the world at various\ninstances (e.g. different points in time). The true states at these instances\nare unknown to us. The sources have varying levels of expertise, also unknown\nto us, and may be knowledgeable on some topics but not others. This may cause\nsources to report false statements in areas they lack expertise. What should we\nbelieve on the basis of these reports? We provide a framework in which to\nexplore this problem, based on an extension of propositional logic with\nexpertise formulas. This extended language allows us to express beliefs about\nthe state of the world at each instance, as well as beliefs about the expertise\nof each source. We propose several postulates, provide a couple of families of\nconcrete operators, and analyse these operators with respect to the postulates.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.12735,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Neuro-Symbolic Learning of Answer Set Programs from Raw Data\n\n  One of the ultimate goals of Artificial Intelligence is to assist humans in\ncomplex decision making. A promising direction for achieving this goal is\nNeuro-Symbolic AI, which aims to combine the interpretability of symbolic\ntechniques with the ability of deep learning to learn from raw data. However,\nmost current approaches require manually engineered symbolic knowledge, and\nwhere end-to-end training is considered, such approaches are either restricted\nto learning definite programs, or are restricted to training binary neural\nnetworks. In this paper, we introduce Neuro-Symbolic Inductive Learner (NSIL),\nan approach that trains a general neural network to extract latent concepts\nfrom raw data, whilst learning symbolic knowledge that maps latent concepts to\ntarget labels. The novelty of our approach is a method for biasing the learning\nof symbolic knowledge, based on the in-training performance of both neural and\nsymbolic components. We evaluate NSIL on three problem domains of different\ncomplexity, including an NP-complete problem. Our results demonstrate that NSIL\nlearns expressive knowledge, solves computationally complex problems, and\nachieves state-of-the-art performance in terms of accuracy and data efficiency.\nCode and technical appendix: https:\/\/github.com\/DanCunnington\/NSIL\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.10127,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000021524,
      "text":"Construction of Rough graph to handle uncertain pattern from an\n  Information System\n\n  Rough membership function defines the measurement of relationship between\nconditional and decision attribute from an Information system. In this paper we\npropose a new method to construct rough graph through rough membership function\n$\\omega_{G}^F(f)$. Rough graph identifies the pattern between the objects with\nimprecise and uncertain information. We explore the operations and properties\nof rough graph in various stages of its structure.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.0485,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Scaling-up Generalized Planning as Heuristic Search with Landmarks\n\n  Landmarks are one of the most effective search heuristics for classical\nplanning, but largely ignored in generalized planning. Generalized planning\n(GP) is usually addressed as a combinatorial search in a given space of\nalgorithmic solutions, where candidate solutions are evaluated w.r.t.~the\ninstances they solve. This type of solution evaluation ignores any sub-goal\ninformation that is not explicit in the representation of the planning\ninstances, causing plateaus in the space of candidate generalized plans.\nFurthermore, node expansion in GP is a run-time bottleneck since it requires\nevaluating every child node over the entire batch of classical planning\ninstances in a GP problem. In this paper we define a landmark counting\nheuristic for GP (that considers sub-goal information that is not explicitly\nrepresented in the planning instances), and a novel heuristic search algorithm\nfor GP (that we call PGP) and that progressively processes subsets of the\nplanning instances of a GP problem. Our two orthogonal contributions are\nanalyzed in an ablation study, showing that both improve the state-of-the-art\nin GP as heuristic search, and that both benefit from each other when used in\ncombination.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.10513,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Computable Artificial General Intelligence\n\n  Artificial general intelligence (AGI) may herald our extinction, according to\nAI safety research. Yet claims regarding AGI must rely upon mathematical\nformalisms -- theoretical agents we may analyse or attempt to build. AIXI\nappears to be the only such formalism supported by proof that its behaviour is\noptimal, a consequence of its use of compression as a proxy for intelligence.\nUnfortunately, AIXI is incomputable and claims regarding its behaviour highly\nsubjective. We argue that this is because AIXI formalises cognition as taking\nplace in isolation from the environment in which goals are pursued (Cartesian\ndualism). We propose an alternative, supported by proof and experiment, which\novercomes these problems. Integrating research from cognitive science with AI,\nwe formalise an enactive model of learning and reasoning to address the problem\nof subjectivity. This allows us to formulate a different proxy for\nintelligence, called weakness, which addresses the problem of incomputability.\nWe prove optimal behaviour is attained when weakness is maximised. This proof\nis supplemented by experimental results comparing weakness and description\nlength (the closest analogue to compression possible without reintroducing\nsubjectivity). Weakness outperforms description length, suggesting it is a\nbetter proxy. Furthermore we show that, if cognition is enactive, then\nminimisation of description length is neither necessary nor sufficient to\nattain optimal performance, undermining the notion that compression is closely\nrelated to intelligence. However, there remain open questions regarding the\nimplementation of scale-able AGI. In the short term, these results may be best\nutilised to improve the performance of existing systems. For example, our\nresults explain why Deepmind's Apperception Engine is able to generalise\neffectively, and how to replicate that performance by maximising weakness.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.13763,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000040068,
      "text":"Tutorial on Course-of-Action (COA) Attack Search Methods in Computer\n  Networks\n\n  In the literature of modern network security research, deriving effective and\nefficient course-of-action (COA) attach search methods are of interests in\nindustry and academia. As the network size grows, the traditional COA attack\nsearch methods can suffer from the limitations to computing and communication\nresources. Therefore, various methods have been developed to solve these\nproblems, and reinforcement learning (RL)-based intelligent algorithms are one\nof the most effective solutions. Therefore, we review the RL-based COA attack\nsearch methods for network attack scenarios in terms of the trends and their\ncontrib\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.11558,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"Using Natural Language and Program Abstractions to Instill Human\n  Inductive Biases in Machines\n\n  Strong inductive biases give humans the ability to quickly learn to perform a\nvariety of tasks. Although meta-learning is a method to endow neural networks\nwith useful inductive biases, agents trained by meta-learning may sometimes\nacquire very different strategies from humans. We show that co-training these\nagents on predicting representations from natural language task descriptions\nand programs induced to generate such tasks guides them toward more human-like\ninductive biases. Human-generated language descriptions and program induction\nmodels that add new learned primitives both contain abstract concepts that can\ncompress description length. Co-training on these representations result in\nmore human-like behavior in downstream meta-reinforcement learning agents than\nless abstract controls (synthetic language descriptions, program induction\nwithout learned primitives), suggesting that the abstraction supported by these\nrepresentations is key.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.11234,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000010928,
      "text":"DagSim: Combining DAG-based model structure with unconstrained data\n  types and relations for flexible, transparent, and modularized data\n  simulation\n\n  Data simulation is fundamental for machine learning and causal inference, as\nit allows exploration of scenarios and assessment of methods in settings with\nfull control of ground truth. Directed acyclic graphs (DAGs) are well\nestablished for encoding the dependence structure over a collection of\nvariables in both inference and simulation settings. However, while modern\nmachine learning is applied to data of an increasingly complex nature,\nDAG-based simulation frameworks are still confined to settings with relatively\nsimple variable types and functional forms. We here present DagSim, a\nPython-based framework for DAG-based data simulation without any constraints on\nvariable types or functional relations. A succinct YAML format for defining the\nsimulation model structure promotes transparency, while separate user-provided\nfunctions for generating each variable based on its parents ensure simulation\ncode modularization. We illustrate the capabilities of DagSim through use cases\nwhere metadata variables control shapes in an image and patterns in\nbio-sequences.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.13954,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000042717,
      "text":"Geometer: Graph Few-Shot Class-Incremental Learning via Prototype\n  Representation\n\n  With the tremendous expansion of graphs data, node classification shows its\ngreat importance in many real-world applications. Existing graph neural network\nbased methods mainly focus on classifying unlabeled nodes within fixed classes\nwith abundant labeling. However, in many practical scenarios, graph evolves\nwith emergence of new nodes and edges. Novel classes appear incrementally along\nwith few labeling due to its newly emergence or lack of exploration. In this\npaper, we focus on this challenging but practical graph few-shot\nclass-incremental learning (GFSCIL) problem and propose a novel method called\nGeometer. Instead of replacing and retraining the fully connected neural\nnetwork classifer, Geometer predicts the label of a node by finding the nearest\nclass prototype. Prototype is a vector representing a class in the metric\nspace. With the pop-up of novel classes, Geometer learns and adjusts the\nattention-based prototypes by observing the geometric proximity, uniformity and\nseparability. Teacher-student knowledge distillation and biased sampling are\nfurther introduced to mitigate catastrophic forgetting and unbalanced labeling\nproblem respectively. Experimental results on four public datasets demonstrate\nthat Geometer achieves a substantial improvement of 9.46% to 27.60% over\nstate-of-the-art methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.10575,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000060598,
      "text":"UVA Resources for the Biomedical Vocabulary Alignment at Scale in the\n  UMLS Metathesaurus\n\n  The construction and maintenance process of the UMLS (Unified Medical\nLanguage System) Metathesaurus is time-consuming, costly, and error-prone as it\nrelies on (1) the lexical and semantic processing for suggesting synonymous\nterms, and (2) the expertise of UMLS editors for curating the suggestions. For\nimproving the UMLS Metathesaurus construction process, our research group has\ndefined a new task called UVA (UMLS Vocabulary Alignment) and generated a\ndataset for evaluating the task. Our group has also developed different\nbaselines for this task using logical rules (RBA), and neural networks (LexLM\nand ConLM).\n  In this paper, we present a set of reusable and reproducible resources\nincluding (1) a dataset generator, (2) three datasets generated by using the\ngenerator, and (3) three baseline approaches. We describe the UVA dataset\ngenerator and its implementation generalized for any given UMLS release. We\ndemonstrate the use of the dataset generator by generating datasets\ncorresponding to three UMLS releases, 2020AA, 2021AA, and 2021AB. We provide\nthree UVA baselines using the three existing approaches (LexLM, ConLM, and\nRBA). The code, the datasets, and the experiments are publicly available,\nreusable, and reproducible with any UMLS release (a no-cost license agreement\nis required for downloading the UMLS).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.06241,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000000662,
      "text":"Can counterfactual explanations of AI systems' predictions skew lay\n  users' causal intuitions about the world? If so, can we correct for that?\n\n  Counterfactual (CF) explanations have been employed as one of the modes of\nexplainability in explainable AI-both to increase the transparency of AI\nsystems and to provide recourse. Cognitive science and psychology, however,\nhave pointed out that people regularly use CFs to express causal relationships.\nMost AI systems are only able to capture associations or correlations in data\nso interpreting them as casual would not be justified. In this paper, we\npresent two experiment (total N = 364) exploring the effects of CF explanations\nof AI system's predictions on lay people's causal beliefs about the real world.\nIn Experiment 1 we found that providing CF explanations of an AI system's\npredictions does indeed (unjustifiably) affect people's causal beliefs\nregarding factors\/features the AI uses and that people are more likely to view\nthem as causal factors in the real world. Inspired by the literature on\nmisinformation and health warning messaging, Experiment 2 tested whether we can\ncorrect for the unjustified change in causal beliefs. We found that pointing\nout that AI systems capture correlations and not necessarily causal\nrelationships can attenuate the effects of CF explanations on people's causal\nbeliefs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.05793,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Robustness Guarantees for Credal Bayesian Networks via Constraint\n  Relaxation over Probabilistic Circuits\n\n  In many domains, worst-case guarantees on the performance (e.g., prediction\naccuracy) of a decision function subject to distributional shifts and\nuncertainty about the environment are crucial. In this work we develop a method\nto quantify the robustness of decision functions with respect to credal\nBayesian networks, formal parametric models of the environment where\nuncertainty is expressed through credal sets on the parameters. In particular,\nwe address the maximum marginal probability (MARmax) problem, that is,\ndetermining the greatest probability of an event (such as misclassification)\nobtainable for parameters in the credal set. We develop a method to faithfully\ntransfer the problem into a constrained optimization problem on a probabilistic\ncircuit. By performing a simple constraint relaxation, we show how to obtain a\nguaranteed upper bound on MARmax in linear time in the size of the circuit. We\nfurther theoretically characterize this constraint relaxation in terms of the\noriginal Bayesian network structure, which yields insight into the tightness of\nthe bound. We implement the method and provide experimental evidence that the\nupper bound is often near tight and demonstrates improved scalability compared\nto other methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.14327,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Efficient Policy Iteration for Robust Markov Decision Processes via\n  Regularization\n\n  Robust Markov decision processes (MDPs) provide a general framework to model\ndecision problems where the system dynamics are changing or only partially\nknown. Efficient methods for some \\texttt{sa}-rectangular robust MDPs exist,\nusing its equivalence with reward regularized MDPs, generalizable to online\nsettings. In comparison to \\texttt{sa}-rectangular robust MDPs,\n\\texttt{s}-rectangular robust MDPs are less restrictive but much more difficult\nto deal with. Interestingly, recent works have established the equivalence\nbetween \\texttt{s}-rectangular robust MDPs and policy regularized MDPs. But we\ndon't have a clear understanding to exploit this equivalence, to do policy\nimprovement steps to get the optimal value function or policy. We don't have a\nclear understanding of greedy\/optimal policy except it can be stochastic. There\nexist no methods that can naturally be generalized to model-free settings. We\nshow a clear and explicit equivalence between \\texttt{s}-rectangular $L_p$\nrobust MDPs and policy regularized MDPs that resemble very much policy entropy\nregularized MDPs widely used in practice. Further, we dig into the policy\nimprovement step and concretely derive optimal robust Bellman operators for\n\\texttt{s}-rectangular $L_p$ robust MDPs. We find that the greedy\/optimal\npolicies in \\texttt{s}-rectangular $L_p$ robust MDPs are threshold policies\nthat play top $k$ actions whose $Q$ value is greater than some threshold\n(value), proportional to the $(p-1)$th power of its advantage. In addition, we\nshow time complexity of (\\texttt{sa} and \\texttt{s}-rectangular) $L_p$ robust\nMDPs is the same as non-robust MDPs up to some log factors. Our work greatly\nextends the existing understanding of \\texttt{s}-rectangular robust MDPs and\nnaturally generalizable to online settings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.09729,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000018875,
      "text":"Reinforcement Learning with Brain-Inspired Modulation can Improve\n  Adaptation to Environmental Changes\n\n  Developments in reinforcement learning (RL) have allowed algorithms to\nachieve impressive performance in highly complex, but largely static problems.\nIn contrast, biological learning seems to value efficiency of adaptation to a\nconstantly-changing world. Here we build on a recently-proposed neuronal\nlearning rule that assumes each neuron can optimize its energy balance by\npredicting its own future activity. That assumption leads to a neuronal\nlearning rule that uses presynaptic input to modulate prediction error. We\nargue that an analogous RL rule would use action probability to modulate reward\nprediction error. This modulation makes the agent more sensitive to negative\nexperiences, and more careful in forming preferences. We embed the proposed\nrule in both tabular and deep-Q-network RL algorithms, and find that it\noutperforms conventional algorithms in simple, but highly-dynamic tasks. We\nsuggest that the new rule encapsulates a core principle of biological\nintelligence; an important component for allowing algorithms to adapt to change\nin a human-like way.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.13745,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000044041,
      "text":"DeepSAT: An EDA-Driven Learning Framework for SAT\n\n  We present DeepSAT, a novel end-to-end learning framework for the Boolean\nsatisfiability (SAT) problem. Unlike existing solutions trained on random SAT\ninstances with relatively weak supervision, we propose applying the knowledge\nof the well-developed electronic design automation (EDA) field for SAT solving.\nSpecifically, we first resort to logic synthesis algorithms to pre-process SAT\ninstances into optimized and-inverter graphs (AIGs). By doing so, the\ndistribution diversity among various SAT instances can be dramatically reduced,\nwhich facilitates improving the generalization capability of the learned model.\nNext, we regard the distribution of SAT solutions being a product of\nconditional Bernoulli distributions. Based on this observation, we approximate\nthe SAT solving procedure with a conditional generative model, leveraging a\nnovel directed acyclic graph neural network (DAGNN) with two polarity\nprototypes for conditional SAT modeling. To effectively train the generative\nmodel, with the help of logic simulation tools, we obtain the probabilities of\nnodes in the AIG being logic `1' as rich supervision. We conduct comprehensive\nexperiments on various SAT problems. Our results show that, DeepSAT achieves\nsignificant accuracy improvements over state-of-the-art learning-based SAT\nsolutions, especially when generalized to SAT instances that are relatively\nlarge or with diverse distributions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.11005,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000041723,
      "text":"Parameter-Efficient Sparsity for Large Language Models Fine-Tuning\n\n  With the dramatically increased number of parameters in language models,\nsparsity methods have received ever-increasing research focus to compress and\naccelerate the models. While most research focuses on how to accurately retain\nappropriate weights while maintaining the performance of the compressed model,\nthere are challenges in the computational overhead and memory footprint of\nsparse training when compressing large-scale language models. To address this\nproblem, we propose a Parameter-efficient Sparse Training (PST) method to\nreduce the number of trainable parameters during sparse-aware training in\ndownstream tasks. Specifically, we first combine the data-free and data-driven\ncriteria to efficiently and accurately measure the importance of weights. Then\nwe investigate the intrinsic redundancy of data-driven weight importance and\nderive two obvious characteristics i.e., low-rankness and structuredness. Based\non that, two groups of small matrices are introduced to compute the data-driven\nimportance of weights, instead of using the original large importance score\nmatrix, which therefore makes the sparse training resource-efficient and\nparameter-efficient. Experiments with diverse networks (i.e., BERT, RoBERTa and\nGPT-2) on dozens of datasets demonstrate PST performs on par or better than\nprevious sparsity methods, despite only training a small number of parameters.\nFor instance, compared with previous sparsity methods, our PST only requires\n1.5% trainable parameters to achieve comparable performance on BERT.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.04522,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Assessing Confidence with Assurance 2.0\n\n  An assurance case is intended to provide justifiable confidence in the truth\nof its top claim, which typically concerns safety or security. A natural\nquestion is then \"how much\" confidence does the case provide? We argue that\nconfidence cannot be reduced to a single attribute or measurement. Instead, we\nsuggest it should be based on attributes that draw on three different\nperspectives: positive, negative, and residual doubts.\n  Positive Perspectives consider the extent to which the evidence and overall\nargument of the case combine to make a positive statement justifying belief in\nits claims. We set a high bar for justification, requiring it to be\nindefeasible. The primary positive measure for this is soundness, which\ninterprets the argument as a logical proof. Confidence in evidence can be\nexpressed probabilistically and we use confirmation measures to ensure that the\n\"weight\" of evidence crosses some threshold. In addition, probabilities can be\naggregated from evidence through the steps of the argument using probability\nlogics to yield what we call probabilistic valuations for the claims.\n  Negative Perspectives record doubts and challenges to the case, typically\nexpressed as defeaters, and their exploration and resolution. Assurance\ndevelopers must guard against confirmation bias and should vigorously explore\npotential defeaters as they develop the case, and should record them and their\nresolution to avoid rework and to aid reviewers.\n  Residual Doubts: the world is uncertain so not all potential defeaters can be\nresolved. We explore risks and may deem them acceptable or unavoidable. It is\ncrucial however that these judgments are conscious ones and that they are\nrecorded in the assurance case.\n  This report examines the perspectives in detail and indicates how Clarissa,\nour prototype toolset for Assurance 2.0, assists in their evaluation.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.1159,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000009934,
      "text":"Forecasting Argumentation Frameworks\n\n  We introduce Forecasting Argumentation Frameworks (FAFs), a novel\nargumentation-based methodology for forecasting informed by recent judgmental\nforecasting research. FAFs comprise update frameworks which empower (human or\nartificial) agents to argue over time about the probability of outcomes, e.g.\nthe winner of a political election or a fluctuation in inflation rates, whilst\nflagging perceived irrationality in the agents' behaviour with a view to\nimproving their forecasting accuracy. FAFs include five argument types,\namounting to standard pro\/con arguments, as in bipolar argumentation, as well\nas novel proposal arguments and increase\/decrease amendment arguments. We adapt\nan existing gradual semantics for bipolar argumentation to determine the\naggregated dialectical strength of proposal arguments and define irrational\nbehaviour. We then give a simple aggregation function which produces a final\ngroup forecast from rational agents' individual forecasts. We identify and\nstudy properties of FAFs and conduct an empirical evaluation which signals\nFAFs' potential to increase the forecasting accuracy of participants.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.02328,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000016226,
      "text":"Exploring the Benefits of Teams in Multiagent Learning\n\n  For problems requiring cooperation, many multiagent systems implement\nsolutions among either individual agents or across an entire population towards\na common goal. Multiagent teams are primarily studied when in conflict;\nhowever, organizational psychology (OP) highlights the benefits of teams among\nhuman populations for learning how to coordinate and cooperate. In this paper,\nwe propose a new model of multiagent teams for reinforcement learning (RL)\nagents inspired by OP and early work on teams in artificial intelligence. We\nvalidate our model using complex social dilemmas that are popular in recent\nmultiagent RL and find that agents divided into teams develop cooperative\npro-social policies despite incentives to not cooperate. Furthermore, agents\nare better able to coordinate and learn emergent roles within their teams and\nachieve higher rewards compared to when the interests of all agents are\naligned.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.07635,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000032783,
      "text":"Relating Information and Proof\n\n  In mathematics information is a number that measures uncertainty (entropy)\nbased on a probabilistic distribution, often of an obscure origin. In real life\nlanguage information is a datum, a statement, more precisely, a formula. But\nsuch a formula should be justified by a proof. I try to formalize this\nperception of information. The measure of informativeness of a proof is based\non the set of proofs related to the formulas under consideration. This set of\npossible proofs (`a knowledge base') defines a probabilistic measure, and\nentropic weight is defined using this measure. The paper is mainly conceptual,\nit is not clear where and how this approach can be applied.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2205.11173,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":5,
    "pangram_prediction":{
      "ai_likelihood":0.0000092718,
      "text":"Multi-objective Optimization of Clustering-based Scheduling for\n  Multi-workflow On Clouds Considering Fairness\n\n  Distributed computing, such as cloud computing, provides promising platforms\nto execute multiple workflows. Workflow scheduling plays an important role in\nmulti-workflow execution with multi-objective requirements. Although there\nexist many multi-objective scheduling algorithms, they focus mainly on\noptimizing makespan and cost for a single workflow. There is a limited research\non multi-objective optimization for multi-workflow scheduling. Considering\nmulti-workflow scheduling, there is an additional key objective to maintain the\nfairness of workflows using the resources. To address such issues, this paper\nfirst defines a new multi-objective optimization model based on makespan, cost,\nand fairness, and then proposes a global clustering-based multi-workflow\nscheduling strategy for resource allocation. Experimental results show that the\nproposed approach performs better than the compared algorithms without\nsignificant compromise of the overall makespan and cost as well as individual\nfairness, which can guide the simulation workflow scheduling on clouds.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.01044,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"Artificial Open World for Evaluating AGI: a Conceptual Design\n\n  How to evaluate Artificial General Intelligence (AGI) is a critical problem\nthat is discussed and unsolved for a long period. In the research of narrow AI,\nthis seems not a severe problem, since researchers in that field focus on some\nspecific problems as well as one or some aspects of cognition, and the criteria\nfor evaluation are explicitly defined. By contrast, an AGI agent should solve\nproblems that are never-encountered by both agents and developers. However,\nonce a developer tests and debugs the agent with a problem, the\nnever-encountered problem becomes the encountered problem, as a result, the\nproblem is solved by the developers to some extent, exploiting their\nexperience, rather than the agents. This conflict, as we call the trap of\ndevelopers' experience, leads to that this kind of problems is probably hard to\nbecome an acknowledged criterion. In this paper, we propose an evaluation\nmethod named Artificial Open World, aiming to jump out of the trap. The\nintuition is that most of the experience in the actual world should not be\nnecessary to be applied to the artificial world, and the world should be open\nin some sense, such that developers are unable to perceive the world and solve\nproblems by themselves before testing, though after that they are allowed to\ncheck all the data. The world is generated in a similar way as the actual\nworld, and a general form of problems is proposed. A metric is proposed aiming\nto quantify the progress of research. This paper describes the conceptual\ndesign of the Artificial Open World, though the formalization and the\nimplementation are left to the future.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.08611,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0001687474,
      "text":"Medical Dialogue Response Generation with Pivotal Information Recalling\n\n  Medical dialogue generation is an important yet challenging task. Most\nprevious works rely on the attention mechanism and large-scale pretrained\nlanguage models. However, these methods often fail to acquire pivotal\ninformation from the long dialogue history to yield an accurate and informative\nresponse, due to the fact that the medical entities usually scatters throughout\nmultiple utterances along with the complex relationships between them. To\nmitigate this problem, we propose a medical response generation model with\nPivotal Information Recalling (MedPIR), which is built on two components, i.e.,\nknowledge-aware dialogue graph encoder and recall-enhanced generator. The\nknowledge-aware dialogue graph encoder constructs a dialogue graph by\nexploiting the knowledge relationships between entities in the utterances, and\nencodes it with a graph attention network. Then, the recall-enhanced generator\nstrengthens the usage of these pivotal information by generating a summary of\nthe dialogue before producing the actual response. Experimental results on two\nlarge-scale medical dialogue datasets show that MedPIR outperforms the strong\nbaselines in BLEU scores and medical entities F1 measure.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.06793,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"How to Agree to Disagree: Managing Ontological Perspectives using\n  Standpoint Logic\n\n  The importance of taking individual, potentially conflicting perspectives\ninto account when dealing with knowledge has been widely recognised. Many\nexisting ontology management approaches fully merge knowledge perspectives,\nwhich may require weakening in order to maintain consistency; others represent\nthe distinct views in an entirely detached way.\n  As an alternative, we propose Standpoint Logic, a simple, yet versatile\nmulti-modal logic \"add-on\" for existing KR languages intended for the\nintegrated representation of domain knowledge relative to diverse, possibly\nconflicting standpoints, which can be hierarchically organised, combined and\nput in relation to each other.\n  Starting from the generic framework of First-Order Standpoint Logic (FOSL),\nwe subsequently focus our attention on the fragment of sentential formulas, for\nwhich we provide a polytime translation into the standpoint-free version. This\nresult yields decidability and favourable complexities for a variety of highly\nexpressive decidable fragments of first-order logic. Using some elaborate\nencoding tricks, we then establish a similar translation for the very\nexpressive description logic SROIQb_s underlying the OWL 2 DL ontology\nlanguage. By virtue of this result, existing highly optimised OWL reasoners can\nbe used to provide practical reasoning support for ontology languages extended\nby standpoint modelling.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.06202,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Constraint Guided Gradient Descent: Guided Training with Inequality\n  Constraints\n\n  Deep learning is typically performed by learning a neural network solely from\ndata in the form of input-output pairs ignoring available domain knowledge. In\nthis work, the Constraint Guided Gradient Descent (CGGD) framework is proposed\nthat enables the injection of domain knowledge into the training procedure. The\ndomain knowledge is assumed to be described as a conjunction of hard inequality\nconstraints which appears to be a natural choice for several applications.\nCompared to other neuro-symbolic approaches, the proposed method converges to a\nmodel that satisfies any inequality constraint on the training data and does\nnot require to first transform the constraints into some ad-hoc term that is\nadded to the learning (optimisation) objective. Under certain conditions, it is\nshown that CGGD can converges to a model that satisfies the constraints on the\ntraining set, while prior work does not necessarily converge to such a model.\nIt is empirically shown on two independent and small data sets that CGGD makes\ntraining less dependent on the initialisation of the network and improves the\nconstraint satisfiability on all data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.02216,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000053644,
      "text":"Sequential Counterfactual Decision-Making Under Confounded Reward\n\n  We investigate the limitations of random trials when the cause of interest is\nconfounded with the effect by formalizing a counterfactual policy-space where\nthe agent's natural predilection is input to a soft-intervention.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.07082,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000012583,
      "text":"Stability and Generalization of Stochastic Optimization with Nonconvex\n  and Nonsmooth Problems\n\n  Stochastic optimization has found wide applications in minimizing objective\nfunctions in machine learning, which motivates a lot of theoretical studies to\nunderstand its practical success. Most of existing studies focus on the\nconvergence of optimization errors, while the generalization analysis of\nstochastic optimization is much lagging behind. This is especially the case for\nnonconvex and nonsmooth problems often encountered in practice. In this paper,\nwe initialize a systematic stability and generalization analysis of stochastic\noptimization on nonconvex and nonsmooth problems. We introduce novel\nalgorithmic stability measures and establish their quantitative connection on\nthe gap between population gradients and empirical gradients, which is then\nfurther extended to study the gap between the Moreau envelope of the empirical\nrisk and that of the population risk. To our knowledge, these quantitative\nconnection between stability and generalization in terms of either gradients or\nMoreau envelopes have not been studied in the literature. We introduce a class\nof sampling-determined algorithms, for which we develop bounds for three\nstability measures. Finally, we apply these discussions to derive error bounds\nfor stochastic gradient descent and its adaptive variant, where we show how to\nachieve an implicit regularization by tuning the step sizes and the number of\niterations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.08626,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000228816,
      "text":"MSDF: A General Open-Domain Multi-Skill Dialog Framework\n\n  Dialog systems have achieved significant progress and have been widely used\nin various scenarios. The previous researches mainly focused on designing\ndialog generation models in a single scenario, while comprehensive abilities\nare required to handle tasks under various scenarios in the real world. In this\npaper, we propose a general Multi-Skill Dialog Framework, namely MSDF, which\ncan be applied in different dialog tasks (e.g. knowledge grounded dialog and\npersona based dialog). Specifically, we propose a transferable response\ngenerator pre-trained on diverse large-scale dialog corpora as the backbone of\nMSDF, consisting of BERT-based encoders and a GPT-based decoder. To select the\nresponse consistent with dialog history, we propose a consistency selector\ntrained through negative sampling. Moreover, the flexible copy mechanism of\nexternal knowledge is also employed to enhance the utilization of multiform\nknowledge in various scenarios. We conduct experiments on knowledge grounded\ndialog, recommendation dialog, and persona based dialog tasks. The experimental\nresults indicate that our MSDF outperforms the baseline models with a large\nmargin. In the Multi-skill Dialog of 2021 Language and Intelligence Challenge,\nour general MSDF won the 3rd prize, which proves our MSDF is effective and\ncompetitive.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.01954,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000029471,
      "text":"MPE inference using an Incremental Build-Infer-Approximate Paradigm\n\n  Exact inference of the most probable explanation (MPE) in Bayesian networks\nis known to be NP-complete. In this paper, we propose an algorithm for\napproximate MPE inference that is based on the incremental\nbuild-infer-approximate (IBIA) framework. We use this framework to obtain an\nordered set of partitions of the Bayesian network and the corresponding\nmax-calibrated clique trees. We show that the maximum belief in the last\npartition gives an estimate of the probability of the MPE assignment. We\npropose an iterative algorithm for decoding, in which the subset of variables\nfor which an assignment is obtained is guaranteed to increase in every\niteration. There are no issues of convergence, and we do not perform a search\nfor solutions. Even though it is a single shot algorithm, we obtain valid\nassignments in 100 out of the 117 benchmarks used for testing. The accuracy of\nour solution is comparable to a branch and bound search in majority of the\nbenchmarks, with competitive run times.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.07472,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000054306,
      "text":"Collaborative Knowledge Graph Fusion by Exploiting the Open Corpus\n\n  To alleviate the challenges of building Knowledge Graphs (KG) from scratch, a\nmore general task is to enrich a KG using triples from an open corpus, where\nthe obtained triples contain noisy entities and relations. It is challenging to\nenrich a KG with newly harvested triples while maintaining the quality of the\nknowledge representation. This paper proposes a system to refine a KG using\ninformation harvested from an additional corpus. To this end, we formulate our\ntask as two coupled sub-tasks, namely join event extraction (JEE) and knowledge\ngraph fusion (KGF). We then propose a Collaborative Knowledge Graph Fusion\nFramework to allow our sub-tasks to mutually assist one another in an\nalternating manner. More concretely, the explorer carries out the JEE\nsupervised by both the ground-truth annotation and an existing KG provided by\nthe supervisor. The supervisor then evaluates the triples extracted by the\nexplorer and enriches the KG with those that are highly ranked. To implement\nthis evaluation, we further propose a Translated Relation Alignment Scoring\nMechanism to align and translate the extracted triples to the prior KG.\nExperiments verify that this collaboration can both improve the performance of\nthe JEE and the KGF.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.13959,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000010928,
      "text":"Comparing and extending the use of defeasible argumentation with\n  quantitative data in real-world contexts\n\n  Dealing with uncertain, contradicting, and ambiguous information is still a\ncentral issue in Artificial Intelligence (AI). As a result, many formalisms\nhave been proposed or adapted so as to consider non-monotonicity, with only a\nlimited number of works and researchers performing any sort of comparison among\nthem. A non-monotonic formalism is one that allows the retraction of previous\nconclusions or claims, from premises, in light of new evidence, offering some\ndesirable flexibility when dealing with uncertainty. This research article\nfocuses on evaluating the inferential capacity of defeasible argumentation, a\nformalism particularly envisioned for modelling non-monotonic reasoning. In\naddition to this, fuzzy reasoning and expert systems, extended for handling\nnon-monotonicity of reasoning, are selected and employed as baselines, due to\ntheir vast and accepted use within the AI community. Computational trust was\nselected as the domain of application of such models. Trust is an ill-defined\nconstruct, hence, reasoning applied to the inference of trust can be seen as\nnon-monotonic. Inference models were designed to assign trust scalars to\neditors of the Wikipedia project. In particular, argument-based models\ndemonstrated more robustness than those built upon the baselines despite the\nknowledge bases or datasets employed. This study contributes to the body of\nknowledge through the exploitation of defeasible argumentation and its\ncomparison to similar approaches. The practical use of such approaches coupled\nwith a modular design that facilitates similar experiments was exemplified and\ntheir respective implementations made publicly available on GitHub [120, 121].\nThis work adds to previous works, empirically enhancing the generalisability of\ndefeasible argumentation as a compelling approach to reason with quantitative\ndata and uncertain knowledge.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.05273,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000010596,
      "text":"A General Framework for the Representation of Function and Affordance: A\n  Cognitive, Causal, and Grounded Approach, and a Step Toward AGI\n\n  In AI research, so far, the attention paid to the characterization and\nrepresentation of function and affordance has been sporadic and sparse, even\nthough this aspect features prominently in an intelligent system's functioning.\nIn the sporadic and sparse, though commendable efforts so far devoted to the\ncharacterization and understanding of function and affordance, there has also\nbeen no general framework that could unify all the different use domains and\nsituations related to the representation and application of functional\nconcepts. This paper develops just such a general framework, with an approach\nthat emphasizes the fact that the representations involved must be explicitly\ncognitive and conceptual, and they must also contain causal characterizations\nof the events and processes involved, as well as employ conceptual constructs\nthat are grounded in the referents to which they refer, in order to achieve\nmaximal generality. The basic general framework is described, along with a set\nof basic guiding principles with regards to the representation of\nfunctionality. To properly and adequately characterize and represent\nfunctionality, a descriptive representation language is needed. This language\nis defined and developed, and many examples of its use are described. The\ngeneral framework is developed based on an extension of the general language\nmeaning representational framework called conceptual dependency. To support the\ngeneral characterization and representation of functionality, the basic\nconceptual dependency framework is enhanced with representational devices\ncalled structure anchor and conceptual dependency elaboration, together with\nthe definition of a set of ground level concepts. These novel representational\nconstructs are defined, developed, and described. A general framework dealing\nwith functionality would represent a major step toward achieving Artificial\nGeneral Intelligence.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.03965,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0001805358,
      "text":"Combining Monte-Carlo Tree Search with Proof-Number Search\n\n  Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) have been\nsuccessfully applied for decision making in a range of games. This paper\nproposes a new approach called PN-MCTS that combines these two tree-search\nmethods by incorporating the concept of proof and disproof numbers into the UCT\nformula of MCTS. Experimental results demonstrate that PN-MCTS outperforms\nbasic MCTS in several games including Lines of Action, MiniShogi,\nKnightthrough, and Awari, achieving win rates up to 94.0%.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.13658,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000027816,
      "text":"Geo-Situation for Modeling Causality of Geo-Events in Knowledge Graphs\n\n  This paper proposes a framework for representing and reasoning causality\nbetween geographic events by introducing the notion of Geo-Situation. This\nconcept links to observational snapshots that represent sets of conditions, and\neither acts as the setting of a geo-event or influences the initiation of a\ngeo-event. We envision the use of this framework within knowledge graphs that\nrepresent geographic entities will help answer the important question of why a\ngeographic event occurred.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.11812,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000231796,
      "text":"Formalizing the Problem of Side Effect Regularization\n\n  AI objectives are often hard to specify properly. Some approaches tackle this\nproblem by regularizing the AI's side effects: Agents must weigh off \"how much\nof a mess they make\" with an imperfectly specified proxy objective. We propose\na formal criterion for side effect regularization via the assistance game\nframework. In these games, the agent solves a partially observable Markov\ndecision process (POMDP) representing its uncertainty about the objective\nfunction it should optimize. We consider the setting where the true objective\nis revealed to the agent at a later time step. We show that this POMDP is\nsolved by trading off the proxy reward with the agent's ability to achieve a\nrange of future tasks. We empirically demonstrate the reasonableness of our\nproblem formalization via ground-truth evaluation in two gridworld\nenvironments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.07084,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000036425,
      "text":"An Efficient HTN to STRIPS Encoding for Concurrent Plans\n\n  The Hierarchical Task Network (HTN) formalism is used to express a wide\nvariety of planning problems in terms of decompositions of tasks into subtaks.\nMany techniques have been proposed to solve such hierarchical planning\nproblems. A particular technique is to encode hierarchical planning problems as\nclassical STRIPS planning problems. One advantage of this technique is to\nbenefit directly from the constant improvements made by STRIPS planners.\nHowever, there are still few effective and expressive encodings. In this paper,\nwe present a new HTN to STRIPS encoding allowing to generate concurrent plans.\nWe show experimentally that this encoding outperforms previous approaches on\nhierarchical IPC benchmarks.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.07988,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000010265,
      "text":"PreCogIIITH at HinglishEval : Leveraging Code-Mixing Metrics & Language\n  Model Embeddings To Estimate Code-Mix Quality\n\n  Code-Mixing is a phenomenon of mixing two or more languages in a speech event\nand is prevalent in multilingual societies. Given the low-resource nature of\nCode-Mixing, machine generation of code-mixed text is a prevalent approach for\ndata augmentation. However, evaluating the quality of such machine generated\ncode-mixed text is an open problem. In our submission to HinglishEval, a\nshared-task collocated with INLG2022, we attempt to build models factors that\nimpact the quality of synthetically generated code-mix text by predicting\nratings for code-mix quality.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.0446,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"Open ERP System Data For Occupational Fraud Detection\n\n  Recent estimates report that companies lose 5% of their revenue to\noccupational fraud. Since most medium-sized and large companies employ\nEnterprise Resource Planning (ERP) systems to track vast amounts of information\nregarding their business process, researchers have in the past shown interest\nin automatically detecting fraud through ERP system data. Current research in\nthis area, however, is hindered by the fact that ERP system data is not\npublicly available for the development and comparison of fraud detection\nmethods. We therefore endeavour to generate public ERP system data that\nincludes both normal business operation and fraud. We propose a strategy for\ngenerating ERP system data through a serious game, model a variety of fraud\nscenarios in cooperation with auditing experts, and generate data from a\nsimulated make-to-stock production company with multiple research participants.\nWe aggregate the generated data into ready to used datasets for fraud detection\nin ERP systems, and supply both the raw and aggregated data to the general\npublic to allow for open development and comparison of fraud detection\napproaches on ERP system data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.06213,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"Symbolic Regression for Space Applications: Differentiable Cartesian\n  Genetic Programming Powered by Multi-objective Memetic Algorithms\n\n  Interpretable regression models are important for many application domains,\nas they allow experts to understand relations between variables from sparse\ndata. Symbolic regression addresses this issue by searching the space of all\npossible free form equations that can be constructed from elementary algebraic\nfunctions. While explicit mathematical functions can be rediscovered this way,\nthe determination of unknown numerical constants during search has been an\noften neglected issue. We propose a new multi-objective memetic algorithm that\nexploits a differentiable Cartesian Genetic Programming encoding to learn\nconstants during evolutionary loops. We show that this approach is competitive\nor outperforms machine learned black box regression models or hand-engineered\nfits for two applications from space: the Mars express thermal power estimation\nand the determination of the age of stars by gyrochronology.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.1448,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Representation and Synthesis of C++ Programs for Generalized Planning\n\n  The paper introduces a novel representation for Generalized Planning (GP)\nproblems, and their solutions, as C++ programs. Our C++ representation allows\nto formally proving the termination of generalized plans, and to specifying\ntheir asymptotic complexity w.r.t. the number of world objects. Characterizing\nthe complexity of C++ generalized plans enables the application of a\ncombinatorial search that enumerates the space of possible GP solutions in\norder of complexity. Experimental results show that our implementation of this\napproach, which we call BFGP++, outperforms the previous GP as heuristic search\napproach for the computation of generalized plans represented as\ncompiler-styled programs. Last but not least, the execution of a C++ program on\na classical planning instance is a deterministic grounding-free and search-free\nprocess, so our C++ representation allows us to automatically validate the\ncomputed solutions on large test instances of thousands of objects, where\noff-the-shelf classical planners get stuck either in the pre-processing or in\nthe search.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2206.06882,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":6,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"An Accurate HDDL Domain Learning Algorithm from Partial and Noisy\n  Observations\n\n  The Hierarchical Task Network ({\\sf HTN}) formalism is very expressive and\nused to express a wide variety of planning problems. In contrast to the\nclassical {\\sf STRIPS} formalism in which only the action model needs to be\nspecified, the {\\sf HTN} formalism requires to specify, in addition, the tasks\nof the problem and their decomposition into subtasks, called {\\sf HTN} methods.\nFor this reason, hand-encoding {\\sf HTN} problems is considered more difficult\nand more error-prone by experts than classical planning problem. To tackle this\nproblem, we propose a new approach (HierAMLSI) based on grammar induction to\nacquire {\\sf HTN} planning domain knowledge, by learning action models and {\\sf\nHTN} methods with their preconditions. Unlike other approaches, HierAMLSI is\nable to learn both actions and methods with noisy and partial inputs\nobservation with a high level or accuracy.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.021,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"Generating Game Levels of Diverse Behaviour Engagement\n\n  Recent years, there has been growing interests in experience-driven\nprocedural level generation. Various metrics have been formulated to model\nplayer experience and help generate personalised levels. In this work, we\nquestion whether experience metrics can adapt to agents with different\npersonas. We start by reviewing existing metrics for evaluating game levels.\nThen, focusing on platformer games, we design a framework integrating various\nagents and evaluation metrics. Experimental studies on \\emph{Super Mario Bros.}\nindicate that using the same evaluation metrics but agents with different\npersonas can generate levels for particular persona. It implies that, for\nsimple games, using a game-playing agent of specific player archetype as a\nlevel tester is probably all we need to generate levels of diverse behaviour\nengagement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.12052,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"Designing an AI-Driven Talent Intelligence Solution: Exploring Big Data\n  to extend the TOE Framework\n\n  AI has the potential to improve approaches to talent management enabling\ndynamic provisions through implementing advanced automation. This study aims to\nidentify the new requirements for developing AI-oriented artifacts to address\ntalent management issues. Focusing on enhancing interactions between\nprofessional assessment and planning attributes, the design artifact is an\nintelligent employment automation solution for career guidance that is largely\ndependent on a talent intelligent module and an individuals growth needs. A\ndesign science method is adopted for conducting the experimental study with\nstructured machine learning techniques which is the primary element of a\ncomprehensive AI solution framework informed through a proposed moderation of\nthe technology-organization-environment theory.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.12252,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000010928,
      "text":"Accessing and Interpreting OPC UA Event Traces based on Semantic Process\n  Descriptions\n\n  The analysis of event data from production systems is the basis for many\napplications associated with Industry 4.0. However, heterogeneous and disjoint\ndata is common in this domain. As a consequence, contextual information of an\nevent might be incomplete or improperly interpreted which results in suboptimal\nanalysis results. This paper proposes an approach to access a production\nsystems' event data based on the event data's context (such as the product\ntype, process type or process parameters). The approach extracts filtered event\nlogs from a database system by combining: 1) a semantic model of a production\nsystem's hierarchical structure, 2) a formalized process description and 3) an\nOPC UA information model. As a proof of concept we demonstrate our approach\nusing a sample server based on OPC UA for Machinery Companion Specifications.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.1476,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000048346,
      "text":"SimCURL: Simple Contrastive User Representation Learning from Command\n  Sequences\n\n  User modeling is crucial to understanding user behavior and essential for\nimproving user experience and personalized recommendations. When users interact\nwith software, vast amounts of command sequences are generated through logging\nand analytics systems. These command sequences contain clues to the users'\ngoals and intents. However, these data modalities are highly unstructured and\nunlabeled, making it difficult for standard predictive systems to learn from.\nWe propose SimCURL, a simple yet effective contrastive self-supervised deep\nlearning framework that learns user representation from unlabeled command\nsequences. Our method introduces a user-session network architecture, as well\nas session dropout as a novel way of data augmentation. We train and evaluate\nour method on a real-world command sequence dataset of more than half a billion\ncommands. Our method shows significant improvement over existing methods when\nthe learned representation is transferred to downstream tasks such as\nexperience and expertise classification.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.11007,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000051988,
      "text":"Gradual Drift Detection in Process Models Using Conformance Metrics\n\nChanges, planned or unexpected, are common during the execution of real-life processes. Detecting these changes is a must for optimizing the performance of organizations running such processes. Most of the algorithms present in the state-of-the-art focus on the detection of sudden changes, leaving aside other types of changes. In this paper, we will focus on the automatic detection of gradual drifts, a special type of change, in which the cases of two models overlap during a period of time. The proposed algorithm relies on conformance checking metrics to carry out the automatic detection of the changes, performing also a fully automatic classification of these changes into sudden or gradual. The approach has been validated with a synthetic dataset consisting of 120 logs with different distributions of changes, getting better results in terms of detection and classification accuracy, delay and change region overlapping than the main state-of-the-art algorithms.",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.01845,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000012219,
      "text":"Planning with RL and episodic-memory behavioral priors\n\n  The practical application of learning agents requires sample efficient and\ninterpretable algorithms. Learning from behavioral priors is a promising way to\nbootstrap agents with a better-than-random exploration policy or a safe-guard\nagainst the pitfalls of early learning. Existing solutions for imitation\nlearning require a large number of expert demonstrations and rely on\nhard-to-interpret learning methods like Deep Q-learning. In this work we\npresent a planning-based approach that can use these behavioral priors for\neffective exploration and learning in a reinforcement learning environment, and\nwe demonstrate that curated exploration policies in the form of behavioral\npriors can help an agent learn faster.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.12174,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000034107,
      "text":"How much of UCCA can be predicted from AMR?\n\n  In this paper, we consider two of the currently popular semantic frameworks:\nAbstract Meaning Representation (AMR)a more abstract framework, and Universal\nConceptual Cognitive Annotation (UCCA)-an anchored framework. We use a\ncorpus-based approach to build two graph rewriting systems, a deterministic and\na non-deterministic one, from the former to the latter framework. We present\ntheir evaluation and a number of ambiguities that we discovered while building\nour rules. Finally, we provide a discussion and some future work directions in\nrelation to comparing semantic frameworks of different flavors.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.0125,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000031127,
      "text":"Three multi-objective memtic algorithms for observation scheduling\n  problem of active-imaging AEOS\n\n  Observation scheduling problem for agile earth observation satellites\n(OSPFAS) plays a critical role in management of agile earth observation\nsatellites (AEOSs). Active imaging enriches the extension of OSPFAS, we call\nthe novel problem as observation scheduling problem for AEOS with variable\nimage duration (OSWVID). A cumulative image quality and a detailed energy\nconsumption is proposed to build OSWVID as a bi-objective optimization model.\nThree multi-objective memetic algorithms, PD+NSGA-II, LA+NSGA-II and\nALNS+NSGA-II, are then designed to solve OSWVID. Considering the heuristic\nknowledge summarized in our previous research, several operators are designed\nfor improving these three algorithms respectively. Based on existing instances,\nwe analyze the critical parameters optimization, operators evolution, and\nefficiency of these three algorithms according to extensive simulation\nexperiments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.00902,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Complementary artificial intelligence designed to augment human\n  discovery\n\n  Neither artificial intelligence designed to play Turing's imitation game, nor\naugmented intelligence built to maximize the human manipulation of information\nare tuned to accelerate innovation and improve humanity's collective advance\nagainst its greatest challenges. We reconceptualize and pilot beneficial AI to\nradically augment human understanding by complementing rather than competing\nwith human cognitive capacity. Our approach to complementary intelligence\nbuilds on insights underlying the wisdom of crowds, which hinges on the\nindependence and diversity of crowd members' information and approach. By\nprogrammatically incorporating information on the evolving distribution of\nscientific expertise from research papers, our approach follows the\ndistribution of content in the literature while avoiding the scientific crowd\nand the hypotheses cognitively available to it. We use this approach to\ngenerate valuable predictions for what materials possess valuable\nenergy-related properties (e.g., thermoelectricity), and what compounds possess\nvaluable medical properties (e.g., asthma) that complement the human scientific\ncrowd. We demonstrate that our complementary predictions, if identified by\nhuman scientists and inventors at all, are only discovered years further into\nthe future. When we evaluate the promise of our predictions with\nfirst-principles equations, we demonstrate that increased complementarity of\nour predictions does not decrease and in some cases increases the probability\nthat the predictions possess the targeted properties. In summary, by tuning AI\nto avoid the crowd, we can generate hypotheses unlikely to be imagined or\npursued until the distant future and promise to punctuate scientific advance.\nBy identifying and correcting for collective human bias, these models also\nsuggest opportunities to improve human prediction by reformulating science\neducation for discovery.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.01434,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000002053,
      "text":"Cybersecurity Entity Alignment via Masked Graph Attention Networks\n\n  Cybersecurity vulnerability information is often recorded by multiple\nchannels, including government vulnerability repositories,\nindividual-maintained vulnerability-gathering platforms, or\nvulnerability-disclosure email lists and forums. Integrating vulnerability\ninformation from different channels enables comprehensive threat assessment and\nquick deployment to various security mechanisms. Efforts to automatically\ngather such information, however, are impeded by the limitations of today's\nentity alignment techniques. In our study, we annotate the first\ncybersecurity-domain entity alignment dataset and reveal the unique\ncharacteristics of security entities. Based on these observations, we propose\nthe first cybersecurity entity alignment model, CEAM, which equips GNN-based\nentity alignment with two mechanisms: asymmetric masked aggregation and\npartitioned attention. Experimental results on cybersecurity-domain entity\nalignment datasets demonstrate that CEAM significantly outperforms\nstate-of-the-art entity alignment methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.06014,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000060598,
      "text":"The DLCC Node Classification Benchmark for Analyzing Knowledge Graph\n  Embeddings\n\n  Knowledge graph embedding is a representation learning technique that\nprojects entities and relations in a knowledge graph to continuous vector\nspaces. Embeddings have gained a lot of uptake and have been heavily used in\nlink prediction and other downstream prediction tasks. Most approaches are\nevaluated on a single task or a single group of tasks to determine their\noverall performance. The evaluation is then assessed in terms of how well the\nembedding approach performs on the task at hand. Still, it is hardly evaluated\n(and often not even deeply understood) what information the embedding\napproaches are actually learning to represent.\n  To fill this gap, we present the DLCC (Description Logic Class Constructors)\nbenchmark, a resource to analyze embedding approaches in terms of which kinds\nof classes they can represent. Two gold standards are presented, one based on\nthe real-world knowledge graph DBpedia and one synthetic gold standard. In\naddition, an evaluation framework is provided that implements an experiment\nprotocol so that researchers can directly use the gold standard. To demonstrate\nthe use of DLCC, we compare multiple embedding approaches using the gold\nstandards. We find that many DL constructors on DBpedia are actually learned by\nrecognizing different correlated patterns than those defined in the gold\nstandard and that specific DL constructors, such as cardinality constraints,\nare particularly hard to be learned for most embedding approaches.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.02953,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"The use of Synthetic Data to solve the scalability and data availability\n  problems in Smart City Digital Twins\n\n  The A.I. disruption and the need to compete on innovation are impacting\ncities that have an increasing necessity to become innovation hotspots.\nHowever, without proven solutions, experimentation, often unsuccessful, is\nneeded. But experimentation in cities has many undesirable effects not only for\nits citizens but also reputational if unsuccessful. Digital Twins, so popular\nin other areas, seem like a promising way to expand experimentation proposals\nbut in simulated environments, translating only the half-baked ones, the ones\nwith higher probability of success, to real environments and therefore\nminimizing risks. However, Digital Twins are data intensive and need highly\nlocalized data, making them difficult to scale, particularly to small cities,\nand with the high cost associated to data collection. We present an alternative\nbased on synthetic data that given some conditions, quite common in Smart\nCities, can solve these two problems together with a proof-of-concept based on\nNO2 pollution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.00788,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000135104,
      "text":"Long-Tail Prediction Uncertainty Aware Trajectory Planning for\n  Self-driving Vehicles\n\n  A typical trajectory planner of autonomous driving commonly relies on\npredicting the future behavior of surrounding obstacles. Recently, deep\nlearning technology has been widely adopted to design prediction models due to\ntheir impressive performance. However, such models may fail in the \"long-tail\"\ndriving cases where the training data is sparse or unavailable, leading to\nplanner failures. To this end, this work proposes a trajectory planner to\nconsider the prediction model uncertainty arising from insufficient data for\nsafer performance. Firstly, an ensemble network structure estimates the\nprediction model's uncertainty due to insufficient training data. Then a\ntrajectory planner is designed to consider the worst-case arising from\nprediction uncertainty. The results show that the proposed method can improve\nthe safety of trajectory planning under the prediction uncertainty caused by\ninsufficient data. At the same time, with sufficient data, the framework will\nnot lead to overly conservative results. This technology helps to improve the\nsafety and reliability of autonomous vehicles under the long-tail data\ndistribution of the real world.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.02917,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000008444,
      "text":"On The Universality of Diagrams for Causal Inference and The Causal\n  Reproducing Property\n\n  We propose Universal Causality, an overarching framework based on category\ntheory that defines the universal property that underlies causal inference\nindependent of the underlying representational formalism used. More formally,\nuniversal causal models are defined as categories consisting of objects and\nmorphisms between them representing causal influences, as well as structures\nfor carrying out interventions (experiments) and evaluating their outcomes\n(observations). Functors map between categories, and natural transformations\nmap between a pair of functors across the same two categories. Abstract causal\ndiagrams in our framework are built using universal constructions from category\ntheory, including the limit or co-limit of an abstract causal diagram, or more\ngenerally, the Kan extension. We present two foundational results in universal\ncausal inference. The first result, called the Universal Causality Theorem\n(UCT), pertains to the universality of diagrams, which are viewed as functors\nmapping both objects and relationships from an indexing category of abstract\ncausal diagrams to an actual causal model whose nodes are labeled by random\nvariables, and edges represent functional or probabilistic relationships. UCT\nstates that any causal inference can be represented in a canonical way as the\nco-limit of an abstract causal diagram of representable objects. UCT follows\nfrom a basic result in the theory of sheaves. The second result, the Causal\nReproducing Property (CRP), states that any causal influence of a object X on\nanother object Y is representable as a natural transformation between two\nabstract causal diagrams. CRP follows from the Yoneda Lemma, one of the deepest\nresults in category theory. The CRP property is analogous to the reproducing\nproperty in Reproducing Kernel Hilbert Spaces that served as the foundation for\nkernel methods in machine learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.09964,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000007947,
      "text":"On a Generalized Framework for Time-Aware Knowledge Graphs\n\n  Knowledge graphs have emerged as an effective tool for managing and\nstandardizing semistructured domain knowledge in a human- and\nmachine-interpretable way. In terms of graph-based domain applications, such as\nembeddings and graph neural networks, current research is increasingly taking\ninto account the time-related evolution of the information encoded within a\ngraph. Algorithms and models for stationary and static knowledge graphs are\nextended to make them accessible for time-aware domains, where time-awareness\ncan be interpreted in different ways. In particular, a distinction needs to be\nmade between the validity period and the traceability of facts as objectives of\ntime-related knowledge graph extensions. In this context, terms and definitions\nsuch as dynamic and temporal are often used inconsistently or interchangeably\nin the literature. Therefore, with this paper we aim to provide a short but\nwell-defined overview of time-aware knowledge graph extensions and thus\nfaciliate future research in this field as well.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.12764,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000529157,
      "text":"Clustering Object-Centric Event Logs\n\n  Process mining provides various algorithms to analyze process executions\nbased on event data. Process discovery, the most prominent category of process\nmining techniques, aims to discover process models from event logs, however, it\nleads to spaghetti models when working with real-life data. Therefore, several\nclustering techniques have been proposed on top of traditional event logs\n(i.e., event logs with a single case notion) to reduce the complexity of\nprocess models and discover homogeneous subsets of cases. Nevertheless, in\nreal-life processes, particularly in the context of Business-to-Business (B2B)\nprocesses, multiple objects are involved in a process. Recently, Object-Centric\nEvent Logs (OCELs) have been introduced to capture the information of such\nprocesses, and several process discovery techniques have been developed on top\nof OCELs. Yet, the output of the proposed discovery techniques on real OCELs\nleads to more informative but also more complex models. In this paper, we\npropose a clustering-based approach to cluster similar objects in OCELs to\nsimplify the obtained process models. Using a case study of a real B2B process,\nwe demonstrate that our approach reduces the complexity of the process models\nand generates coherent subsets of objects which help the end-users gain\ninsights into the process.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.05271,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000013577,
      "text":"Online Game Level Generation from Music\n\n  Game consists of multiple types of content, while the harmony of different\ncontent types play an essential role in game design. However, most works on\nprocedural content generation consider only one type of content at a time. In\nthis paper, we propose and formulate online level generation from music, in a\nway of matching a level feature to a music feature in real-time, while adapting\nto players' play speed. A generic framework named online player-adaptive\nprocedural content generation via reinforcement learning, OPARL for short, is\nbuilt upon the experience-driven reinforcement learning and controllable\nreinforcement learning, to enable online level generation from music.\nFurthermore, a novel control policy based on local search and k-nearest\nneighbours is proposed and integrated into OPARL to control the level generator\nconsidering the play data collected online. Results of simulation-based\nexperiments show that our implementation of OPARL is competent to generate\nplayable levels with difficulty degree matched to the ``energy'' dynamic of\nmusic for different artificial players in an online fashion.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.13181,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000045697,
      "text":"Planning and Learning: Path-Planning for Autonomous Vehicles, a Review\n  of the Literature\n\n  This short review aims to make the reader familiar with state-of-the-art\nworks relating to planning, scheduling and learning. First, we study\nstate-of-the-art planning algorithms. We give a brief introduction of neural\nnetworks. Then we explore in more detail graph neural networks, a recent\nvariant of neural networks suited for processing graph-structured inputs. We\ndescribe briefly the concept of reinforcement learning algorithms and some\napproaches designed to date. Next, we study some successful approaches\ncombining neural networks for path-planning. Lastly, we focus on temporal\nplanning problems with uncertainty.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.10991,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.000000596,
      "text":"Algorithmic Fairness in Business Analytics: Directions for Research and\n  Practice\n\n  The extensive adoption of business analytics (BA) has brought financial gains\nand increased efficiencies. However, these advances have simultaneously drawn\nattention to rising legal and ethical challenges when BA inform decisions with\nfairness implications. As a response to these concerns, the emerging study of\nalgorithmic fairness deals with algorithmic outputs that may result in\ndisparate outcomes or other forms of injustices for subgroups of the\npopulation, especially those who have been historically marginalized. Fairness\nis relevant on the basis of legal compliance, social responsibility, and\nutility; if not adequately and systematically addressed, unfair BA systems may\nlead to societal harms and may also threaten an organization's own survival,\nits competitiveness, and overall performance. This paper offers a\nforward-looking, BA-focused review of algorithmic fairness. We first review the\nstate-of-the-art research on sources and measures of bias, as well as bias\nmitigation algorithms. We then provide a detailed discussion of the\nutility-fairness relationship, emphasizing that the frequent assumption of a\ntrade-off between these two constructs is often mistaken or short-sighted.\nFinally, we chart a path forward by identifying opportunities for business\nscholars to address impactful, open challenges that are key to the effective\nand responsible deployment of BA.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2207.03086,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":7,
    "pangram_prediction":{
      "ai_likelihood":0.0000020862,
      "text":"Word Embedding for Social Sciences: An Interdisciplinary Survey\n\n  To extract essential information from complex data, computer scientists have\nbeen developing machine learning models that learn low-dimensional\nrepresentation mode. From such advances in machine learning research, not only\ncomputer scientists but also social scientists have benefited and advanced\ntheir research because human behavior or social phenomena lies in complex data.\nHowever, this emerging trend is not well documented because different social\nscience fields rarely cover each other's work, resulting in fragmented\nknowledge in the literature. To document this emerging trend, we survey recent\nstudies that apply word embedding techniques to human behavior mining. We built\na taxonomy to illustrate the methods and procedures used in the surveyed\npapers, aiding social science researchers in contextualizing their research\nwithin the literature on word embedding applications. This survey also conducts\na simple experiment to warn that common similarity measurements used in the\nliterature could yield different results even if they return consistent results\nat an aggregate level.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.06377,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Relational Action Bases: Formalization, Effective Safety Verification,\n  and Invariants (Extended Version)\n\n  Modeling and verification of dynamic systems operating over a relational\nrepresentation of states are increasingly investigated problems in AI, Business\nProcess Management, and Database Theory. To make these systems amenable to\nverification, the amount of information stored in each relational state needs\nto be bounded, or restrictions are imposed on the preconditions and effects of\nactions. We introduce the general framework of relational action bases (RABs),\nwhich generalizes existing models by lifting both these restrictions: unbounded\nrelational states can be evolved through actions that can quantify both\nexistentially and universally over the data, and that can exploit numerical\ndatatypes with arithmetic predicates. We then study parameterized safety of\nRABs via (approximated) SMT-based backward search, singling out essential\nmeta-properties of the resulting procedure, and showing how it can be realized\nby an off-the-shelf combination of existing verification modules of the\nstate-of-the-art MCMT model checker. We demonstrate the effectiveness of this\napproach on a benchmark of data-aware business processes. Finally, we show how\nuniversal invariants can be exploited to make this procedure fully correct.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.13515,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000003311,
      "text":"Detecting Surprising Situations in Event Data\n\n  Process mining is a set of techniques that are used by organizations to\nunderstand and improve their operational processes. The first essential step in\ndesigning any process reengineering procedure is to find process improvement\nopportunities. In existing work, it is usually assumed that the set of\nproblematic process instances in which an undesirable outcome occurs is known\nprior or is easily detectable. So the process enhancement procedure involves\nfinding the root causes and the treatments for the problem in those process\ninstances. For example, the set of problematic instances is considered as those\nwith outlier values or with values smaller\/bigger than a given threshold in one\nof the process features. However, on various occasions, using this approach,\nmany process enhancement opportunities, not captured by these problematic\nprocess instances, are missed. To overcome this issue, we formulate finding the\nprocess enhancement areas as a context-sensitive anomaly\/outlier detection\nproblem. We define a process enhancement area as a set of situations (process\ninstances or prefixes of process instances) where the process performance is\nsurprising. We aim to characterize those situations where process\nperformance\/outcome is significantly different from what was expected\nconsidering its performance\/outcome in similar situations. To evaluate the\nvalidity and relevance of the proposed approach, we have implemented and\nevaluated it on several real-life event logs.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.08218,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000080797,
      "text":"ODformer: Spatial-Temporal Transformers for Long Sequence\n  Origin-Destination Matrix Forecasting Against Cross Application Scenario\n\n  Origin-Destination (OD) matrices record directional flow data between pairs\nof OD regions. The intricate spatiotemporal dependency in the matrices makes\nthe OD matrix forecasting (ODMF) problem not only intractable but also\nnon-trivial. However, most of the related methods are designed for very short\nsequence time series forecasting in specific application scenarios, which\ncannot meet the requirements of the variation in scenarios and forecasting\nlength of practical applications. To address these issues, we propose a\nTransformer-like model named ODformer, with two salient characteristics: (i)\nthe novel OD Attention mechanism, which captures special spatial dependencies\nbetween OD pairs of the same origin (destination), greatly improves the ability\nof the model to predict cross-application scenarios after combining with 2D-GCN\nthat captures spatial dependencies between OD regions. (ii) a PeriodSparse\nSelf-attention that effectively forecasts long sequence OD matrix series while\nadapting to the periodic differences in different scenarios. Generous\nexperiments in three application backgrounds (i.e., transportation traffic, IP\nbackbone network traffic, crowd flow) show our method outperforms the\nstate-of-the-art methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.08157,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"On Establishing Robust Consistency in Answer Set Programs\n\n  Answer set programs used in real-world applications often require that the\nprogram is usable with different input data. This, however, can often lead to\ncontradictory statements and consequently to an inconsistent program. Causes\nfor potential contradictions in a program are conflicting rules. In this paper,\nwe show how to ensure that a program $\\mathcal{P}$ remains non-contradictory\ngiven any allowed set of such input data. For that, we introduce the notion of\nconflict-resolving $\\lambda$- extensions. A conflict-resolving\n$\\lambda$-extension for a conflicting rule $r$ is a set $\\lambda$ of (default)\nliterals such that extending the body of $r$ by $\\lambda$ resolves all\nconflicts of $r$ at once. We investigate the properties that suitable\n$\\lambda$-extensions should possess and building on that, we develop a strategy\nto compute all such conflict-resolving $\\lambda$-extensions for each\nconflicting rule in $\\mathcal{P}$. We show that by implementing a conflict\nresolution process that successively resolves conflicts using\n$\\lambda$-extensions eventually yields a program that remains non-contradictory\ngiven any allowed set of input data.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.07805,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000008941,
      "text":"SIERRA: A Modular Framework for Research Automation and Reproducibility\n\n  Modern intelligent systems researchers form hypotheses about system behavior\nand then run experiments using one or more independent variables to test their\nhypotheses. We present SIERRA, a novel framework structured around that idea\nfor accelerating research development and improving reproducibility of results.\nSIERRA accelerates research by automating the process of generating executable\nexperiments from queries over independent variables(s), executing experiments,\nand processing the results to generate deliverables such as graphs and videos.\nIt shifts the paradigm for testing hypotheses from procedural (\"Do these steps\nto answer the query\") to declarative (\"Here is the query to test--GO!\"),\nreducing the burden on researchers. It employs a modular architecture enabling\neasy customization and extension for the needs of individual researchers,\nthereby eliminating manual configuration and processing via throw-away scripts.\nSIERRA improves reproducibility of research by providing automation independent\nof the execution environment (HPC hardware, real robots, etc.) and targeted\nplatform (arbitrary simulator or real robots). This enables exact experiment\nreplication, up to the limit of the execution environment and platform, as well\nas making it easy for researchers to test hypotheses in different computational\nenvironments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.02029,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000021193,
      "text":"Supervised and Reinforcement Learning from Observations in\n  Reconnaissance Blind Chess\n\n  In this work, we adapt a training approach inspired by the original AlphaGo\nsystem to play the imperfect information game of Reconnaissance Blind Chess.\nUsing only the observations instead of a full description of the game state, we\nfirst train a supervised agent on publicly available game records. Next, we\nincrease the performance of the agent through self-play with the on-policy\nreinforcement learning algorithm Proximal Policy Optimization. We do not use\nany search to avoid problems caused by the partial observability of game states\nand only use the policy network to generate moves when playing. With this\napproach, we achieve an ELO of 1330 on the RBC leaderboard, which places our\nagent at position 27 at the time of this writing. We see that self-play\nsignificantly improves performance and that the agent plays acceptably well\nwithout search and without making assumptions about the true game state.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.0832,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic\n  Consistency\n\n  Twitter bots are automatic programs operated by malicious actors to\nmanipulate public opinion and spread misinformation. Research efforts have been\nmade to automatically identify bots based on texts and networks on social\nmedia. Existing methods only leverage texts or networks alone, and while few\nworks explored the shallow combination of the two modalities, we hypothesize\nthat the interaction and information exchange between texts and graphs could be\ncrucial for holistically evaluating bot activities on social media. In\naddition, according to a recent survey (Cresci, 2020), Twitter bots are\nconstantly evolving while advanced bots steal genuine users' tweets and dilute\ntheir malicious content to evade detection. This results in greater\ninconsistency across the timeline of novel Twitter bots, which warrants more\nattention. In light of these challenges, we propose BIC, a Twitter Bot\ndetection framework with text-graph Interaction and semantic Consistency.\nSpecifically, in addition to separately modeling the two modalities on social\nmedia, BIC employs a text-graph interaction module to enable information\nexchange across modalities in the learning process. In addition, given the\nstealing behavior of novel Twitter bots, BIC proposes to model semantic\nconsistency in tweets based on attention weights while using it to augment the\ndecision process. Extensive experiments demonstrate that BIC consistently\noutperforms state-of-the-art baselines on two widely adopted datasets. Further\nanalyses reveal that text-graph interactions and modeling semantic consistency\nare essential improvements and help combat bot evolution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.0239,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000140402,
      "text":"ProjB: An Improved Bilinear Biased ProjE model for Knowledge Graph\n  Completion\n\n  Knowledge Graph Embedding (KGE) methods have gained enormous attention from a\nwide range of AI communities including Natural Language Processing (NLP) for\ntext generation, classification and context induction. Embedding a huge number\nof inter-relationships in terms of a small number of dimensions, require proper\nmodeling in both cognitive and computational aspects. Recently, numerous\nobjective functions regarding cognitive and computational aspects of natural\nlanguages are developed. Among which are the state-of-the-art methods of\nlinearity, bilinearity, manifold-preserving kernels, projection-subspace, and\nanalogical inference. However, the major challenge of such models lies in their\nloss functions that associate the dimension of relation embeddings to\ncorresponding entity dimension. This leads to inaccurate prediction of\ncorresponding relations among entities when counterparts are estimated wrongly.\nProjE KGE, published by Bordes et al., due to low computational complexity and\nhigh potential for model improvement, is improved in this work regarding all\ntranslative and bilinear interactions while capturing entity nonlinearity.\nExperimental results on benchmark Knowledge Graphs (KGs) such as FB15K and WN18\nshow that the proposed approach outperforms the state-of-the-art models in\nentity prediction task using linear and bilinear methods and other recent\npowerful ones. In addition, a parallel processing structure is proposed for the\nmodel in order to improve the scalability on large KGs. The effects of\ndifferent adaptive clustering and newly proposed sampling approaches are also\nexplained which prove to be effective in improving the accuracy of knowledge\ngraph completion.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.12386,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000004967,
      "text":"Swarm Analytics: Designing Information Markers to Characterise Swarm\n  Systems in Shepherding Contexts\n\n  Contemporary swarm indicators are often used in isolation, focused on\nextracting information at the individual or collective levels. Consequently,\nthese are seldom integrated to infer a top-level operating picture of the\nswarm, its members, and its overall collective dynamics. The primary\ncontribution of this paper is to organise a suite of indicators about swarms\ninto an ontologically-arranged collection of information markers to\ncharacterise the swarm from the perspective of an external observer\\textemdash,\na recognition agent. Our contribution shows the foundations for a new area of\nresearch that we tile swarm analytics, whose primary concern is with the design\nand organisation of collections of swarm markers to understand, detect,\nrecognise, track, and learn a particular insight about a swarm system. We\npresent our designed framework of information markers that offer a new avenue\nfor swarm research, especially for heterogeneous and cognitive swarms that may\nrequire more advanced capabilities to detect agencies and categorise agent\ninfluences and responses.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.10327,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000044041,
      "text":"Incorporating Rivalry in Reinforcement Learning for a Competitive Game\n\n  Recent advances in reinforcement learning with social agents have allowed\nsuch models to achieve human-level performance on specific interaction tasks.\nHowever, most interactive scenarios do not have a version alone as an end goal;\ninstead, the social impact of these agents when interacting with humans is as\nimportant and largely unexplored. In this regard, this work proposes a novel\nreinforcement learning mechanism based on the social impact of rivalry\nbehavior. Our proposed model aggregates objective and social perception\nmechanisms to derive a rivalry score that is used to modulate the learning of\nartificial agents. To investigate our proposed model, we design an interactive\ngame scenario, using the Chef's Hat Card Game, and examine how the rivalry\nmodulation changes the agent's playing style, and how this impacts the\nexperience of human players in the game. Our results show that humans can\ndetect specific social characteristics when playing against rival agents when\ncompared to common agents, which directly affects the performance of the human\nplayers in subsequent games. We conclude our work by discussing how the\ndifferent social and objective features that compose the artificial rivalry\nscore contribute to our results.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.02914,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000245041,
      "text":"Solving the Baby Intuitions Benchmark with a Hierarchically Bayesian\n  Theory of Mind\n\n  To facilitate the development of new models to bridge the gap between machine\nand human social intelligence, the recently proposed Baby Intuitions Benchmark\n(arXiv:2102.11938) provides a suite of tasks designed to evaluate commonsense\nreasoning about agents' goals and actions that even young infants exhibit. Here\nwe present a principled Bayesian solution to this benchmark, based on a\nhierarchically Bayesian Theory of Mind (HBToM). By including hierarchical\npriors on agent goals and dispositions, inference over our HBToM model enables\nfew-shot learning of the efficiency and preferences of an agent, which can then\nbe used in commonsense plausibility judgements about subsequent agent behavior.\nThis approach achieves near-perfect accuracy on most benchmark tasks,\noutperforming deep learning and imitation learning baselines while producing\ninterpretable human-like inferences, demonstrating the advantages of structured\nBayesian models of human social cognition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.11024,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000013577,
      "text":"KGxBoard: Explainable and Interactive Leaderboard for Evaluation of\n  Knowledge Graph Completion Models\n\n  Knowledge Graphs (KGs) store information in the form of (head, predicate,\ntail)-triples. To augment KGs with new knowledge, researchers proposed models\nfor KG Completion (KGC) tasks such as link prediction; i.e., answering (h; p;\n?) or (?; p; t) queries. Such models are usually evaluated with averaged\nmetrics on a held-out test set. While useful for tracking progress, averaged\nsingle-score metrics cannot reveal what exactly a model has learned -- or\nfailed to learn. To address this issue, we propose KGxBoard: an interactive\nframework for performing fine-grained evaluation on meaningful subsets of the\ndata, each of which tests individual and interpretable capabilities of a KGC\nmodel. In our experiments, we highlight the findings that we discovered with\nthe use of KGxBoard, which would have been impossible to detect with standard\naveraged single-score metrics.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.03097,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"An ASP Framework for Efficient Urban Traffic Optimization\n\n  Avoiding congestion and controlling traffic in urban scenarios is becoming\nnowadays of paramount importance due to the rapid growth of our cities'\npopulation and vehicles. The effective control of urban traffic as a means to\nmitigate congestion can be beneficial in an economic, environmental and health\nway. In this paper, a framework which allows to efficiently simulate and\noptimize traffic flow in a large roads' network with hundreds of vehicles is\npresented. The framework leverages on an Answer Set Programming (ASP) encoding\nto formally describe the movements of vehicles inside a network. Taking\nadvantage of the ability to specify optimization constraints in ASP and the\noff-the-shelf solver Clingo, it is then possible to optimize the routes of\nvehicles inside the network to reduce a range of relevant metrics (e.g., travel\ntimes or emissions). Finally, an analysis on real-world traffic data is\nperformed, utilizing the state-of-the-art Urban Mobility Simulator (SUMO) to\nkeep track of the state of the network, test the correctness of the solution\nand to prove the efficiency and capabilities of the presented solution.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.03685,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000000331,
      "text":"A Parallel Technique for Multi-objective Bayesian Global Optimization:\n  Using a Batch Selection of Probability of Improvement\n\n  Bayesian global optimization (BGO) is an efficient surrogate-assisted\ntechnique for problems involving expensive evaluations. A parallel technique\ncan be used to parallelly evaluate the true-expensive objective functions in\none iteration to boost the execution time. An effective and straightforward\napproach is to design an acquisition function that can evaluate the performance\nof a bath of multiple solutions, instead of a single point\/solution, in one\niteration. This paper proposes five alternatives of \\emph{Probability of\nImprovement} (PoI) with multiple points in a batch (q-PoI) for multi-objective\nBayesian global optimization (MOBGO), taking the covariance among multiple\npoints into account. Both exact computational formulas and the Monte Carlo\napproximation algorithms for all proposed q-PoIs are provided. Based on the\ndistribution of the multiple points relevant to the Pareto-front, the\nposition-dependent behavior of the five q-PoIs is investigated. Moreover, the\nfive q-PoIs are compared with the other nine state-of-the-art and recently\nproposed batch MOBGO algorithms on twenty bio-objective benchmarks. The\nempirical experiments on different variety of benchmarks are conducted to\ndemonstrate the effectiveness of two greedy q-PoIs ($\\kpoi_{\\mbox{best}}$ and\n$\\kpoi_{\\mbox{all}}$) on low-dimensional problems and the effectiveness of two\nexplorative q-PoIs ($\\kpoi_{\\mbox{one}}$ and $\\kpoi_{\\mbox{worst}}$) on\nhigh-dimensional problems with difficult-to-approximate Pareto front\nboundaries.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.12551,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000153316,
      "text":"Itemset Utility Maximization with Correlation Measure\n\n  As an important data mining technology, high utility itemset mining (HUIM) is\nused to find out interesting but hidden information (e.g., profit and risk).\nHUIM has been widely applied in many application scenarios, such as market\nanalysis, medical detection, and web click stream analysis. However, most\nprevious HUIM approaches often ignore the relationship between items in an\nitemset. Therefore, many irrelevant combinations (e.g., \\{gold, apple\\} and\n\\{notebook, book\\}) are discovered in HUIM. To address this limitation, many\nalgorithms have been proposed to mine correlated high utility itemsets\n(CoHUIs). In this paper, we propose a novel algorithm called the Itemset\nUtility Maximization with Correlation Measure (CoIUM), which considers both a\nstrong correlation and the profitable values of the items. Besides, the novel\nalgorithm adopts a database projection mechanism to reduce the cost of database\nscanning. Moreover, two upper bounds and four pruning strategies are utilized\nto effectively prune the search space. And a concise array-based structure\nnamed utility-bin is used to calculate and store the adopted upper bounds in\nlinear time and space. Finally, extensive experimental results on dense and\nsparse datasets demonstrate that CoIUM significantly outperforms the\nstate-of-the-art algorithms in terms of runtime and memory consumption.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.12789,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000012914,
      "text":"Learning and Compositionality: a Unification Attempt via Connectionist\n  Probabilistic Programming\n\n  We consider learning and compositionality as the key mechanisms towards\nsimulating human-like intelligence. While each mechanism is successfully\nachieved by neural networks and symbolic AIs, respectively, it is the\ncombination of the two mechanisms that makes human-like intelligence possible.\nDespite the numerous attempts on building hybrid neuralsymbolic systems, we\nargue that our true goal should be unifying learning and compositionality, the\ncore mechanisms, instead of neural and symbolic methods, the surface approaches\nto achieve them. In this work, we review and analyze the strengths and\nweaknesses of neural and symbolic methods by separating their forms and\nmeanings (structures and semantics), and propose Connectionist Probabilistic\nProgram (CPPs), a framework that connects connectionist structures (for\nlearning) and probabilistic program semantics (for compositionality). Under the\nframework, we design a CPP extension for small scale sequence modeling and\nprovide a learning algorithm based on Bayesian inference. Although challenges\nexist in learning complex patterns without supervision, our early results\ndemonstrate CPP's successful extraction of concepts and relations from raw\nsequential data, an initial step towards compositional learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.12047,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000043048,
      "text":"Even vertex $\\zeta$-graceful labeling on Rough Graph\n\n  Rough graph is the graphical structure of information system with imprecise\nknowledge. Tong He designed the properties of rough graph in 2006[6] and\nfollowing that He and Shi introduced the notion of edge rough graph[7]. He et\nal developed the concept of weighted rough graph with weighted attributes[6].\nIn this paper, we introduce a new type of labeling called Even vertex {\\zeta}-\ngraceful labeling as weight value for edges. We investigate this labeling for\nsome special graphs like rough path graph, rough cycle graph, rough comb graph,\nrough ladder graph and rough star graph.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.11652,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0005274349,
      "text":"A Review of Knowledge Graph Completion\n\n  Information extraction methods proved to be effective at triple extraction\nfrom structured or unstructured data. The organization of such triples in the\nform of (head entity, relation, tail entity) is called the construction of\nKnowledge Graphs (KGs). Most of the current knowledge graphs are incomplete. In\norder to use KGs in downstream tasks, it is desirable to predict missing links\nin KGs. Different approaches have been recently proposed for representation\nlearning of KGs by embedding both entities and relations into a low-dimensional\nvector space aiming to predict unknown triples based on previously visited\ntriples. According to how the triples will be treated independently or\ndependently, we divided the task of knowledge graph completion into\nconventional and graph neural network representation learning and we discuss\nthem in more detail. In conventional approaches, each triple will be processed\nindependently and in GNN-based approaches, triples also consider their local\nneighborhood. View Full-Text\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.09554,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000013245,
      "text":"Integrating Diverse Knowledge Sources for Online One-shot Learning of\n  Novel Tasks\n\n  Autonomous agents are able to draw on a wide variety of potential sources of\ntask knowledge; however current approaches invariably focus on only one or two.\nHere we investigate the challenges and impact of exploiting diverse knowledge\nsources to learn online, in one-shot, new tasks for a simulated office mobile\nrobot. The resulting agent, developed in the Soar cognitive architecture, uses\nthe following sources of domain and task knowledge: interaction with the\nenvironment, task execution and search knowledge, human natural language\ninstruction, and responses retrieved from a large language model (GPT-3). We\nexplore the distinct contributions of these knowledge sources and evaluate the\nperformance of different combinations in terms of learning correct task\nknowledge and human workload. Results show that an agent's online integration\nof diverse knowledge sources improves one-shot task learning overall, reducing\nhuman feedback needed for rapid and reliable task learning.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2208.07622,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":8,
    "pangram_prediction":{
      "ai_likelihood":0.0000028478,
      "text":"KRACL: Contrastive Learning with Graph Context Modeling for Sparse\n  Knowledge Graph Completion\n\n  Knowledge Graph Embeddings (KGE) aim to map entities and relations to low\ndimensional spaces and have become the \\textit{de-facto} standard for knowledge\ngraph completion. Most existing KGE methods suffer from the sparsity challenge,\nwhere it is harder to predict entities that appear less frequently in knowledge\ngraphs. In this work, we propose a novel framework KRACL to alleviate the\nwidespread sparsity in KGs with graph context and contrastive learning.\nFirstly, we propose the Knowledge Relational Attention Network (KRAT) to\nleverage the graph context by simultaneously projecting neighboring triples to\ndifferent latent spaces and jointly aggregating messages with the attention\nmechanism. KRAT is capable of capturing the subtle semantic information and\nimportance of different context triples as well as leveraging multi-hop\ninformation in knowledge graphs. Secondly, we propose the knowledge contrastive\nloss by combining the contrastive loss with cross entropy loss, which\nintroduces more negative samples and thus enriches the feedback to sparse\nentities. Our experiments demonstrate that KRACL achieves superior results\nacross various standard knowledge graph benchmarks, especially on WN18RR and\nNELL-995 which have large numbers of low in-degree entities. Extensive\nexperiments also bear out KRACL's effectiveness in handling sparse knowledge\ngraphs and robustness against noisy triples.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.12623,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000079804,
      "text":"Cognitive Architecture for Co-Evolutionary Hybrid Intelligence\n\n  This paper questions the feasibility of a strong (general) data-centric\nartificial intelligence (AI). The disadvantages of this type of intelligence\nare discussed. As an alternative, the concept of co-evolutionary hybrid\nintelligence is proposed. It is based on the cognitive interoperability of man\nand machine. An analysis of existing approaches to the construction of\ncognitive architectures is given. An architecture seamlessly incorporates a\nhuman into the loop of intelligent problem solving is considered. The article\nis organized as follows. The first part contains a critique of data-centric\nintelligent systems. The reasons why it is impossible to create a strong\nartificial intelligence based on this type of intelligence are indicated. The\nsecond part briefly presents the concept of co-evolutionary hybrid intelligence\nand shows its advantages. The third part gives an overview and analysis of\nexisting cognitive architectures. It is concluded that many do not consider\nhumans part of the intelligent data processing process. The next part discusses\nthe cognitive architecture for co-evolutionary hybrid intelligence, providing\nintegration with humans. It finishes with general conclusions about the\nfeasibility of developing intelligent systems with humans in the\nproblem-solving loop.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.12398,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000016557,
      "text":"Real-time Anomaly Detection for Multivariate Data Streams\n\n  We present a real-time multivariate anomaly detection algorithm for data\nstreams based on the Probabilistic Exponentially Weighted Moving Average\n(PEWMA). Our formulation is resilient to (abrupt transient, abrupt\ndistributional, and gradual distributional) shifts in the data. The novel\nanomaly detection routines utilize an incremental online algorithm to handle\nstreams. Furthermore, our proposed anomaly detection algorithm works in an\nunsupervised manner eliminating the need for labeled examples. Our algorithm\nperforms well and is resilient in the face of concept drifts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.04189,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000076824,
      "text":"Conversion of Acoustic Signal (Speech) Into Text By Digital Filter using\n  Natural Language Processing\n\n  One of the most crucial aspects of communication in daily life is speech\nrecognition. Speech recognition that is based on natural language processing is\none of the essential elements in the conversion of one system to another. In\nthis paper, we created an interface that transforms speech and other auditory\ninputs into text using a digital filter. Contrary to the many methods for this\nconversion, it is also possible for linguistic faults to appear occasionally,\ngender recognition, speech recognition that is unsuccessful (cannot recognize\nvoice), and gender recognition to fail. Since technical problems are involved,\nwe developed a program that acts as a mediator to prevent initiating software\nissues in order to eliminate even this little deviation. Its planned MFCC and\nHMM are in sync with its AI system. As a result, technical errors have been\navoided.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.07479,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000002649,
      "text":"Gollum: A Gold Standard for Large Scale Multi Source Knowledge Graph\n  Matching\n\n  The number of Knowledge Graphs (KGs) generated with automatic and manual\napproaches is constantly growing. For an integrated view and usage, an\nalignment between these KGs is necessary on the schema as well as instance\nlevel. While there are approaches that try to tackle this multi source\nknowledge graph matching problem, large gold standards are missing to evaluate\ntheir effectiveness and scalability. We close this gap by presenting Gollum --\na gold standard for large-scale multi source knowledge graph matching with over\n275,000 correspondences between 4,149 different KGs. They originate from\nknowledge graphs derived by applying the DBpedia extraction framework to a\nlarge wiki farm. Three variations of the gold standard are made available: (1)\na version with all correspondences for evaluating unsupervised matching\napproaches, and two versions for evaluating supervised matching: (2) one where\neach KG is contained both in the train and test set, and (3) one where each KG\nis exclusively contained in the train or the test set.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.13883,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000017881,
      "text":"MLink: Linking Black-Box Models from Multiple Domains for Collaborative\n  Inference\n\n  The cost efficiency of model inference is critical to real-world machine\nlearning (ML) applications, especially for delay-sensitive tasks and\nresource-limited devices. A typical dilemma is: in order to provide complex\nintelligent services (e.g. smart city), we need inference results of multiple\nML models, but the cost budget (e.g. GPU memory) is not enough to run all of\nthem. In this work, we study underlying relationships among black-box ML models\nand propose a novel learning task: model linking, which aims to bridge the\nknowledge of different black-box models by learning mappings (dubbed model\nlinks) between their output spaces. We propose the design of model links which\nsupports linking heterogeneous black-box ML models. Also, in order to address\nthe distribution discrepancy challenge, we present adaptation and aggregation\nmethods of model links. Based on our proposed model links, we developed a\nscheduling algorithm, named MLink. Through collaborative multi-model inference\nenabled by model links, MLink can improve the accuracy of obtained inference\nresults under the cost budget. We evaluated MLink on a multi-modal dataset with\nseven different ML models and two real-world video analytics systems with six\nML models and 3,264 hours of video. Experimental results show that our proposed\nmodel links can be effectively built among various black-box models. Under the\nbudget of GPU memory, MLink can save 66.7% inference computations while\npreserving 94% inference accuracy, which outperforms multi-task learning, deep\nreinforcement learning-based scheduler and frame filtering baselines.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.0547,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000018213,
      "text":"A Quantum Algorithm for Computing All Diagnoses of a Switching Circuit\n\n  Faults are stochastic by nature while most man-made systems, and especially\ncomputers, work deterministically. This necessitates the linking of probability\ntheory with mathematical logics, automata, and switching circuit theory. This\npaper provides such a connecting via quantum information theory which is an\nintuitive approach as quantum physics obeys probability laws. In this paper we\nprovide a novel approach for computing diagnosis of switching circuits with\ngate-based quantum computers. The approach is based on the idea of putting the\nqubits representing faults in superposition and compute all, often\nexponentially many, diagnoses simultaneously. We empirically compare the\nquantum algorithm for diagnostics to an approach based on SAT and\nmodel-counting. For a benchmark of combinational circuits we establish an error\nof less than one percent in estimating the true probability of faults.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.00917,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Proceedings of the 2022 XCSP3 Competition\n\n  This document represents the proceedings of the 2022 XCSP3 Competition. The\nresults of this competition of constraint solvers were presented at FLOC\n(Federated Logic Conference) 2022 Olympic Games, held in Haifa, Israel from\n31th July 2022 to 7th August, 2022.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.04355,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000054638,
      "text":"MIntRec: A New Dataset for Multimodal Intent Recognition\n\n  Multimodal intent recognition is a significant task for understanding human\nlanguage in real-world multimodal scenes. Most existing intent recognition\nmethods have limitations in leveraging the multimodal information due to the\nrestrictions of the benchmark datasets with only text information. This paper\nintroduces a novel dataset for multimodal intent recognition (MIntRec) to\naddress this issue. It formulates coarse-grained and fine-grained intent\ntaxonomies based on the data collected from the TV series Superstore. The\ndataset consists of 2,224 high-quality samples with text, video, and audio\nmodalities and has multimodal annotations among twenty intent categories.\nFurthermore, we provide annotated bounding boxes of speakers in each video\nsegment and achieve an automatic process for speaker annotation. MIntRec is\nhelpful for researchers to mine relationships between different modalities to\nenhance the capability of intent recognition. We extract features from each\nmodality and model cross-modal interactions by adapting three powerful\nmultimodal fusion methods to build baselines. Extensive experiments show that\nemploying the non-verbal modalities achieves substantial improvements compared\nwith the text-only modality, demonstrating the effectiveness of using\nmultimodal information for intent recognition. The gap between the\nbest-performing methods and humans indicates the challenge and importance of\nthis task for the community. The full dataset and codes are available for use\nat https:\/\/github.com\/thuiar\/MIntRec.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.0141,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000015895,
      "text":"Closed-Loop View of the Regulation of AI: Equal Impact across Repeated\n  Interactions\n\n  There has been much recent interest in the regulation of AI. We argue for a\nview based on civil-rights legislation, built on the notions of equal treatment\nand equal impact. In a closed-loop view of the AI system and its users, the\nequal treatment concerns one pass through the loop. Equal impact, in our view,\nconcerns the long-run average behaviour across repeated interactions. In order\nto establish the existence of the average and its properties, one needs to\nstudy the ergodic properties of the closed-loop and its unique stationary\nmeasure.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.05226,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000018875,
      "text":"Efficient Customer Service Combining Human Operators and Virtual Agents\n\n  The prospect of combining human operators and virtual agents (bots) into an\neffective hybrid system that provides proper customer service to clients is\npromising yet challenging. The hybrid system decreases the customers'\nfrustration when bots are unable to provide appropriate service and increases\ntheir satisfaction when they prefer to interact with human operators.\nFurthermore, we show that it is possible to decrease the cost and efforts of\nbuilding and maintaining such virtual agents by enabling the virtual agent to\nincrementally learn from the human operators. We employ queuing theory to\nidentify the key parameters that govern the behavior and efficiency of such\nhybrid systems and determine the main parameters that should be optimized in\norder to improve the service. We formally prove, and demonstrate in extensive\nsimulations and in a user study, that with the proper choice of parameters,\nsuch hybrid systems are able to increase the number of served clients while\nsimultaneously decreasing their expected waiting time and increasing\nsatisfaction.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.10319,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000092718,
      "text":"Controller Synthesis for Timeline-based Games\n\n  In the timeline-based approach to planning, originally born in the space\nsector, the evolution over time of a set of state variables (the timelines) is\ngoverned by a set of temporal constraints. Traditional timeline-based planning\nsystems excel at the integration of planning with execution by handling\ntemporal uncertainty. In order to handle general nondeterminism as well, the\nconcept of timeline-based games has been recently introduced. It has been\nproved that finding whether a winning strategy exists for such games is\n2EXPTIME-complete. However, a concrete approach to synthesize controllers\nimplementing such strategies is missing. This paper fills this gap, outlining\nan approach to controller synthesis for timeline-based games.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.02157,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000069539,
      "text":"A New Approach to Training Multiple Cooperative Agents for Autonomous\n  Driving\n\n  Training multiple agents to perform safe and cooperative control in the\ncomplex scenarios of autonomous driving has been a challenge. For a small fleet\nof cars moving together, this paper proposes Lepus, a new approach to training\nmultiple agents. Lepus adopts a pure cooperative manner for training multiple\nagents, featured with the shared parameters of policy networks and the shared\nreward function of multiple agents. In particular, Lepus pre-trains the policy\nnetworks via an adversarial process, improving its collaborative\ndecision-making capability and further the stability of car driving. Moreover,\nfor alleviating the problem of sparse rewards, Lepus learns an approximate\nreward function from expert trajectories by combining a random network and a\ndistillation network. We conduct extensive experiments on the MADRaS simulation\nplatform. The experimental results show that multiple agents trained by Lepus\ncan avoid collisions as many as possible while driving simultaneously and\noutperform the other four methods, that is, DDPG-FDE, PSDDPG, MADDPG, and\nMAGAIL(DDPG) in terms of stability.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.15067,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"Reasoning about Complex Networks: A Logic Programming Approach\n\n  Reasoning about complex networks has in recent years become an important\ntopic of study due to its many applications: the adoption of commercial\nproducts, spread of disease, the diffusion of an idea, etc. In this paper, we\npresent the MANCaLog language, a formalism based on logic programming that\nsatisfies a set of desiderata proposed in previous work as recommendations for\nthe development of approaches to reasoning in complex networks. To the best of\nour knowledge, this is the first formalism that satisfies all such criteria. We\nfirst focus on algorithms for finding minimal models (on which multi-attribute\nanalysis can be done), and then on how this formalism can be applied in certain\nreal world scenarios. Towards this end, we study the problem of deciding group\nmembership in social networks: given a social network and a set of groups where\ngroup membership of only some of the individuals in the network is known, we\nwish to determine a degree of membership for the remaining group-individual\npairs. We develop a prototype implementation that we use to obtain experimental\nresults on two real world datasets, including a current social network of\ncriminal gangs in a major U.S.\\ city. We then show how the assignment of degree\nof membership to nodes in this case allows for a better understanding of the\ncriminal gang problem when combined with other social network mining techniques\n-- including detection of sub-groups and identification of core group members\n-- which would not be possible without further identification of additional\ngroup members.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.04759,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000057949,
      "text":"A Semantic Tableau Method for Argument Construction\n\n  A semantic tableau method, called an argumentation tableau, that enables the\nderivation of arguments, is proposed. First, the derivation of arguments for\nstandard propositional and predicate logic is addressed. Next, an extension\nthat enables reasoning with defeasible rules is presented. Finally, reasoning\nby cases using an argumentation tableau is discussed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.0416,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000013245,
      "text":"Metaverse for Healthcare: A Survey on Potential Applications, Challenges\n  and Future Directions\n\n  The rapid progress in digitalization and automation have led to an\naccelerated growth in healthcare, generating novel models that are creating new\nchannels for rendering treatment with reduced cost. The Metaverse is an\nemerging technology in the digital space which has huge potential in\nhealthcare, enabling realistic experiences to the patients as well as the\nmedical practitioners. The Metaverse is a confluence of multiple enabling\ntechnologies such as artificial intelligence, virtual reality, augmented\nreality, internet of medical devices, robotics, quantum computing, etc. through\nwhich new directions for providing quality healthcare treatment and services\ncan be explored. The amalgamation of these technologies ensures immersive,\nintimate and personalized patient care. It also provides adaptive intelligent\nsolutions that eliminates the barriers between healthcare providers and\nreceivers. This article provides a comprehensive review of the Metaverse for\nhealthcare, emphasizing on the state of the art, the enabling technologies for\nadopting the Metaverse for healthcare, the potential applications and the\nrelated projects. The issues in the adaptation of the Metaverse for healthcare\napplications are also identified and the plausible solutions are highlighted as\npart of future research directions.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.05698,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000202325,
      "text":"KSG: Knowledge and Skill Graph\n\n  The knowledge graph (KG) is an essential form of knowledge representation\nthat has grown in prominence in recent years. Because it concentrates on\nnominal entities and their relationships, traditional knowledge graphs are\nstatic and encyclopedic in nature. On this basis, event knowledge graph (Event\nKG) models the temporal and spatial dynamics by text processing to facilitate\ndownstream applications, such as question-answering, recommendation and\nintelligent search. Existing KG research, on the other hand, mostly focuses on\ntext processing and static facts, ignoring the vast quantity of dynamic\nbehavioral information included in photos, movies, and pre-trained neural\nnetworks. In addition, no effort has been done to include behavioral\nintelligence information into the knowledge graph for deep reinforcement\nlearning (DRL) and robot learning. In this paper, we propose a novel dynamic\nknowledge and skill graph (KSG), and then we develop a basic and specific KSG\nbased on CN-DBpedia. The nodes are divided into entity and attribute nodes,\nwith entity nodes containing the agent, environment, and skill (DRL policy or\npolicy representation), and attribute nodes containing the entity description,\npre-train network, and offline dataset. KSG can search for different agents'\nskills in various environments and provide transferable information for\nacquiring new skills. This is the first study that we are aware of that looks\ninto dynamic KSG for skill retrieval and learning. Extensive experimental\nresults on new skill learning show that KSG boosts new skill learning\nefficiency.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.01728,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000376503,
      "text":"Features Fusion Framework for Multimodal Irregular Time-series Events\n\n  Some data from multiple sources can be modeled as multimodal time-series\nevents which have different sampling frequencies, data compositions, temporal\nrelations and characteristics. Different types of events have complex nonlinear\nrelationships, and the time of each event is irregular. Neither the classical\nRecurrent Neural Network (RNN) model nor the current state-of-the-art\nTransformer model can deal with these features well. In this paper, a features\nfusion framework for multimodal irregular time-series events is proposed based\non the Long Short-Term Memory networks (LSTM). Firstly, the complex features\nare extracted according to the irregular patterns of different events.\nSecondly, the nonlinear correlation and complex temporal dependencies\nrelationship between complex features are captured and fused into a tensor.\nFinally, a feature gate are used to control the access frequency of different\ntensors. Extensive experiments on MIMIC-III dataset demonstrate that the\nproposed framework significantly outperforms to the existing methods in terms\nof AUC (the area under Receiver Operating Characteristic curve) and AP (Average\nPrecision).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.0399,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000007285,
      "text":"Vision for Bosnia and Herzegovina in Artificial Intelligence Age: Global\n  Trends, Potential Opportunities, Selected Use-cases and Realistic Goals\n\n  Artificial Intelligence (AI) is one of the most promising technologies of the\n21. century, with an already noticeable impact on society and the economy. With\nthis work, we provide a short overview of global trends, applications in\nindustry and selected use-cases from our international experience and work in\nindustry and academia. The goal is to present global and regional positive\npractices and provide an informed opinion on the realistic goals and\nopportunities for positioning B&H on the global AI scene.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.13002,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000078148,
      "text":"Automated Urban Planning aware Spatial Hierarchies and Human\n  Instructions\n\n  Traditional urban planning demands urban experts to spend considerable time\nand effort producing an optimal urban plan under many architectural\nconstraints. The remarkable imaginative ability of deep generative learning\nprovides hope for renovating urban planning. While automated urban planners\nhave been examined, they are constrained because of the following: 1)\nneglecting human requirements in urban planning; 2) omitting spatial\nhierarchies in urban planning, and 3) lacking numerous urban plan data samples.\nTo overcome these limitations, we propose a novel, deep, human-instructed urban\nplanner. In the preliminary work, we formulate it into an encoder-decoder\nparadigm. The encoder is to learn the information distribution of surrounding\ncontexts, human instructions, and land-use configuration. The decoder is to\nreconstruct the land-use configuration and the associated urban functional\nzones. The reconstruction procedure will capture the spatial hierarchies\nbetween functional zones and spatial grids. Meanwhile, we introduce a\nvariational Gaussian mechanism to mitigate the data sparsity issue. Even though\nearly work has led to good results, the performance of generation is still\nunstable because the way spatial hierarchies are captured may lead to unclear\noptimization directions. In this journal version, we propose a cascading deep\ngenerative framework based on generative adversarial networks (GANs) to solve\nthis problem, inspired by the workflow of urban experts. In particular, the\npurpose of the first GAN is to build urban functional zones based on\ninformation from human instructions and surrounding contexts. The second GAN\nwill produce the land-use configuration based on the functional zones that have\nbeen constructed. Additionally, we provide a conditioning augmentation module\nto augment data samples. Finally, we conduct extensive experiments to validate\nthe efficacy of our work.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2209.14252,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":9,
    "pangram_prediction":{
      "ai_likelihood":0.0000007616,
      "text":"Physics-aware Differentiable Discrete Codesign for Diffractive Optical\n  Neural Networks\n\n  Diffractive optical neural networks (DONNs) have attracted lots of attention\nas they bring significant advantages in terms of power efficiency, parallelism,\nand computational speed compared with conventional deep neural networks (DNNs),\nwhich have intrinsic limitations when implemented on digital platforms.\nHowever, inversely mapping algorithm-trained physical model parameters onto\nreal-world optical devices with discrete values is a non-trivial task as\nexisting optical devices have non-unified discrete levels and non-monotonic\nproperties. This work proposes a novel device-to-system hardware-software\ncodesign framework, which enables efficient physics-aware training of DONNs\nw.r.t arbitrary experimental measured optical devices across layers.\nSpecifically, Gumbel-Softmax is employed to enable differentiable discrete\nmapping from real-world device parameters into the forward function of DONNs,\nwhere the physical parameters in DONNs can be trained by simply minimizing the\nloss function of the ML task. The results have demonstrated that our proposed\nframework offers significant advantages over conventional quantization-based\nmethods, especially with low-precision optical devices. Finally, the proposed\nalgorithm is fully verified with physical experimental optical systems in\nlow-precision settings.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.11194,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000048015,
      "text":"Controller-Guided Partial Label Consistency Regularization with\n  Unlabeled Data\n\n  Partial label learning (PLL) learns from training examples each associated\nwith multiple candidate labels, among which only one is valid. In recent years,\nbenefiting from the strong capability of dealing with ambiguous supervision and\nthe impetus of modern data augmentation methods, consistency\nregularization-based PLL methods have achieved a series of successes and become\nmainstream. However, as the partial annotation becomes insufficient, their\nperformances drop significantly. In this paper, we leverage easily accessible\nunlabeled examples to facilitate the partial label consistency regularization.\nIn addition to a partial supervised loss, our method performs a\ncontroller-guided consistency regularization at both the label-level and\nrepresentation-level with the help of unlabeled data. To minimize the\ndisadvantages of insufficient capabilities of the initial supervised model, we\nuse the controller to estimate the confidence of each current prediction to\nguide the subsequent consistency regularization. Furthermore, we dynamically\nadjust the confidence thresholds so that the number of samples of each class\nparticipating in consistency regularization remains roughly equal to alleviate\nthe problem of class-imbalance. Experiments show that our method achieves\nsatisfactory performances in more practical situations, and its modules can be\napplied to existing PLL methods to enhance their capabilities.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.13207,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000070201,
      "text":"GeoAI at ACM SIGSPATIAL: The New Frontier of Geospatial Artificial\n  Intelligence Research\n\n  Geospatial Artificial Intelligence (GeoAI) is an interdisciplinary field\nenjoying tremendous adoption. However, the efficient design and implementation\nof GeoAI systems face many open challenges. This is mainly due to the lack of\nnon-standardized approaches to artificial intelligence tool development,\ninadequate platforms, and a lack of multidisciplinary engagements, which all\nmotivate domain experts to seek a shared stage with scientists and engineers to\nsolve problems of significant impact on society. Since its inception in 2017,\nthe GeoAI series of workshops has been co-located with the Association for\nComputing Machinery International Conference on Advances in Geographic\nInformation Systems. The workshop series has fostered a nexus for\ngeoscientists, computer scientists, engineers, entrepreneurs, and\ndecision-makers, from academia, industry, and government to engage in\nartificial intelligence, spatiotemporal data computing, and geospatial data\nscience research, motivated by various challenges. In this article, we revisit\nand discuss the state of GeoAI open research directions, the recent\ndevelopments, and an emerging agenda calling for a continued cross-disciplinary\ncommunity engagement.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.0505,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000150336,
      "text":"Neurosymbolic Programming for Science\n\n  Neurosymbolic Programming (NP) techniques have the potential to accelerate\nscientific discovery. These models combine neural and symbolic components to\nlearn complex patterns and representations from data, using high-level concepts\nor known constraints. NP techniques can interface with symbolic domain\nknowledge from scientists, such as prior knowledge and experimental context, to\nproduce interpretable outputs. We identify opportunities and challenges between\ncurrent NP models and scientific workflows, with real-world examples from\nbehavior analysis in science: to enable the use of NP broadly for workflows\nacross the natural and social sciences.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.15637,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000212921,
      "text":"Towards Correlated Sequential Rules\n\n  The goal of high-utility sequential pattern mining (HUSPM) is to efficiently\ndiscover profitable or useful sequential patterns in a large number of\nsequences. However, simply being aware of utility-eligible patterns is\ninsufficient for making predictions. To compensate for this deficiency,\nhigh-utility sequential rule mining (HUSRM) is designed to explore the\nconfidence or probability of predicting the occurrence of consequence\nsequential patterns based on the appearance of premise sequential patterns. It\nhas numerous applications, such as product recommendation and weather\nprediction. However, the existing algorithm, known as HUSRM, is limited to\nextracting all eligible rules while neglecting the correlation between the\ngenerated sequential rules. To address this issue, we propose a novel algorithm\ncalled correlated high-utility sequential rule miner (CoUSR) to integrate the\nconcept of correlation into HUSRM. The proposed algorithm requires not only\nthat each rule be correlated but also that the patterns in the antecedent and\nconsequent of the high-utility sequential rule be correlated. The algorithm\nadopts a utility-list structure to avoid multiple database scans. Additionally,\nseveral pruning strategies are used to improve the algorithm's efficiency and\nperformance. Based on several real-world datasets, subsequent experiments\ndemonstrated that CoUSR is effective and efficient in terms of operation time\nand memory consumption.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.03918,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000305971,
      "text":"Finding and Exploring Promising Search Space for the 0-1\n  Multidimensional Knapsack Problem\n\n  The 0-1 Multidimensional Knapsack Problem (MKP) is a classical NP-hard\ncombinatorial optimization problem with many engineering applications. In this\npaper, we propose a novel algorithm combining evolutionary computation with the\nexact algorithm to solve the 0-1 MKP. It maintains a set of solutions and\nutilizes the information from the population to extract good partial\nassignments. To find high-quality solutions, an exact algorithm is applied to\nexplore the promising search space specified by the good partial assignments.\nThe new solutions are used to update the population. Thus, the good partial\nassignments evolve towards a better direction with the improvement of the\npopulation. Extensive experimentation with commonly used benchmark sets shows\nthat our algorithm outperforms the state-of-the-art heuristic algorithms, TPTEA\nand DQPSO, as well as the commercial solver CPlex. It finds better solutions\nthan the existing algorithms and provides new lower bounds for 10 large and\nhard instances.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.08153,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000099672,
      "text":"CUP: Critic-Guided Policy Reuse\n\n  The ability to reuse previous policies is an important aspect of human\nintelligence. To achieve efficient policy reuse, a Deep Reinforcement Learning\n(DRL) agent needs to decide when to reuse and which source policies to reuse.\nPrevious methods solve this problem by introducing extra components to the\nunderlying algorithm, such as hierarchical high-level policies over source\npolicies, or estimations of source policies' value functions on the target\ntask. However, training these components induces either optimization\nnon-stationarity or heavy sampling cost, significantly impairing the\neffectiveness of transfer. To tackle this problem, we propose a novel policy\nreuse algorithm called Critic-gUided Policy reuse (CUP), which avoids training\nany extra components and efficiently reuses source policies. CUP utilizes the\ncritic, a common component in actor-critic methods, to evaluate and choose\nsource policies. At each state, CUP chooses the source policy that has the\nlargest one-step improvement over the current target policy, and forms a\nguidance policy. The guidance policy is theoretically guaranteed to be a\nmonotonic improvement over the current target policy. Then the target policy is\nregularized to imitate the guidance policy to perform efficient policy search.\nEmpirical results demonstrate that CUP achieves efficient transfer and\nsignificantly outperforms baseline algorithms.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.00315,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000080466,
      "text":"Using Argumentation Schemes to Model Legal Reasoning\n\n  We present argumentation schemes to model reasoning with legal cases. We\nprovide schemes for each of the three stages that take place after the facts\nare established: factor ascription, issue resolution and outcome determination.\nThe schemes are illustrated with examples from a specific legal domain, US\nTrade Secrets law, and the wider applicability of these schemes is discussed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.08713,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000085764,
      "text":"Supervised Prototypical Contrastive Learning for Emotion Recognition in\n  Conversation\n\n  Capturing emotions within a conversation plays an essential role in modern\ndialogue systems. However, the weak correlation between emotions and semantics\nbrings many challenges to emotion recognition in conversation (ERC). Even\nsemantically similar utterances, the emotion may vary drastically depending on\ncontexts or speakers. In this paper, we propose a Supervised Prototypical\nContrastive Learning (SPCL) loss for the ERC task. Leveraging the Prototypical\nNetwork, the SPCL targets at solving the imbalanced classification problem\nthrough contrastive learning and does not require a large batch size.\nMeanwhile, we design a difficulty measure function based on the distance\nbetween classes and introduce curriculum learning to alleviate the impact of\nextreme samples. We achieve state-of-the-art results on three widely used\nbenchmarks. Further, we conduct analytical experiments to demonstrate the\neffectiveness of our proposed SPCL and curriculum learning strategy. We release\nthe code at https:\/\/github.com\/caskcsg\/SPCL.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.08998,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000004636,
      "text":"A Symbolic Representation of Human Posture for Interpretable Learning\n  and Reasoning\n\n  Robots that interact with humans in a physical space or application need to\nthink about the person's posture, which typically comes from visual sensors\nlike cameras and infra-red. Artificial intelligence and machine learning\nalgorithms use information from these sensors either directly or after some\nlevel of symbolic abstraction, and the latter usually partitions the range of\nobserved values to discretize the continuous signal data. Although these\nrepresentations have been effective in a variety of algorithms with respect to\naccuracy and task completion, the underlying models are rarely interpretable,\nwhich also makes their outputs more difficult to explain to people who request\nthem. Instead of focusing on the possible sensor values that are familiar to a\nmachine, we introduce a qualitative spatial reasoning approach that describes\nthe human posture in terms that are more familiar to people. This paper\nexplores the derivation of our symbolic representation at two levels of detail\nand its preliminary use as features for interpretable activity recognition.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.12114,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000064903,
      "text":"Modelling Control Arguments via Cooperation Logic in Unforeseen\n  Scenarios\n\n  The intent of control argumentation frameworks is to specifically model\nstrategic scenarios from the perspective of an agent by extending the standard\nmodel of argumentation framework in a way that takes unquantified uncertainty\nregarding arguments and attacks into account. They do not, however, adequately\naccount for coalition formation and interactions among a set of agents in an\nuncertain environment. To address this challenge, we propose a formalism of a\nmulti-agent scenario via cooperation logic and investigate agents' strategies\nand actions in a dynamic environment.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.08608,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000015563,
      "text":"Posterior Regularized Bayesian Neural Network Incorporating Soft and\n  Hard Knowledge Constraints\n\n  Neural Networks (NNs) have been widely {used in supervised learning} due to\ntheir ability to model complex nonlinear patterns, often presented in\nhigh-dimensional data such as images and text. However, traditional NNs often\nlack the ability for uncertainty quantification. Bayesian NNs (BNNS) could help\nmeasure the uncertainty by considering the distributions of the NN model\nparameters. Besides, domain knowledge is commonly available and could improve\nthe performance of BNNs if it can be appropriately incorporated. In this work,\nwe propose a novel Posterior-Regularized Bayesian Neural Network (PR-BNN) model\nby incorporating different types of knowledge constraints, such as the soft and\nhard constraints, as a posterior regularization term. Furthermore, we propose\nto combine the augmented Lagrangian method and the existing BNN solvers for\nefficient inference. The experiments in simulation and two case studies about\naviation landing prediction and solar energy output prediction have shown the\nknowledge constraints and the performance improvement of the proposed model\nover traditional BNNs without the constraints.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.11298,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.000046889,
      "text":"Tele-Knowledge Pre-training for Fault Analysis\n\n  In this work, we share our experience on tele-knowledge pre-training for\nfault analysis, a crucial task in telecommunication applications that requires\na wide range of knowledge normally found in both machine log data and product\ndocuments. To organize this knowledge from experts uniformly, we propose to\ncreate a Tele-KG (tele-knowledge graph). Using this valuable data, we further\npropose a tele-domain language pre-training model TeleBERT and its\nknowledge-enhanced version, a tele-knowledge re-training model KTeleBERT. which\nincludes effective prompt hints, adaptive numerical data encoding, and two\nknowledge injection paradigms. Concretely, our proposal includes two stages:\nfirst, pre-training TeleBERT on 20 million tele-related corpora, and then\nre-training it on 1 million causal and machine-related corpora to obtain\nKTeleBERT. Our evaluation on multiple tasks related to fault analysis in\ntele-applications, including root-cause analysis, event association prediction,\nand fault chain tracing, shows that pre-training a language model with\ntele-domain data is beneficial for downstream tasks. Moreover, the KTeleBERT\nre-training further improves the performance of task models, highlighting the\neffectiveness of incorporating diverse tele-knowledge into the model.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.01484,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000001656,
      "text":"Estimating the hardness of SAT encodings for Logical Equivalence\n  Checking of Boolean circuits\n\n  In this paper we investigate how to estimate the hardness of Boolean\nsatisfiability (SAT) encodings for the Logical Equivalence Checking problem\n(LEC). Meaningful estimates of hardness are important in cases when a\nconventional SAT solver cannot solve a SAT instance in a reasonable time. We\nshow that the hardness of SAT encodings for LEC instances can be estimated\n\\textit{w.r.t.} some SAT partitioning. We also demonstrate the dependence of\nthe accuracy of the resulting estimates on the probabilistic characteristics of\na specially defined random variable associated with the considered\npartitioning. The paper proposes several methods for constructing\npartitionings, which, when used in practice, allow one to estimate the hardness\nof SAT encodings for LEC with good accuracy. In the experimental part we\npropose a class of scalable LEC tests that give extremely complex instances\nwith a relatively small input size $n$ of the considered circuits. For example,\nfor $n = 40$, none of the state-of-the-art SAT solvers can cope with the\nconsidered tests in a reasonable time. However, these tests can be solved in\nparallel using the proposed partitioning methods.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.09708,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000054306,
      "text":"HiSMatch: Historical Structure Matching based Temporal Knowledge Graph\n  Reasoning\n\n  A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective\ntimestamps, which adopts quadruples in the form of (\\emph{subject},\n\\emph{relation}, \\emph{object}, \\emph{timestamp}) to describe dynamic facts.\nTKG reasoning has facilitated many real-world applications via answering such\nqueries as (\\emph{query entity}, \\emph{query relation}, \\emph{?}, \\emph{future\ntimestamp}) about future. This is actually a matching task between a query and\ncandidate entities based on their historical structures, which reflect\nbehavioral trends of the entities at different timestamps. In addition, recent\nKGs provide background knowledge of all the entities, which is also helpful for\nthe matching. Thus, in this paper, we propose the \\textbf{Hi}storical\n\\textbf{S}tructure \\textbf{Match}ing (\\textbf{HiSMatch}) model. It applies two\nstructure encoders to capture the semantic information contained in the\nhistorical structures of the query and candidate entities. Besides, it adopts\nanother encoder to integrate the background knowledge into the model. TKG\nreasoning experiments on six benchmark datasets demonstrate the significant\nimprovement of the proposed HiSMatch model, with up to 5.6\\% performance\nimprovement in MRR, compared to the state-of-the-art baselines.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.00283,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000001325,
      "text":"Swift Markov Logic for Probabilistic Reasoning on Knowledge Graphs\n\n  We provide a framework for probabilistic reasoning in Vadalog-based Knowledge\nGraphs (KGs), satisfying the requirements of ontological reasoning: full\nrecursion, powerful existential quantification, expression of inductive\ndefinitions. Vadalog is a Knowledge Representation and Reasoning (KRR) language\nbased on Warded Datalog+\/-, a logical core language of existential rules, with\na good balance between computational complexity and expressive power. Handling\nuncertainty is essential for reasoning with KGs. Yet Vadalog and Warded\nDatalog+\/- are not covered by the existing probabilistic logic programming and\nstatistical relational learning approaches for several reasons, including\ninsufficient support for recursion with existential quantification, and the\nimpossibility to express inductive definitions. In this work, we introduce Soft\nVadalog, a probabilistic extension to Vadalog, satisfying these desiderata. A\nSoft Vadalog program induces what we call a Probabilistic Knowledge Graph\n(PKG), which consists of a probability distribution on a network of chase\ninstances, structures obtained by grounding the rules over a database using the\nchase procedure. We exploit PKGs for probabilistic marginal inference. We\ndiscuss the theory and present MCMC-chase, a Monte Carlo method to use Soft\nVadalog in practice. We apply our framework to solve data management and\nindustrial problems, and experimentally evaluate it in the Vadalog system.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.12324,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000048346,
      "text":"Trustworthy Human Computation: A Survey\n\n  Human computation is an approach to solving problems that prove difficult\nusing AI only, and involves the cooperation of many humans. Because human\ncomputation requires close engagement with both \"human populations as users\"\nand \"human populations as driving forces,\" establishing mutual trust between AI\nand humans is an important issue to further the development of human\ncomputation. This survey lays the groundwork for the realization of trustworthy\nhuman computation. First, the trustworthiness of human computation as computing\nsystems, that is, trust offered by humans to AI, is examined using the RAS\n(Reliability, Availability, and Serviceability) analogy, which define measures\nof trustworthiness in conventional computer systems. Next, the social\ntrustworthiness provided by human computation systems to users or participants\nis discussed from the perspective of AI ethics, including fairness, privacy,\nand transparency. Then, we consider human--AI collaboration based on two-way\ntrust, in which humans and AI build mutual trust and accomplish difficult tasks\nthrough reciprocal collaboration. Finally, future challenges and research\ndirections for realizing trustworthy human computation are discussed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.12556,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000022517,
      "text":"B$^3$RTDP: A Belief Branch and Bound Real-Time Dynamic Programming\n  Approach to Solving POMDPs\n\n  Partially Observable Markov Decision Processes (POMDPs) offer a promising\nworld representation for autonomous agents, as they can model both transitional\nand perceptual uncertainties. Calculating the optimal solution to POMDP\nproblems can be computationally expensive as they require reasoning over the\n(possibly infinite) space of beliefs. Several approaches have been proposed to\novercome this difficulty, such as discretizing the belief space, point-based\nbelief sampling, and Monte Carlo tree search. The Real-Time Dynamic Programming\napproach of the RTDP-Bel algorithm approximates the value function by storing\nit in a hashtable with discretized belief keys. We propose an extension to the\nRTDP-Bel algorithm which we call Belief Branch and Bound RTDP (B$^3$RTDP). Our\nalgorithm uses a bounded value function representation and takes advantage of\nthis in two novel ways: a search-bounding technique based on action selection\nconvergence probabilities, and a method for leveraging early action convergence\ncalled the \\textit{Convergence Frontier}. Lastly, we empirically demonstrate\nthat B$^3$RTDP can achieve greater returns in less time than the\nstate-of-the-art SARSOP solver on known POMDP problems.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.08263,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0001065599,
      "text":"Reinforcement Learning for ConnectX\n\n  ConnectX is a two-player game that generalizes the popular game Connect 4.\nThe objective is to get X coins across a row, column, or diagonal of an M x N\nboard. The first player to do so wins the game. The parameters (M, N, X) are\nallowed to change in each game, making ConnectX a novel and challenging\nproblem. In this paper, we present our work on the implementation and\nmodification of various reinforcement learning algorithms to play ConnectX.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.15507,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000003643,
      "text":"How To Overcome Richness Axiom Fallacy\n\n  The paper points at the grieving problems implied by the richness axiom in\nthe Kleinberg's axiomatic system and suggests resolutions. The richness induces\nlearnability problem in general and leads to conflicts with consistency axiom.\nAs a resolution, learnability constraints and usage of centric consistency or\nrestriction of the domain of considered clusterings to super-ball-clusterings\nis proposed.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2210.12896,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":10,
    "pangram_prediction":{
      "ai_likelihood":0.0000026491,
      "text":"Classifying Ambiguous Identities in Hidden-Role Stochastic Games with\n  Multi-Agent Reinforcement Learning\n\n  Multi-agent reinforcement learning (MARL) is a prevalent learning paradigm\nfor solving stochastic games. In most MARL studies, agents in a game are\ndefined as teammates or enemies beforehand, and the relationships among the\nagents remain fixed throughout the game. However, in real-world problems, the\nagent relationships are commonly unknown in advance or dynamically changing.\nMany multi-party interactions start off by asking: who is on my team? This\nquestion arises whether it is the first day at the stock exchange or the\nkindergarten. Therefore, training policies for such situations in the face of\nimperfect information and ambiguous identities is an important problem that\nneeds to be addressed. In this work, we develop a novel identity detection\nreinforcement learning (IDRL) framework that allows an agent to dynamically\ninfer the identities of nearby agents and select an appropriate policy to\naccomplish the task. In the IDRL framework, a relation network is constructed\nto deduce the identities of other agents by observing the behaviors of the\nagents. A danger network is optimized to estimate the risk of false-positive\nidentifications. Beyond that, we propose an intrinsic reward that balances the\nneed to maximize external rewards and accurate identification. After\nidentifying the cooperation-competition pattern among the agents, IDRL applies\none of the off-the-shelf MARL methods to learn the policy. To evaluate the\nproposed method, we conduct experiments on Red-10 card-shedding game, and the\nresults show that IDRL achieves superior performance over other\nstate-of-the-art MARL methods. Impressively, the relation network has the par\nperformance to identify the identities of agents with top human players; the\ndanger network reasonably avoids the risk of imperfect identification. The code\nto reproduce all the reported results is available online at\nhttps:\/\/github.com\/MR-BENjie\/IDRL.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.06561,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000050995,
      "text":"Explainable Artificial Intelligence in Construction: The Content,\n  Context, Process, Outcome Evaluation Framework\n\n  Explainable artificial intelligence is an emerging and evolving concept. Its\nimpact on construction, though yet to be realised, will be profound in the\nforeseeable future. Still, XAI has received limited attention in construction.\nAs a result, no evaluation frameworks have been propagated to enable\nconstruction organisations to understand the what, why, how, and when of XAI.\nOur paper aims to fill this void by developing a content, context, process, and\noutcome evaluation framework that can be used to justify the adoption and\neffective management of XAI. After introducing and describing this novel\nframework, we discuss its implications for future research. While our novel\nframework is conceptual, it provides a frame of reference for construction\norganisations to make headway toward realising XAI business value and benefits.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.10085,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000031789,
      "text":"Identifying Unique Spatial-Temporal Bayesian Network without Markov Equivalence\n\nIdentifying vanilla Bayesian network to model spatial-temporal causality can be a critical yet challenging task. Different Markovian-equivalent directed acyclic graphs would be identified if the identifiability is not satisfied. To address this issue, Directed Cyclic Graph is proposed to drop the directed acyclic constraint. But it does not always hold, and cannot model dynamical time-series process. Then, Full Time Graph is proposed with introducing high-order time delay. Full Time Graph has no Markov equivalence class by assuming no instantaneous effects. But, it also assumes that the causality is invariant with varying time, that is not always satisfied in the spatio-temporal scenarios. Thus, in this work, a Spatial-Temporal Bayesian Network (STBN) is proposed to theoretically model the spatial-temporal causality from the perspective of information transfer. STBN explains the disappearance of network structure $X\\rightarrow Z \\rightarrow Y$ and $X\\leftarrow Z \\leftarrow Y$ by the principle of information path blocking. And finally, the uniqueness of STBN is proved. Based on this, a High-order Causal Entropy (HCE) algorithm is also proposed to uniquely identify STBN under time complexity $\\mathcal{O}(n^3\\tau_{max})$, where $n$ is the number of variables and $\\tau_{max}$ is the maximum time delay. Numerical experiments are conducted with comparison to other baseline algorithms. The results show that HCE algorithm obtains state-of-the-art identification accuracy. The code is available at https:\/\/github.com\/KMY-SEU\/HCE.",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.008,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000004305,
      "text":"The purpose of qualia: What if human thinking is not (only) information\n  processing?\n\n  Despite recent breakthroughs in the field of artificial intelligence (AI) -\nor more specifically machine learning (ML) algorithms for object recognition\nand natural language processing - it seems to be the majority view that current\nAI approaches are still no real match for natural intelligence (NI). More\nimportantly, philosophers have collected a long catalogue of features which\nimply that NI works differently from current AI not only in a gradual sense,\nbut in a more substantial way: NI is closely related to consciousness,\nintentionality and experiential features like qualia (the subjective contents\nof mental states) and allows for understanding (e.g., taking insight into\ncausal relationships instead of 'blindly' relying on correlations), as well as\naesthetical and ethical judgement beyond what we can put into (explicit or\ndata-induced implicit) rules to program machines with. Additionally,\nPsychologists find NI to range from unconscious psychological processes to\nfocused information processing, and from embodied and implicit cognition to\n'true' agency and creativity. NI thus seems to transcend any neurobiological\nfunctionalism by operating on 'bits of meaning' instead of information in the\nsense of data, quite unlike both the 'good old fashioned', symbolic AI of the\npast, as well as the current wave of deep neural network based, 'sub-symbolic'\nAI, which both share the idea of thinking as (only) information processing. In\nthe following I propose an alternative view of NI as information processing\nplus 'bundle pushing', discuss an example which illustrates how bundle pushing\ncan cut information processing short, and suggest first ideas for scientific\nexperiments in neuro-biology and information theory as further investigations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.05457,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000516574,
      "text":"Syntax-Guided Domain Adaptation for Aspect-based Sentiment Analysis\n\n  Aspect-based sentiment analysis (ABSA) aims at extracting opinionated aspect\nterms in review texts and determining their sentiment polarities, which is\nwidely studied in both academia and industry. As a fine-grained classification\ntask, the annotation cost is extremely high. Domain adaptation is a popular\nsolution to alleviate the data deficiency issue in new domains by transferring\ncommon knowledge across domains. Most cross-domain ABSA studies are based on\nstructure correspondence learning (SCL), and use pivot features to construct\nauxiliary tasks for narrowing down the gap between domains. However, their\npivot-based auxiliary tasks can only transfer knowledge of aspect terms but not\nsentiment, limiting the performance of existing models. In this work, we\npropose a novel Syntax-guided Domain Adaptation Model, named SDAM, for more\neffective cross-domain ABSA. SDAM exploits syntactic structure similarities for\nbuilding pseudo training instances, during which aspect terms of target domain\nare explicitly related to sentiment polarities. Besides, we propose a\nsyntax-based BERT mask language model for further capturing domain-invariant\nfeatures. Finally, to alleviate the sentiment inconsistency issue in multi-gram\naspect terms, we introduce a span-based joint aspect term and sentiment\nanalysis module into the cross-domain End2End ABSA. Experiments on five\nbenchmark datasets show that our model consistently outperforms the\nstate-of-the-art baselines with respect to Micro-F1 metric for the cross-domain\nEnd2End ABSA task.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.14422,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000657969,
      "text":"Quantitative Method for Security Situation of the Power Information\n  Network Based on the Evolutionary Neural Network\n\n  Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.08671,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000010596,
      "text":"LEMMA: Bootstrapping High-Level Mathematical Reasoning with Learned\n  Symbolic Abstractions\n\n  Humans tame the complexity of mathematical reasoning by developing\nhierarchies of abstractions. With proper abstractions, solutions to hard\nproblems can be expressed concisely, thus making them more likely to be found.\nIn this paper, we propose Learning Mathematical Abstractions (LEMMA): an\nalgorithm that implements this idea for reinforcement learning agents in\nmathematical domains. LEMMA augments Expert Iteration with an abstraction step,\nwhere solutions found so far are revisited and rewritten in terms of new\nhigher-level actions, which then become available to solve new problems. We\nevaluate LEMMA on two mathematical reasoning tasks--equation solving and\nfraction simplification--in a step-by-step fashion. In these two domains, LEMMA\nimproves the ability of an existing agent, both solving more problems and\ngeneralizing more effectively to harder problems than those seen during\ntraining.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.14492,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000011259,
      "text":"Enhancing Constraint Programming via Supervised Learning for Job Shop\n  Scheduling\n\n  Constraint programming (CP) is a powerful technique for solving constraint\nsatisfaction and optimization problems. In CP solvers, the variable ordering\nstrategy used to select which variable to explore first in the solving process\nhas a significant impact on solver effectiveness. To address this issue, we\npropose a novel variable ordering strategy based on supervised learning, which\nwe evaluate in the context of job shop scheduling problems. Our learning-based\nmethods predict the optimal solution of a problem instance and use the\npredicted solution to order variables for CP solvers. \\added[]{Unlike\ntraditional variable ordering methods, our methods can learn from the\ncharacteristics of each problem instance and customize the variable ordering\nstrategy accordingly, leading to improved solver performance.} Our experiments\ndemonstrate that training machine learning models is highly efficient and can\nachieve high accuracy. Furthermore, our learned variable ordering methods\nperform competitively when compared to four existing methods. Finally, we\ndemonstrate that hybridising the machine learning-based variable ordering\nmethods with traditional domain-based methods is beneficial.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.05939,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000015232,
      "text":"pyRDDLGym: From RDDL to Gym Environments\n\n  We present pyRDDLGym, a Python framework for auto-generation of OpenAI Gym\nenvironments from RDDL declerative description. The discrete time step\nevolution of variables in RDDL is described by conditional probability\nfunctions, which fits naturally into the Gym step scheme. Furthermore, since\nRDDL is a lifted description, the modification and scaling up of environments\nto support multiple entities and different configurations becomes trivial\nrather than a tedious process prone to errors. We hope that pyRDDLGym will\nserve as a new wind in the reinforcement learning community by enabling easy\nand rapid development of benchmarks due to the unique expressive power of RDDL.\nBy providing explicit access to the model in the RDDL description, pyRDDLGym\ncan also facilitate research on hybrid approaches for learning from interaction\nwhile leveraging model knowledge. We present the design and built-in examples\nof pyRDDLGym, and the additions made to the RDDL language that were\nincorporated into the framework.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.15552,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000016226,
      "text":"AI Enabled Maneuver Identification via the Maneuver Identification\n  Challenge\n\n  Artificial intelligence (AI) has enormous potential to improve Air Force\npilot training by providing actionable feedback to pilot trainees on the\nquality of their maneuvers and enabling instructor-less flying familiarization\nfor early-stage trainees in low-cost simulators. Historically, AI challenges\nconsisting of data, problem descriptions, and example code have been critical\nto fueling AI breakthroughs. The Department of the Air Force-Massachusetts\nInstitute of Technology AI Accelerator (DAF-MIT AI Accelerator) developed such\nan AI challenge using real-world Air Force flight simulator data. The Maneuver\nID challenge assembled thousands of virtual reality simulator flight recordings\ncollected by actual Air Force student pilots at Pilot Training Next (PTN). This\ndataset has been publicly released at Maneuver-ID.mit.edu and represents the\nfirst of its kind public release of USAF flight training data. Using this\ndataset, we have applied a variety of AI methods to separate \"good\" vs \"bad\"\nsimulator data and categorize and characterize maneuvers. These data,\nalgorithms, and software are being released as baselines of model performance\nfor others to build upon to enable the AI ecosystem for flight simulator\ntraining.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.14673,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000013245,
      "text":"Evaluation Beyond Task Performance: Analyzing Concepts in AlphaZero in\n  Hex\n\n  AlphaZero, an approach to reinforcement learning that couples neural networks\nand Monte Carlo tree search (MCTS), has produced state-of-the-art strategies\nfor traditional board games like chess, Go, shogi, and Hex. While researchers\nand game commentators have suggested that AlphaZero uses concepts that humans\nconsider important, it is unclear how these concepts are captured in the\nnetwork. We investigate AlphaZero's internal representations in the game of Hex\nusing two evaluation techniques from natural language processing (NLP): model\nprobing and behavioral tests. In doing so, we introduce new evaluation tools to\nthe RL community and illustrate how evaluations other than task performance can\nbe used to provide a more complete picture of a model's strengths and\nweaknesses. Our analyses in the game of Hex reveal interesting patterns and\ngenerate some testable hypotheses about how such models learn in general. For\nexample, we find that MCTS discovers concepts before the neural network learns\nto encode them. We also find that concepts related to short-term end-game\nplanning are best encoded in the final layers of the model, whereas concepts\nrelated to long-term planning are encoded in the middle layers of the model.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.10435,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000046028,
      "text":"The Expertise Level\n\n  Computers are quickly gaining on us. Artificial systems are now exceeding the\nperformance of human experts in several domains. However, we do not yet have a\ndeep definition of expertise. This paper examines the nature of expertise and\npresents an abstract knowledge-level and skill-level description of expertise.\nA new level lying above the Knowledge Level, called the Expertise Level, is\nintroduced to describe the skills of an expert without having to worry about\ndetails of the knowledge required. The Model of Expertise is introduced\ncombining the knowledge-level and expertise-level descriptions. Application of\nthe model to the fields of cognitive architectures and human cognitive\naugmentation is demonstrated and several famous intelligent systems are\nanalyzed with the model.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.09622,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000010596,
      "text":"AlphaSnake: Policy Iteration on a Nondeterministic NP-hard Markov\n  Decision Process\n\n  Reinforcement learning has recently been used to approach well-known NP-hard\ncombinatorial problems in graph theory. Among these problems, Hamiltonian cycle\nproblems are exceptionally difficult to analyze, even when restricted to\nindividual instances of structurally complex graphs. In this paper, we use\nMonte Carlo Tree Search (MCTS), the search algorithm behind many\nstate-of-the-art reinforcement learning algorithms such as AlphaZero, to create\nautonomous agents that learn to play the game of Snake, a game centered on\nproperties of Hamiltonian cycles on grid graphs. The game of Snake can be\nformulated as a single-player discounted Markov Decision Process (MDP) where\nthe agent must behave optimally in a stochastic environment. Determining the\noptimal policy for Snake, defined as the policy that maximizes the probability\nof winning - or win rate - with higher priority and minimizes the expected\nnumber of time steps to win with lower priority, is conjectured to be NP-hard.\nPerformance-wise, compared to prior work in the Snake game, our algorithm is\nthe first to achieve a win rate over $0.5$ (a uniform random policy achieves a\nwin rate $< 2.57 \\times 10^{-15}$), demonstrating the versatility of AlphaZero\nin approaching NP-hard environments.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.03888,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000013577,
      "text":"Proceedings of Principle and practice of data and Knowledge Acquisition\n  Workshop 2022 (PKAW 2022)\n\n  Over the past two decades, PKAW has provided a forum for researchers and\npractitioners to discuss the state-of-the-arts in the area of knowledge\nacquisition and machine intelligence (MI, also Artificial Intelligence, AI).\nPKAW2022 will continue the above focus and welcome the contributions on the\nmulti-disciplinary approach of human and big data-driven knowledge acquisition,\nas well as AI techniques and applications.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.17262,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000155965,
      "text":"Non-Deterministic Approximation Fixpoint Theory and Its Application in\n  Disjunctive Logic Programming\n\n  Approximation fixpoint theory (AFT) is an abstract and general algebraic\nframework for studying the semantics of nonmonotonic logics. It provides a\nunifying study of the semantics of different formalisms for nonmonotonic\nreasoning, such as logic programming, default logic and autoepistemic logic. In\nthis paper, we extend AFT to dealing with non-deterministic constructs that\nallow to handle indefinite information, represented e.g. by disjunctive\nformulas. This is done by generalizing the main constructions and corresponding\nresults of AFT to non-deterministic operators, whose ranges are sets of\nelements rather than single elements. The applicability and usefulness of this\ngeneralization is illustrated in the context of disjunctive logic programming.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.03943,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000027484,
      "text":"Final Report on MITRE Evaluations for the DARPA Big Mechanism Program\n\n  This report presents the evaluation approach developed for the DARPA Big\nMechanism program, which aimed at developing computer systems that will read\nresearch papers, integrate the information into a computer model of cancer\nmechanisms, and frame new hypotheses. We employed an iterative, incremental\napproach to the evaluation of the three phases of the program. In Phase I, we\nevaluated the ability of system and human teams ability to read-with-a-model to\ncapture mechanistic information from the biomedical literature, integrated with\ninformation from expert curated biological databases. In Phase II we evaluated\nthe ability of systems to assemble fragments of information into a mechanistic\nmodel. The Phase III evaluation focused on the ability of systems to provide\nexplanations of experimental observations based on models assembled (largely\nautomatically) by the Big Mechanism process. The evaluation for each phase\nbuilt on earlier evaluations and guided developers towards creating\ncapabilities for the new phase. The report describes our approach, including\ninnovations such as a reference set (a curated data set limited to major\nfindings of each paper) to assess the accuracy of systems in extracting\nmechanistic findings in the absence of a gold standard, and a method to\nevaluate model-based explanations of experimental data. Results of the\nevaluation and supporting materials are included in the appendices.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.09752,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000030796,
      "text":"Learning to Counterfactually Explain Recommendations\n\n  Recommender system practitioners are facing increasing pressure to explain\nrecommendations. We explore how to explain recommendations using counterfactual\nlogic, i.e. \"Had you not interacted with the following items, we would not\nrecommend it.\" Compared to the traditional explanation logic, counterfactual\nexplanations are easier to understand, more technically verifiable, and more\ninformative in terms of giving users control over recommendations. The major\nchallenge of generating such explanations is the computational cost because it\nrequires repeatedly retraining the models to obtain the effect on a\nrecommendation caused by the absence of user history. We propose a\nlearning-based framework to generate counterfactual explanations. The key idea\nis to train a surrogate model to learn the effect of removing a subset of user\nhistory on the recommendation. To this end, we first artificially simulate the\ncounterfactual outcomes on the recommendation after deleting subsets of\nhistory. Then we train a surrogate model to learn the mapping between a history\ndeletion and the corresponding change of the recommendation caused by the\ndeletion. Finally, to generate an explanation, we find the history subset\npredicted by the surrogate model that is most likely to remove the\nrecommendation. Through offline experiments and online user studies, we show\nour method, compared to baselines, can generate explanations that are more\ncounterfactually valid and more satisfactory considered by users.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.15324,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.000010199,
      "text":"Low-resource Personal Attribute Prediction from Conversation\n\n  Personal knowledge bases (PKBs) are crucial for a broad range of applications\nsuch as personalized recommendation and Web-based chatbots. A critical\nchallenge to build PKBs is extracting personal attribute knowledge from users'\nconversation data. Given some users of a conversational system, a personal\nattribute and these users' utterances, our goal is to predict the ranking of\nthe given personal attribute values for each user. Previous studies often rely\non a relative number of resources such as labeled utterances and external data,\nyet the attribute knowledge embedded in unlabeled utterances is underutilized\nand their performance of predicting some difficult personal attributes is still\nunsatisfactory. In addition, it is found that some text classification methods\ncould be employed to resolve this task directly. However, they also perform not\nwell over those difficult personal attributes. In this paper, we propose a\nnovel framework PEARL to predict personal attributes from conversations by\nleveraging the abundant personal attribute knowledge from utterances under a\nlow-resource setting in which no labeled utterances or external data are\nutilized. PEARL combines the biterm semantic information with the word\nco-occurrence information seamlessly via employing the updated prior attribute\nknowledge to refine the biterm topic model's Gibbs sampling process in an\niterative manner. The extensive experimental results show that PEARL\noutperforms all the baseline methods not only on the task of personal attribute\nprediction from conversations over two data sets, but also on the more general\nweakly supervised text classification task over one data set.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.10446,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000010596,
      "text":"Neural Network Learner for Minesweeper\n\n  Minesweeper is an interesting single player game based on logic, memory and\nguessing. Solving Minesweeper has been shown to be an NP-hard task.\nDeterministic solvers are the best known approach for solving Minesweeper. This\nproject proposes a neural network based learner for solving Minesweeper. To\nchoose the best learner, different architectures and configurations of neural\nnetworks were trained on hundreds of thousands of games. Surprisingly, the\nproposed neural network based learner has shown to be a very good approximation\nfunction for solving Minesweeper. The neural network learner competes well with\nthe CSP solvers, especially in Beginner and Intermediate modes of the game. It\nwas also observed that despite having high success rates, the best neural\nlearner was considerably slower than the best deterministic solver. This report\nalso discusses the overheads and limitations faced while creating highly\nsuccessful neural networks for Minesweeper.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.15271,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000088745,
      "text":"The Myth of Culturally Agnostic AI Models\n\n  The paper discusses the potential of large vision-language models as objects\nof interest for empirical cultural studies. Focusing on the comparative\nanalysis of outputs from two popular text-to-image synthesis models, DALL-E 2\nand Stable Diffusion, the paper tries to tackle the pros and cons of striving\ntowards culturally agnostic vs. culturally specific AI models. The paper\ndiscusses several examples of memorization and bias in generated outputs which\nshowcase the trade-off between risk mitigation and cultural specificity, as\nwell as the overall impossibility of developing culturally agnostic models.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2211.02849,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":11,
    "pangram_prediction":{
      "ai_likelihood":0.0000126163,
      "text":"Coarse-to-fine Knowledge Graph Domain Adaptation based on\n  Distantly-supervised Iterative Training\n\n  Modern supervised learning neural network models require a large amount of\nmanually labeled data, which makes the construction of domain-specific\nknowledge graphs time-consuming and labor-intensive. In parallel, although\nthere has been much research on named entity recognition and relation\nextraction based on distantly supervised learning, constructing a\ndomain-specific knowledge graph from large collections of textual data without\nmanual annotations is still an urgent problem to be solved. In response, we\npropose an integrated framework for adapting and re-learning knowledge graphs\nfrom one coarse domain (biomedical) to a finer-define domain (oncology). In\nthis framework, we apply distant-supervision on cross-domain knowledge graph\nadaptation. Consequently, no manual data annotation is required to train the\nmodel. We introduce a novel iterative training strategy to facilitate the\ndiscovery of domain-specific named entities and triples. Experimental results\nindicate that the proposed framework can perform domain adaptation and\nconstruction of knowledge graph efficiently.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.06564,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000043379,
      "text":"Prescriptive Process Monitoring in Intelligent Process Automation with\n  Chatbot Orchestration\n\n  Business processes that involve AI-powered automation have been gaining\nimportance and market share in recent years. These business processes combine\nthe characteristics of classical business process management, goal-driven\nchatbots, conversational recommendation systems, and robotic process\nautomation. In the new context, prescriptive process monitoring demands\ninnovative approaches. Unfortunately, data logs from these new processes are\nstill not available in the public domain. We describe the main challenges in\nthis new domain and introduce a synthesized dataset that is based on an actual\nuse case of intelligent process automation with chatbot orchestration. Using\nthis dataset, we demonstrate crowd-wisdom and goal-driven approaches to\nprescriptive process monitoring.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2304.00002,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000118878,
      "text":"Beyond Interpretable Benchmarks: Contextual Learning through Cognitive\n  and Multimodal Perception\n\n  With state-of-the-art models achieving high performance on standard\nbenchmarks, contemporary research paradigms continue to emphasize general\nintelligence as an enduring objective. However, this pursuit overlooks the\nfundamental disparities between the high-level data perception abilities of\nartificial and natural intelligence systems. This study questions the Turing\nTest as a criterion of generally intelligent thought and contends that it is\nmisinterpreted as an attempt to anthropomorphize computer systems. Instead, it\nemphasizes tacit learning as a cornerstone of general-purpose intelligence,\ndespite its lack of overt interpretability. This abstract form of intelligence\nnecessitates contextual cognitive attributes that are crucial for human-level\nperception: generalizable experience, moral responsibility, and implicit\nprioritization. The absence of these features yields undeniable perceptual\ndisparities and constrains the cognitive capacity of artificial systems to\neffectively contextualize their environments. Additionally, this study\nestablishes that, despite extensive exploration of potential architecture for\nfuture systems, little consideration has been given to how such models will\ncontinuously absorb and adapt to contextual data. While conventional models may\ncontinue to improve in benchmark performance, disregarding these contextual\nconsiderations will lead to stagnation in human-like comprehension. Until\ngeneral intelligence can be abstracted from task-specific domains and systems\ncan learn implicitly from their environments, research standards should instead\nprioritize the disciplines in which AI thrives.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.07523,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000001159,
      "text":"Many-valued Argumentation, Conditionals and a Probabilistic Semantics for Gradual Argumentation\n\nIn this paper we propose a general approach to define a many-valued preferential interpretation of gradual argumentation semantics. The approach allows for conditional reasoning over arguments and boolean combination of arguments, with respect to a class of gradual semantics, through the verification of graded (strict or defeasible) implications over a preferential interpretation. As a proof of concept, in the finitely-valued case, an Answer set Programming approach is proposed for conditional reasoning in a many-valued argumentation semantics of weighted argumentation graphs. The paper also develops and discusses a probabilistic semantics for gradual argumentation, which builds on the many-valued conditional semantics.",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.1247,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000000993,
      "text":"Proximal Policy Optimization with Graph Neural Networks for Optimal Power Flow\n\nOptimal Power Flow (OPF) is a very traditional research area within the power systems field that seeks for the optimal operation point of electric power plants, and which needs to be solved every few minutes in real-world scenarios. However, due to the nonconvexities that arise in power generation systems, there is not yet a fast, robust solution technique for the full Alternating Current Optimal Power Flow (ACOPF). In the last decades, power grids have evolved into a typical dynamic, non-linear and large-scale control system, known as the power system, so searching for better and faster ACOPF solutions is becoming crucial. Appearance of Graph Neural Networks (GNN) has allowed the natural use of Machine Learning (ML) algorithms on graph data, such as power networks. On the other hand, Deep Reinforcement Learning (DRL) is known for its powerful capability to solve complex decision-making problems. Although solutions that use these two methods separately are beginning to appear in the literature, none has yet combined the advantages of both. We propose a novel architecture based on the Proximal Policy Optimization algorithm with Graph Neural Networks to solve the Optimal Power Flow. The objective is to design an architecture that learns how to solve the optimization problem and that is at the same time able to generalize to unseen scenarios. We compare our solution with the DCOPF in terms of cost after having trained our DRL agent on IEEE 30 bus system and then computing the OPF on that base network with topology changes",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.00994,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000106295,
      "text":"Knowledge Graph Quality Evaluation under Incomplete Information\n\n  Knowledge graphs (KGs) have attracted more and more attentions because of\ntheir fundamental roles in many tasks. Quality evaluation for KGs is thus\ncrucial and indispensable. Existing methods in this field evaluate KGs by\neither proposing new quality metrics from different dimensions or measuring\nperformances at KG construction stages. However, there are two major issues\nwith those methods. First, they highly rely on raw data in KGs, which makes\nKGs' internal information exposed during quality evaluation. Second, they\nconsider more about the quality at data level instead of ability level, where\nthe latter one is more important for downstream applications. To address these\nissues, we propose a knowledge graph quality evaluation framework under\nincomplete information (QEII). The quality evaluation task is transformed into\nan adversarial Q&A game between two KGs. Winner of the game is thus considered\nto have better qualities. During the evaluation process, no raw data is\nexposed, which ensures information protection. Experimental results on four\npairs of KGs demonstrate that, compared with baselines, the QEII implements a\nreasonable quality evaluation at ability level under incomplete information.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.10915,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000052651,
      "text":"Automatic Semantic Modeling for Structural Data Source with the Prior\n  Knowledge from Knowledge Base\n\n  A critical step in sharing semantic content online is to map the structural\ndata source to a public domain ontology. This problem is denoted as the\nRelational-To-Ontology Mapping Problem (Rel2Onto). A huge effort and expertise\nare required for manually modeling the semantics of data. Therefore, an\nautomatic approach for learning the semantics of a data source is desirable.\nMost of the existing work studies the semantic annotation of source attributes.\nHowever, although critical, the research for automatically inferring the\nrelationships between attributes is very limited. In this paper, we propose a\nnovel method for semantically annotating structured data sources using machine\nlearning, graph matching and modified frequent subgraph mining to amend the\ncandidate model. In our work, Knowledge graph is used as prior knowledge. Our\nevaluation shows that our approach outperforms two state-of-the-art solutions\nin tricky cases where only a few semantic models are known.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.00368,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000118878,
      "text":"Ontomathedu Ontology Enrichment Method\n\n  Nowadays, distance learning technologies have become very popular. The recent\npandemic has had a particularly strong impact on the development of distance\neducation technologies. Kazan Federal University has a distance learning system\nbased on LMS Moodle. This article describes the structure of the OntoMathEdu\necosystem aimed at improving the process of teaching school mathematics\ncourses, and also provides a method for improving the OntoMathEdu ontology\nstructure based on identifying new connections between contextually related\nconcepts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.00506,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000084771,
      "text":"Fairness in Multi-Agent Planning\n\n  In cooperative Multi-Agent Planning (MAP), a set of goals has to be achieved\nby a set of agents. Independently of whether they perform a pre-assignment of\ngoals to agents or they directly search for a solution without any goal\nassignment, most previous works did not focus on a fair\ndistribution\/achievement of goals by agents. This paper adapts well-known\nfairness schemes to MAP, and introduces two novel approaches to generate\ncost-aware fair plans. The first one solves an optimization problem to\npre-assign goals to agents, and then solves a centralized MAP task using that\nassignment. The second one consists of a planning-based compilation that allows\nsolving the joint problem of goal assignment and planning while taking into\naccount the given fairness scheme. Empirical results in several standard MAP\nbenchmarks show that these approaches outperform different baselines. They also\nshow that there is no need to sacrifice much plan cost to generate fair plans.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.13725,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000073976,
      "text":"Robust Sequence Networked Submodular Maximization\n\n  In this paper, we study the \\underline{R}obust \\underline{o}ptimization for\n\\underline{se}quence \\underline{Net}worked \\underline{s}ubmodular maximization\n(RoseNets) problem. We interweave the robust optimization with the sequence\nnetworked submodular maximization. The elements are connected by a directed\nacyclic graph and the objective function is not submodular on the elements but\non the edges in the graph. Under such networked submodular scenario, the impact\nof removing an element from a sequence depends both on its position in the\nsequence and in the network. This makes the existing robust algorithms\ninapplicable. In this paper, we take the first step to study the RoseNets\nproblem. We design a robust greedy algorithm, which is robust against the\nremoval of an arbitrary subset of the selected elements. The approximation\nratio of the algorithm depends both on the number of the removed elements and\nthe network topology. We further conduct experiments on real applications of\nrecommendation and link prediction. The experimental results demonstrate the\neffectiveness of the proposed algorithm.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.11214,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000025498,
      "text":"Crowd Score: A Method for the Evaluation of Jokes using Large Language\n  Model AI Voters as Judges\n\n  This paper presents the Crowd Score, a novel method to assess the funniness\nof jokes using large language models (LLMs) as AI judges. Our method relies on\ninducing different personalities into the LLM and aggregating the votes of the\nAI judges into a single score to rate jokes. We validate the votes using an\nauditing technique that checks if the explanation for a particular vote is\nreasonable using the LLM. We tested our methodology on 52 jokes in a crowd of\nfour AI voters with different humour types: affiliative, self-enhancing,\naggressive and self-defeating. Our results show that few-shot prompting leads\nto better results than zero-shot for the voting question. Personality induction\nshowed that aggressive and self-defeating voters are significantly more\ninclined to find more jokes funny of a set of aggressive\/self-defeating jokes\nthan the affiliative and self-enhancing voters. The Crowd Score follows the\nsame trend as human judges by assigning higher scores to jokes that are also\nconsidered funnier by human judges. We believe that our methodology could be\napplied to other creative domains such as story, poetry, slogans, etc. It could\nboth help the adoption of a flexible and accurate standard approach to compare\ndifferent work in the CC community under a common metric and by minimizing\nhuman participation in assessing creative artefacts, it could accelerate the\nprototyping of creative artefacts and reduce the cost of hiring human\nparticipants to rate creative artefacts.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.04401,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000010265,
      "text":"A Rubric for Human-like Agents and NeuroAI\n\n  Researchers across cognitive, neuro-, and computer sciences increasingly\nreference human-like artificial intelligence and neuroAI. However, the scope\nand use of the terms are often inconsistent. Contributed research ranges widely\nfrom mimicking behaviour, to testing machine learning methods as neurally\nplausible hypotheses at the cellular or functional levels, or solving\nengineering problems. However, it cannot be assumed nor expected that progress\non one of these three goals will automatically translate to progress in others.\nHere a simple rubric is proposed to clarify the scope of individual\ncontributions, grounded in their commitments to human-like behaviour, neural\nplausibility, or benchmark\/engineering goals. This is clarified using examples\nof weak and strong neuroAI and human-like agents, and discussing the\ngenerative, corroborate, and corrective ways in which the three dimensions\ninteract with one another. The author maintains that future progress in\nartificial intelligence will need strong interactions across the disciplines,\nwith iterative feedback loops and meticulous validity tests, leading to both\nknown and yet-unknown advances that may span decades to come.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.12575,
    "paper_type":"review",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000002053,
      "text":"Continual Causal Abstractions\n\n  This short paper discusses continually updated causal abstractions as a\npotential direction of future research. The key idea is to revise the existing\nlevel of causal abstraction to a different level of detail that is both\nconsistent with the history of observed data and more effective in solving a\ngiven task.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.09077,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"Answer-Set Programming for Lexicographical Makespan Optimisation in\n  Parallel Machine Scheduling\n\n  We deal with a challenging scheduling problem on parallel machines with\nsequence-dependent setup times and release dates from a real-world application\nof semiconductor work-shop production. There, jobs can only be processed by\ndedicated machines, thus few machines can determine the makespan almost\nregardless of how jobs are scheduled on the remaining ones. This causes\nproblems when machines fail and jobs need to be rescheduled. Instead of\noptimising only the makespan, we put the individual machine spans in\nnon-ascending order and lexicographically minimise the resulting tuples. This\nachieves that all machines complete as early as possible and increases the\nrobustness of the schedule. We study the application of Answer-Set Programming\n(ASP) to solve this problem. While ASP eases modelling, the combination of\ntiming constraints and the considered objective function challenges current\nsolving technology. The former issue is addressed by using an extension of ASP\nby difference logic. For the latter, we devise different algorithms that use\nmulti-shot solving. To tackle industrial-sized instances, we study different\napproximations and heuristics. Our experimental results show that ASP is indeed\na promising KRR paradigm for this problem and is competitive with\nstate-of-the-art CP and MIP solvers. Under consideration in Theory and Practice\nof Logic Programming (TPLP).\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.0633,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000162588,
      "text":"Generative artificial intelligence-enabled dynamic detection of\n  nicotine-related circuits\n\n  The identification of addiction-related circuits is critical for explaining\naddiction processes and developing addiction treatments. And models of\nfunctional addiction circuits developed from functional imaging are an\neffective tool for discovering and verifying addiction circuits. However,\nanalyzing functional imaging data of addiction and detecting functional\naddiction circuits still have challenges. We have developed a data-driven and\nend-to-end generative artificial intelligence(AI) framework to address these\ndifficulties. The framework integrates dynamic brain network modeling and novel\nnetwork architecture networks architecture, including temporal graph\nTransformer and contrastive learning modules. A complete workflow is formed by\nour generative AI framework: the functional imaging data, from neurobiological\nexperiments, and computational modeling, to end-to-end neural networks, is\ntransformed into dynamic nicotine addiction-related circuits. It enables the\ndetection of addiction-related brain circuits with dynamic properties and\nreveals the underlying mechanisms of addiction.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.09399,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000001987,
      "text":"AI Art in Architecture\n\n  Recent diffusion-based AI art platforms are able to create impressive images\nfrom simple text descriptions. This makes them powerful tools for concept\ndesign in any discipline that requires creativity in visual design tasks. This\nis also true for early stages of architectural design with multiple stages of\nideation, sketching and modelling. In this paper, we investigate how applicable\ndiffusion-based models already are to these tasks. We research the\napplicability of the platforms Midjourney, DALL-E 2 and StableDiffusion to a\nseries of common use cases in architectural design to determine which are\nalready solvable or might soon be. We also analyze how they are already being\nused by analyzing a data set of 40 million Midjourney queries with NLP methods\nto extract common usage patterns. With this insights we derived a workflow to\ninterior and exterior design that combines the strengths of the individual\nplatforms.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.00258,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000002318,
      "text":"To think inside the box, or to think out of the box? Scientific\n  discovery via the reciprocation of insights and concepts\n\n  If scientific discovery is one of the main driving forces of human progress,\ninsight is the fuel for the engine, which has long attracted behavior-level\nresearch to understand and model its underlying cognitive process. However,\ncurrent tasks that abstract scientific discovery mostly focus on the emergence\nof insight, ignoring the special role played by domain knowledge. In this\nconcept paper, we view scientific discovery as an interplay between $thinking \\\nout \\ of \\ the \\ box$ that actively seeks insightful solutions and $thinking \\\ninside \\ the \\ box$ that generalizes on conceptual domain knowledge to keep\ncorrect. Accordingly, we propose Mindle, a semantic searching game that\ntriggers scientific-discovery-like thinking spontaneously, as infrastructure\nfor exploring scientific discovery on a large scale. On this basis, the\nmeta-strategies for insights and the usage of concepts can be investigated\nreciprocally. In the pilot studies, several interesting observations inspire\nelaborated hypotheses on meta-strategies, context, and individual diversity for\nfurther investigations.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.05412,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000188748,
      "text":"A Hierarchical Temporal Planning-Based Approach for Dynamic Hoist\n  Scheduling Problems\n\n  Hoist scheduling has become a bottleneck in electroplating industry\napplications with the development of autonomous devices. Although there are a\nfew approaches proposed to target at the challenging problem, they generally\ncannot scale to large-scale scheduling problems. In this paper, we formulate\nthe hoist scheduling problem as a new temporal planning problem in the form of\nadapted PDDL, and propose a novel hierarchical temporal planning approach to\nefficiently solve the scheduling problem. Additionally, we provide a collection\nof real-life benchmark instances that can be used to evaluate solution methods\nfor the problem. We exhibit that the proposed approach is able to efficiently\nfind solutions of high quality for large-scale real-life benchmark instances,\nwith comparison to state-of-the-art baselines.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.09918,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000024835,
      "text":"Generalizing Multimodal Variational Methods to Sets\n\n  Making sense of multiple modalities can yield a more comprehensive\ndescription of real-world phenomena. However, learning the co-representation of\ndiverse modalities is still a long-standing endeavor in emerging machine\nlearning applications and research. Previous generative approaches for\nmultimodal input approximate a joint-modality posterior by uni-modality\nposteriors as product-of-experts (PoE) or mixture-of-experts (MoE). We argue\nthat these approximations lead to a defective bound for the optimization\nprocess and loss of semantic connection among modalities. This paper presents a\nnovel variational method on sets called the Set Multimodal VAE (SMVAE) for\nlearning a multimodal latent space while handling the missing modality problem.\nBy modeling the joint-modality posterior distribution directly, the proposed\nSMVAE learns to exchange information between multiple modalities and compensate\nfor the drawbacks caused by factorization. In public datasets of various\ndomains, the experimental results demonstrate that the proposed method is\napplicable to order-agnostic cross-modal generation while achieving outstanding\nperformance compared to the state-of-the-art multimodal methods. The source\ncode for our method is available online\nhttps:\/\/anonymous.4open.science\/r\/SMVAE-9B3C\/.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.02098,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.000006689,
      "text":"A Machine with Short-Term, Episodic, and Semantic Memory Systems\n\n  Inspired by the cognitive science theory of the explicit human memory\nsystems, we have modeled an agent with short-term, episodic, and semantic\nmemory systems, each of which is modeled with a knowledge graph. To evaluate\nthis system and analyze the behavior of this agent, we designed and released\nour own reinforcement learning agent environment, \"the Room\", where an agent\nhas to learn how to encode, store, and retrieve memories to maximize its return\nby answering questions. We show that our deep Q-learning based agent\nsuccessfully learns whether a short-term memory should be forgotten, or rather\nbe stored in the episodic or semantic memory systems. Our experiments indicate\nthat an agent with human-like memory systems can outperform an agent without\nthis memory structure in the environment.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  },
  {
    "arxiv_id":2212.11868,
    "paper_type":"regular",
    "period":"pre_llm",
    "year":2022,
    "month":12,
    "pangram_prediction":{
      "ai_likelihood":0.0000072519,
      "text":"Variational Reasoning over Incomplete Knowledge Graphs for\n  Conversational Recommendation\n\n  Conversational recommender systems (CRSs) often utilize external knowledge\ngraphs (KGs) to introduce rich semantic information and recommend relevant\nitems through natural language dialogues. However, original KGs employed in\nexisting CRSs are often incomplete and sparse, which limits the reasoning\ncapability in recommendation. Moreover, only few of existing studies exploit\nthe dialogue context to dynamically refine knowledge from KGs for better\nrecommendation. To address the above issues, we propose the Variational\nReasoning over Incomplete KGs Conversational Recommender (VRICR). Our key idea\nis to incorporate the large dialogue corpus naturally accompanied with CRSs to\nenhance the incomplete KGs; and perform dynamic knowledge reasoning conditioned\non the dialogue context. Specifically, we denote the dialogue-specific\nsubgraphs of KGs as latent variables with categorical priors for adaptive\nknowledge graphs refactor. We propose a variational Bayesian method to\napproximate posterior distributions over dialogue-specific subgraphs, which not\nonly leverages the dialogue corpus for restructuring missing entity relations\nbut also dynamically selects knowledge based on the dialogue context. Finally,\nwe infuse the dialogue-specific subgraphs to decode the recommendation and\nresponses. We conduct experiments on two benchmark CRSs datasets. Experimental\nresults confirm the effectiveness of our proposed method.\n",
      "prediction":"Unlikely AI",
      "llm_prediction":{
        "GPT35":0.0,
        "GPT4":0.0,
        "CLAUDE":0.0,
        "GOOGLE":0.0,
        "OPENAI_O_SERIES":0.0,
        "DEEPSEEK":0.0,
        "GROK":0.0,
        "NOVA":0.0,
        "OTHER":0.0,
        "HUMAN":0.0
      }
    }
  }
]