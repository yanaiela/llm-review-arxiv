arxiv_id,paper_type,period,year,month,pangram_prediction
2001.06681,regular,pre_llm,2020,1,"{'ai_likelihood': 1.8212530348036025e-06, 'text': 'Automating the Generation of Cyber Range Virtual Scenarios with VSDL\n\n  A cyber range is an environment used for training security experts and\ntesting attack and defence tools and procedures. Usually, a cyber range\nsimulates one or more critical infrastructures that attacking (red) and\ndefending (blue) teams must compromise and protect, respectively. The\ninfrastructure can be physically assembled, but much more convenient is to rely\non the Infrastructure as a Service (IaaS) paradigm. Although some modern\ntechnologies support the IaaS, the design and deployment of scenarios of\ninterest is mostly a manual operation. As a consequence, it is a common\npractice to have a cyber range hosting few (sometimes only one), consolidated\nscenarios. However, reusing the same scenario may significantly reduce the\neffectiveness of the training and testing sessions. In this paper, we propose a\nframework for automating the definition and deployment of arbitrarily complex\ncyber range scenarios. The framework relies on the virtual scenario description\nlanguage (VSDL), i.e., a domain-specific language for defining high-level\nfeatures of the desired infrastructure while hiding low-level details. The\nsemantics of VSDL is given in terms of constraints that must be satisfied by\nthe virtual infrastructure. These constraints are then submitted to an SMT\nsolver for checking the satisfiability of the specification. If satisfiable,\nthe specification gives rise to a model that is automatically converted to a\nset of deployment scripts to be submitted to the IaaS provider.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.11259,regular,pre_llm,2020,1,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'RTM: Blockchain That Support Revocable Transaction Model\n\n  In many typical application scenarios, it is necessary to revoke the\nincorrect account operations caused by user mis-operation, financial fraud,\nillegal hacking, etc. Unfortunately, users often blur the lines between the\nconcept of ""transaction state revocable"" and ""business status revocable"", which\nresult in revocable transaction not universally supported in blockchain systems\nat present. In this work, we propose GateChain , a blockchain that support\nrevocable transaction model (RTM) on distributed ledger. Specifically, based on\nthe state-of-the-art blockchain technologies, GateChain can safely withdraw the\naccount status change operations by leveraging an improved account model and\nextra designed transaction types. On that basis, GateChain exploit the\ncharacteristics of functional completeness, easy to deployment and lower\ncomplexity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.05734,review,pre_llm,2020,1,"{'ai_likelihood': 5.298190646701389e-07, 'text': 'A Systems Thinking for Cybersecurity Modeling\n\n  Solving cybersecurity issues requires a holistic understanding of components,\nfactors, structures and their interactions in cyberspace, but conventional\nmodeling approaches view the field of cybersecurity by their boundaries so that\nwe are still not clear to cybersecurity and its changes. In this paper, we\nattempt to discuss the application of systems thinking approaches to\ncybersecurity modeling. This paper reviews the systems thinking approaches and\nprovides the systems theories and methods for tackling cybersecurity\nchallenges, regarding relevant fields, associated impact factors and their\ninteractions. Moreover, an illustrative example of systems thinking frameworks\nfor cybersecurity modeling is developed to help broaden the mind in\nmethodology, theory, technology and practice. This article concludes that\nsystems thinking can be considered as one of the powerful tools of\ncybersecurity modeling to find, characterize, understand, evaluate and predict\ncybersecurity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.0917,regular,pre_llm,2020,1,"{'ai_likelihood': 3.973642985026042e-07, 'text': 'Software-Defined Location Privacy Protection for Vehicular Networks\n\n  While the adoption of connected vehicles is growing, security and privacy\nconcerns are still the key barriers raised by society. These concerns mandate\nautomakers and standardization groups to propose convenient solutions for\nprivacy preservation. One of the main proposed solutions is the use of\nPseudonym-Changing Strategies (PCSs). However, ETSI has recently published a\ntechnical report which highlights the absence of standardized and efficient\nPCSs [1]. This alarming situation mandates an innovative shift in the way that\nthe privacy of end-users is protected during their journey. Software-Defined\nNetworking (SDN) is emerging as a key 5G enabler to manage the network in a\ndynamic manner. SDN-enabled wireless networks are opening up new programmable\nand highly-flexible privacy-aware solutions. We exploit this paradigm to\npropose an innovative software-defined location privacy architecture for\nvehicular networks. The proposed architecture is context-aware, programmable,\nextensible, and able to encompass all existing and future pseudonym-changing\nstrategies. To demonstrate the merit of our architecture, we consider a case\nstudy that involves four pseudonym-changing strategies, which we deploy over\nour architecture and compare with their static implementations. We also detail\nhow the SDN controller dynamically switches between the strategies according to\nthe context.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.03782,regular,pre_llm,2020,1,"{'ai_likelihood': 4.3047799004448785e-07, 'text': ""Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users\n\n  Cyber hygiene measures are often recommended for strengthening an\norganization's security posture, especially for protecting against social\nengineering attacks that target the human element. However, the related\nrecommendations are typically the same for all organizations and their\nemployees, regardless of the nature and the level of risk for different groups\nof users. Building upon an existing cybersecurity investment model, this paper\npresents a tool for optimal selection of cyber hygiene safeguards, which we\nrefer as the Optimal Safeguards Tool. The model combines game theory and\ncombinatorial optimization taking into account the probability of each user\ngroup to being attacked, the value of assets accessible by each group, and the\nefficacy of each control for a particular group. The model considers indirect\ncost as the time employees could require for learning and training against an\nimplemented control. Utilizing a game-theoretic framework to support the\nKnapsack optimization problem permits us to optimally select safeguards'\napplication levels minimizing the aggregated expected damage within a security\ninvestment budget. We evaluate OST in a healthcare domain use case. The\nCritical Internet Security Control group 17 for implementing security awareness\nand training programs for employees belonging to the ICT, clinical and\nadministration personnel of a hospital. We compare the strategies implemented\nby OST against alternative common-sense defending approaches for three\ndifferent types of attackers: Nash, Weighted and Opportunistic. Nash defending\nstrategies are consistently better than the competing strategies for all\nattacker types with a minor exception where the Nash defending strategy\nperforms at least as good as other common-sense approaches.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.08014,review,pre_llm,2020,1,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'Security and Privacy in Vehicular Social Networks\n\n  We surveyed and presented the state-of-the-art VC systems, security and\nprivacy architectures and technologies, emphasizing on security and privacy\nchallenges and their solutions for P2P interactions in VSNs towards\nstandardization and deployment. We note that beyond safety applications that\nhave drawn a lot of attention in VC systems, there is significant and rising\ninterest in vehicle-to-vehicle interaction for a range of transportation\nefficiency and infotainment applications, notably LBS as well as a gamut of\nservices by mobile providers. While this enriches the VC systems and the user\nexperience, security and privacy concerns are also intensified. This is\nespecially so, considering (i) the privacy risk from the exposure of the users\nto the service providers, and (ii) the security risk from the interaction with\nmalicious or selfish and thus misbehaving users or infrastructure. We showed\nexisting solutions can in fact evolve and address the VSN-specific challenges,\nand improve or even accelerate the adoption of VSN applications.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.07534,review,pre_llm,2020,1,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'VeSPA: Vehicular Security and Privacy-preserving Architecture\n\n  Standardization and harmonization efforts have reached a consensus towards\nusing a special-purpose Vehicular Public-Key Infrastructure (VPKI) in upcoming\nVehicular Communication (VC) systems. However, there are still several\ntechnical challenges with no conclusive answers; one such an important yet open\nchallenge is the acquisition of short-term credentials, pseudonym: how should\neach vehicle interact with the VPKI, e.g., how frequently and for how long?\nShould each vehicle itself determine the pseudonym lifetime? Answering these\nquestions is far from trivial. Each choice can affect both the user privacy and\nthe system performance and possibly, as a result, its security. In this paper,\nwe make a novel systematic effort to address this multifaceted question. We\ncraft three generally applicable policies and experimentally evaluate the VPKI\nsystem performance, leveraging two large-scale mobility datasets. We consider\nthe most promising, in terms of efficiency, pseudonym acquisition policies; we\nfind that within this class of policies, the most promising policy in terms of\nprivacy protection can be supported with moderate overhead. Moreover, in all\ncases, this work is the first to provide tangible evidence that the\nstate-of-the-art VPKI can serve sizable areas or domain with modest computing\nresources.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.02975,review,pre_llm,2020,1,"{'ai_likelihood': 5.960464477539062e-07, 'text': ""Is Cryptojacking Dead after Coinhive Shutdown?\n\n  Cryptojacking is the exploitation of victims' computer resources to mine for\ncryptocurrency using malicious scripts. It has become popular after 2017 when\nattackers started to exploit legal mining scripts, especially Coinhive scripts.\nCoinhive was actually a legal mining service that provided scripts and servers\nfor in-browser mining activities. Nevertheless, over 10 million web users had\nbeen victims every month before the Coinhive shutdown that happened in Mar\n2019. This paper explores the new era of the cryptojacking world after Coinhive\ndiscontinued its service. We aimed to see whether and how attackers continue\ncryptojacking, generate new malicious scripts, and developed new methods. We\nused a capable cryptojacking detector named CMTracker that proposed by Hong et\nal. in 2018. We automatically and manually examined 2770 websites that had been\ndetected by CMTracker before the Coinhive shutdown. The results revealed that\n99\\% of sites no longer continue cryptojacking. 1\\% of websites still run 8\nunique mining scripts. By tracking these mining scripts, we detected 632 unique\ncryptojacking websites. Moreover, open-source investigations (OSINT)\ndemonstrated that attackers still use the same methods. Therefore, we listed\nthe typical patterns of cryptojacking. We concluded that cryptojacking is not\ndead after the Coinhive shutdown. It is still alive, but not as attractive as\nit used to be.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.04827,regular,pre_llm,2020,1,"{'ai_likelihood': 2.9802322387695312e-06, 'text': 'Correlations of Multi-input Monero Transactions\n\n  A variety of correlations are detected in the Monero blockchain. The joint\ndistribution of the time-since-last-transaction between elements of pairs of\nRingCTs is enhanced in comparison with the product of the marginal\ndistributions. Similarly there is an enhancement in the joint distribution of\nthe hour timestamps between the same pairs. Lastly, we find another enhancement\nwhen the correlation is measured between the hour timestamps of the transaction\nitself and the elements of the RingCTs. We calculate some adjustments to the\nprobabilities of which input in a RingCT is real, providing an additional\nheuristic to denoising the Monero blockchain.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.11229,regular,pre_llm,2020,1,"{'ai_likelihood': 6.688965691460504e-06, 'text': 'Parity (XOR) Reasoning for the Index Calculus Attack\n\n  Cryptographic problems can often be reduced to solving Boolean polynomial\nsystems, whose equivalent logical formulas can be treated using SAT solvers.\nGiven the algebraic nature of the problem, the use of the logical XOR operator\nis common in SAT-based cryptanalysis. Recent works have focused on advanced\ntechniques for handling parity (XOR) constraints, such as the Gaussian\nElimination technique. First, we propose an original XOR-reasoning SAT solver,\nnamed WDSat (Weil Descent SAT solving), dedicated to a specific cryptographic\nproblem. Secondly, we show that in some cases Gaussian Elimination on SAT\ninstances does not work as well as Gaussian Elimination on algebraic systems.\nWe demonstrate how this oversight is fixed in our solver, which is adapted to\nread instances in algebraic normal form (ANF). Finally, we propose a novel\npreprocessing technique based on the Minimal Vertex Cover Problem in graph\ntheory. This preprocessing technique is, within the framework of multivariate\nBoolean polynomial systems, used as a DLL branching selection rule that leads\nto quick linearization of the underlying algebraic system. Our benchmarks use a\nmodel obtained from cryptographic instances for which a significant speedup is\nachieved using the findings in this paper. We further explain how our\npreprocessing technique can be used as an assessment of the security of a\ncryptographic system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.06616,review,pre_llm,2020,1,"{'ai_likelihood': 3.642506069607205e-07, 'text': 'Research Directions in Cyber Threat Intelligence\n\n  Cyber threat intelligence is a relatively new field that has grown from two\ndistinct fields, cyber security and intelligence. As such, it draws knowledge\nfrom and mixes the two fields. Yet, looking into current scientific research on\ncyber threat intelligence research, it is relatively scarce, which opens up a\nlot of opportunities. In this paper we define what cyber threat intelligence\nis, briefly review some aspects for cyber threat intelligence. Then, we analyze\nexisting research fields that are much older that cyber threat intelligence but\nrelated to it. This opens up an opportunity to draw knowledge and methods from\nthose older field, and in that way advance cyber threat intelligence much\nfaster than it would by following its own path. With such an approach we\neffectively give a research directions for CTI.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.08231,review,pre_llm,2020,1,"{'ai_likelihood': 6.622738308376736e-08, 'text': ""Nonlinear Blockchain Scalability: a Game-Theoretic Perspective\n\n  Recent advances in the blockchain research have been made in two important\ndirections. One is refined resilience analysis utilizing game theory to study\nthe consequences of selfish behaviors of users (miners), and the other is the\nextension from a linear (chain) structure to a non-linear (graphical) structure\nfor performance improvements, such as IOTA and Graphcoin. The first question\nthat comes to people's minds is what improvements that a blockchain system\nwould see by leveraging these new advances. In this paper, we consider three\nmajor metrics for a blockchain system: full verification, scalability, and\nfinality-duration. We { establish a formal framework and} prove that no\nblockchain system can achieve full verification, high scalability, and low\nfinality-duration simultaneously. We observe that classical blockchain systems\nlike Bitcoin achieves full verification and low finality-duration, Harmony and\nEthereum 2.0 achieve low finality-duration and high scalability. As a\ncomplementary, we design a non-linear blockchain system that achieves full\nverification and scalability. We also establish, for the first time, the\ntrade-off between scalability and finality-duration.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.07157,regular,pre_llm,2020,1,"{'ai_likelihood': 1.5232298109266494e-06, 'text': 'On the Feasibility of Acoustic Attacks Using Commodity Smart Devices\n\n  Sound at frequencies above (ultrasonic) or below (infrasonic) the range of\nhuman hearing can, in some settings, cause adverse physiological and\npsychological effects to individuals. In this paper, we investigate the\nfeasibility of cyber-attacks that could make smart consumer devices produce\npossibly imperceptible sound at both high (17-21kHz) and low (60-100Hz)\nfrequencies, at the maximum available volume setting, potentially turning them\ninto acoustic cyber-weapons. To do so, we deploy attacks targeting different\nsmart devices and take sound measurements in an anechoic chamber. For\ncomparison, we also test possible attacks on traditional devices.\n  Overall, we find that many of the devices tested are capable of reproducing\nfrequencies within both high and low ranges, at levels exceeding those\nrecommended in published guidelines. Generally speaking, such attacks are often\ntrivial to develop and in many cases could be added to existing malware\npayloads, as they may be attractive to adversaries with specific motivations or\ntargets. Finally, we suggest a number of countermeasures, both\nplatform-specific and generic ones.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.10405,regular,pre_llm,2020,1,"{'ai_likelihood': 3.675619761149089e-06, 'text': 'Language-Based Web Session Integrity\n\n  Session management is a fundamental component of web applications: despite\nthe apparent simplicity, correctly implementing web sessions is extremely\ntricky, as witnessed by the large number of existing attacks. This motivated\nthe design of formal methods to rigorously reason about web session security\nwhich, however, are not supported at present by suitable automated verification\ntechniques. In this paper we introduce the first security type system that\nenforces session security on a core model of web applications, focusing in\nparticular on server-side code. We showcase the expressiveness of our type\nsystem by analyzing the session management logic of HotCRP, Moodle, and\nphpMyAdmin, unveiling novel security flaws that have been acknowledged by\nsoftware developers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.0884,regular,pre_llm,2020,1,"{'ai_likelihood': 1.5762117173936633e-05, 'text': 'SeCloak: ARM Trustzone-based Mobile Peripheral Control\n\n  Reliable on-off control of peripherals on smart devices is a key to security\nand privacy in many scenarios. Journalists want to reliably turn off radios to\nprotect their sources during investigative reporting. Users wish to ensure\ncameras and microphones are reliably off during private meetings. In this\npaper, we present SeCloak, an ARM TrustZone-based solution that ensures\nreliable on-off control of peripherals even when the platform software is\ncompromised. We design a secure kernel that co-exists with software running on\nmobile devices (e.g., Android and Linux) without requiring any code\nmodifications. An Android prototype demonstrates that mobile peripherals like\nradios, cameras, and microphones can be controlled reliably with a very small\ntrusted computing base and with minimal performance overhead.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.00694,regular,pre_llm,2020,1,"{'ai_likelihood': 7.483694288465712e-06, 'text': 'Differentially Private Combinatorial Cloud Auction\n\n  Cloud service providers typically provide different types of virtual machines\n(VMs) to cloud users with various requirements. Thanks to its effectiveness and\nfairness, auction has been widely applied in this heterogeneous resource\nallocation. Recently, several strategy-proof combinatorial cloud auction\nmechanisms have been proposed. However, they fail to protect the bid privacy of\nusers from being inferred from the auction results. In this paper, we design a\ndifferentially private combinatorial cloud auction mechanism (DPCA) to address\nthis privacy issue. Technically, we employ the exponential mechanism to compute\na clearing unit price vector with a probability proportional to the\ncorresponding revenue. We further improve the mechanism to reduce the running\ntime while maintaining high revenues, by computing a single clearing unit\nprice, or a subgroup of clearing unit prices at a time, resulting in the\nimproved mechanisms DPCA-S and its generalized version DPCA-M, respectively. We\ntheoretically prove that our mechanisms can guarantee differential privacy,\napproximate truthfulness and high revenue. Extensive experimental results\ndemonstrate that DPCA can generate near-optimal revenues at the price of\nrelatively high time complexity, while the improved mechanisms achieve a\ntunable trade-off between auction revenue and running time.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.06077,regular,pre_llm,2020,1,"{'ai_likelihood': 3.1458006964789497e-06, 'text': 'Securing Wireless Sensor Networks Against Denial-of-Sleep Attacks Using\n  RSA Cryptography Algorithm and Interlock Protocol\n\n  Wireless sensor networks (WSNs) have been vastly employed in the collection\nand transmission of data via wireless networks. This type of network is\nnowadays used in many applications for surveillance activities in various\nenvironments due to its low cost and easy communications. In these networks,\nthe sensors use a limited power source which after its depletion, since it is\nnon-renewable, network lifetime ends. Due to the weaknesses in sensor nodes,\nthey are vulnerable to many threats. One notable attack threating WSN is Denial\nof Sleep (DoS). DoS attacks denotes the loss of energy in these sensors by\nkeeping the nodes from going into sleep and energy-saving mode. In this paper,\nthe Abnormal Sensor Detection Accuracy (ASDA-RSA) method is utilised to\ncounteract DoS attacks to reducing the amount of energy consumed. The ASDA-RSA\nschema in this paper consists of two phases to enhancement security in the\nWSNs. In the first phase, a clustering approach based on energy and distance is\nused to select the proper cluster head and in the second phase, the RSA\ncryptography algorithm and interlock protocol are used here along with an\nauthentication method, to prevent DoS attacks. Moreover, ASDA-RSA method is\nevaluated here via extensive simulations carried out in NS-2. The simulation\nresults indicate that the WSN network performance metrics are improved in terms\nof average throughput, Packet Delivery Ratio (PDR), network lifetime, detection\nratio, and average residual energy.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.01841,regular,pre_llm,2020,1,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Towards a secure behavior modeling for IoT networks using Blockchain\n\n  Internet of Things (IoT) occupies a vital aspect of our everyday lives. IoT\nnetworks composed of smart-devices which communicate and transfer the\ninformation without the physical intervention of humans. Due to such\nproliferation and autonomous nature of IoT systems make these devices\nthreatened and prone to a severe kind of threats. In this paper, we introduces\na behavior capturing, and verification procedures in blockchain supported\nsmart-IoT systems that can be able to show the trust-level confidence to\noutside networks. We defined a custom \\emph{Behavior Monitor} and implement on\na selected node that can extract the activity of each device and analyzes the\nbehavior using deep machine learning strategy. Besides, we deploy Trusted\nExecution Technology (TEE) which can be used to provide a secure execution\nenvironment (enclave) for sensitive application code and data on the\nblockchain. Finally, in the evaluation phase we analyze various IoT devices\ndata that is infected by Mirai attack. The evaluation results show the strength\nof our proposed method in terms of accuracy and time required for detection.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.10248,regular,pre_llm,2020,1,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Beyond the Front Page: Measuring Third Party Dynamics in the Field\n\n  In the modern Web, service providers often rely heavily on third parties to\nrun their services. For example, they make use of ad networks to finance their\nservices, externally hosted libraries to develop features quickly, and\nanalytics providers to gain insights into visitor behavior.\n  For security and privacy, website owners need to be aware of the content they\nprovide their users. However, in reality, they often do not know which third\nparties are embedded, for example, when these third parties request additional\ncontent as it is common in real-time ad auctions.\n  In this paper, we present a large-scale measurement study to analyze the\nmagnitude of these new challenges. To better reflect the connectedness of third\nparties, we measured their relations in a model we call third party trees,\nwhich reflects an approximation of the loading dependencies of all third\nparties embedded into a given website. Using this concept, we show that\nincluding a single third party can lead to subsequent requests from up to eight\nadditional services. Furthermore, our findings indicate that the third parties\nembedded on a page load are not always deterministic, as 50% of the branches in\nthe third party trees change between repeated visits. In addition, we found\nthat 93% of the analyzed websites embedded third parties that are located in\nregions that might not be in line with the current legal framework. Our study\nalso replicates previous work that mostly focused on landing pages of websites.\nWe show that this method is only able to measure a lower bound as subsites show\na significant increase of privacy-invasive techniques. For example, our results\nshow an increase of used cookies by about 36% when crawling websites more\ndeeply.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2001.06724,regular,pre_llm,2020,1,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'DynUnlock: Unlocking Scan Chains Obfuscated using Dynamic Keys\n\n  Outsourcing in semiconductor industry opened up venues for faster and\ncost-effective chip manufacturing. However, this also introduced untrusted\nentities with malicious intent, to steal intellectual property (IP),\noverproduce the circuits, insert hardware Trojans, or counterfeit the chips.\nRecently, a defense is proposed to obfuscate the scan access based on a dynamic\nkey that is initially generated from a secret key but changes in every clock\ncycle. This defense can be considered as the most rigorous defense among all\nthe scan locking techniques. In this paper, we propose an attack that remodels\nthis defense into one that can be broken by the SAT attack, while we also note\nthat our attack can be adjusted to break other less rigorous (key that is\nupdated less frequently) scan locking techniques as well.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.07748,regular,pre_llm,2020,2,"{'ai_likelihood': 1.0927518208821616e-06, 'text': 'Profile-Guided, Multi-Version Binary Rewriting\n\n  The static instrumentation of machine code, also known as binary rewriting,\nis a power technique, but suffers from high runtime overhead compared to\ncompiler-level instrumentation. Recent research has shown that tools can\nachieve near-to-zero overhead when rewriting binaries (excluding the overhead\nfrom the application specific instrumentation). However, the users of binary\nrewriting tools often have difficulties in understanding why their\ninstrumentation is slow and how to optimize their instrumentation.\n  We are inspired by a traditional program optimization workflow, where one can\nprofile the program execution to identify performance hot spots, modify the\nsource code or apply suitable compiler optimizations, and even apply\nprofile-guided optimization. We present profile-guided, Multi-Version Binary\nRewriting to enable this optimization workflow for static binary\ninstrumentation. Our new techniques include three components. First, we augment\nexisting binary rewriting to support call path profiling; one can interactively\nview instrumentation costs and understand the calling contexts where the costs\nincur. Second, we present Versioned Structure Binary Editing, which is a\ngeneral binary transformation technique. Third, we use call path profiles to\nguide the application of binary transformation.\n  We apply our new techniques to shadow stack and basic block code coverage.\nOur instrumentation optimization workflow helps us identify several\nopportunities with regard to code transformation and instrumentation data\nlayout. Our evaluation on SPEC CPU 2017 shows that the geometric overhead of\nshadow stack and block coverage is reduced from 7.6% and 161.3% to 1.4% and\n4.0%, respectively. We also achieve promising results on Apache HTTP Server,\nwhere the shadow stack overhead is reduced from about 20% to 3.5%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.12506,review,pre_llm,2020,2,"{'ai_likelihood': 2.814663781060113e-06, 'text': 'Forensic analysis of the Windows telemetry for diagnostics\n\n  Telemetry is the automated sensing and collection of data from a remote\ndevice. It is often used to provide better services for users. Microsoft uses\ntelemetry to periodically collect information about Windows systems and to help\nimprove user experience and fix potential issues. Windows telemetry service\nfunctions by creating RBS files on the local system to reliably transfer and\nmanage the telemetry data, and these files can provide useful information in a\ndigital forensic investigation. Combined with the information derived from\ntraditional Windows forensics, investigators can have greater confidence in the\nevidence derived from various artifacts. It is possible to acquire information\nthat can be confirmed only for live systems, such as the computer hardware\nserial number, the connection records for external storage devices, and traces\nof executed processes. This information is included in the RBS files that are\ncreated for use in Windows telemetry. In this paper, we introduced how to\nacquire RBS files telemetry and analyzed the data structure of these RBS files,\nwhich are able to determine the types of information that Windows OS have been\ncollected. We also discussed the reliability and the novelty by comparing the\nconventional artifacts with the RBS files, which could be useful in digital\nforensic investigation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.10667,regular,pre_llm,2020,2,"{'ai_likelihood': 6.324715084499783e-06, 'text': 'CybORG: An Autonomous Cyber Operations Research Gym\n\n  Autonomous Cyber Operations (ACO) involves the consideration of blue team\n(defender) and red team (attacker) decision-making models in adversarial\nscenarios. To support the application of machine learning algorithms to solve\nthis problem, and to encourage such practitioners to attend to problems in the\nACO setting, a suitable gym (toolkit for experiments) is necessary. We\nintroduce CybORG, a work-in-progress gym for ACO research. Driven by the need\nto efficiently support reinforcement learning to train adversarial\ndecision-making models through simulation and emulation, our design differs\nfrom prior related work. Our early evaluation provides some evidence that\nCybORG is appropriate for our purpose and may provide a basis for advancing ACO\nresearch towards practical applications.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.10635,review,pre_llm,2020,2,"{'ai_likelihood': 3.311369154188368e-08, 'text': ""Formalizing Data Deletion in the Context of the Right to be Forgotten\n\n  The right of an individual to request the deletion of their personal data by\nan entity that might be storing it -- referred to as the right to be forgotten\n-- has been explicitly recognized, legislated, and exercised in several\njurisdictions across the world, including the European Union, Argentina, and\nCalifornia. However, much of the discussion surrounding this right offers only\nan intuitive notion of what it means for it to be fulfilled -- of what it means\nfor such personal data to be deleted.\n  In this work, we provide a formal definitional framework for the right to be\nforgotten using tools and paradigms from cryptography. In particular, we\nprovide a precise definition of what could be (or should be) expected from an\nentity that collects individuals' data when a request is made of it to delete\nsome of this data. Our framework captures several, though not all, relevant\naspects of typical systems involved in data processing. While it cannot be\nviewed as expressing the statements of current laws (especially since these are\nrather vague in this respect), our work offers technically precise definitions\nthat represent possibilities for what the law could reasonably expect, and\nalternatives for what future versions of the law could explicitly require.\n  Finally, with the goal of demonstrating the applicability of our framework\nand definitions, we consider various natural and simple scenarios where the\nright to be forgotten comes up. For each of these scenarios, we highlight the\npitfalls that arise even in genuine attempts at implementing systems offering\ndeletion guarantees, and also describe technological solutions that provably\nsatisfy our definitions. These solutions bring together techniques built by\nvarious communities.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.06713,regular,pre_llm,2020,2,"{'ai_likelihood': 3.973642985026042e-07, 'text': 'AMOUN: Asymmetric lightweight cryptographic scheme for wireless group\n  communication\n\n  Multi-recipient cryptographic schemes provide secure communication, between\none sender and multiple recipients, in a multi-party group. Providing secure\nmulti-party communication is very challenging, especially in dynamic networks.\nExisting multi-recipient cryptographic schemes pose a variety of limitations.\nThese include high computational overhead for both encryption and decryption,\nadditional communication overhead and high setup cost due to change in\nmembership, and collusion among recipients. In order to overcome these\nlimitations, this paper introduces a novel asymmetric multi-recipient\ncryptographic scheme, AMOUN. In the proposed scheme, to better utilize network\nresources, the sender transmits a ciphertext containing different messages to\nmultiple recipients, where each recipient only allowed to retrieve its own\ndesignated message. Security analysis demonstrates that the proposed scheme is\nindistinguishable under adaptive chosen plaintext attack. Quantitative analysis\nreveals that lightweight AMOUN shows lower average computational cost than both\nRSA and Multi-RSA, for both encryption and decryption, even when the key sizes\nare four times larger. For a given prime size, in case of encryption, AMOUN\nshows 98% and 99% lower average computational cost than RSA and Multi-RSA,\nrespectively. For decryption, AMOUN shows a performance improvement of 99%\ncompared to RSA and Multi-RSA.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.01243,regular,pre_llm,2020,2,"{'ai_likelihood': 5.960464477539062e-07, 'text': ""Local Bitcoin Network Simulator for Performance Evaluation using\n  Lightweight Virtualization\n\n  This paper presents a new blockchain network simulator that uses bitcoin's\noriginal reference implementation as its main application. The proposed\nsimulator leverages the use of lightweight virtualization technology to build a\nfine tuned local testing network. To enable fast simulation of a large scale\nnetwork without disabling mining service, the simulator can adjust the bitcoin\nmining difficulty level to below the default minimum value. In order to assess\nthe performance of blockchain under different network conditions, the simulator\nallows to define different network topologies, and integrates Linux kernel\ntraffic control (tc) tool to apply distinct delay or packet loss on the network\nnodes. Moreover, to validate the efficiency of our simulator we conduct a set\nof experiments and study the impact of the computation power and network delay\non the network's consistency in terms of number of forks and mining revenues.\nThe impact of applying different mining difficulty levels is also studied and\nthe block time as well as fork occurrences are evaluated. Furthermore, a\ncomprehensive survey and taxonomy of existing blockchain simulators are\nprovided along with a discussion justifying the need of new simulator. As part\nof our contribution, we have made the simulator available on Github\n(https://github.com/noureddinel/core-bitcoin-net-simulator) for the community\nto use and improve it.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.04059,regular,pre_llm,2020,2,"{'ai_likelihood': 6.622738308376736e-08, 'text': 'Nested Multiple Instance Learning in Modelling of HTTP network traffic\n\n  In many interesting cases, the application of machine learning is hindered by\ndata having a complicated structure stimulated by a structured file-formats\nlike JSONs, XMLs, or ProtoBuffers, which is non-trivial to convert to a vector\n/ matrix. Moreover, since the structure frequently carries a semantic meaning,\nreflecting it in the machine learning model should improve the accuracy but\nmore importantly it facilitates the explanation of decisions and the model.\nThis paper demonstrates on the identification of infected computers in the\ncomputer network from their HTTP traffic, how to achieve this reflection using\nrecent progress in multiple-instance learning. The proposed model is compared\nto complementary approaches from the prior art, the first relying on\nhuman-designed features and the second on automatically learned features\nthrough convolution neural networks. In a challenging scenario measuring\naccuracy only on unseen domains/malware families, the proposed model is\nsuperior to the prior art while providing a valuable feedback to the security\nresearchers. We believe that the proposed framework will found applications\nelsewhere even beyond the field of security.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.11,regular,pre_llm,2020,2,"{'ai_likelihood': 4.569689432779948e-06, 'text': 'Distributed Ledger for Provenance Tracking of Artificial Intelligence\n  Assets\n\n  High availability of data is responsible for the current trends in Artificial\nIntelligence (AI) and Machine Learning (ML). However, high-grade datasets are\nreluctantly shared between actors because of lacking trust and fear of losing\ncontrol. Provenance tracing systems are a possible measure to build trust by\nimproving transparency. Especially the tracing of AI assets along complete AI\nvalue chains bears various challenges such as trust, privacy, confidentiality,\ntraceability, and fair remuneration. In this paper we design a graph-based\nprovenance model for AI assets and their relations within an AI value chain.\nMoreover, we propose a protocol to exchange AI assets securely to selected\nparties. The provenance model and exchange protocol are then combined and\nimplemented as a smart contract on a permission-less blockchain. We show how\nthe smart contract enables the tracing of AI assets in an existing industry use\ncase while solving all challenges. Consequently, our smart contract helps to\nincrease traceability and transparency, encourages trust between actors and\nthus fosters collaboration between them.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.02855,regular,pre_llm,2020,2,"{'ai_likelihood': 1.0563267601860894e-05, 'text': ""Security Certification in Payment Card Industry: Testbeds, Measurements,\n  and Recommendations\n\n  The massive payment card industry (PCI) involves various entities such as\nmerchants, issuer banks, acquirer banks, and card brands. Ensuring security for\nall entities that process payment card information is a challenging task. The\nPCI Security Standards Council requires all entities to be compliant with the\nPCI Data Security Standard (DSS), which specifies a series of security\nrequirements. However, little is known regarding how well PCI DSS is enforced\nin practice. In this paper, we take a measurement approach to systematically\nevaluate the PCI DSS certification process for e-commerce websites. We develop\nan e-commerce web application testbed, BuggyCart, which can flexibly add or\nremove 35 PCI DSS related vulnerabilities. Then we use the testbed to examine\nthe capability and limitations of PCI scanners and the rigor of the\ncertification process. We find that there is an alarming gap between the\nsecurity standard and its real-world enforcement. None of the 6 PCI scanners we\ntested are fully compliant with the PCI scanning guidelines, issuing\ncertificates to merchants that still have major vulnerabilities. To further\nexamine the compliance status of real-world e-commerce websites, we build a new\nlightweight scanning tool named PciCheckerLite and scan 1,203 e-commerce\nwebsites across various business sectors. The results confirm that 86% of the\nwebsites have at least one PCI DSS violation that should have disqualified them\nas non-compliant. Our in-depth accuracy analysis also shows that\nPciCheckerLite's output is more precise than w3af. We reached out to the PCI\nSecurity Council to share our research results to improve the enforcement in\npractice.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.07769,regular,pre_llm,2020,2,"{'ai_likelihood': 6.291601392957899e-06, 'text': 'High-speed KATAN Ciphers on-a-Chip\n\n  Security in embedded systems has become a main requirement in modern\nelectronic devices. The demand for low-cost and highly secure cryptographic\nalgorithms is increasingly growing in fields such as mobile telecommunications,\nhandheld devices, etc. In this paper, we analyze and evaluate the development\nof cheap and relatively fast hardware implementations of the KATAN family of\nblock ciphers. KATAN is a family of six hardware oriented block ciphers. All\nKATAN ciphers share an 80-bit key and have 32, 48, or 64-bit blocks. We use\nVHDL under Altera Quartus in conjunction with ModelSim to implement and analyze\nour hardware designs. The developed designs are mapped onto high-performance\nField Programmable Gate Arrays. We compare our findings with similar hardware\nimplementations and C software versions of the algorithms. The performance\nanalysis of the C implementations is done using Intel Vtune Amplifier running\non Dell precision T7500 with its dual quad-core Xeon processor and 24 GB of\nRAM. The obtained results show better performance when compared with existing\nhardware and software implementations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.04863,regular,pre_llm,2020,2,"{'ai_likelihood': 3.973642985026042e-06, 'text': 'Measuring privacy in smart metering anonymized data\n\n  In recent years, many proposals have arisen from research on privacy in smart\nmetering. In one of the considered approaches, referred to as anonymization,\nsmart meters transmit fine-grained electricity consumption values in such a way\nthat the energy supplier can not exactly determine procedence. This paper\nmeasures the real privacy provided by such approach by taking into account that\nat the end of a billing period the energy supplier collects the overall\nelectricity consumption of each meter for billing purposes. An entropy-based\nmeasure is proposed for quantifying privacy and determine the extent to which\nknowledge on the overall consumption of meters allows to re-identify anonymous\nfine-grained consumption values.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.07041,regular,pre_llm,2020,2,"{'ai_likelihood': 1.655684577094184e-07, 'text': 'A Lightweight ISA Extension for AES and SM4\n\n  We describe a lightweight RISC-V ISA extension for AES and SM4 block ciphers.\nSixteen instructions (and a subkey load) is required to implement an AES round\nwith the extension, instead of 80 without. An SM4 step (quarter-round) has 6.5\narithmetic instructions, a similar reduction. Perhaps even more importantly the\nISA extension helps to eliminate slow, secret-dependent table lookups and to\nprotect against cache timing side-channel attacks. Having only one S-box, the\nextension has a minimal hardware size and is well suited for ultra-low power\napplications. AES and SM4 implementations using the ISA extension also have a\nmuch-reduced software footprint. The AES and SM4 instances can share the same\ndata paths but are independent in the sense that a chip designer can implement\nSM4 without AES and vice versa. Full AES and SM4 assembler listings, HDL source\ncode for instruction\'s combinatorial logic, and C code for emulation is\nprovided to the community under a permissive open source license. The\nimplementation contains depth- and size-optimized joint AES and SM4 S-Box logic\nbased on the Boyar-Peralta construction with a shared non-linear middle layer,\ndemonstrating additional avenues for logic optimization. The instruction logic\nhas been experimentally integrated into the single-cycle execution path of the\n""Pluto"" RV32 core and has been tested on an FPGA system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.08437,regular,pre_llm,2020,2,"{'ai_likelihood': 4.125965966118707e-05, 'text': 'CopyCat: Controlled Instruction-Level Attacks on Enclaves\n\n  The adversarial model presented by trusted execution environments (TEEs) has\nprompted researchers to investigate unusual attack vectors. One particularly\npowerful class of controlled-channel attacks abuses page-table modifications to\nreliably track enclave memory accesses at a page-level granularity. In contrast\nto noisy microarchitectural timing leakage, this line of deterministic\ncontrolled-channel attacks abuses indispensable architectural interfaces and\nhence cannot be mitigated by tweaking microarchitectural resources.\n  We propose an innovative controlled-channel attack, named CopyCat, that\ndeterministically counts the number of instructions executed within a single\nenclave code page. We show that combining the instruction counts harvested by\nCopyCat with traditional, coarse-grained page-level leakage allows the accurate\nreconstruction of enclave control flow at a maximal instruction-level\ngranularity. CopyCat can identify intra-page and intra-cache line branch\ndecisions that ultimately may only differ in a single instruction, underscoring\nthat even extremely subtle control flow deviations can be deterministically\nleaked from secure enclaves. We demonstrate the improved resolution and\npracticality of CopyCat on Intel SGX in an extensive study of single-trace and\ndeterministic attacks against cryptographic implementations, and give novel\nalgorithmic attacks to perform single-trace key extraction that exploit subtle\nvulnerabilities in the latest versions of widely-used cryptographic libraries.\nOur findings highlight the importance of stricter verification of cryptographic\nimplementations, especially in the context of TEEs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.09629,regular,pre_llm,2020,2,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'An Empirical Study of Android Security Bulletins in Different Vendors\n\n  Mobile devices encroach on almost every part of our lives, including work and\nleisure, and contain a wealth of personal and sensitive information. It is,\ntherefore, imperative that these devices uphold high security standards. A key\naspect is the security of the underlying operating system. In particular,\nAndroid plays a critical role due to being the most dominant platform in the\nmobile ecosystem with more than one billion active devices and due to its\nopenness, which allows vendors to adopt and customize it. Similar to other\nplatforms, Android maintains security by providing monthly security patches and\nannouncing them via the Android security bulletin. To absorb this information\nsuccessfully across the Android ecosystem, impeccable coordination by many\ndifferent vendors is required.\n  In this paper, we perform a comprehensive study of 3,171 Android-related\nvulnerabilities and study to which degree they are reflected in the Android\nsecurity bulletin, as well as in the security bulletins of three leading\nvendors: Samsung, LG, and Huawei. In our analysis, we focus on the metadata of\nthese security bulletins (e.g., timing, affected layers, severity, and CWE\ndata) to better understand the similarities and differences among vendors. We\nfind that (i) the studied vendors in the Android ecosystem have adopted\ndifferent structures for vulnerability reporting, (ii) vendors are less likely\nto react with delay for CVEs with Android Git repository references, (iii)\nvendors handle Qualcomm-related CVEs differently from the rest of external\nlayer CVEs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.01277,regular,pre_llm,2020,2,"{'ai_likelihood': 1.026524437798394e-06, 'text': 'Public-Key Based Authentication Architecture for IoT Devices Using PUF\n\n  Nowadays, Internet of Things (IoT) is a trending topic in the computing\nworld. Notably, IoT devices have strict design requirements and are often\nreferred to as constrained devices. Therefore, security techniques and\nprimitives that are lightweight are more suitable for such devices, e.g.,\nStatic Random-Access Memory (SRAM) Physical Unclonable Functions (PUFs) and\nElliptic Curve Cryptography (ECC). SRAM PUF is an intrinsic security primitive\nthat is seeing widespread adoption in the IoT segment. ECC is a public-key\nalgorithm technique that has been gaining popularity among constrained IoT\ndevices. The popularity is due to using significantly smaller operands when\ncompared to other public-key techniques such as RSA (Rivest Shamir Adleman).\nThis paper shows the design, development, and evaluation of an\napplication-specific secure communication architecture based on SRAM PUF\ntechnology and ECC for constrained IoT devices. More specifically, it\nintroduces an Elliptic Curve Diffie-Hellman (ECDH) public-key based\ncryptographic protocol that utilizes PUF-derived keys as the root-of-trust for\nsilicon authentication. Also, it proposes a design of a modular hardware\narchitecture that supports the protocol. Finally, to analyze the practicality\nas well as the feasibility of the proposed protocol, we demonstrate the\nsolution by prototyping and verifying a protocol variant on the commercial\nXilinx Zynq-7000 APSoC device.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.08912,regular,pre_llm,2020,2,"{'ai_likelihood': 9.602970547146267e-07, 'text': 'Modeling the Impact of Network Connectivity on Consensus Security of\n  Proof-of-Work Blockchain\n\n  Blockchain, the technology behind the popular Bitcoin, is considered a\n""security by design"" system as it is meant to create security among a group of\ndistrustful parties yet without a central trusted authority. The security of\nblockchain relies on the premise of honest-majority, namely, the blockchain\nsystem is assumed to be secure as long as the majority of consensus voting\npower is honest. And in the case of proof-of-work (PoW) blockchain, adversaries\ncannot control more than 50% of the network\'s gross computing power. However,\nthis 50% threshold is based on the analysis of computing power only, with\nimplicit and idealistic assumptions on the network and node behavior. Recent\nresearches have alluded that factors such as network connectivity, presence of\nblockchain forks, and mining strategy could undermine the consensus security\nassured by the honest-majority, but neither concrete analysis nor quantitative\nevaluation is provided. In this paper we fill the gap by proposing an\nanalytical model to assess the impact of network connectivity on the consensus\nsecurity of PoW blockchain under different adversary models. We apply our\nanalytical model to two adversarial scenarios: 1)\nhonest-but-potentially-colluding, 2) selfish mining. For each scenario, we\nquantify the communication capability of nodes involved in a fork race and\nestimate the adversary\'s mining revenue and its impact on security properties\nof the consensus protocol. Simulation results validated our analysis. Our\nmodeling and analysis provide a paradigm for assessing the security impact of\nvarious factors in a distributed consensus system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.00456,regular,pre_llm,2020,2,"{'ai_likelihood': 1.986821492513021e-06, 'text': 'Permissioned Blockchain-Based Security for SDN in IoT Cloud Networks\n\n  The advancement in cloud networks has enabled connectivity of both\ntraditional networked elements and new devices from all walks of life, thereby\nforming the Internet of Things (IoT). In an IoT setting, improving and scaling\nnetwork components as well as reducing cost is essential to sustain exponential\ngrowth. In this domain, software-defined networking (SDN) is revolutionizing\nthe network infrastructure with a new paradigm. SDN splits the control/routing\nlogic from the data transfer/forwarding. This splitting causes many issues in\nSDN, such as vulnerabilities of DDoS attacks. Many solutions (including\nblockchain based) have been proposed to overcome these problems. In this work,\nwe offer a blockchain-based solution that is provided in redundant SDN\n(load-balanced) to service millions of IoT devices. Blockchain is considered as\ntamper-proof and impossible to corrupt due to the replication of the ledger and\nconsensus for verification and addition to the ledger. Therefore, it is a\nperfect fit for SDN in IoT Networks. Blockchain technology provides everyone\nwith a working proof of decentralized trust. The experimental results show gain\nand efficiency with respect to the accuracy, update process, and bandwidth\nutilization.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.0454,regular,pre_llm,2020,2,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Hidden in Plain Sight: Obfuscated Strings Threatening Your Privacy\n\n  String obfuscation is an established technique used by proprietary,\nclosed-source applications to protect intellectual property. Furthermore, it is\nalso frequently used to hide spyware or malware in applications. In both cases,\nthe techniques range from bit-manipulation over XOR operations to AES\nencryption. However, string obfuscation techniques/tools suffer from one shared\nweakness: They generally have to embed the necessary logic to deobfuscate\nstrings into the app code.\n  In this paper, we show that most of the string obfuscation techniques found\nin malicious and benign applications for Android can easily be broken in an\nautomated fashion. We developed StringHound, an open-source tool that uses\nnovel techniques that identify obfuscated strings and reconstruct the originals\nusing slicing.\n  We evaluated StringHound on both benign and malicious Android apps. In\nsummary, we deobfuscate almost 30 times more obfuscated strings than other\nstring deobfuscation tools. Additionally, we analyzed 100,000 Google Play Store\napps and found multiple obfuscated strings that hide vulnerable cryptographic\nusages, insecure internet accesses, API keys, hard-coded passwords, and\nexploitation of privileges without the awareness of the developer. Furthermore,\nour analysis reveals that not only malware uses string obfuscation but also\nbenign apps make extensive use of string obfuscation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.08343,regular,pre_llm,2020,2,"{'ai_likelihood': 5.629327562120226e-07, 'text': 'Algebraic Extension Ring Framework for Non-Commutative Asymmetric\n  Cryptography\n\n  Post-Quantum Cryptography PQC attempts to find cryptographic protocols\nresistant to attacks using Shors polynomial time algorithm for numerical field\nproblems or Grovers algorithm to find the unique input to a black-box function\nthat produces a particular output value. The use of non-standard algebraic\nstructures like non-commutative or non-associative structures, combined with\none-way trapdoor functions derived from combinatorial group theory, are mainly\nunexplored choices for these new kinds of protocols and overlooked in current\nPQC solutions. In this paper, we develop an algebraic extension ring framework\nwho could be applied to different asymmetric protocols, i.e. key exchange, key\ntransport, enciphering, digital signature, zero-knowledge authentication,\noblivious transfer, secret sharing etc.. A valuable feature is that there is no\nneed for big number libraries as all arithmetic is performed in F256 extension\nfield operations (precisely the AES field). We assume that the new framework is\ncryptographical secure against strong classical attacks like the\nsometimes-useful length-based attack, Romankovs linearization attacks and\nTsabans algebraic span attack. This statement is based on the non-linear\nstructure of the selected platform which proved to be useful protecting the AES\nprotocol. Otherwise, it could resist post-quantum attacks Grover, Shor and be\nparticularly useful for computational platforms with limited capabilities like\nUSB cryptographic keys or smartcards. Semantic security IND-CCA2 could also be\ninferred for this new platform.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2002.08463,regular,pre_llm,2020,2,"{'ai_likelihood': 9.934107462565105e-07, 'text': 'Tricking Johnny into Granting Web Permissions\n\n  We studied the web permission API dialog box in popular mobile and desktop\nbrowsers, and found that it typically lacks measures to protect users from\nunwittingly granting web permission when clicking too fast.\n  We developed a game that exploits this issue, and tricks users into granting\nwebcam permission. We conducted three experiments, each with 40 different\nparticipants, on both desktop and mobile browsers. The results indicate that in\nthe absence of a prevention mechanism, we achieve a considerably high success\nrate in tricking 95% and 72% of participants on mobile and desktop browsers,\nrespectively. Interestingly, we also tricked 47% of participants on a desktop\nbrowser where a prevention mechanism exists.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.05067,regular,pre_llm,2020,3,"{'ai_likelihood': 1.3245476616753473e-07, 'text': ""The Framework of Consensus Equilibria for Mining-Pool Games in\n  Blockchain Ecosystems\n\n  The goal of this paper is to establish the general framework of consensus\nequilibria for Mining-Pool Games in Blockchain Ecosystems, and with the\nexplanation for the stability of in terms of the existence of consensus\nequilibria related to mining gap game's behaviors by using one new concept\ncalled consensus games in Blockchain Ecosystems, here, the Blockchain ecosystem\nmainly means the economic activities by taking into the account of three types\nof different factors which are expenses, reward mechanism and mining power for\nthe work on blockschain by applying the key consensus called Proof of Work due\nto Nakamoto in 2008.\n  In order to do so, we first give an outline how the general existence of\nconsensus equilibria for Mining Pool Games is formulated, and then used to\nexplain the stable for Gap Games for Bitcoin in the sense by the existence of\nconsensus equilibria under the framework of Blockchain consensus, we then\nestablish a general existence result for consensus equilibria of general mining\ngap games by using the profit functions for miners as the payoffs in game\ntheory. As applications, the general existence results for consensus equilibria\nof Gap games are established, which not only help us to claim the existence for\nthe general stability for Gap games under the general framework of Blockchain\necosystems, but also allow us to illustrate a number of different phenomenon on\nthe study of mining-pool games with possible impacts due to miners's gap\nbehaviors with scenarios embedded n Bitcoin economics. Our study on the\nexplanation for the stability of mining gap game for Blockchain ecosystems\nshows that the concept of consensus equilibria may play a important role for\nthe development of fundamental theory for consensus economics.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.02164,review,pre_llm,2020,3,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'Towards a Context-Aware Security and Privacy as a Service in the\n  Internet of Things\n\n  Smart city is one of the most known Internet of Things (IoT) applications.\nThe smart city services improve user\'s daily lives. However, security and\nprivacy issues are slowing down their adoption. In addition, the\ncharacteristics of IoT devices, applications and users make security\nimplementation of the considered applications a challenging task. To address\nthese issues, we present, in this paper, a new context-aware security and\nprivacy architecture for the IoT. Thanks to the ""as a service"" approach, this\nnew architecture will be user-centric. It will also support known context-aware\nsecurity issues: dynamicity, flexibility. In addition, it will address\nmobility, customization of security and privacy services, and support for\ngeneric IoT applications, particularly for smart city. To do so, a knowledge\nplane allowing effective management of context-awareness is proposed. A\nsecurity and privacy plane allowing better implementation of context-aware\nsecurity and privacy mechanisms is also proposed. This will be done through\ndynamic composition of context-based micro services. The role of the different\ncomponents of these two planes are also described.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.07421,regular,pre_llm,2020,3,"{'ai_likelihood': 4.3047799004448785e-07, 'text': ""Formal Methods Analysis of the Secure Remote Password Protocol\n\n  We analyze the Secure Remote Password (SRP) protocol for structural\nweaknesses using the Cryptographic Protocol Shapes Analyzer (CPSA) in the first\nformal analysis of SRP (specifically, Version 3).\n  SRP is a widely deployed Password Authenticated Key Exchange (PAKE) protocol\nused in 1Password, iCloud Keychain, and other products. As with many PAKE\nprotocols, two participants use knowledge of a pre-shared password to\nauthenticate each other and establish a session key. SRP aims to resist\ndictionary attacks, not store plaintext-equivalent passwords on the server,\navoid patent infringement, and avoid export controls by not using encryption.\nFormal analysis of SRP is challenging in part because existing tools provide no\nsimple way to reason about its use of the mathematical expression $v + g^b \\mod\nq$.\n  Modeling $v + g^b$ as encryption, we complete an exhaustive study of all\npossible execution sequences of SRP. Ignoring possible algebraic attacks, this\nanalysis detects no major structural weakness, and in particular no leakage of\nany secrets. We do uncover one notable weakness of SRP, which follows from its\ndesign constraints. It is possible for a malicious server to fake an\nauthentication session with a client, without the client's participation. This\naction might facilitate an escalation of privilege attack, if the client has\nhigher privileges than does the server. We conceived of this attack before we\nused CPSA and confirmed it by generating corresponding execution shapes using\nCPSA.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.12598,regular,pre_llm,2020,3,"{'ai_likelihood': 1.9172827402750652e-05, 'text': 'A Security and Performance Driven Architecture for Cloud Data Centers\n\n  With the growing cyber-security threats, ensuring the security of data in\nCloud data centers is a challenging task. A prominent type of attack on Cloud\ndata centers is data tampering attack that can jeopardize the confidentiality\nand the integrity of data. In this article, we present a security and\nperformance driven architecture for these centers that incorporates an\nintrusion management system for multi-tenant distributed transactional\ndatabases. The proposed architecture uses a novel data partitioning and\nplacement scheme based on damage containment and communication cost of\ndistributed transactions. In addition, we present a benchmarking framework for\nevaluating the performance of the proposed architecture. The results illustrate\na trade-off between security and performance goals for Cloud data centers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.12401,regular,pre_llm,2020,3,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'Resilient Cyber-Physical Systems: Using NFV Orchestration\n\n  Cyber-Physical Systems (CPSs) are increasingly important in critical areas of\nour society such as intelligent power grids, next generation mobile devices,\nand smart buildings. CPS operation has characteristics including considerable\nheterogeneity, variable dynamics, and high complexity. These systems have also\nscarce resources in order to satisfy their entire load demand, which can be\ndivided into data processing and service execution. These new characteristics\nof CPSs need to be managed with novel strategies to ensure their resilient\noperation. Towards this goal, we propose an SDN-based solution enhanced by\ndistributed Network Function Virtualization (NFV) modules located at the\ntop-most level of our solution architecture. These NFV agents will take\norchestrated management decisions among themselves to ensure a resilient CPS\nconfiguration against threats, and an optimum operation of the CPS. For this,\nwe study and compare two distinct incentive mechanisms to enforce cooperation\namong NFVs. Thus, we aim to offer novel perspectives into the management of\nresilient CPSs, embedding IoT devices, modeled by Game Theory (GT), using the\nlatest software and virtualization platforms.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.05273,regular,pre_llm,2020,3,"{'ai_likelihood': 6.622738308376736e-07, 'text': ""Opportunistic multi-party shuffling for data reporting privacy\n\n  An important feature of data collection frameworks, in which voluntary\nparticipants are involved, is that of privacy. Besides data encryption, which\nprotects the data from third parties in case the communication channel is\ncompromised, there are schemes to obfuscate the data and thus provide some\nanonymity in the data itself, as well as schemes that 'mix' the data to prevent\ntracing the data back to the source by using network identifiers. This mixing\nis usually implemented by utilizing special mix networks in the data collection\nframework. In this paper we focus on schemes for mixing the data where the\nparticipants do not need to trust the mix network or the data collector with\nhiding the source of the data so that we can evaluate the efficacy of peer to\npeer mixing strategies in the real world. To achieve this, we present a simple\nopportunistic multi-party shuffling scheme to mix the data and effectively\nobfuscate the source of the data. We successfully simulate 3 cases with\nartificial parameters and then use the real-world Mobile Data Challenge (MDC)\ndata to simulate an additional 2 scenarios with realistic parameters. Our\nresults show that such approaches can be effective depending on the time\nconstraints of the data collection and we conclude with design implications for\nthe implementation of the proposed data collection scheme in real life\ndeployments.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.00542,regular,pre_llm,2020,3,"{'ai_likelihood': 6.953875223795574e-07, 'text': 'User profiling using smartphone network traffic analysis\n\n  The recent decade has witnessed phenomenal growth in communication\ntechnology. Development of user-friendly software platforms, such as Facebook,\nWhatsApp etc. have facilitated ease of communication and thereby people have\nstarted freely sharing messages and multimedia over the Internet. Further,\nthere is a shift in trends with services being accessed from smartphones over\npersonal computers. To protect the security and privacy of the smartphone\nusers, most of the applications use encryption that encapsulates communications\nover the Internet. However, research has shown that the statistical information\npresent in a traffic can be used to identify the application, and further, the\nactivity performed by the user inside that application. In this paper, we\nextend the scope of analysis by proposing a learning framework to leverage\napplication and activity data to profile smartphone users in terms of their\ngender, profession age group etc. This will greatly help the authoritative\nagencies to conduct their investigations related to national security and other\npurposes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.14123,regular,pre_llm,2020,3,"{'ai_likelihood': 1.655684577094184e-07, 'text': ""When the Guard failed the Droid: A case study of Android malware\n\n  Android malware is a persistent threat to billions of users around the world.\nAs a countermeasure, Android malware detection systems are occasionally\nimplemented. However, these systems are often vulnerable to \\emph{evasion\nattacks}, in which an adversary manipulates malicious instances so that they\nare misidentified as benign. In this paper, we launch various innovative\nevasion attacks against several Android malware detection systems. The\nvulnerability inherent to all of these systems is that they are part of\nAndroguard~\\cite{desnos2011androguard}, a popular open source library used in\nAndroid malware detection systems. Some of the detection systems decrease to a\n0\\% detection rate after the attack. Therefore, the use of open source\nlibraries in malware detection systems calls for caution.\n  In addition, we present a novel evaluation scheme for evasion attack\ngeneration that exploits the weak spots of known Android malware detection\nsystems. In so doing, we evaluate the functionality and maliciousness of the\nmanipulated instances created by our evasion attacks. We found variations in\nboth the maliciousness and functionality tests of our manipulated apps. We show\nthat non-functional apps, while considered malicious, do not threaten users and\nare thus useless from an attacker's point of view. We conclude that evasion\nattacks must be assessed for both functionality and maliciousness to evaluate\ntheir impact, a step which is far from commonplace today.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.11424,regular,pre_llm,2020,3,"{'ai_likelihood': 2.6490953233506946e-07, 'text': ""BlockMarkchain: A Secure Decentralized Data Market with a Constant Load\n  on the Blockchain\n\n  In this paper, we develop BlockMarkchain, as a secure data market place,\nwhere individual data sellers can exchange certified data with buyers, in a\nsecure environment, without any mutual trust among the parties, and without\ntrusting on a third party, as a mediator. To develop this platform, we rely on\na smart contract, deployed on a secure public blockchain. The main challenges\nhere are to verify the validity of data and to prevent malicious behavior of\nthe parties, while preserving the privacy of the data and taking into account\nthe limited computing and storage resources available on the blockchain. In\nBlockMarkchain, the buyer has the option to dispute the honesty of the seller\nand prove the invalidity of the data to the smart contract. The smart contract\nevaluates the buyer's claim and punishes the dishonest party by forfeiting\nhis/her deposit in favor of the honest party. BlockMarkchain enjoys several\nsalient features including (i) the certified data has never been revealed on\nthe public blockchain, (ii) the size of data posted on the blockchain, the load\nof computation on the blockchain, and the cost of communication with the\nblockchain is constant and negligible, and (iii) the computation cost of\nverifications on the parties is not expensive.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.00916,regular,pre_llm,2020,3,"{'ai_likelihood': 4.006756676567926e-06, 'text': 'Code Renewability for Native Software Protection\n\n  Software protection aims at safeguarding assets embedded in software by\npreventing and delaying reverse engineering and tampering attacks. This paper\npresents an architecture and supporting tool flow to renew parts of native\napplications dynamically. Renewed and diversified code and data belonging to\neither the original application or to linked-in protections are delivered from\na secure server to a client on demand. This results in frequent changes to the\nsoftware components when they are under attack, thus making attacks harder. By\nsupporting various forms of diversification and renewability, novel protection\ncombinations become available, and existing combinations become stronger. The\nprototype implementation is evaluated on a number of industrial use cases.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.11511,review,pre_llm,2020,3,"{'ai_likelihood': 3.311369154188368e-08, 'text': 'Contact Tracing Mobile Apps for COVID-19: Privacy Considerations and\n  Related Trade-offs\n\n  Contact tracing is an essential tool for public health officials and local\ncommunities to fight the spread of novel diseases, such as for the COVID-19\npandemic. The Singaporean government just released a mobile phone app,\nTraceTogether, that is designed to assist health officials in tracking down\nexposures after an infected individual is identified. However, there are\nimportant privacy implications of the existence of such tracking apps. Here, we\nanalyze some of those implications and discuss ways of ameliorating the privacy\nconcerns without decreasing usefulness to public health. We hope in writing\nthis document to ensure that privacy is a central feature of conversations\nsurrounding mobile contact tracing apps and to encourage community efforts to\ndevelop alternative effective solutions with stronger privacy protection for\nthe users. Importantly, though we discuss potential modifications, this\ndocument is not meant as a formal research paper, but instead is a response to\nsome of the privacy characteristics of direct contact tracing apps like\nTraceTogether and an early-stage Request for Comments to the community.\n  Date written: 2020-03-24\n  Minor correction: 2020-03-30\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.01991,review,pre_llm,2020,3,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Vessels Cybersecurity: Issues, Challenges, and the Road Ahead\n\n  Vessels cybersecurity is recently gaining momentum, as a result of a few\nrecent attacks to vessels at sea. These recent attacks have shacked the\nmaritime domain, which was thought to be relatively immune to cyber threats.\nThe cited belief is now over, as proved by recent mandates issued by the\nInternational Maritime Organization (IMO). According to these regulations, all\nvessels should be the subject of a cybersecurity risk analysis, and technical\ncontrols should be adopted to mitigate the resulting risks. This initiative is\nlaudable since, despite the recent incidents, the vulnerabilities and threats\naffecting modern vessels are still unclear to operating entities, leaving the\npotential for dreadful consequences of further attacks just a matter of ""when"",\nnot ""if"". In this contribution, we investigate and systematize the major\nsecurity weaknesses affecting systems and communication technologies adopted in\nmodern vessels. Specifically, we describe the architecture and main features of\nthe different systems, pointing out their main security issues, and specifying\nhow they were exploited by attackers to cause service disruption and relevant\nfinancial losses. We also identify a few countermeasures to the introduced\nattacks. Finally, we highlight a few research challenges to be addressed by\nindustry and academia to strengthen vessels security.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.10513,review,pre_llm,2020,3,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Fault Attacks on Secure Embedded Software: Threats, Design and\n  Evaluation\n\n  Embedded software is developed under the assumption that hardware execution\nis always correct. Fault attacks break and exploit that assumption. Through the\ncareful introduction of targeted faults, an adversary modifies the control-flow\nor data-flow integrity of software. The modified program execution is then\nanalyzed and used as a source of information leakage, or as a mechanism for\nprivilege escalation. Due to the increasing complexity of modern embedded\nsystems, and due to the difficulty of guaranteeing correct hardware execution\neven under a weak adversary, fault attacks are a growing threat. For example,\nthe assumption that an adversary has to be close to the physical execution of\nsoftware, in order to inject an exploitable fault into hardware, has repeatedly\nbeen shown to be incorrect. This article is a review on hardware-based fault\nattacks on software, with emphasis on the context of embedded systems. We\npresent a detailed discussion of the anatomy of a fault attack, and we make a\nreview of fault attack evaluation techniques. The paper emphasizes the\nperspective from the attacker, rather than the perspective of countermeasure\ndevelopment. However, we emphasize that improvements to countermeasures often\nbuild on insight into the attacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.00572,regular,pre_llm,2020,3,"{'ai_likelihood': 2.317958407931858e-07, 'text': 'Retrofitting Fine Grain Isolation in the Firefox Renderer (Extended\n  Version)\n\n  Firefox and other major browsers rely on dozens of third-party libraries to\nrender audio, video, images, and other content. These libraries are a frequent\nsource of vulnerabilities. To mitigate this threat, we are migrating Firefox to\nan architecture that isolates these libraries in lightweight sandboxes,\ndramatically reducing the impact of a compromise.\n  Retrofitting isolation can be labor-intensive, very prone to security bugs,\nand requires critical attention to performance. To help, we developed RLBox, a\nframework that minimizes the burden of converting Firefox to securely and\nefficiently use untrusted code. To enable this, RLBox employs static\ninformation flow enforcement, and lightweight dynamic checks, expressed\ndirectly in the C++ type system.\n  RLBox supports efficient sandboxing through either software-based-fault\nisolation or multi-core process isolation. Performance overheads are modest and\ntransient, and have only minor impact on page latency. We demonstrate this by\nsandboxing performance-sensitive image decoding libraries ( libjpeg and libpng\n), video decoding libraries ( libtheora and libvpx ), the libvorbis audio\ndecoding library, and the zlib decompression library.\n  RLBox, using a WebAssembly sandbox, has been integrated into production\nFirefox to sandbox the libGraphite font shaping library.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.05039,regular,pre_llm,2020,3,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Devil is Virtual: Reversing Virtual Inheritance in C++ Binaries\n\n  Complexities that arise from implementation of object-oriented concepts in\nC++ such as virtual dispatch and dynamic type casting have attracted the\nattention of attackers and defenders alike.\n  Binary-level defenses are dependent on full and precise recovery of class\ninheritance tree of a given program.\n  While current solutions focus on recovering single and multiple inheritances\nfrom the binary, they are oblivious to virtual inheritance. Conventional wisdom\namong binary-level defenses is that virtual inheritance is uncommon and/or\nsupport for single and multiple inheritances provides implicit support for\nvirtual inheritance. In this paper, we show neither to be true.\n  Specifically, (1) we present an efficient technique to detect virtual\ninheritance in C++ binaries and show through a study that virtual inheritance\ncan be found in non-negligible number (more than 10\\% on Linux and 12.5\\% on\nWindows) of real-world C++ programs including Mysql and libstdc++. (2) we show\nthat failure to handle virtual inheritance introduces both false positives and\nfalse negatives in the hierarchy tree. These false positves and negatives\neither introduce attack surface when the hierarchy recovered is used to enforce\nCFI policies, or make the hierarchy difficult to understand when it is needed\nfor program understanding (e.g., during decompilation). (3) We present a\nsolution to recover virtual inheritance from COTS binaries. We recover a\nmaximum of 95\\% and 95.5\\% (GCC -O0) and a minimum of 77.5\\% and 73.8\\% (Clang\n-O2) of virtual and intermediate bases respectively in the virtual inheritance\ntree.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.05813,regular,pre_llm,2020,3,"{'ai_likelihood': 7.947285970052084e-07, 'text': 'SMap: Internet-wide Scanning for Spoofing\n\n  To protect themselves from attacks, networks need to enforce ingress\nfiltering, i.e., block inbound packets sent from spoofed IP addresses. Although\nthis is a widely known best practice, it is still not clear how many networks\ndo not block spoofed packets. Inferring the extent of spoofability at Internet\nscale is challenging and despite multiple efforts the existing studies\ncurrently cover only a limited set of the Internet networks: they can either\nmeasure networks that operate servers with faulty network-stack\nimplementations, or require installation of the measurement software on\nvolunteer networks, or assume specific properties, like traceroute loops.\nImproving coverage of the spoofing measurements is critical.\n  In this work we present the Spoofing Mapper (SMap): the first scanner for\nperforming Internet-wide studies of ingress filtering. SMap evaluates\nspoofability of networks utilising standard protocols that are present in\nalmost any Internet network. We applied SMap for Internet-wide measurements of\ningress filtering: we found that 69.8% of all the Autonomous Systems (ASes) in\nthe Internet do not filter spoofed packets and found 46880 new spoofable ASes\nwhich were not identified in prior studies. Our measurements with SMap provide\nthe first comprehensive view of ingress filtering deployment in the Internet as\nwell as remediation in filtering spoofed packets over a period of two years\nuntil May 2021.\n  We set up a web service at https://smap.cad.sit.fraunhofer.de to perform\ncontinual Internet-wide data collection with SMap and display statistics from\nspoofing evaluation. We make our datasets as well as the SMap (implementation\nand the source code) publicly available to enable researchers to reproduce and\nvalidate our results, as well as to continually keep track of changes in\nfiltering spoofed packets in the Internet.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.00405,regular,pre_llm,2020,3,"{'ai_likelihood': 3.5100513034396704e-06, 'text': 'Efficient Wu-Manber Pattern Matching Hardware for Intrusion and Malware\n  Detection\n\n  Network intrusion detection systems and antivirus software are essential in\ndetecting malicious network traffic and attacks such as denial-of-service and\nmalwares. Each attack, worm or virus has its own distinctive signature.\nSignature-based intrusion detection and antivirus systems depend on pattern\nmatching to look for possible attack signatures. Pattern matching is a very\ncomplex task, which requires a lot of time, memory and computing resources.\nSoftware-based intrusion detection is not fast enough to match high network\nspeeds and the increasing number of attacks. In this paper, we propose special\npurpose hardware for Wu-Manber pattern matching algorithm. FPGAs form an\nexcellent choice because of their massively parallel structure, reprogrammable\nlogic and memory resources. The hardware is designed in Verilog and implemented\nusing Xilinx ISE. For evaluation, we dope network traffic traces collected\nusing Wireshark with 2500 signatures from the ClamAV virus definitions\ndatabase. Experimental results show high speed that reaches up to 216 Mbps. In\naddition, we evaluate time, device usage, and power consumption.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.04024,regular,pre_llm,2020,3,"{'ai_likelihood': 1.430511474609375e-05, 'text': 'A Verifiable Quantum Secret Sharing Scheme Based on a Single Qubit\n\n  To detect frauds from some internal participants or external attackers, some\nverifiable threshold quantum secret sharing schemes have been proposed. In this\npaper, we present a new verifiable threshold structure based on a single qubit\nusing bivariate polynomial. First, Alice chooses an asymmetric bivariate\npolynomial and sends a pair of values from this polynomial to each participant.\nThen Alice and participants implement in sequence unitary transformation on the\n$d$-dimensional quantum state based on unbiased bases, where those unitary\ntransformations are contacted by this polynomial. Finally, security analysis\nshows that the proposed scheme can detect the fraud from external and internal\nattacks compared with the exiting schemes and is comparable to the recent\nschemes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.06127,regular,pre_llm,2020,3,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Fail-safe Watchtowers and Short-lived Assertions for Payment Channels\n\n  The recent development of payment channels and their extensions (e.g., state\nchannels) provides a promising scalability solution for blockchains which\nallows untrusting parties to transact off-chain and resolve potential disputes\nvia on-chain smart contracts. To protect participants who have no constant\naccess to the blockchain, a watching service named as watchtower is proposed --\na third-party entity obligated to monitor channel states (on behalf of the\nparticipants) and correct them on-chain if necessary. Unfortunately, currently\nproposed watchtower schemes suffer from multiple security and efficiency\ndrawbacks. In this paper, we explore the design space behind watchtowers. We\npropose a novel watching service named as fail-safe watchtowers. In contrast to\nprior proposed watching services, our fail-safe watchtower does not watch\non-chain smart contracts constantly. Instead, it only sends a single on-chain\nmessage periodically confirming or denying the final states of channels being\nclosed. Our watchtowers can easily handle a large number of channels, are\nprivacy-preserving, and fail-safe tolerating multiple attack vectors.\nFurthermore, we show that watchtowers (in general) may be an option\neconomically unjustified for multiple payment scenarios and we introduce a\nsimple, yet powerful concept of short-lived assertions which can mitigate\nmisbehaving parties in these scenarios.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2003.12359,regular,pre_llm,2020,3,"{'ai_likelihood': 1.2748771243625217e-05, 'text': 'Guardauto: A Decentralized Runtime Protection System for Autonomous\n  Driving\n\n  Due to the broad attack surface and the lack of runtime protection, potential\nsafety and security threats hinder the real-life adoption of autonomous\nvehicles. Although efforts have been made to mitigate some specific attacks,\nthere are few works on the protection of the self-driving system. This paper\npresents a decentralized self-protection framework called Guardauto to protect\nthe self-driving system against runtime threats. First, Guardauto proposes an\nisolation model to decouple the self-driving system and isolate its components\nwith a set of partitions. Second, Guardauto provides self-protection mechanisms\nfor each target component, which combines different methods to monitor the\ntarget execution and plan adaption actions accordingly. Third, Guardauto\nprovides cooperation among local self-protection mechanisms to identify the\nroot-cause component in the case of cascading failures affecting multiple\ncomponents. A prototype has been implemented and evaluated on the open-source\nautonomous driving system Autoware. Results show that Guardauto could\neffectively mitigate runtime failures and attacks, and protect the control\nsystem with acceptable performance overhead.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.12264,regular,pre_llm,2020,4,"{'ai_likelihood': 1.2252065870496963e-06, 'text': 'A novel encryption algorithm using multiple semifield S-boxes based on\n  permutation of symmetric group\n\n  With the tremendous benefits of internet and advanced communications, there\nis a serious threat from the data security perspective. There is a need of\nsecure and robust encryption algorithm that can be implemented on each and\ndiverse software and hardware platforms. Also, in block symmetric encryption\nalgorithms, substitution boxes are the most vital part. In this paper, we\ninvestigate semifield substitution boxes using permutation of symmetric group\non a set of size 8 S_8 and establish an effective procedure for generating S_8\nsemifield substitution boxes having same algebraic properties. Further, the\nstrength analysis of the generated substitution boxes is carried out using the\nwell-known standards namely bijectivity, nonlinearity, strict avalanche\ncriterion, bit independence criterion, XOR table and differential invariant.\nBased on the analysis results, it is shown that the cryptographic strength of\ngenerated substitution boxes is on par with the best known $8\\times 8$\nsubstitution boxes. As application, an encryption algorithm is proposed that\ncan be employed to strengthen any kind of secure communication. The presented\nalgorithm is mainly based on the Shannon idea of (S-P) network where the\nprocess of substitution is performed by the proposed S_8 semifield substitution\nboxes and permutation operation is performed by the binary cyclic shift of\nsubstitution box transformed data. In addition, the proposed encryption\nalgorithm utilizes two different chaotic maps. In order to ensure the\nappropriate utilization of these chaotic maps, we carry out in-depth analyses\nof their behavior in the context of secure communication and apply the\npseudo-random sequences of chaotic maps in the proposed image encryption\nalgorithm accordingly. The statistical and simulation results imply that our\nencryption scheme is secure against different attacks and can resist linear and\ndifferential cryptanalysis.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.06563,regular,pre_llm,2020,4,"{'ai_likelihood': 5.993578169080946e-06, 'text': 'Topology-Aware Hashing for Effective Control Flow Graph Similarity\n  Analysis\n\n  Control Flow Graph (CFG) similarity analysis is an essential technique for a\nvariety of security analysis tasks, including malware detection and malware\nclustering. Even though various algorithms have been developed, existing CFG\nsimilarity analysis methods still suffer from limited efficiency, accuracy, and\nusability. In this paper, we propose a novel fuzzy hashing scheme called\ntopology-aware hashing (TAH) for effective and efficient CFG similarity\nanalysis. Given the CFGs constructed from program binaries, we extract blended\nn-gram graphical features of the CFGs, encode the graphical features into\nnumeric vectors (called graph signatures), and then measure the graph\nsimilarity by comparing the graph signatures. We further employ a fuzzy hashing\ntechnique to convert the numeric graph signatures into smaller fixed-size fuzzy\nhash signatures for efficient similarity calculation. Our comprehensive\nevaluation demonstrates that TAH is more effective and efficient compared to\nexisting CFG comparison techniques. To demonstrate the applicability of TAH to\nreal-world security analysis tasks, we develop a binary similarity analysis\ntool based on TAH, and show that it outperforms existing similarity analysis\ntools while conducting malware clustering.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.01891,regular,pre_llm,2020,4,"{'ai_likelihood': 2.1192762586805556e-06, 'text': 'Scalar Product Lattice Computation for Efficient Privacy-preserving\n  Systems\n\n  Privacy-preserving applications allow users to perform on-line daily actions\nwithout leaking sensitive information. Privacy-preserving scalar product is one\nof the critical algorithms in many private applications. The state-of-the-art\nprivacy-preserving scalar product schemes use either computationally intensive\nhomomorphic (public-key) encryption techniques such as Paillier encryption to\nachieve strong security (i.e., 128-bit) or random masking technique to achieve\nhigh efficiency for low security. In this paper, lattice structures have been\nexploited to develop an efficient privacy-preserving system. The proposed\nscheme is not only efficient in computation as compared to the state-of-the-art\nbut also provides high degree of security against quantum attacks. Rigorous\nsecurity and privacy analyses of the proposed scheme have been provided along\nwith a concrete set of parameters to achieve 128-bit and 256-bit security.\nPerformance analysis shows that the scheme is at least five orders faster than\nthe Paillier schemes and at least twice as faster than the existing\nrandomisation technique at 128-bit security.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.07297,regular,pre_llm,2020,4,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'Secure protocol to protect location privacy in distance calculation\n\n  Several applications require computing distances between different people.\nFor example,this is required if we want to obtain the close contacts of people\nin case of and epidemic,or when restraining orders are imposed by a judge.\nHowever, periodically revealing location might pose a privacy threat to the\ninvolved parties. Continuous location data may be used to infer personal\ninformation about the owner, like behaviors, religious beliefs, buying habits,\nroutines, etc. In this paper, we show that it is possible to calculate distance\nbetween two parties without disclosing their latitude and longitude data. For\nthis purpose, we design a secure protocol based on the ElGamal cryptosystem and\nits homomorphic properties. The proposed protocol allows the calculation of\ndistances while preserving location privacy. The protocol is analyzed in terms\nof security and performance. The security analysis shows that no involved party\ncan learn any information about location.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.14804,regular,pre_llm,2020,4,"{'ai_likelihood': 2.4835268656412763e-06, 'text': 'Real-Time Energy Monitoring in IoT-enabled Mobile Devices\n\n  With rapid advancements in the Internet of Things (IoT) paradigm, electrical\ndevices in the near future is expected to have IoT capabilities. This enables\nfine-grained tracking of individual energy consumption data of such devices,\noffering location-independent per-device billing. Thus, it is more fine-grained\nthan the location-based metering of state-of-the-art infrastructure, which\ntraditionally aggregates on a building or household level, defining the entity\nto be billed. However, such in-device energy metering is susceptible to\nmanipulation and fraud. As a remedy, we propose a decentralized metering\narchitecture that enables devices with IoT capabilities to measure their own\nenergy consumption. In this architecture, the device-level consumption is\nadditionally reported to a system-level aggregator that verifies distributed\ninformation and provides secure data storage using Blockchain, preventing data\nmanipulation by untrusted entities. Using evaluations on an experimental\ntestbed, we show that the proposed architecture supports device mobility and\nenables location-independent monitoring of energy consumption.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.01556,review,pre_llm,2020,4,"{'ai_likelihood': 8.940696716308594e-07, 'text': 'Phishing Attacks: Detection And Prevention\n\n  This paper aims to provide an understanding of what a phishing attack is, the\ntypes of phishing attacks and methods employed by cyber criminals. This journal\nwill also provide an understanding on where phishing attacks are carried via\nvarious technologies and provide an understanding of working actively to detect\nand proactively to prevent. As we are continuously developing the technology\nthe chance of cyber-attacks will proportionally increase. Consequently, this\npaper will help the readers understand what studies have been conducted,\nanalyzed and results provided pinpointed the essence of phishing attacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.10952,regular,pre_llm,2020,4,"{'ai_likelihood': 3.907415601942274e-05, 'text': ""Securing Organization's Data: A Role-Based Authorized Keyword Search\n  Scheme with Efficient Decryption\n\n  For better data availability and accessibility while ensuring data secrecy,\norganizations often tend to outsource their encrypted data to the cloud storage\nservers, thus bringing the challenge of keyword search over encrypted data. In\nthis paper, we propose a novel authorized keyword search scheme using\nRole-Based Encryption (RBE) technique in a cloud environment. The contributions\nof this paper are multi-fold. First, it presents a keyword search scheme which\nenables only the authorized users, having proper assigned roles, to delegate\nkeyword-based data search capabilities over encrypted data to the cloud\nproviders without disclosing any sensitive information. Second, it supports a\nmulti-organization cloud environment, where the users can be associated with\nmore than one organization. Third, the proposed scheme provides efficient\ndecryption, conjunctive keyword search and revocation mechanisms. Fourth, the\nproposed scheme outsources expensive cryptographic operations in decryption to\nthe cloud in a secure manner. Fifth, we have provided a formal security\nanalysis to prove that the proposed scheme is semantically secure against\nChosen Plaintext and Chosen Keyword Attacks. Finally, our performance analysis\nshows that the proposed scheme is suitable for practical applications.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.07877,regular,pre_llm,2020,4,"{'ai_likelihood': 5.629327562120226e-07, 'text': 'AuthCODE: A Privacy-preserving and Multi-device Continuous\n  Authentication Architecture based on Machine and Deep Learning\n\n  The authentication field is evolving towards mechanisms able to keep users\ncontinuously authenticated without the necessity of remembering or possessing\nauthentication credentials. While existing continuous authentication systems\nhave demonstrated their suitability for single-device scenarios, the Internet\nof Things and next generation of mobile networks (5G) are enabling novel\nmulti-device scenarios -- such as Smart Offices -- where continuous\nauthentication is still an open challenge. The paper at hand, proposes an\nAI-based, privacy-preserving and multi-device continuous authentication\narchitecture called AuthCODE. A realistic Smart Office scenario with several\nusers, interacting with their mobile devices and personal computer, has been\nused to create a set of single- and multi-device behavioural datasets and\nvalidate AuthCODE. A pool of experiments with machine and deep learning\nclassifiers measured the impact of time in authentication accuracy and improved\nthe results of single-device approaches by considering multi-device behaviour\nprofiles. The f1-score average reached for XGBoost on multi-device profiles\nbased on 1-minute windows was 99.33%, while the best performance achieved for\nsingle devices was lower than 97.39%. The inclusion of temporal information in\nthe form of vector sequences classified by a Long-Short Term Memory Network,\nallowed the identification of additional complex behaviour patterns associated\nto each user, resulting in an average f1-score of 99.02% on identification of\nlong-term behaviours.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.03002,regular,pre_llm,2020,4,"{'ai_likelihood': 1.0596381293402778e-06, 'text': ""Can Two Walk Together: Privacy Enhancing Methods and Preventing Tracking\n  of Users\n\n  We present a new concern when collecting data from individuals that arises\nfrom the attempt to mitigate privacy leakage in multiple reporting: tracking of\nusers participating in the data collection via the mechanisms added to provide\nprivacy. We present several definitions for untrackable mechanisms, inspired by\nthe differential privacy framework.\n  Specifically, we define the trackable parameter as the log of the maximum\nratio between the probability that a set of reports originated from a single\nuser and the probability that the same set of reports originated from two users\n(with the same private value). We explore the implications of this new\ndefinition. We show how differentially private and untrackable mechanisms can\nbe combined to achieve a bound for the problem of detecting when a certain user\nchanged their private value.\n  Examining Google's deployed solution for everlasting privacy, we show that\nRAPPOR (Erlingsson et al. ACM CCS, 2014) is trackable in our framework for the\nparameters presented in their paper.\n  We analyze a variant of randomized response for collecting statistics of\nsingle bits, Bitwise Everlasting Privacy, that achieves good accuracy and\neverlasting privacy, while only being reasonably untrackable, specifically\ngrows linearly in the number of reports. For collecting statistics about data\nfrom larger domains (for histograms and heavy hitters) we present a mechanism\nthat prevents tracking for a limited number of responses.\n  We also present the concept of Mechanism Chaining, using the output of one\nmechanism as the input of another, in the scope of Differential Privacy, and\nshow that the chaining of an $\\varepsilon_1$-LDP mechanism with an\n$\\varepsilon_2$-LDP mechanism is\n$\\ln\\frac{e^{\\varepsilon_1+\\varepsilon_2}+1}{e^{\\varepsilon_1}+e^{\\varepsilon_2}}$-LDP\nand that this bound is tight.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.1436,regular,pre_llm,2020,4,"{'ai_likelihood': 2.086162567138672e-06, 'text': ""Big Fish, Little Fish, Critical Infrastructure: An Analysis of Phineas\n  Fisher and the 'Hacktivist' Threat to Critical Infrastructure\n\n  The hacktivist threat actor is listed in many risk decision documents. Yet\ntheir tactics and techniques often remain a mystery. We create a MITRE ATT&CK\n(ATT&CK) model of a well known hacktivist who goes under the pseudonym of\nPhineas Fisher, and map that threat to critical infrastructure. The analysis is\nderived from hacker manifestos, journalist reporting, and official government\ndocumentation. This analysis fills a gap in current threat models, to better\ndefine what skills and methods a determined hacker might employ. This paper\nalso identifies seven essential mitigations which can be deployed by critical\ninfrastructure operations and asset owners, to prevent such intrusions by\nhacktivists. We are in the process of contributing this threat actor into the\nATT&CK knowledge base.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.09062,regular,pre_llm,2020,4,"{'ai_likelihood': 5.993578169080946e-06, 'text': 'S3Library: Automatically Eliminating C/C++ Buffer Overflow using\n  Compatible Safer Libraries\n\n  Annex K of C11, bounds-checking interfaces, recently introduced a set of\nalternative functions to mitigate buffer overflows, primarily those caused by\nstring/memory functions. However, poor compatibility limits their adoption.\nFailure oblivious computing can eliminate the possibility that an attacker can\nexploit memory errors to corrupt the address space and significantly increase\nthe availability of systems.\n  In this paper, we present S3Library (Saturation-Memory-Access Safer String\nLibrary), which is compatible with the standard C library in terms of function\nsignature. Our technique automatically replaces unsafe deprecated memory/string\nfunctions with safer versions that perform bounds checking and eliminate buffer\noverflows via boundless memory. S3Library employs MinFat, a very compact\npointer representation following the Less is More principle, to encode metadata\ninto unused upper bits within pointers. In addition, S3Library utilizes\nSaturation Memory Access to eliminate illegal memory accesses into boundless\npadding area. Even if an out-of-bounds access is made, the fault program will\nnot be interrupted. We implement our scheme within the LLVM framework on X86-64\nand evaluate our approach on correctness, security, runtime performance and\navailability.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.01403,regular,pre_llm,2020,4,"{'ai_likelihood': 2.705388598971897e-05, 'text': 'A ""Final"" Security Bug\n\n  This article discusses a fixed critical security bug in Google Tink\'s Ed25519\nJava implementation. The bug allows remote attackers to extract the private key\nwith only two Ed25519 signatures. The vulnerability comes from the\nmisunderstanding of what ""final"" in Java programming language means. The bug\nwas discovered during security review before Google Tink was officially\nreleased. It reinforces the challenge in writing safe cryptographic code and\nthe importance of the security review process even for the code written by\nprofessional cryptographers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.10781,review,pre_llm,2020,4,"{'ai_likelihood': 1.8874804178873699e-06, 'text': 'Cyberattacks and Countermeasures For In-Vehicle Networks\n\n  As connectivity between and within vehicles increases, so does concern about\nsafety and security. Various automotive serial protocols are used inside\nvehicles such as Controller Area Network (CAN), Local Interconnect Network\n(LIN) and FlexRay. CAN bus is the most used in-vehicle network protocol to\nsupport exchange of vehicle parameters between Electronic Control Units (ECUs).\nThis protocol lacks security mechanisms by design and is therefore vulnerable\nto various attacks. Furthermore, connectivity of vehicles has made the CAN bus\nnot only vulnerable from within the vehicle but also from outside. With the\nrise of connected cars, more entry points and interfaces have been introduced\non board vehicles, thereby also leading to a wider potential attack surface.\nExisting security mechanisms focus on the use of encryption, authentication and\nvehicle Intrusion Detection Systems (IDS), which operate under various\nconstrains such as low bandwidth, small frame size (e.g. in the CAN protocol),\nlimited availability of computational resources and real-time sensitivity. We\nsurvey In-Vehicle Network (IVN) attacks which have been grouped under: direct\ninterfaces-initiated attacks, telematics and infotainment-initiated attacks,\nand sensor-initiated attacks. We survey and classify current cryptographic and\nIDS approaches and compare these approaches based on criteria such as real time\nconstrains, types of hardware used, changes in CAN bus behaviour, types of\nattack mitigation and software/ hardware used to validate these approaches. We\nconclude with potential mitigation strategies and research challenges for the\nfuture.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.11361,review,pre_llm,2020,4,"{'ai_likelihood': 3.046459621853299e-06, 'text': ""Enhancing Privacy via Hierarchical Federated Learning\n\n  Federated learning suffers from several privacy-related issues that expose\nthe participants to various threats. A number of these issues are aggravated by\nthe centralized architecture of federated learning. In this paper, we discuss\napplying federated learning on a hierarchical architecture as a potential\nsolution. We introduce the opportunities for more flexible decentralized\ncontrol over the training process and its impact on the participants' privacy.\nFurthermore, we investigate possibilities to enhance the efficiency and\neffectiveness of defense and verification methods.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.13107,review,pre_llm,2020,4,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Identity Management on Blockchain -- Privacy and Security Aspects\n\n  In the last years, identity management solutions on blockchain were proposed\nas a possible solution to the digital identity management problem. However,\nthey are still at an early stage and further research needs to be done to\nconclude whether identity systems could benefit from the use of blockchain or\nnot. Motivated by this, we investigate identity management solutions on\nblockchain intending to give the reader an overview of the current status and\nprovide a better understanding of the pros and cons of using such solutions. We\nconduct an analysis on ten of the most known implementations, with a focus on\nprivacy and security aspects. Finally, we identify existing challenges and give\nnew directions for research.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.09583,regular,pre_llm,2020,4,"{'ai_likelihood': 1.3907750447591147e-06, 'text': ""FlashFlow: A Secure Speed Test for Tor\n\n  The Tor network uses a measurement system to estimate its relays' forwarding\ncapacity and to balance traffic among them. This system has been shown to be\nvulnerable to adversarial manipulation. Moreover, its accuracy and\neffectiveness in benign circumstances has never been fully quantified. We first\nobtain such a quantification by analyzing Tor metrics data and performing\nexperiments on the live network. Our results show that Tor currently\nunderestimates its true capacity by about 50% and improperly balances its\ntraffic by 15-25%. Then, to solve the problems with security and accuracy, we\npresent FlashFlow, a system to measure the capacity of Tor relays. Our analysis\nshows that FlashFlow limits a malicious relay to obtaining a capacity estimate\nat most 1.33 times its true capacity. Through realistic Internet experiments,\nwe find that FlashFlow measures relay capacity with at least 89% accuracy 95%\nof the time. Through simulation, we find that FlashFlow can measure the entire\nTor network in less than 5 hours using 3 measurers with 1 Gbit/s of bandwidth\neach. Finally, simulations using FlashFlow for load balancing shows that,\ncompared to TorFlow, network weight error decreases by 86%, while the median of\n50 KiB, 1 MiB, and 5 MiB transfer times decreases by 15%, 29%, and 37%,\nrespectively. Moreover, FlashFlow yields more consistent client performance:\nthe median rate of transfer timeouts decreases by 100%, while the standard\ndeviation of 50 KiB, 1 MiB, and 5 MiB transfer times decreases by 55%, 61%, and\n41%, respectively. We also find that the performance improvements increase\nrelative to TorFlow as the total client-traffic load increases, demonstrating\nthat FlashFlow is better suited to supporting network growth.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.04497,regular,pre_llm,2020,4,"{'ai_likelihood': 7.28501213921441e-07, 'text': 'Efficient and Secure Flash-based Gaming CAPTCH\n\n  With the growth of connectivity to smart grids, new applications, and the\nchanging interaction between customer and energy clouds, clouds are more\nvulnerable to denial-of-service attacks. Efficient detection methods are\nrequired to authenticate, detect and control attackers. Completely Automated\nPublic Turing test to tell Computers and Humans Apart, CAPTCHA, is one\nefficient tool to thwart denial of service attacks. The server presents the\nuser with a client puzzle to solve in order to gain access to the service or\nwebsite. The puzzle should be hard enough for computers, but easy for humans to\nsolve. Several methods have been suggested including the popular image-based,\nas well as video-based, and text-based CAPTCHAs. In this paper, we present a\nnew Flash-based gaming CAPTCHA to differentiate bots from humans. We propose a\ndrag and drop client puzzle where the user will play a simple game to answer a\nvisual question. Our method turns out to be convenient, easy for users and\nchallenging for bots. Additionally, it has gaming aspect, which makes it\ninteresting to users of all age groups.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.10411,regular,pre_llm,2020,4,"{'ai_likelihood': 2.7484363979763457e-06, 'text': 'A NIS Directive compliant Cybersecurity Maturity Assessment Framework\n\n  The NIS Directive introduces obligations for the security of the network and\ninformation systems of operators of essential services and of digital service\nproviders and require from the national competent authorities to assess their\ncompliance to these obligations. This paper describes a novel cybersecurity\nmaturity assessment framework (CMAF) that is tailored to the NIS Directive\nrequirements and can be used either as a self assessment tool from critical\nnational infrastructures either as an audit tool from the National Competent\nAuthorities for cybersecurity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.07723,review,pre_llm,2020,4,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'Covid Notions: Towards Formal Definitions -- and Documented\n  Understanding -- of Privacy Goals and Claimed Protection in Proximity-Tracing\n  Services\n\n  The recent SARS-CoV-2 pandemic gave rise to management approaches using\nmobile apps for contact tracing. The corresponding apps track individuals and\ntheir interactions, to facilitate alerting users of potential infections well\nbefore they become infectious themselves. Naive implementation obviously\njeopardizes the privacy of health conditions, location, activities, and social\ninteraction of its users. A number of protocol designs for colocation tracking\nhave already been developed, most of which claim to function in a privacy\npreserving manner. However, despite claims such as ""GDPR compliance"",\n""anonymity"", ""pseudonymity"" or other forms of ""privacy"", the authors of these\ndesigns usually neglect to precisely define what they (aim to) protect. We make\na first step towards formally defining the privacy notions of proximity tracing\nservices, especially with regards to the health, (co-)location, and social\ninteraction of their users. We also give a high-level intuition of which\nprotection the most prominent proposals can and cannot achieve. This initial\noverview indicates that all proposals include some centralized services, and\nnone protects identity and (co-)locations of infected users perfectly from both\nother users and the service provider.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2004.06195,regular,pre_llm,2020,4,"{'ai_likelihood': 1.986821492513021e-07, 'text': ""AiR-ViBeR: Exfiltrating Data from Air-Gapped Computers via Covert\n  Surface ViBrAtIoNs\n\n  Air-gap covert channels are special types of covert communication channels\nthat enable attackers to exfiltrate data from isolated, network-less computers.\nVarious types of air-gap covert channels have been demonstrated over the years,\nincluding electromagnetic, magnetic, acoustic, optical, and thermal.\n  In this paper, we introduce a new type of vibrational (seismic) covert\nchannel. We observe that computers vibrate at a frequency correlated to the\nrotation speed of their internal fans. These inaudible vibrations affect the\nentire structure on which the computer is placed. Our method is based on\nmalware's capability of controlling the vibrations generated by a computer, by\nregulating its internal fan speeds. We show that the malware-generated covert\nvibrations can be sensed by nearby smartphones via the integrated, sensitive\n\\textit{accelerometers}. Notably, the accelerometer sensors in smartphones can\nbe accessed by any app without requiring the user permissions, which make this\nattack highly evasive. We implemented AiR-ViBeR, malware that encodes binary\ninformation, and modulate it over a low frequency vibrational carrier. The data\nis then decoded by malicious application on a smartphone placed on the same\nsurface (e.g., on a desk). We discuss the attack model, provide technical\nbackground, and present the implementation details and evaluation results. Our\nresults show that using AiR-ViBeR, data can be exfiltrated from air-gapped\ncomputer to a nearby smartphone on the same table, or even an adjacent table,\nvia vibrations. Finally, we propose a set of countermeasures for this new type\nof attack.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.12156,regular,pre_llm,2020,5,"{'ai_likelihood': 1.0927518208821615e-05, 'text': 'ConFuzzius: A Data Dependency-Aware Hybrid Fuzzer for Smart Contracts\n\n  Smart contracts are Turing-complete programs that are executed across a\nblockchain. Unlike traditional programs, once deployed, they cannot be\nmodified. As smart contracts carry more value, they become more of an exciting\ntarget for attackers. Over the last years, they suffered from exploits costing\nmillions of dollars due to simple programming mistakes. As a result, a variety\nof tools for detecting bugs have been proposed. Most of these tools rely on\nsymbolic execution, which may yield false positives due to over-approximation.\nRecently, many fuzzers have been proposed to detect bugs in smart contracts.\nHowever, these tend to be more effective in finding shallow bugs and less\neffective in finding bugs that lie deep in the execution, therefore achieving\nlow code coverage and many false negatives. An alternative that has proven to\nachieve good results in traditional programs is hybrid fuzzing, a combination\nof symbolic execution and fuzzing. In this work, we study hybrid fuzzing on\nsmart contracts and present ConFuzzius, the first hybrid fuzzer for smart\ncontracts. ConFuzzius uses evolutionary fuzzing to exercise shallow parts of a\nsmart contract and constraint solving to generate inputs that satisfy complex\nconditions that prevent evolutionary fuzzing from exploring deeper parts.\nMoreover, ConFuzzius leverages dynamic data dependency analysis to efficiently\ngenerate sequences of transactions that are more likely to result in contract\nstates in which bugs may be hidden. We evaluate the effectiveness of ConFuzzius\nby comparing it with state-of-the-art symbolic execution tools and fuzzers for\nsmart contracts. Our evaluation on a curated dataset of 128 contracts and 21K\nreal-world contracts shows that our hybrid approach detects more bugs (up to\n23%) while outperforming state-of-the-art in terms of code coverage (up to\n69%), and that data dependency analysis boosts bug detection up to 18%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.14619,regular,pre_llm,2020,5,"{'ai_likelihood': 2.6490953233506944e-06, 'text': ""Beyond the Virus: A First Look at Coronavirus-themed Mobile Malware\n\n  As the COVID-19 pandemic emerged in early 2020, a number of malicious actors\nhave started capitalizing the topic. Although a few media reports mentioned the\nexistence of coronavirus-themed mobile malware, the research community lacks\nthe understanding of the landscape of the coronavirus-themed mobile malware. In\nthis paper, we present the first systematic study of coronavirus-themed Android\nmalware. We first make efforts to create a daily growing COVID-19 themed mobile\napp dataset, which contains 4,322 COVID-19 themed apk samples (2,500 unique\napps) and 611 potential malware samples (370 unique malicious apps) by the time\nof mid-November, 2020. We then present an analysis of them from multiple\nperspectives including trends and statistics, installation methods, malicious\nbehaviors and malicious actors behind them. We observe that the COVID-19 themed\napps as well as malicious ones began to flourish almost as soon as the pandemic\nbroke out worldwide. Most malicious apps are camouflaged as benign apps using\nthe same app identifiers (e.g., app name, package name and app icon). Their\nmain purposes are either stealing users' private information or making profit\nby using tricks like phishing and extortion. Furthermore, only a quarter of the\nCOVID-19 malware creators are habitual developers who have been active for a\nlong time, while 75% of them are newcomers in this pandemic. The malicious\ndevelopers are mainly located in US, mostly targeting countries including\nEnglish-speaking countries, China, Arabic countries and Europe. To facilitate\nfuture research, we have publicly released all the well-labelled COVID-19\nthemed apps (and malware) to the research community. Till now, over 30 research\ninstitutes around the world have requested our dataset for COVID-19 themed\nresearch.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.13793,regular,pre_llm,2020,5,"{'ai_likelihood': 2.4835268656412763e-06, 'text': ""Efficient Privacy-Preserving Electricity Theft Detection with Dynamic\n  Billing and Load Monitoring for AMI Networks\n\n  In advanced metering infrastructure (AMI), smart meters (SMs) are installed\nat the consumer side to send fine-grained power consumption readings\nperiodically to the system operator (SO) for load monitoring, energy\nmanagement, billing, etc. However, fraudulent consumers launch electricity\ntheft cyber-attacks by reporting false readings to reduce their bills\nillegally. These attacks do not only cause financial losses but may also\ndegrade the grid performance because the readings are used for grid management.\nTo identify these attackers, the existing schemes employ machine-learning\nmodels using the consumers' fine-grained readings, which violates the\nconsumers' privacy by revealing their lifestyle. In this paper, we propose an\nefficient scheme that enables the SO to detect electricity theft, compute\nbills, and monitor load while preserving the consumers' privacy. The idea is\nthat SMs encrypt their readings using functional encryption, and the SO uses\nthe ciphertexts to (i) compute the bills following dynamic pricing approach,\n(ii) monitor the grid load, and (iii) evaluate a machine-learning model to\ndetect fraudulent consumers, without being able to learn the individual\nreadings to preserve consumers' privacy. We adapted a functional encryption\nscheme so that the encrypted readings are aggregated for billing and load\nmonitoring and only the aggregated value is revealed to the SO. Also, we\nexploited the inner-product operations on encrypted readings to evaluate a\nmachine-learning model to detect fraudulent consumers. Real dataset is used to\nevaluate our scheme, and our evaluations indicate that our scheme is secure and\ncan detect fraudulent consumers accurately with low communication and\ncomputation overhead.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.04368,review,pre_llm,2020,5,"{'ai_likelihood': 6.523397233751085e-06, 'text': 'HACK3D: Crowdsourcing the Assessment of Cybersecurity in Digital Manufacturing\n\nDigital manufacturing (DM) cyber-physical system is vulnerable to both cyber and physical attacks. HACK3D is a series of crowdsourcing red-team-blue-team events hosted by the NYU Center for Cybersecurity to assess the strength of the security methods embedded in designs using DM. This study summarizes the lessons learned from the past three offerings of HACK3D, including ingenious ways in which skilled engineers can launch surprising attacks on DM designs not anticipated before. A key outcome is a taxonomy-guided creation of DM security benchmarks for use by the DM community.', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.10607,regular,pre_llm,2020,5,"{'ai_likelihood': 1.0927518208821616e-06, 'text': 'CovidChain: An Anonymity Preserving Blockchain Based Framework for\n  Protection Against Covid-19\n\n  Today, the entire world is facing incredible health and economic challenges\ndue to the rapid spread of the life threatening novel Coronavirus Disease -\n2019 (COVID-19). In the prevailing situation when a vaccine is many months\naway, the way forward seems to be a controlled exit from the lockdown - where,\ninfected/exposed people are strictly quarantined and recovered/unexposed people\nare allowed to carry on with their day to day business activities. However,\nappropriate physical distancing norms will have to be strictly followed for\nsuch relaxations. Therefore, mechanisms are required that will assist people in\nfollowing the social and physical distancing norms in public places. In this\npaper, we propose an anonymity preserving blockchain based framework that\nallows people, through use of their smart phones and other communication\ndevices, to protect themselves from infections as they conduct their daily\nbusiness activities.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.10083,regular,pre_llm,2020,5,"{'ai_likelihood': 5.728668636745877e-06, 'text': 'Securing Digital Systems via Split-Chip Obfuscation\n\n  Security is an important facet of integrated circuit design for many\napplications. IP privacy and Trojan insertion are growing threats as circuit\nfabrication in advanced nodes almost inevitably relies on untrusted foundries.\nA proposed solution is Split-Chip Obfuscation that uses a combination trusted\nand untrusted IC fabrication scheme. By utilizing two CMOS processes, a system\nis endowed with the stronger security guaranties of a trusted legacy node while\nalso leveraging the performance and density of an advanced untrusted node.\nCritical to the effectiveness of Split-Chip Obfuscation is finding an optimum\npartitioning of a system between the two ICs. In this paper, we develop a\ndesign flow for the Split-Chip Obfuscation scheme, defining the essential\nsystem metrics and creating a tool to rapidly assess the large design space. We\ndemonstrate the concept of such a tool and show its application on an example\nSoC.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.03749,regular,pre_llm,2020,5,"{'ai_likelihood': 1.3245476616753472e-06, 'text': ""Dispute Resolution in Voting\n\n  In voting, disputes arise when a voter claims that the voting authority is\ndishonest and did not correctly process his ballot while the authority claims\nto have followed the protocol. A dispute can be resolved if any third party can\nunambiguously determine who is right. We systematically characterize all\nrelevant disputes for a generic, practically relevant, class of voting\nprotocols. Based on our characterization, we propose a new definition of\ndispute resolution for voting that accounts for the possibility that both\nvoters and the voting authority can make false claims and that voters may\nabstain from voting.\n  A central aspect of our work is timeliness: a voter should possess the\nevidence required to resolve disputes no later than the election's end. We\ncharacterize what assumptions are necessary and sufficient for timeliness in\nterms of a communication topology for our voting protocol class. We formalize\nthe dispute resolution properties and communication topologies symbolically.\nThis provides the basis for verification of dispute resolution for a broad\nclass of protocols. To demonstrate the utility of our model, we analyze a\nmixnet-based voting protocol and prove that it satisfies dispute resolution as\nwell as verifiability and receipt-freeness. To prove our claims, we combine\nmachine-checked proofs with traditional pen-and-paper proofs.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.03199,regular,pre_llm,2020,5,"{'ai_likelihood': 8.344650268554688e-06, 'text': 'Enabling Cross-chain Transactions: A Decentralized Cryptocurrency\n  Exchange Protocol\n\n  Inspired by Bitcoin, many different kinds of cryptocurrencies based on\nblockchain technology have turned up on the market. Due to the special\nstructure of the blockchain, it has been deemed impossible to directly trade\nbetween traditional currencies and cryptocurrencies or between different types\nof cryptocurrencies. Generally, trading between different currencies is\nconducted through a centralized third-party platform. However, it has the\nproblem of a single point of failure, which is vulnerable to attacks and thus\naffects the security of the transactions. In this paper, we propose a\ndistributed cryptocurrency trading scheme to solve the problem of centralized\nexchanges, which can achieve trading between different types of\ncryptocurrencies. Our scheme is implemented with smart contracts on the\nEthereum blockchain and deployed on the Ethereum test network. We not only\nimplement transactions between individual users, but also allow transactions\nbetween multiple users. The experimental result proves that the cost of our\nscheme is acceptable.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.00395,regular,pre_llm,2020,5,"{'ai_likelihood': 1.986821492513021e-07, 'text': ""POWER-SUPPLaY: Leaking Data from Air-Gapped Systems by Turning the\n  Power-Supplies Into Speakers\n\n  It is known that attackers can exfiltrate data from air-gapped computers\nthrough their speakers via sonic and ultrasonic waves. To eliminate the threat\nof such acoustic covert channels in sensitive systems, audio hardware can be\ndisabled and the use of loudspeakers can be strictly forbidden. Such audio-less\nsystems are considered to be \\textit{audio-gapped}, and hence immune to\nacoustic covert channels.\n  In this paper, we introduce a technique that enable attackers leak data\nacoustically from air-gapped and audio-gapped systems. Our developed malware\ncan exploit the computer power supply unit (PSU) to play sounds and use it as\nan out-of-band, secondary speaker with limited capabilities. The malicious code\nmanipulates the internal \\textit{switching frequency} of the power supply and\nhence controls the sound waveforms generated from its capacitors and\ntransformers. Our technique enables producing audio tones in a frequency band\nof 0-24khz and playing audio streams (e.g., WAV) from a computer power supply\nwithout the need for audio hardware or speakers. Binary data (files,\nkeylogging, encryption keys, etc.) can be modulated over the acoustic signals\nand sent to a nearby receiver (e.g., smartphone). We show that our technique\nworks with various types of systems: PC workstations and servers, as well as\nembedded systems and IoT devices that have no audio hardware at all. We provide\ntechnical background and discuss implementation details such as signal\ngeneration and data modulation. We show that the POWER-SUPPLaY code can operate\nfrom an ordinary user-mode process and doesn't need any hardware access or\nspecial privileges. Our evaluation shows that using POWER-SUPPLaY, sensitive\ndata can be exfiltrated from air-gapped and audio-gapped systems from a\ndistance of five meters away at a maximal bit rates of 50 bit/sec.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.00514,regular,pre_llm,2020,5,"{'ai_likelihood': 3.741847144232856e-06, 'text': 'New Code-Based Cryptosystem with Arbitrary Error Vectors\n\n  McEliece cryptosystem represents a smart open key system based on the\nhardness of the decoding of an arbitrary linear code, which is believed to be\nable to resist the advent of quantum computers. But the original McEliece\ncryptosystem, based on Goppa codes, has just very limited interest in practice,\npartly because it requires a very large public key. In this paper we propose a\nnew general way to reduce the public key size. Unlike most papers on reducing\nkey length of the cryptosystem, where original Goppa codes are substituted by\nsome other codes, we suggest a new method of key size reduction which is\ncode-independent.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.11776,regular,pre_llm,2020,5,"{'ai_likelihood': 6.622738308376736e-08, 'text': ""Custody Protocols Using Bitcoin Vaults\n\n  A bitcoin \\textit{covenant} is a mechanism to enforce conditions on future\nbitcoin transactions. A bitcoin \\textit{vault} is a specific type of covenant\ntransaction that enforces a time-lock on the transfer of control of funds to a\nhot wallet, but enables an immediate transfer of funds into a deep cold\nrecovery wallet. This paper demonstrates how to integrate a bitcoin vault into\na custody protocol and demonstrates the security properties of that protocol.\nThe vault is implemented using pre-signed transactions with secure key deletion\n(as proposed in \\cite{Swambo2020cov}). It is shown that vault-custody protocols\nenable the wallet owner to specify their desired balance for an inherent\ntrade-off between the security of and accessibility of bitcoin holdings by\nadjusting the length of time-locks used. It is also demonstrated that wallet\nowners have increased control of risk-management by compartmentalizing funds\nacross numerous vault transactions. While it isn't realistic to completely\nprevent theft, the most likely theft scenarios (compromising the hot wallet)\nhave severely limited profitability for an attacker, deterring attempts at\ntheft from the beginning. The proposed architecture was designed to offer\ndefence-in-depth through redundancy and fault-tolerant functionality as well as\ncountermeasures for class breaks through diversity across hardware and software\nlayers. Finally, the architecture employs a detection (a watchtower) and\nresponse system that enables fail-safe recovery from attempted or partial\nthefts through a second type of covenant transaction, a push-to-recovery-wallet\ntransaction.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.14645,regular,pre_llm,2020,5,"{'ai_likelihood': 1.986821492513021e-07, 'text': ""DatashareNetwork: A Decentralized Privacy-Preserving Search Engine for\n  Investigative Journalists\n\n  Investigative journalists collect large numbers of digital documents during\ntheir investigations. These documents can greatly benefit other journalists'\nwork. However, many of these documents contain sensitive information. Hence,\npossessing such documents can endanger reporters, their stories, and their\nsources. Consequently, many documents are used only for single, local,\ninvestigations.\n  We present DatashareNetwork, a decentralized and privacy-preserving search\nsystem that enables journalists worldwide to find documents via a dedicated\nnetwork of peers. DatashareNetwork combines well-known anonymous authentication\nmechanisms and anonymous communication primitives, a novel asynchronous\nmessaging system, and a novel multi-set private set intersection protocol\n(MS-PSI) into a *decentralized peer-to-peer private document search engine*. We\nprove that DatashareNetwork is secure; and show using a prototype\nimplementation that it scales to thousands of users and millions of documents.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.13382,regular,pre_llm,2020,5,"{'ai_likelihood': 7.947285970052084e-07, 'text': ""Security Improvements of Several Basic Quantum Private Query Protocols\n  with O(log N) Communication Complexity\n\n  New quantum private database (with N elements) query protocols are presented\nand analyzed. Protocols preserve O(logN) communication complexity of known\nprotocols for the same task, but achieve several significant improvements in\nsecurity, especially concerning user privacy. For example, the randomized form\nof our protocol has a cheat-sensitive property - it allows the user to detect a\ndishonest database with a nonzero probability, while the phase-encoded private\nquery protocols for the same task do not have such a property. Moreover, when\nthe database performs the computational basis measurement, a particular\nprojective measurement which can cause a significant loss of user privacy in\nthe previous private query protocols with O(logN) communication complexity, at\nmost half of the user privacy could leak to such a database in our protocol,\nwhile in the QPQ protocol, the entire user privacy could leak out. In addition,\nit is proved here that for large N, the user could detect a cheating via the\ncomputational basis measurement, with a probability close to 1/2 using\nO(\\sqrt{N}) special queries. Finally, it is shown here, for both forms of our\nprotocol, basic and randomized, how a dishonest database has to act in case it\ncould not learn user's queries.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.04262,review,pre_llm,2020,5,"{'ai_likelihood': 4.470348358154297e-06, 'text': 'On Designing Secure and Robust Scan Chain for Protecting Obfuscated\n  Logic\n\n  In this paper, we assess the security and testability of the state-of-the-art\ndesign-for-security (DFS) architectures in the presence of scan-chain\nlocking/obfuscation, a group of solution that has previously proposed to\nrestrict unauthorized access to the scan chain. We discuss the key leakage\nvulnerability in the recently published prior-art DFS architectures. This\nleakage relies on the potential glitches in the DFS architecture that could\nlead the adversary to make a leakage condition in the circuit. Also, we\ndemonstrate that the state-of-the-art DFS architectures impose some substantial\narchitectural drawbacks that moderately affect both test flow and design\nconstraints. We propose a new DFS architecture for building a secure scan chain\narchitecture while addressing the potential of key leakage. The proposed\narchitecture allows the designer to perform the structural test with no\nlimitation, enabling an untrusted foundry to utilize the scan chain for\nmanufacturing fault testing without needing to access the scan chain. Our\nproposed solution poses negligible limitation/overhead on the test flow, as\nwell as the design criteria.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.14585,regular,pre_llm,2020,5,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'DEMO: Extracting Physical-Layer BLE Advertisement Information from\n  Broadcom and Cypress Chips\n\n  Multiple initiatives propose utilizing Bluetooth Low Energy (BLE)\nadvertisements for contact tracing and SARS-CoV-2 exposure notifications. This\ndemo shows a research tool to analyze BLE advertisements; if universally\nenabled by the vendors, the uncovered features could improve exposure\nnotifications for everyone. We reverse-engineer the firmware-internal\nimplementation of BLE advertisements on Broadcom and Cypress chips and show how\nto extract further physical-layer information at the receiver. The analyzed\nfirmware works on hundreds of millions of devices, such as all iPhones, the\nEuropean Samsung Galaxy S series, and Raspberry Pis.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.02061,regular,pre_llm,2020,5,"{'ai_likelihood': 2.6490953233506946e-07, 'text': ""Privately Connecting Mobility to Infectious Diseases via Applied\n  Cryptography\n\n  Recent work has shown that cell phone mobility data has the unique potential\nto create accurate models for human mobility and consequently the spread of\ninfected diseases. While prior studies have exclusively relied on a mobile\nnetwork operator's subscribers' aggregated data in modelling disease dynamics,\nit may be preferable to contemplate aggregated mobility data of infected\nindividuals only. Clearly, naively linking mobile phone data with health\nrecords would violate privacy by either allowing to track mobility patterns of\ninfected individuals, leak information on who is infected, or both. This work\naims to develop a solution that reports the aggregated mobile phone location\ndata of infected individuals while still maintaining compliance with privacy\nexpectations. To achieve privacy, we use homomorphic encryption, validation\ntechniques derived from zero-knowledge proofs, and differential privacy. Our\nprotocol's open-source implementation can process eight million subscribers in\n70 minutes.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.04047,review,pre_llm,2020,5,"{'ai_likelihood': 7.616149054633247e-07, 'text': 'Convergence of IT and SCADA: Associated Security Threats and\n  Vulnerabilities\n\n  As many industries shift towards centralised controlled information systems\nfor monitoring and control, more importance is being placed upon technologies\nsuch as Supervisory Control and Data Acquisitions industrial systems (SCADA).\nThis focus on integration and interoperability presents numerous challenges for\nsecurity personnel and organisational management alike. It becomes paramount\ntherefore to reciprocate this new direction within an organisation with\nadequate plans and frameworks that ensure protection and security of its SCADA\narchitecture. A clear understanding of the relevant threats and vulnerabilities\nis critical for adopting/developing appropriate policy and frameworks. To this\nend, in this research we identify and analyse relevant SCADA security threats\nand vulnerabilities and present a simple scheme to classify them for better\nunderstanding.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.1117,regular,pre_llm,2020,5,"{'ai_likelihood': 1.526541180080838e-05, 'text': 'Authenticating On-Body IoT Devices: An Adversarial Learning Approach\n\n  By adding users as a new dimension to connectivity, on-body\nInternet-of-Things (IoT) devices have gained considerable momentum in recent\nyears, while raising serious privacy and safety issues. Existing approaches to\nauthenticate these devices limit themselves to dedicated sensors or specified\nuser motions, undermining their widespread acceptance. This paper overcomes\nthese limitations with a general authentication solution by integrating\nwireless physical layer (PHY) signatures with upper-layer protocols. The key\nenabling techniques are constructing representative radio propagation profiles\nfrom received signals, and developing an adversarial multi-player neural\nnetwork to accurately recognize underlying radio propagation patterns and\nfacilitate on-body device authentication. Once hearing a suspicious\ntransmission, our system triggers a PHY-based challenge-response protocol to\ndefend in depth against active attacks. We prove that at equilibrium, our\nadversarial model can extract all information about propagation patterns and\neliminate any irrelevant information caused by motion variances and environment\nchanges. We build a prototype of our system using Universal Software Radio\nPeripheral (USRP) devices and conduct extensive experiments with various static\nand dynamic body motions in typical indoor and outdoor environments. The\nexperimental results show that our system achieves an average authentication\naccuracy of 91.6%, with a high area under the receiver operating characteristic\ncurve (AUROC) of 0.96 and a better generalization performance compared with the\nconventional non-adversarial approach.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.04163,regular,pre_llm,2020,5,"{'ai_likelihood': 4.5365757412380644e-06, 'text': 'Human Error in IT Security\n\n  This paper details on the analysis of human error, an IT security issue, and\na major threat to the company. The human is one of the weakest links in the\ncybersecurity chain however it is a fundamental constituent of the embodiment.\nThis report provides a sophisticated elucidation on the various human errors\nand the necessary measures to mitigate and control the menacing IT security\nissue.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2005.12969,regular,pre_llm,2020,5,"{'ai_likelihood': 1.9272168477376304e-05, 'text': ""A Taxonomy for Dynamic Honeypot Measures of Effectiveness\n\n  Honeypots are computing systems used to capture unauthorized, often\nmalicious, activity. While honeypots can take on a variety of forms,\nresearchers agree the technology is useful for studying adversary behavior,\ntools, and techniques. Unfortunately, researchers also agree honeypots are\ndifficult to implement and maintain. A lack of measures of effectiveness\ncompounds the implementation issues specifically. In other words, existing\nresearch does not provide a set of measures to determine if a honeypot is\neffective in its implementation. This is problematic because an ineffective\nimplementation may lead to poor performance, inadequate emulation of legitimate\nservices, or even premature discovery by an adversary. Accordingly, we have\ndeveloped a taxonomy for measures of effectiveness in dynamic honeypot\nimplementations. Our aim is for these measures to be used to quantify a dynamic\nhoneypot's effectiveness in fingerprinting its environment, capturing valid\ndata from adversaries, deceiving adversaries, and intelligently monitoring\nitself and its surroundings.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.06419,regular,pre_llm,2020,6,"{'ai_likelihood': 6.9207615322536894e-06, 'text': 'DEPOSafe: Demystifying the Fake Deposit Vulnerability in Ethereum Smart\n  Contracts\n\n  Cryptocurrency has seen an explosive growth in recent years, thanks to the\nevolvement of blockchain technology and its economic ecosystem. Besides\nBitcoin, thousands of cryptocurrencies have been distributed on blockchains,\nwhile hundreds of cryptocurrency exchanges are emerging to facilitate the\ntrading of digital assets. At the same time, it also attracts the attentions of\nattackers. Fake deposit, as one of the most representative attacks\n(vulnerabilities) related to exchanges and tokens, has been frequently observed\nin the blockchain ecosystem, causing large financial losses. However, besides a\nfew security reports, our community lacks of the understanding of this\nvulnerability, for example its scale and the impacts. In this paper, we take\nthe first step to demystify the fake deposit vulnerability. Based on the\nessential patterns we have summarized, we implement DEPOSafe, an automated tool\nto detect and verify (exploit) the fake deposit vulnerability in ERC-20 smart\ncontracts. DEPOSafe incorporates several key techniques including symbolic\nexecution based static analysis and behavior modeling based dynamic\nverification. By applying DEPOSafe to 176,000 ERC-20 smart contracts, we have\nidentified over 7,000 vulnerable contracts that may suffer from two types of\nattacks. Our findings demonstrate the urgency to identify and prevent the fake\ndeposit vulnerability.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.06045,regular,pre_llm,2020,6,"{'ai_likelihood': 5.298190646701389e-07, 'text': 'Evaluating the Exploitability of Implicit Interactions in Distributed\n  Systems\n\n  Implicit interactions refer to those interactions among the components of a\nsystem that may be unintended and/or unforeseen by the system designers. As\nsuch, they represent cybersecurity vulnerabilities that can be exploited to\nmount cyber-attacks causing serious and destabilizing system effects. In this\npaper, we study implicit interactions in distributed systems specified using\nthe algebraic modeling framework known as Communicating Concurrent Kleene\nAlgebra (C$^2$KA). To identify and defend against a range of possible attack\nscenarios, we develop a new measure of exploitability for implicit interactions\nto aid in evaluating the threat posed by the existence of such vulnerabilities\nin system designs for launching cyber-attacks. The presented approach is based\non the modeling and analysis of the influence and response of the system agents\nand their C$^2$KA specifications. We also demonstrate the applicability of the\nproposed approach using a prototype tool that supports the automated analysis.\nThe rigorous, practical techniques presented here enable cybersecurity\nvulnerabilities in the designs of distributed systems to be more easily\nidentified, assessed, and then mitigated, offering significant improvements to\noverall system resilience, dependability, and security.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.10972,regular,pre_llm,2020,6,"{'ai_likelihood': 1.5232298109266494e-06, 'text': ""On the Security of Proofs of Sequential Work in a Post-Quantum World\n\n  A Proof of Sequential Work (PoSW) allows a prover to convince a\nresource-bounded verifier that the prover invested a substantial amount of\nsequential time to perform some underlying computation. PoSWs have many\napplications including time-stamping, blockchain design, and universally\nverifiable CPU benchmarks. Mahmoody, Moran, and Vadhan (ITCS 2013) gave the\nfirst construction of a PoSW in the random oracle model though the construction\nrelied on expensive depth-robust graphs. In a recent breakthrough, Cohen and\nPietrzak (EUROCRYPT 2018) gave an efficient PoSW construction that does not\nrequire expensive depth-robust graphs.\n  In the classical parallel random oracle model, it is straightforward to argue\nthat any successful PoSW attacker must produce a long $\\mathcal{H}$-sequence\nand that any malicious party running in sequential time $T-1$ will fail to\nproduce an $\\mathcal{H}$-sequence of length $T$ except with negligible\nprobability. In this paper, we prove that any quantum attacker running in\nsequential time $T-1$ will fail to produce an $\\mathcal{H}$-sequence except\nwith negligible probability -- even if the attacker submits a large batch of\nquantum queries in each round. The proof is substantially more challenging and\nhighlights the power of Zhandry's recent compressed oracle technique (CRYPTO\n2019). We further extend this result to establish post-quantum security of a\nnon-interactive PoSW obtained by applying the Fiat-Shamir transform to Cohen\nand Pietrzak's efficient construction (EUROCRYPT 2018).\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.10289,regular,pre_llm,2020,6,"{'ai_likelihood': 9.934107462565105e-08, 'text': 'On the Design of Chaos-Based S-boxes\n\n  Substitution boxes (S-boxes) are critical nonlinear elements to achieve\ncryptanalytic resistance of modern block and stream ciphers. Given their\nimportance, a rich variety of S-box construction strategies exists. In this\npaper, S-boxes generated by using chaotic functions (CF) are analyzed to\nmeasure their actual resistance to linear cryptanalysis. The aforementioned\npapers emphasize on the average nonlinearity of the S-box coordinates only,\nignoring the rest of the S-box components in the process. Thus, the majority of\nthose studies should be re-evaluated. Integrating such S-boxes in a given\ncryptosystem should be done with a considerable caution. Furthermore, we show\nthat in the context of nonlinearity optimization problem the profit of using\nchaos structures is negligible. By using two heuristic methods and starting\nfrom pseudo-random S-boxes, we repeatedly reached S-boxes, which significantly\noutperform all previously published CF-based S-boxes, in those cryptographic\nterms, which the aforementioned papers utilize for comparison. Moreover, we\nhave linked the multi-armed bandit problem to the problem of maximizing an\nS-box average coordinate nonlinearity value, which further allowed us to reach\nnear-optimal average coordinate nonlinearity values significantly greater than\nthose known in literature.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.1534,regular,pre_llm,2020,6,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Machine Learning Based IoT Intrusion Detection System: An MQTT Case\n  Study (MQTT-IoT-IDS2020 Dataset)\n\n  The Internet of Things (IoT) is one of the main research fields in the\nCybersecurity domain. This is due to (a) the increased dependency on automated\ndevice, and (b) the inadequacy of general purpose Intrusion Detection Systems\n(IDS) to be deployed for special purpose networks usage. Numerous lightweight\nprotocols are being proposed for IoT devices communication usage. One of the\ndistinguishable IoT machine-to-machine communication protocols is Message\nQueuing Telemetry Transport (MQTT) protocol. However, as per the authors best\nknowledge, there are no available IDS datasets that include MQTT benign or\nattack instances and thus, no IDS experimental results available. In this\npaper, the effectiveness of six Machine Learning (ML) techniques to detect\nMQTT-based attacks is evaluated. Three abstraction levels of features are\nassessed, namely, packet-based, unidirectional flow, and bidirectional flow\nfeatures. An MQTT simulated dataset is generated and used for the training and\nevaluation processes. The dataset is released with an open access licence to\nhelp the research community further analyse the accompanied challenges. The\nexperimental results demonstrated the adequacy of the proposed ML models to\nsuit MQTT-based networks IDS requirements. Moreover, the results emphasise on\nthe importance of using flow-based features to discriminate MQTT-based attacks\nfrom benign traffic, while packet-based features are sufficient for traditional\nnetworking attacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.08524,regular,pre_llm,2020,6,"{'ai_likelihood': 9.602970547146267e-07, 'text': 'A Suite of Metrics for Calculating the Most Significant Security\n  Relevant Software Flaw Types\n\n  The Common Weakness Enumeration (CWE) is a prominent list of software\nweakness types. This list is used by vulnerability databases to describe the\nunderlying security flaws within analyzed vulnerabilities. This linkage opens\nthe possibility of using the analysis of software vulnerabilities to identify\nthe most significant weaknesses that enable those vulnerabilities. We\naccomplish this through creating mashup views combining CWE weakness taxonomies\nwith vulnerability analysis data. The resulting graphs have CWEs as nodes,\nedges derived from multiple CWE taxonomies, and nodes adorned with\nvulnerability analysis information (propagated from children to parents). Using\nthese graphs, we develop a suite of metrics to identify the most significant\nweakness types (using the perspectives of frequency, impact, exploitability,\nand overall severity).\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.08817,regular,pre_llm,2020,6,"{'ai_likelihood': 7.947285970052084e-06, 'text': ""BubbleMap: Privilege Mapping for Behavior-based Implicit Authentication\n  Systems\n\n  Leveraging users' behavioral data sampled by various sensors during the\nidentification process, implicit authentication (IA) relieves users from\nexplicit actions such as remembering and entering passwords. Various IA schemes\nhave been proposed based on different behavioral and contextual features such\nas gait, touch, and GPS. However, existing IA schemes suffer from false\npositives, i.e., falsely accepting an adversary, and false negatives, i.e.,\nfalsely rejecting the legitimate user due to users' behavior change and noise.\nTo deal with this problem, we propose BubbleMap (BMap), a framework that can be\nseamlessly incorporated into any existing IA system to balance between security\n(reducing false positives) and usability (reducing false negatives) as well as\nreducing the equal error rate (EER). To evaluate the proposed framework, we\nimplemented BMap on five state-of-the-art IA systems. We also conducted an\nexperiment in a real-world environment from 2016 to 2020. Most of the\nexperimental results show that BMap can greatly enhance the IA schemes'\nperformances in terms of the EER, security, and usability, with a small amount\nof penalty on energy consumption.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.1399,regular,pre_llm,2020,6,"{'ai_likelihood': 3.5762786865234375e-06, 'text': 'WikipediaBot: Automated Adversarial Manipulation of Wikipedia Articles\n\n  This paper presents an automated adversarial mechanism called WikipediaBot.\nWikipediaBot allows an adversary to create and control a bot infrastructure for\nthe purpose of adversarial edits of Wikipedia articles. The WikipediaBot is a\nself-contained mechanism with modules for generating credentials for Wikipedia\neditors, bypassing login protections, and a production of contextually-relevant\nadversarial edits for target Wikipedia articles that evade conventional\ndetection. The contextually-relevant adversarial edits are generated using an\nadversarial Markov chain that incorporates a linguistic manipulation attack\nknown as MIM or malware-induced misperceptions. Because the nefarious use of\nWikipediaBot could result in harmful damages to the integrity of wide range of\nWikipedia articles, we provide an elaborate discussion about the implications,\ndetection, and defenses Wikipedia could employ to address the threat of\nautomated adversarial manipulations and acts of Wikipedia vandalism.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.16374,review,pre_llm,2020,6,"{'ai_likelihood': 2.9802322387695312e-06, 'text': 'Evaluation of Attack Vectors and Risks in Automobiles and Road\n  Infrastructure\n\n  The evolution of smart automobiles and vehicles within the Internet of Things\n(IoT) - particularly as that evolution leads toward a proliferation of\ncompletely autonomous vehicles - has sparked considerable interest in the\nsubject of vehicle/automotive security. While the attack surface is wide, there\nare patterns of exploitable vulnerabilities. In this study we reviewed,\nclassified according to their attack surface, and evaluated some of the common\nvehicle and infrastructure attack vectors identified in the literature. To\nremediate these attack vectors, specific technical recommendations have been\nprovided as a way towards secure deployments of smart automobiles and\ntransportation infrastructures.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.11657,regular,pre_llm,2020,6,"{'ai_likelihood': 6.65585199991862e-06, 'text': ""Securing Smart Home Edge Devices against Compromised Cloud Servers\n\n  Smart home IoT systems often rely on cloud-based servers for communication\nbetween components. Although there exists a body of work on IoT security, most\nof it focuses on securing clients (i.e., IoT devices). However, cloud servers\ncan also be compromised. Existing approaches do not typically protect smart\nhome systems against compromised cloud servers.\n  This paper presents FIDELIUS: a runtime system for secure cloud-based storage\nand communication even in the presence of compromised servers. FIDELIUS's\ndesign is tailored for smart home systems that have intermittent Internet\naccess. In particular, it supports local control of smart home devices in the\nevent that communication with the cloud is lost, and provides a consistency\nmodel using transactions to mitigate inconsistencies that can arise due to\nnetwork partitions. We have implemented FIDELIUS, developed a smart home\nbenchmark that uses FIDELIUS, and measured FIDELIUS's performance and power\nconsumption. Our experiments show that compared to the commercial Particle.io\nframework, FIDELIUS reduces more than 50% of the data communication time and\nincreases battery life by 2X. Compared to PyORAM, an alternative (ORAM-based)\noblivious storage implementation, FIDELIUS has 4-7X faster access times with\n25-43X less data transferred.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.0593,regular,pre_llm,2020,6,"{'ai_likelihood': 5.364418029785156e-06, 'text': 'A Novel Topology-Guided Attack and Its Countermeasure Towards Secure\n  Logic Locking\n\n  The outsourcing of the design and manufacturing of integrated circuits (ICs)\nin the current horizontal semiconductor integration flow has posed various\nsecurity threats due to the presence of untrusted entities, such as\noverproduction of ICs, sale of out-of-specification/rejected ICs, and piracy of\nIntellectual Properties (IPs). Consequently, logic locking emerged as one of\nthe prominent design for trust techniques. Unfortunately, these locking\ntechniques are now inclined to achieve complete Boolean satisfiability (SAT)\nresiliency after the seminal work published in [47]. In this paper, we propose\na novel oracle-less attack that is based on the topological analysis of the\nlocked netlist even though it is SAT-resilient. The attack relies on\nidentifying and constructing unit functions with a hypothesis key to be\nsearched in the entire netlist to find its replica. The proposed graph search\nalgorithm efficiently finds the duplicate functions in the netlist, making it a\nself-referencing attack. This proposed attack is extremely efficient and can\ndetermine the secret key within a few minutes. We have also proposed a\ncountermeasure to make the circuit resilient against this topology-guided\nattack to progress towards a secure logic locking technique.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.13353,regular,pre_llm,2020,6,"{'ai_likelihood': 3.2782554626464844e-06, 'text': 'CacheOut: Leaking Data on Intel CPUs via Cache Evictions\n\n  Recent transient-execution attacks, such as RIDL, Fallout, and ZombieLoad,\ndemonstrated that attackers can leak information while it transits through\nmicroarchitectural buffers. Named Microarchitectural Data Sampling (MDS) by\nIntel, these attacks are likened to ""drinking from the firehose"", as the\nattacker has little control over what data is observed and from what origin.\nUnable to prevent the buffers from leaking, Intel issued countermeasures via\nmicrocode updates that overwrite the buffers when the CPU changes security\ndomains.\n  In this work we present CacheOut, a new microarchitectural attack that is\ncapable of bypassing Intel\'s buffer overwrite countermeasures. We observe that\nas data is being evicted from the CPU\'s L1 cache, it is often transferred back\nto the leaky CPU buffers where it can be recovered by the attacker. CacheOut\nimproves over previous MDS attacks by allowing the attacker to choose which\ndata to leak from the CPU\'s L1 cache, as well as which part of a cache line to\nleak. We demonstrate that CacheOut can leak information across multiple\nsecurity boundaries, including those between processes, virtual machines, user\nand kernel space, and from SGX enclaves.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.15344,regular,pre_llm,2020,6,"{'ai_likelihood': 1.4901161193847656e-06, 'text': 'Utilising Deep Learning Techniques for Effective Zero-Day Attack\n  Detection\n\n  Machine Learning (ML) and Deep Learning (DL) have been used for building\nIntrusion Detection Systems (IDS). The increase in both the number and sheer\nvariety of new cyber-attacks poses a tremendous challenge for IDS solutions\nthat rely on a database of historical attack signatures. Therefore, the\nindustrial pull for robust IDSs that are capable of flagging zero-day attacks\nis growing. Current outlier-based zero-day detection research suffers from high\nfalse-negative rates, thus limiting their practical use and performance. This\npaper proposes an autoencoder implementation for detecting zero-day attacks.\nThe aim is to build an IDS model with high recall while keeping the miss rate\n(false-negatives) to an acceptable minimum. Two well-known IDS datasets are\nused for evaluation-CICIDS2017 and NSL-KDD. In order to demonstrate the\nefficacy of our model, we compare its results against a One-Class Support\nVector Machine (SVM). The manuscript highlights the performance of a One-Class\nSVM when zero-day attacks are distinctive from normal behaviour. The proposed\nmodel benefits greatly from autoencoders encoding-decoding capabilities. The\nresults show that autoencoders are well-suited at detecting complex zero-day\nattacks. The results demonstrate a zero-day detection accuracy of [89-99%] for\nthe NSL-KDD dataset and [75-98%] for the CICIDS2017 dataset. Finally, the paper\noutlines the observed trade-off between recall and fallout.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.0999,review,pre_llm,2020,6,"{'ai_likelihood': 3.311369154188368e-08, 'text': 'ZKPs: Does This Make The Cut? Recent Advances and Success of\n  Zero-Knowledge Security Protocols\n\n  How someone can get health insurance without sharing his health information?\nHow you can get a loan without disclosing your credit score? There is a method\nto certify certain attributes of various data, either this is health metrics or\nfinance information, without revealing the data itself or any other kind of\npersonal data. This method is known as zero-knowledge proofs. Zero-Knowledge\ntechniques are mathematical methods used to verify things without sharing or\nrevealing underlying data. Zero-Knowledge protocols have vast applications from\nsimple identity schemes and blockchains to defense research programs and\nnuclear arms control\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.15272,regular,pre_llm,2020,6,"{'ai_likelihood': 1.158979203965929e-06, 'text': ""Software Enabled Security Architecture for Counteracting Attacks in\n  Control Systems\n\n  Increasingly Industrial Control Systems (ICS) systems are being connected to\nthe Internet to minimise the operational costs and provide additional\nflexibility. These control systems such as the ones used in power grids,\nmanufacturing and utilities operate continually and have long lifespans\nmeasured in decades rather than years as in the case of IT systems. Such\nindustrial control systems require uninterrupted and safe operation. However,\nthey can be vulnerable to a variety of attacks, as successful attacks on\ncritical control infrastructures could have devastating consequences to the\nsafety of human lives as well as a nation's security and prosperity.\nFurthermore, there can be a range of attacks that can target ICS and it is not\neasy to secure these systems against all known attacks let alone unknown ones.\nIn this paper, we propose a software enabled security architecture using\nSoftware Defined Networking (SDN) and Network Function Virtualisation (NFV)\nthat can enhance the capability to secure industrial control systems. We have\ndesigned such an SDN/NFV enabled security architecture and developed a Control\nSystem Security Application (CSSA) in SDN Controller for enhancing security in\nICS against certain specific attacks namely denial of service attacks, from\nunpatched vulnerable control system components and securing the communication\nflows from the legacy devices that do not support any security functionality.\nIn this paper, we discuss the prototype implementation of the proposed\narchitecture and the results obtained from our analysis.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.10196,regular,pre_llm,2020,6,"{'ai_likelihood': 2.086162567138672e-06, 'text': 'MBTree: Detecting Encryption RAT Communication Using Malicious Behavior\n  Tree\n\n  Network trace signature matching is one reliable approach to detect active\nRemote Control Trojan, (RAT). Compared to statistical-based detection of\nmalicious network traces in the face of known RATs, the signature-based method\ncan achieve more stable performance and thus more reliability. However, with\nthe development of encrypted technologies and disguise tricks, current methods\nsuffer inaccurate signature descriptions and inflexible matching mechanisms. In\nthis paper, we propose to tackle above problems by presenting MBTree, an\napproach to detect encryption RATs Command and Control (C&C) communication\nbased on host-level network trace behavior. MBTree first models the RAT network\nbehaviors as the malicious set by automatically building the multiple level\ntree, MLTree from distinctive network traces of each sample. Then, MBTree\nemploys a detection algorithm to detect malicious network traces that are\nsimilar to any MLTrees in the malicious set. To illustrate the effectiveness of\nour proposed method, we adopt theoretical analysis of MBTree from the\nprobability perspective. In addition, we have implemented MBTree to evaluate it\non five datasets which are reorganized in a sophisticated manner for\ncomprehensive assessment. The experimental results demonstrate the accurate and\nrobust of MBTree, especially in the face of new emerging benign applications.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.16714,regular,pre_llm,2020,6,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Bitcoin Covenants: Three Ways to Control the Future\n\n  A bitcoin covenant is a mechanism to enforce conditions on how the control of\ncoins will be transferred in the future. This work introduces deleted-key\ncovenants; using pre-signed transactions with secure key deletion. With this, a\ngeneral class of covenants are possible without introducing new security risks\nto bitcoin. There is a range of security models for the key deletion process,\nbut this is subject to a security-convenience trade-off and requires\ninteractivity in a multi-party context. On the other hand, this work makes a\ncompelling case for what can be gained through a soft-fork upgrade to the\nsignature hash system [Dec17] which enables recovered-key covenants through\nelliptic curve key recovery. This has similar properties to script-based\ncovenant mechanisms proposed previously [Rub20]. Key factors are discussed and\ncompared for the three covenant mechanisms, including; the enforcement process,\nmethods for proving accessibility of funds and whether or not they are bound by\na covenant, methods for dynamic fee allocation, the underlying cryptographic\nassumptions, and their feasibility in single-party, hierarchical and\nadversarial multi-party contexts. Despite the relative downsides of deleted-key\ncovenants, they are a practical tool for custody protocol design. The\ncomparison shows precisely how soft-fork proposals improve the practicality of\nbitcoin covenants, through non-interactive enforcement and tighter\ncryptographic assumptions, to enhance custody protocols and enable some\nadversarial applications such as payment protocols.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.16554,review,pre_llm,2020,6,"{'ai_likelihood': 3.311369154188368e-06, 'text': 'Security Issues of Low Power Wide Area Networks in the Context of LoRa\n  Networks\n\n  Low Power Wide Area Networks (LPWAN) have been used to support low cost and\nmobile bi-directional communications for the Internet of Things (IoT), smart\ncity and a wide range of industrial applications. A primary security concern of\nLPWAN technology is the attacks that block legitimate communication between\nnodes resulting in scenarios like loss of packets, delayed packet arrival, and\nskewed packet reaching the reporting gateway. LoRa (Long Range) is a promising\nwireless radio access technology that supports long-range communication at low\ndata rates and low power consumption. LoRa is considered as one of the ideal\ncandidates for building LPWANs. We use LoRa as a reference technology to review\nthe IoT security threats on the air and the applicability of different\ncountermeasures that have been adopted so far. LoRa nodes that are close to the\ngateway use a small SF than the nodes which are far away. But it also implies\nlong in-the-air transmission time, which makes the transmitted packets\nvulnerable to different kinds of malicious attacks, especially in the physical\nand the link layer. Therefore, it is not possible to enforce a fixed set of\nrules for all LoRa nodes since they have different levels of vulnerabilities.\nOur survey reveals that there is an urgent need for secure and uninterrupted\ncommunication between an end-device and the gateway, especially when the threat\nmodels are unknown in advance. We explore the traditional countermeasures and\nfind that most of them are ineffective now, such as frequency hopping and\nspread spectrum methods. In order to adapt to new threats, the emerging\ncountermeasures using game-theoretic approaches and reinforcement machine\nlearning methods can effectively identify threats and dynamically choose the\ncorresponding actions to resist threats, thereby making secured and reliable\ncommunications.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.08249,regular,pre_llm,2020,6,"{'ai_likelihood': 3.543164994981554e-06, 'text': ""The EMV Standard: Break, Fix, Verify\n\n  EMV is the international protocol standard for smartcard payment and is used\nin over 9 billion cards worldwide. Despite the standard's advertised security,\nvarious issues have been previously uncovered, deriving from logical flaws that\nare hard to spot in EMV's lengthy and complex specification, running over 2,000\npages. We formalize a comprehensive symbolic model of EMV in Tamarin, a\nstate-of-the-art protocol verifier. Our model is the first that supports a\nfine-grained analysis of all relevant security guarantees that EMV is intended\nto offer. We use our model to automatically identify flaws that lead to two\ncritical attacks: one that defrauds the cardholder and a second that defrauds\nthe merchant. First, criminals can use a victim's Visa contactless card to make\npayments for amounts that require cardholder verification, without knowledge of\nthe card's PIN. We built a proof-of-concept Android application and\nsuccessfully demonstrated this attack on real-world payment terminals. Second,\ncriminals can trick the terminal into accepting an unauthentic offline\ntransaction, which the issuing bank should later decline, after the criminal\nhas walked away with the goods. This attack is possible for implementations\nfollowing the standard, although we did not test it on actual terminals for\nethical reasons. Finally, we propose and verify improvements to the standard\nthat prevent these attacks, as well as any other attacks that violate the\nconsidered security properties. The proposed improvements can be easily\nimplemented in the terminals and do not affect the cards in circulation.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2006.13598,review,pre_llm,2020,6,"{'ai_likelihood': 8.940696716308594e-07, 'text': 'A Survey of Published Attacks on Intel SGX\n\n  Intel Software Guard Extensions (SGX) provides a trusted execution\nenvironment (TEE) to run code and operate sensitive data. SGX provides runtime\nhardware protection where both code and data are protected even if other code\ncomponents are malicious. However, recently many attacks targeting SGX have\nbeen identified and introduced that can thwart the hardware defence provided by\nSGX. In this paper we present a survey of all attacks specifically targeting\nIntel SGX that are known to the authors, to date. We categorized the attacks\nbased on their implementation details into 7 different categories. We also look\ninto the available defence mechanisms against identified attacks and categorize\nthe available types of mitigations for each presented attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.04086,regular,pre_llm,2020,7,"{'ai_likelihood': 5.298190646701389e-07, 'text': 'Green-PoW: An Energy-Efficient Blockchain Proof-of-Work Consensus\n  Algorithm\n\n  This paper opts to mitigate the energy-inefficiency of the Blockchain\nProof-of-Work (PoW) consensus algorithm by rationally repurposing the power\nspent during the mining process. The original PoW mining scheme is designed to\nconsider one block at a time and assign a reward to the first place winner of a\ncomputation race. To reduce the mining-related energy consumption, we propose\nto compensate the computation effort of the runner(s)-up of a mining round, by\ngranting them exclusivity of solving the upcoming block in the next round. This\nwill considerably reduce the number of competing nodes in the next round and\nconsequently, the consumed energy. Our proposed scheme divides time into\nepochs, where each comprises two mining rounds; in the first one, all network\nnodes can participate in the mining process, whereas in the second round only\nrunners-up can take part. Thus, the overall mining energy consumption can be\nreduced to nearly $50\\%$. To the best of our knowledge, our proposed scheme is\nthe first to considerably improve the energy consumption of the original PoW\nalgorithm. Our analysis demonstrates the effectiveness of our scheme in\nreducing energy consumption, the probability of fork occurrences, the level of\nmining centralization presented in the original PoW algorithm, and the effect\nof transaction censorship attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.08041,review,pre_llm,2020,7,"{'ai_likelihood': 1.205338372124566e-05, 'text': ""A Survey on Security Attacks and Defense Techniques for Connected and\n  Autonomous Vehicles\n\n  Autonomous Vehicle has been transforming intelligent transportation systems.\nAs telecommunication technology improves, autonomous vehicles are getting\nconnected to each other and to infrastructures, forming Connected and\nAutonomous Vehicles (CAVs). CAVs will help humans achieve safe, efficient, and\nautonomous transportation systems. However, CAVs will face significant security\nchallenges because many of their components are vulnerable to attacks, and a\nsuccessful attack on a CAV may have significant impacts on other CAVs and\ninfrastructures due to their communications. In this paper, we conduct a survey\non 184 papers from 2000 to 2020 to understand state-of-the-art CAV attacks and\ndefense techniques. This survey first presents a comprehensive overview of\nsecurity attacks and their corresponding countermeasures on CAVs. We then\ndiscuss the details of attack models based on the targeted CAV components of\nattacks, access requirements, and attack motives. Finally, we identify some\ncurrent research challenges and trends from the perspectives of both academic\nresearch and industrial development. Based on our studies of academic\nliterature and industrial publications, we have not found any strong connection\nbetween academic research and industry's implementation on CAV-related security\nissues. While efforts from CAV manufacturers to secure CAVs have been reported,\nthere is no evidence to show that CAVs on the market have the ability to defend\nagainst some novel attack models that the research community has recently\nfound. This survey may give researchers and engineers a better understanding of\nthe current status and trend of CAV security for CAV future improvement.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.09588,regular,pre_llm,2020,7,"{'ai_likelihood': 1.986821492513021e-06, 'text': ""PUF-RLA: A PUF-based Reliable and Lightweight Authentication Protocol\n  employing Binary String Shuffling\n\n  Physically unclonable functions (PUFs) can be employed for device\nidentification, authentication, secret key storage, and other security tasks.\nHowever, PUFs are susceptible to modeling attacks if a number of PUFs'\nchallenge-response pairs (CRPs) are exposed to the adversary. Furthermore, many\nof the embedded devices requiring authentication have stringent resource\nconstraints and thus require a lightweight authentication mechanism. We propose\nPUF-RLA, a PUF-based lightweight, highly reliable authentication scheme\nemploying binary string shuffling. The proposed scheme enhances the reliability\nof PUF as well as alleviates the resource constraints by employing error\ncorrection in the server instead of the device without compromising the\nsecurity. The proposed PUF-RLA is robust against brute force, replay, and\nmodeling attacks. In PUF-RLA, we introduce an inexpensive yet secure stream\nauthentication scheme inside the device which authenticates the server before\nthe underlying PUF can be invoked. This prevents an adversary from brute\nforcing the device's PUF to acquire CRPs essentially locking out the device\nfrom unauthorized model generation. Additionally, we also introduce a\nlightweight CRP obfuscation mechanism involving XOR and shuffle operations.\nResults and security analysis verify that the PUF-RLA is secure against brute\nforce, replay, and modeling attacks, and provides ~99% reliable authentication.\nIn addition, PUF-RLA provides a reduction of 63% and 74% for look-up tables\n(LUTs) and register count, respectively, in FPGA compared to a recently\nproposed approach while providing additional authentication advantages.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.14916,regular,pre_llm,2020,7,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Boardroom Voting: Verifiable Voting with Ballot Privacy Using Low-Tech\n  Cryptography in a Single Room\n\n  A boardroom election is an election that takes place in a single room -- the\nboardroom -- in which all voters can see and hear each other. We present an\ninitial exploration of boardroom elections with ballot privacy and voter\nverifiability that use only ""low-tech cryptography"" without using computers to\nmark or collect ballots. Specifically, we define the problem, introduce several\nbuilding blocks, and propose a new protocol that combines these blocks in novel\nways. Our new building blocks include ""foldable ballots"" that can be rotated to\nhide the alignment of ballot choices with voting marks, and ""visual secrets""\nthat are easy to remember and use but hard to describe. Although closely seated\nparticipants in a boardroom election have limited privacy, the protocol ensures\nthat no one can determine how others voted. Moreover, each voter can verify\nthat their ballot was correctly cast, collected, and counted, without being\nable to prove how they voted, providing assurance against undue influence.\nLow-tech cryptography is useful in situations where constituents do not trust\ncomputer technology, and it avoids the complex auditing requirements of\nend-to-end cryptographic voting systems such as Pr\\^{e}t-\\`{a}-Voter. This\npaper\'s building blocks and protocol are meant to be a proof of concept that\nmight be tested for usability and improved.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.08296,regular,pre_llm,2020,7,"{'ai_likelihood': 0.0, 'text': ""Deep ahead-of-threat virtual patching\n\n  Many applications have security vulnerabilities that can be exploited. It is\npractically impossible to find all of them due to the NP-complete nature of the\ntesting problem. Security solutions provide defenses against these attacks\nthrough continuous application testing, fast-patching of vulnerabilities,\nautomatic deployment of patches, and virtual patching detection techniques\ndeployed in network and endpoint security tools. These techniques are limited\nby the need to find vulnerabilities before the black-hats. We propose an\ninnovative technique to virtually patch vulnerabilities before they are found.\nWe leverage testing techniques for supervised-learning data generation, and\nshow how artificial intelligence techniques can use this data to create\npredictive deep neural-network models that read an application's input and\npredict in real time whether it is a potential malicious input. We set up an\nahead-of-threat experiment in which we generated data on old versions of an\napplication, and then evaluated the predictive model accuracy on\nvulnerabilities found years later. Our experiments show ahead-of-threat\ndetection on LibXML2 and LibTIFF vulnerabilities with 91.3% and 93.7% accuracy,\nrespectively. We expect to continue work on this field of research and provide\nahead-of-threat virtual patching for more libraries. Success in this research\ncan change the current state of endless racing after application\nvulnerabilities and put the defenders one step ahead of the attackers\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.04025,regular,pre_llm,2020,7,"{'ai_likelihood': 4.371007283528646e-06, 'text': ""Privacy and Integrity Preserving Computations with CRISP\n\n  In the digital era, users share their personal data with service providers to\nobtain some utility, e.g., access to high-quality services. Yet, the induced\ninformation flows raise privacy and integrity concerns. Consequently, cautious\nusers may want to protect their privacy by minimizing the amount of information\nthey disclose to curious service providers. Service providers are interested in\nverifying the integrity of the users' data to improve their services and obtain\nuseful knowledge for their business. In this work, we present a generic\nsolution to the trade-off between privacy, integrity, and utility, by achieving\nauthenticity verification of data that has been encrypted for offloading to\nservice providers. Based on lattice-based homomorphic encryption and\ncommitments, as well as zero-knowledge proofs, our construction enables a\nservice provider to process and reuse third-party signed data in a\nprivacy-friendly manner with integrity guarantees. We evaluate our solution on\ndifferent use cases such as smart-metering, disease susceptibility, and\nlocation-based activity tracking, thus showing its versatility. Our solution\nachieves broad generality, quantum-resistance, and relaxes some assumptions of\nstate-of-the-art solutions without affecting performance.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.13639,regular,pre_llm,2020,7,"{'ai_likelihood': 3.0795733133951826e-06, 'text': ""Don't Fish in Troubled Waters! Characterizing Coronavirus-themed\n  Cryptocurrency Scams\n\n  As COVID-19 has been spreading across the world since early 2020, a growing\nnumber of malicious campaigns are capitalizing the topic of COVID-19. COVID-19\nthemed cryptocurrency scams are increasingly popular during the pandemic.\nHowever, these newly emerging scams are poorly understood by our community. In\nthis paper, we present the first measurement study of COVID-19 themed\ncryptocurrency scams. We first create a comprehensive taxonomy of COVID-19\nscams by manually analyzing the existing scams reported by users from online\nresources. Then, we propose a hybrid approach to perform the investigation by:\n1) collecting reported scams in the wild; and 2) detecting undisclosed ones\nbased on information collected from suspicious entities (e.g., domains, tweets,\netc). We have collected 195 confirmed COVID-19 cryptocurrency scams in total,\nincluding 91 token scams, 19 giveaway scams, 9 blackmail scams, 14 crypto\nmalware scams, 9 Ponzi scheme scams, and 53 donation scams. We then identified\nover 200 blockchain addresses associated with these scams, which lead to at\nleast 330K US dollars in losses from 6,329 victims. For each type of scams, we\nfurther investigated the tricks and social engineering techniques they used. To\nfacilitate future research, we have released all the well-labelled scams to the\nresearch community.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.00349,regular,pre_llm,2020,7,"{'ai_likelihood': 2.086162567138672e-06, 'text': ""DEMO: BTLEmap: Nmap for Bluetooth Low Energy\n\n  The market for Bluetooth Low Energy devices is booming and, at the same time,\nhas become an attractive target for adversaries. To improve BLE security at\nlarge, we present BTLEmap, an auditing application for BLE environments.\nBTLEmap is inspired by network discovery and security auditing tools such as\nNmap for IP-based networks. It allows for device enumeration, GATT service\ndiscovery, and device fingerprinting. It goes even further by integrating a BLE\nadvertisement dissector, data exporter, and a user-friendly UI, including a\nproximity view. BTLEmap currently runs on iOS and macOS using Apple's\nCoreBluetooth API but also accepts alternative data inputs such as a Raspberry\nPi to overcome the restricted vendor API. The open-source project is under\nactive development and will provide more advanced capabilities such as\nlong-term device tracking (in spite of MAC address randomization) in the\nfuture.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.0355,regular,pre_llm,2020,7,"{'ai_likelihood': 3.973642985026042e-07, 'text': ""Detile: Fine-Grained Information Leak Detection in Script Engines\n\n  Memory disclosure attacks play an important role in the exploitation of\nmemory corruption vulnerabilities. By analyzing recent research, we observe\nthat bypasses of defensive solutions that enforce control-flow integrity or\nattempt to detect return-oriented programming require memory disclosure attacks\nas a fundamental first step. However, research lags behind in detecting such\ninformation leaks.\n  In this paper, we tackle this problem and present a system for fine-grained,\nautomated detection of memory disclosure attacks against scripting engines. The\nbasic insight is as follows: scripting languages, such as JavaScript in web\nbrowsers, are strictly sandboxed. They must not provide any insights about the\nmemory layout in their contexts. In fact, any such information potentially\nrepresents an ongoing memory disclosure attack. Hence, to detect information\nleaks, our system creates a clone of the scripting engine process with a\nre-randomized memory layout. The clone is instrumented to be synchronized with\nthe original process. Any inconsistency in the script contexts of both\nprocesses appears when a memory disclosure was conducted to leak information\nabout the memory layout. Based on this detection approach, we have designed and\nimplemented Detile (\\underline{det}ection of \\underline{i}nformation\n\\underline{le}aks), a prototype for the JavaScript engine in Microsoft's\nInternet Explorer 10/11 on Windows 8.0/8.1. An empirical evaluation shows that\nour tool can successfully detect memory disclosure attacks even against this\nproprietary software.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.01029,regular,pre_llm,2020,7,"{'ai_likelihood': 1.026524437798394e-06, 'text': 'Hunting for Re-Entrancy Attacks in Ethereum Smart Contracts via Static\n  Analysis\n\n  Ethereum smart contracts are programs that are deployed and executed in a\nconsensus-based blockchain managed by a peer-to-peer network. Several\nre-entrancy attacks that aim to steal Ether, the cryptocurrency used in\nEthereum, stored in deployed smart contracts have been found in the recent\nyears. A countermeasure to such attacks is based on dynamic analysis that\nexecutes the smart contracts themselves, but it requires the spending of Ether\nand knowledge of attack patterns for analysis in advance. In this paper, we\npresent a static analysis tool named \\textit{RA (Re-entrancy Analyzer)}, a\ncombination of symbolic execution and equivalence checking by a satisfiability\nmodulo theories solver to analyze smart contract vulnerabilities to re-entrancy\nattacks. In contrast to existing tools, RA supports analysis of inter-contract\nbehaviors by using only the Etherum Virtual Machine bytecodes of target smart\ncontracts, i.e., even without prior knowledge of attack patterns and without\nspending Ether. Furthermore, RA can verify existence of vulnerabilities to\nre-entrancy attacks without execution of smart contracts and it does not\nprovide false positives and false negatives. We also present an implementation\nof RA to evaluate its performance in analyzing the vulnerability of deployed\nsmart contracts to re-entrancy attacks and show that RA can precisely determine\nwhich smart contracts are vulnerable.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.10513,regular,pre_llm,2020,7,"{'ai_likelihood': 2.317958407931858e-07, 'text': 'Confidential Attestation: Efficient in-Enclave Verification of Privacy\n  Policy Compliance\n\n  A trusted execution environment (TEE) such as Intel Software Guard Extension\n(SGX) runs a remote attestation to prove to a data owner the integrity of the\ninitial state of an enclave, including the program to operate on her data. For\nthis purpose, the data-processing program is supposed to be open to the owner,\nso its functionality can be evaluated before trust can be established. However,\nincreasingly there are application scenarios in which the program itself needs\nto be protected. So its compliance with privacy policies as expected by the\ndata owner should be verified without exposing its code.\n  To this end, this paper presents CAT, a new model for TEE-based confidential\nattestation. Our model is inspired by Proof-Carrying Code, where a code\ngenerator produces proof together with the code and a code consumer verifies\nthe proof against the code on its compliance with security policies. Given that\nthe conventional solutions do not work well under the resource-limited and\nTCB-frugal TEE, we propose a new design that allows an untrusted out-enclave\ngenerator to analyze the source code of a program when compiling it into binary\nand a trusted in-enclave consumer efficiently verifies the correctness of the\ninstrumentation and the presence of other protection before running the binary.\nOur design strategically moves most of the workload to the code generator,\nwhich is responsible for producing well-formatted and easy-to-check code, while\nkeeping the consumer simple. Also, the whole consumer can be made public and\nverified through a conventional attestation. We implemented this model on Intel\nSGX and demonstrate that it introduces a very small part of TCB. We also\nthoroughly evaluated its performance on micro- and macro- benchmarks and\nreal-world applications, showing that the new design only incurs a small\noverhead when enforcing several categories of security policies.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.06353,review,pre_llm,2020,7,"{'ai_likelihood': 8.609559800889757e-07, 'text': 'Puncturable Encryption: A Generic Construction from Delegatable Fully\n  Key-Homomorphic Encryption\n\n  Puncturable encryption (PE), proposed by Green and Miers at IEEE S&P 2015, is\na kind of public key encryption that allows recipients to revoke individual\nmessages by repeatedly updating decryption keys without communicating with\nsenders. PE is an essential tool for constructing many interesting\napplications, such as asynchronous messaging systems, forward-secret zero\nround-trip time protocols, public-key watermarking schemes and forward-secret\nproxy re-encryptions. This paper revisits PEs from the observation that the\npuncturing property can be implemented as efficiently computable functions.\nFrom this view, we propose a generic PE construction from the fully\nkey-homomorphic encryption, augmented with a key delegation mechanism (DFKHE)\nfrom Boneh et al. at Eurocrypt 2014. We show that our PE construction enjoys\nthe selective security under chosen plaintext attacks (that can be converted\ninto the adaptive security with some efficiency loss) from that of DFKHE in the\nstandard model. Basing on the framework, we obtain the first post-quantum\nsecure PE instantiation that is based on the learning with errors problem,\nselective secure under chosen plaintext attacks (CPA) in the standard model. We\nalso discuss about the ability of modification our framework to support the\nunbounded number of ciphertext tags inspired from the work of Brakerski and\nVaikuntanathan at CRYPTO 2016.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.15881,regular,pre_llm,2020,7,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""Password-authenticated Decentralized Identities\n\n  Password-authenticated identities, where users establish username-password\npairs with individual servers and use them later on for authentication, is the\nmost widespread user authentication method over the Internet. Although they are\nsimple, user-friendly, and broadly adopted, they offer insecure authentication\nand position server operators as trusted parties, giving them full control over\nusers' identities. To mitigate these limitations, many identity systems have\nembraced public-key cryptography and the concept of decentralization. All these\nsystems, however, require users to create and manage public-private keypairs.\nUnfortunately, users usually do not have the required knowledge and resources\nto properly handle their cryptographic secrets, which arguably contributed to\nfailures of many end-user-focused public-key infrastructures (PKIs). In fact,\nas for today, no end-user PKI, able to authenticate users to web servers, has a\nsignificant adoption rate.\n  In this paper, we propose Password-authenticated Decentralized Identities\n(PDIDs), an identity and authentication framework where users can register\ntheir self-sovereign username-password pairs and use them as universal\ncredentials. Our system provides global namespace, human-meaningful usernames,\nand resilience against username collision attacks. A user's identity can be\nused to authenticate the user to any server without revealing that server\nanything about the password, such that no offline dictionary attacks are\npossible against the password. We analyze PDIDs and implement it using existing\ninfrastructures and tools. We report on our implementation and evaluation.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.01648,regular,pre_llm,2020,7,"{'ai_likelihood': 1.1920928955078125e-06, 'text': 'Fast Arithmetic Hardware Library For RLWE-Based Homomorphic Encryption\n\n  In this work, we propose an open-source, first-of-its-kind, arithmetic\nhardware library with a focus on accelerating the arithmetic operations\ninvolved in Ring Learning with Error (RLWE)-based somewhat homomorphic\nencryption (SHE). We design and implement a hardware accelerator consisting of\nsubmodules like Residue Number System (RNS), Chinese Remainder Theorem (CRT),\nNTT-based polynomial multiplication, modulo inverse, modulo reduction, and all\nthe other polynomial and scalar operations involved in SHE. For all of these\noperations, wherever possible, we include a hardware-cost efficient serial and\na fast parallel implementation in the library. A modular and parameterized\ndesign approach helps in easy customization and also provides flexibility to\nextend these operations for use in most homomorphic encryption applications\nthat fit well into emerging FPGA-equipped cloud architectures. Using the\nsubmodules from the library, we prototype a hardware accelerator on FPGA. The\nevaluation of this hardware accelerator shows a speed up of approximately 4200x\nand 2950x to evaluate a homomorphic multiplication and addition respectively\nwhen compared to an existing software implementation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.15759,regular,pre_llm,2020,7,"{'ai_likelihood': 5.298190646701389e-06, 'text': 'The Program with a Personality: Analysis of Elk Cloner, the First\n  Personal Computer Virus\n\n  Although self-replicating programs and viruses have existed since the 1960s\nand 70s, Elk Cloner was the first virus to circulate among personal computers\nin the wild. Despite its historical significance, it received comparatively\nlittle attention when it first appeared in 1982. In this paper, we: present the\nfirst detailed examination of the operation and structure of Elk Cloner;\ndiscuss the effect of environmental characteristics on its virulence; and\nprovide supporting evidence for several hypotheses about why its release was\nlargely ignored in the early 1980s.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.06751,regular,pre_llm,2020,7,"{'ai_likelihood': 6.622738308376736e-08, 'text': ""SESAME: Software defined Enclaves to Secure Inference Accelerators with\n  Multi-tenant Execution\n\n  Hardware-enclaves that target complex CPU designs compromise both security\nand performance. Programs have little control over micro-architecture, which\nleads to side-channel leaks, and then have to be transformed to have worst-case\ncontrol- and data-flow behaviors and thus incur considerable slowdown. We\npropose to address these security and performance problems by bringing enclaves\ninto the realm of accelerator-rich architectures. The key idea is to construct\nsoftware-defined enclaves (SDEs) where the protections and slowdown are tied to\nan application-defined threat model and tuned by a compiler for the\naccelerator's specific domain. This vertically integrated approach requires new\nhardware data-structures to partition, clear, and shape the utilization of\nhardware resources; and a compiler that instantiates and schedules these\ndata-structures to create multi-tenant enclaves on accelerators. We demonstrate\nour ideas with a comprehensive prototype -- Sesame -- that includes\nmodifications to compiler, ISA, and microarchitecture to a decoupled access\nexecute (DAE) accelerator framework for deep learning models. Our security\nevaluation shows that classifiers that could distinguish different layers in\nVGG, ResNet, and AlexNet, fail to do so when run using Sesame. Our\nsynthesizable hardware prototype (on a Xilinx Pynq board) demonstrates how the\ncompiler and micro-architecture enables threat-model-specific trade-offs in\ncode size increase ranging from 3-7 $\\%$ and run-time performance overhead for\nspecific defenses ranging from 3.96$\\%$ to 34.87$\\%$ (across confidential\ninputs and models and single vs. multi-tenant systems).\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.03548,regular,pre_llm,2020,7,"{'ai_likelihood': 5.198849572075738e-06, 'text': 'Breaking and Fixing Destructive Code Read Defenses\n\n  Just-in-time return-oriented programming (JIT-ROP) is a powerful memory\ncorruption attack that bypasses various forms of code randomization.\nExecute-only memory (XOM) can potentially prevent these attacks, but requires\nsource code. In contrast, destructive code reads (DCR) provide a trade-off\nbetween security and legacy compatibility. The common belief is that DCR\nprovides strong protection if combined with a high-entropy code randomization.\n  The contribution of this paper is twofold: first, we demonstrate that DCR can\nbe bypassed regardless of the underlying code randomization scheme. To this\nend, we show novel, generic attacks that infer the code layout for highly\nrandomized program code. Second, we present the design and implementation of\nBGDX (Byte-Granular DCR and XOM), a novel mitigation technique that protects\nlegacy binaries against code inference attacks. BGDX enforces memory\npermissions on a byte-granular level allowing us to combine DCR and XOM for\nlegacy, off-the-shelf binaries. Our evaluation shows that BGDX is not only\neffective, but highly efficient, imposing only a geometric mean performance\noverhead of 3.95% on SPEC.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.10755,regular,pre_llm,2020,7,"{'ai_likelihood': 6.821420457628038e-06, 'text': 'Authentication against Man-in-the-Middle Attack with a Time-variant\n  Reconfigurable Dual-LFSR-based Arbiter PUF\n\n  With the expansion of the Internet of Things industry, the information\nsecurity of Internet of Things devices attracts much attention. Traditional\nencryption algorithms require sensitive information such as keys to be stored\nin memory, and also need the support of operating system, which is obviously\nunacceptable for resource-constrained Internet of Things terminals. Physical\nnot cloning function by extracting the chip is inevitable in the process of\nmanufacturing process deviation, the introduction of the corresponding function\nrelationship between incentive and response, not to need the storage user\nsensitive information, and only when electricity will respond, in power\nresponse immediately disappear, this can save a lot of resources of equipment\nand the power consumption. However, PUF is vulnerable to modeling attacks, and\nthe traditional methods such as the challenge obfuscation method are\ntime-invariant, which is equivalent to adding a fixed function to the front\nstage of a traditional APUF circuit. Therefore, it can be potentially modelling\nattacked with sufficient CRPs. In order to further enhance APUF circuit\nresistance to modelling attack, this paper proposes a dual-LFSR-based APUF\ncircuit with time-variant challenge obfuscation. Besides, traditional\nauthentication scheme generally adopts the one-time key scheme to enhance\nresistance to man-in-the-middle attack. The two-time authentication scheme\nproposed in this paper can improve the ability of RFID system to resist\nman-in-the-middle attack without sacrificing CRPs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.02314,regular,pre_llm,2020,7,"{'ai_likelihood': 1.357661353217231e-06, 'text': 'Static Detection of Uninitialized Stack Variables in Binary Code\n\n  More than two decades after the first stack smashing attacks, memory\ncorruption vulnerabilities utilizing stack anomalies are still prevalent and\nplay an important role in practice. Among such vulnerabilities, uninitialized\nvariables play an exceptional role due to their unpleasant property of\nunpredictability: as compilers are tailored to operate fast, costly\ninterprocedural analysis procedures are not used in practice to detect such\nvulnerabilities. As a result, complex relationships that expose uninitialized\nmemory reads remain undiscovered in binary code. Recent vulnerability reports\nshow the versatility on how uninitialized memory reads are utilized in\npractice, especially for memory disclosure and code execution. Research in\nrecent years proposed detection and prevention techniques tailored to source\ncode. To date, however, there has not been much attention for these types of\nsoftware bugs within binary executables.\n  In this paper, we present a static analysis framework to find uninitialized\nvariables in binary executables. We developed methods to lift the binaries into\na knowledge representation which builds the base for specifically crafted\nalgorithms to detect uninitialized reads. Our prototype implementation is\ncapable of detecting uninitialized memory errors in complex binaries such as\nweb browsers and OS kernels, and we detected 7 novel bugs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2007.00826,regular,pre_llm,2020,7,"{'ai_likelihood': 1.986821492513021e-07, 'text': ""Secret Sharing MPC on FPGAs in the Datacenter\n\n  Multi-Party Computation (MPC) is a technique enabling data from several\nsources to be used in a secure computation revealing only the result while\nprotecting the original data, facilitating shared utilization of data sets\ngathered by different entities. The presence of Field Programmable Gate Array\n(FPGA) hardware in datacenters can provide accelerated computing as well as low\nlatency, high bandwidth communication that bolsters the performance of MPC and\nlowers the barrier to using MPC for many applications. In this work, we propose\na Secret Sharing FPGA design based on the protocol described by Araki et al. We\ncompare our hardware design to the original authors' software implementations\nof Secret Sharing and to work accelerating MPC protocols based on Garbled\nCircuits with FPGAs. Our conclusion is that Secret Sharing in the datacenter is\ncompetitive and when implemented on FPGA hardware was able to use at least\n10$\\times$ fewer computer resources than the original work using CPUs.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.06747,regular,pre_llm,2020,8,"{'ai_likelihood': 3.874301910400391e-06, 'text': 'Smart Voltage Monitoring: Centralised and Blockchain-based Decentralised\n  Approach\n\n  Voltage controls the majority of the processes around us, starting from\nlighting an incandescent lamp to running huge machines in industries.\nTherefore, voltage monitoring becomes essential, which demands efficient\nmeasurement and storage of voltage data. However, there is hardly any system\ntill date that fulfils both the goals of voltage monitoring and voltage data\nstorage. To achieve this goal, we propose the application of the Internet of\nThings along with the server-based framework and Distributed Ledger Technology\nto build systems for smart voltage monitoring. Two models - a centralised model\nand a decentralised model have been presented and analysed thoroughly in this\npaper. The centralised model is built on client-server architecture, whereas\nthe decentralised model is based on a peer-to-peer architecture. Blockchain and\nInterPlanetary File System have been used for the implementation of the\ndecentralised system. Potential improvements to make these systems robust have\nalso been discussed. The methods proposed in this paper for voltage monitoring\nare novel; ensure efficient data storage and can be used for IoT data storage\nof any form.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.09518,regular,pre_llm,2020,8,"{'ai_likelihood': 1.7219119601779514e-06, 'text': 'BLONDiE: Blockchain Ontology with Dynamic Extensibility\n\n  There are thousands of projects worldwide based primarily on blockchain\ntechnology. These have a large number of users and hundreds of use cases. One\nof the most popular is the use of cryptocurrencies and their benefits against\nmoney without intrinsic value (fiat money) and centralized financial solutions.\nHowever, although thousands of new transactions are carried out daily in\ndifferent platforms, uniform and standardized information does not exist to be\nable to manage the large amount of data that is generated and exchanged between\nusers through transactions and the generation of new blocks. This research\nreports the development of BLONDiE, an ontology that allows the semantic\nrepresentation of knowledge to describe the native structure and related\ninformation of the three most relevant blockchain projects to date: Bitcoin,\nEthereum and in the recent 1.0 version extends its definitions to include\nHyperledger, specifically the Hyperledger Fabric infrastructure. Its use allows\nhaving common data formats of different platforms for further processing, such\nas the execution of semantic queries.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.06913,review,pre_llm,2020,8,"{'ai_likelihood': 1.2914339701334636e-06, 'text': 'SoK: Why Johnny Can\'t Fix PGP Standardization\n\n  Pretty Good Privacy (PGP) has long been the primary IETF standard for\nencrypting email, but suffers from widespread usability and security problems\nthat have limited its adoption. As time has marched on, the underlying\ncryptographic protocol has fallen out of date insofar as PGP is unauthenticated\non a per message basis and compresses before encryption. There have been an\nincreasing number of attacks on the increasingly outdated primitives and\ncomplex clients used by the PGP eco-system. However, attempts to update the\nOpenPGP standard have failed at the IETF except for adding modern cryptographic\nprimitives. Outside of official standardization, Autocrypt is a ""bottom-up""\ncommunity attempt to fix PGP, but still falls victim to attacks on PGP\ninvolving authentication. The core reason for the inability to ""fix"" PGP is the\nlack of a simple AEAD interface which in turn requires a decentralized public\nkey infrastructure to work with email. Yet even if standards like MLS replace\nPGP, the deployment of a decentralized PKI remains an open issue.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.11362,regular,pre_llm,2020,8,"{'ai_likelihood': 4.967053731282552e-07, 'text': ""FileBounty: Fair Data Exchange\n\n  Digital contents are typically sold online through centralized and custodian\nmarketplaces, which requires the trading partners to trust a central entity. We\npresent FileBounty, a fair protocol which, assuming the cryptographic hash of\nthe file of interest is known to the buyer, is trust-free and lets a buyer\npurchase data for a previously agreed monetary amount, while guaranteeing the\nintegrity of the contents. To prevent misbehavior, FileBounty guarantees that\nany deviation from the expected participants' behavior results in a negative\nfinancial payoff; i.e. we show that honest behavior corresponds to a subgame\nperfect Nash equilibrium. Our novel deposit refunding scheme is resistant to\nextortion attacks under rational adversaries. If buyer and seller behave\nhonestly, FileBounty's execution requires only three on-chain transactions,\nwhile the actual data is exchanged off-chain in an efficient and\nprivacy-preserving manner. We moreover show how FileBounty enables a flexible\npeer-to-peer setting where multiple parties fairly sell a file to a buyer.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.05629,regular,pre_llm,2020,8,"{'ai_likelihood': 2.463658650716146e-05, 'text': ""A Differentially Private Game Theoretic Approach for Deceiving Cyber\n  Adversaries\n\n  Cyber deception is one of the key approaches used to mislead attackers by\nhiding or providing inaccurate system information. There are two main factors\nlimiting the real-world application of existing cyber deception approaches. The\nfirst limitation is that the number of systems in a network is assumed to be\nfixed. However, in the real world, the number of systems may be dynamically\nchanged. The second limitation is that attackers' strategies are simplified in\nthe literature. However, in the real world, attackers may be more powerful than\ntheory suggests. To overcome these two limitations, we propose a novel\ndifferentially private game theoretic approach to cyber deception. In this\nproposed approach, a defender adopts differential privacy mechanisms to\nstrategically change the number of systems and obfuscate the configurations of\nsystems, while an attacker adopts a Bayesian inference approach to infer the\nreal configurations of systems. By using the differential privacy technique,\nthe proposed approach can 1) reduce the impacts on network security resulting\nfrom changes in the number of systems and 2) resist attacks regardless of\nattackers' reasoning power. The experimental results demonstrate the\neffectiveness of the proposed approach.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.05048,review,pre_llm,2020,8,"{'ai_likelihood': 2.4835268656412763e-06, 'text': 'Trust Infrastructures for Virtual Asset Service Providers\n\n  Virtual asset service providers (VASPs) currently face a number of\nchallenges, both from the technological and the regulatory perspectives. In the\ncontext of virtual asset transfers one key issue is the need for VASPs to\nsecurely exchange customer information to comply to the Travel Rule. We discuss\na VASP information sharing network as one form of a trust infrastructure for\nVASP-to-VASP interactions. Related to this is the need for a trusted identity\ninfrastructure for VASPs that would permit other entities to quickly ascertain\nthe legal business status of a VASP. For regulated wallets, an attestation\ninfrastructure may provide VASPs and insurance providers with better visibility\ninto the state of wallets based on trusted hardware. Finally, for customers of\nVASPs there is a need for seamless integration between the VASP services with\nthe existing consumer identity management infrastructure, providing a\nuser-friendly experience for transferring virtual assets to other users.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.00086,regular,pre_llm,2020,8,"{'ai_likelihood': 1.026524437798394e-06, 'text': 'ArchiveSafe: Mass-Leakage-Resistant Storage from Proof-of-Work\n\n  Data breaches-mass leakage of stored information-are a major security\nconcern. Encryption can provide confidentiality, but encryption depends on a\nkey which, if compromised, allows the attacker to decrypt everything,\neffectively instantly. Security of encrypted data thus becomes a question of\nprotecting the encryption keys. In this paper, we propose using keyless\nencryption to construct a mass leakage resistant archiving system, where\ndecryption of a file is only possible after the requester, whether an\nauthorized user or an adversary, completes a proof of work in the form of\nsolving a cryptographic puzzle. This proposal is geared towards protection of\ninfrequently-accessed archival data, where any one file may not require too\nmuch work to decrypt, decryption of a large number of files-mass\nleakage-becomes increasingly expensive for an attacker. We present a prototype\nimplementation realized as a user-space file system driver for Linux. We report\nexperimental results of system behaviour under different file sizes and puzzle\ndifficulty levels. Our keyless encryption technique can be added as a layer on\ntop of traditional encryption: together they provide strong security against\nadversaries without the key and resistance against mass decryption by an\nattacker.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.1293,regular,pre_llm,2020,8,"{'ai_likelihood': 1.986821492513021e-07, 'text': ""A Formal Security Analysis of the pEp Authentication Protocol for\n  Decentralized Key Distribution and End-to-End Encrypted Email\n\n  To send encrypted emails, users typically need to create and exchange keys\nwhich later should be manually authenticated, for instance, by comparing long\nstrings of characters. These tasks are cumbersome for the average user. To make\nmore accessible the use of encrypted email, a secure email application named\npEp automates the key management operations; pEp still requires the users to\ncarry out the verification, however, the authentication process is simple:\nusers have to compare familiar words instead of strings of random characters,\nthen the application shows the users what level of trust they have achieved via\ncolored visual indicators. Yet, users may not execute the authentication\nceremony as intended, pEp's trust rating may be wrongly assigned, or both. To\nlearn whether pEp's trust ratings (and the corresponding visual indicators) are\nassigned consistently, we present a formal security analysis of pEp's\nauthentication ceremony. From the software implementation in C, we derive the\nspecifications of an abstract protocol for public key distribution, encryption\nand trust establishment; then, we model the protocol in a variant of the\napplied pi calculus and later formally verify and validate specific privacy and\nauthentication properties. We also discuss alternative research directions that\ncould enrich the analysis.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.12981,regular,pre_llm,2020,8,"{'ai_likelihood': 1.1093086666531033e-05, 'text': 'Off-Path TCP Exploits of the Mixed IPID Assignment\n\n  In this paper, we uncover a new off-path TCP hijacking attack that can be\nused to terminate victim TCP connections or inject forged data into victim TCP\nconnections by manipulating the new mixed IPID assignment method, which is\nwidely used in Linux kernel version 4.18 and beyond to help defend against TCP\nhijacking attacks. The attack has three steps. First, an off-path attacker can\ndowngrade the IPID assignment for TCP packets from the more secure\nper-socket-based policy to the less secure hash-based policy, building a shared\nIPID counter that forms a side channel on the victim. Second, the attacker\ndetects the presence of TCP connections by observing the shared IPID counter on\nthe victim. Third, the attacker infers the sequence number and the\nacknowledgment number of the detected connection by observing the side channel\nof the shared IPID counter. Consequently, the attacker can completely hijack\nthe connection, i.e., resetting the connection or poisoning the data stream.\n  We evaluate the impacts of this off-path TCP attack in the real world. Our\ncase studies of SSH DoS, manipulating web traffic, and poisoning BGP routing\ntables show its threat on a wide range of applications. Our experimental\nresults show that our off-path TCP attack can be constructed within 215 seconds\nand the success rate is over 88%. Finally, we analyze the root cause of the\nexploit and develop a new IPID assignment method to defeat this attack. We\nprototype our defense in Linux 4.18 and confirm its effectiveness through\nextensive evaluation over real applications on the Internet.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.12188,regular,pre_llm,2020,8,"{'ai_likelihood': 4.3047799004448785e-07, 'text': ""CACHE SNIPER : Accurate timing control of cache evictions\n\n  Microarchitectural side channel attacks have been very prominent in security\nresearch over the last few years. Caches have been an outstanding covert\nchannel, as they provide high resolution and generic cross-core leakage even\nwith simple user-mode code execution privileges. To prevent these generic\ncross-core attacks, all major cryptographic libraries now provide\ncountermeasures to hinder key extraction via cross-core cache attacks, for\ninstance avoiding secret dependent access patterns and prefetching data. In\nthis paper, we show that implementations protected by 'good-enough'\ncountermeasures aimed at preventing simple cache attacks are still vulnerable.\nWe present a novel attack that uses a special timing technique to determine\nwhen an encryption has started and then evict the data precisely at the desired\ninstant. This new attack does not require special privileges nor explicit\nsynchronization between the attacker and the victim. One key improvement of our\nattack is a method to evict data from the cache with a single memory access and\nin absence of shared memory by leveraging the transient capabilities of TSX and\nrelying on the recently reverse-engineered L3 replacement policy. We\ndemonstrate the efficiency by performing an asynchronous last level cache\nattack to extract an RSA key from the latest wolfSSL library, which has been\nespecially adapted to avoid leaky access patterns, and by extracting an AES key\nfrom the S-Box implementation included in OpenSSL bypassing the per round\nprefetch intended as a protection against cache attacks.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.12645,regular,pre_llm,2020,8,"{'ai_likelihood': 1.7881393432617188e-06, 'text': 'Dragon Crypto -- An Innovative Cryptosystem\n\n  In recent years cyber-attacks are continuously developing. This means that\nhackers can find their way around the traditional cryptosystems. This calls for\nnew and more secure cryptosystems to take their place. This paper outlines a\nnew cryptosystem based on the dragon curve fractal. The security level of this\nscheme is based on multiple private keys, that are crucial for effective\nencryption and decryption of data. This paper discusses, how core concepts\nemerging from fractal geometry can be used as a trapdoor function for this\ncryptosystem.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.11358,regular,pre_llm,2020,8,"{'ai_likelihood': 7.28501213921441e-07, 'text': ""Applying Private Information Retrieval to Lightweight Bitcoin Clients\n\n  Lightweight Bitcoin clients execute a Simple Payment Verification (SPV)\nprotocol to verify the validity of transactions related to a particular user.\nCurrently, lightweight clients use Bloom filters to significantly reduce the\namount of bandwidth required to validate a particular transaction. This is\ndespite the fact that research has shown that Bloom filters are insufficient at\npreserving the privacy of clients' queries.\n  In this paper we describe our design of an SPV protocol that leverages\nPrivate Information Retrieval (PIR) to create fully private and performant\nqueries. We show that our protocol has a low bandwidth and latency cost;\nproperties that make our protocol a viable alternative for lightweight Bitcoin\nclients and other cryptocurrencies with a similar SPV model. In contract to\nBloom filters, our PIR-based approach offers deterministic privacy to the user.\n  Among our results, we show that in the worst case, clients who would like to\nverify 100 transactions occurring in the past week incurs a bandwidth cost of\n33.54 MB with an associated latency of approximately 4.8 minutes, when using\nour protocol. The same query executed using the Bloom-filter-based SPV protocol\nincurs a bandwidth cost of 12.85 MB; this is a modest overhead considering the\nprivacy guarantees it provides.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.11612,review,pre_llm,2020,8,"{'ai_likelihood': 4.635916815863716e-07, 'text': ""Server-side Fingerprint-Based Indoor Localization Using Encrypted\n  Sorting\n\n  GPS signals, the main origin of navigation, are not functional in indoor\nenvironments. Therefore, Wi-Fi access points have started to be increasingly\nused for localization and tracking inside the buildings by relying on a\nfingerprint-based approach. However, with these types of approaches, several\nconcerns regarding the privacy of the users have arisen. Malicious individuals\ncan determine a client's daily habits and activities by simply analyzing their\nwireless signals. While there are already efforts to incorporate privacy into\nthe existing fingerprint-based approaches, they are limited to the\ncharacteristics of the homomorphic cryptographic schemes they employed. In this\npaper, we propose to enhance the performance of these approaches by exploiting\nanother homomorphic algorithm, namely DGK, with its unique encrypted sorting\ncapability and thus pushing most of the computations to the server side. We\ndeveloped an Android app and tested our system within a Columbia University\ndormitory. Compared to existing systems, the results indicated that more power\nsavings can be achieved at the client side and DGK can be a viable option with\nmore powerful server computation capabilities.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.0643,regular,pre_llm,2020,8,"{'ai_likelihood': 2.086162567138672e-06, 'text': 'Privacy Preserving Passive DNS\n\n  The Domain Name System (DNS) was created to resolve the IP addresses of the\nweb servers to easily remembered names. When it was initially created, security\nwas not a major concern; nowadays, this lack of inherent security and trust has\nexposed the global DNS infrastructure to malicious actors. The passive DNS data\ncollection process creates a database containing various DNS data elements,\nsome of which are personal and need to be protected to preserve the privacy of\nthe end users. To this end, we propose the use of distributed ledger\ntechnology. We use Hyperledger Fabric to create a permissioned blockchain,\nwhich only authorized entities can access. The proposed solution supports\nqueries for storing and retrieving data from the blockchain ledger, allowing\nthe use of the passive DNS database for further analysis, e.g. for the\nidentification of malicious domain names. Additionally, it effectively protects\nthe DNS personal data from unauthorized entities, including the administrators\nthat can act as potential malicious insiders, and allows only the data owners\nto perform queries over these data. We evaluated our proposed solution by\ncreating a proof-of-concept experimental setup that passively collects DNS data\nfrom a network and then uses the distributed ledger technology to store the\ndata in an immutable ledger, thus providing a full historical overview of all\nthe records.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.05958,regular,pre_llm,2020,8,"{'ai_likelihood': 1.6887982686360678e-06, 'text': 'Zecale: Reconciling Privacy and Scalability on Ethereum\n\n  In this paper, we present Zecale, a general purpose SNARK proof aggregator\nthat uses recursive composition of SNARKs. We start by introducing the notion\nof recursive composition of SNARKs, before introducing Zecale as a privacy\npreserving scalability solution. Then, we list application types that can\nemerge and be built with Zecale. Finally, we argue that such scalability\nsolutions for privacy preserving state transitions are paramount to emulate\n""cash"" on blockchain systems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.03395,review,pre_llm,2020,8,"{'ai_likelihood': 3.642506069607205e-07, 'text': 'Security Design Patterns in Distributed Microservice Architecture\n\n  Micro service architecture has revolutionized the landscape for the\ndevelopment of web and mobile applications alike. Due to the stateless nature\nand loose coupling involved in the design of micro services, native mobile\napplications can be developed by utilizing the same backend services which feed\nthe inputs to the web application front ends. Extending the same concept, a\nplethora of automated devices, thanks to the advancements in the field of IOT,\nhave come into existence which can feed on the same set of micro services. This\nconcept of build once and utilize for many use cases has become a new norm in\nthe enterprise design patterns. To handle the horizontal scalability needs of\nso many calling clients, significant advancements have been made on the\ncontainerization and their orchestration strategies on the public cloud\nplatforms. However, scalable design techniques have led to the increased\nexposure of backend services to unwanted entities. This broadened the attack\nsurface and also the risk. On top of it the mix of heterogeneous technologies\nin MSA, their distinct logging strategies, makes the central logging difficult,\nwhich in turn loosens the security. Additionally, the complexity around\nbuilding the resilience for fault tolerance across the decentralized networks,\nadds to the security loop holes. The simple security designs which were once\nused with traditional web applications cannot be used for Microservice based\napplications. This paper articulates the innovative approaches of handling the\nsecurity needs involved in protection of distributed services in Microservice\narchitecture.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.10705,regular,pre_llm,2020,8,"{'ai_likelihood': 3.973642985026042e-07, 'text': 'Integrating Hardware Security into a Blockchain-Based Transactive Energy\n  Platform\n\n  This applied research paper introduces a novel framework for integrating\nhardware security and blockchain functionality with grid-edge devices to\nestablish a distributed cyber-security mechanism that verifies the provenance\nof messages to and from the devices. Expanding the idea of Two Factor\nAuthentication and Hardware Root of Trust, this work describes the development\nof a Cryptographic Trust Center(TM) (CTC(TM)) chip integrated into grid-edge\ndevices to create uniform cryptographic key management. Product managers,\nenergy system designers, and security architects can utilize this modular\nframework as a unified approach to manage distributed devices of various\nvendors, vintages, and sizes. Results demonstrate the application of CTC(TM) to\na blockchain-based Transactive Energy (TE) platform for provisioning of\ncryptographic keys and improved uniformity of the operational network and data\nmanagement. This process of configuring, installing, and maintaining keys is\ndescribed as Eco-Secure Provisioning(TM) (ESP(TM)). Laboratory test results\nshow the approach can resolve several cyber-security gaps in common blockchain\nframeworks such as Hyperledger Fabric.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.03475,regular,pre_llm,2020,8,"{'ai_likelihood': 1.556343502468533e-06, 'text': ""A Differentially Private Framework for Spatial Crowdsourcing with\n  Historical Data Learning\n\n  Spatial crowdsourcing (SC) is an increasing popular category of crowdsourcing\nin the era of mobile Internet and sharing economy. It requires workers to\narrive at a particular location for task fulfillment. Effective protection of\nlocation privacy is essential for workers' enthusiasm and valid task\nassignment. However, existing SC models with differential privacy usually\nperturb real-time location data for both partition and data publication. Such a\nway may produce large perturbations to counting queries that affect assignment\nsuccess rate and allocation accuracy. This paper proposes a framework (R-HT)\nfor protecting location privacy of workers taking advantage of both real-time\nand historical data. We simulate locations by sampling the probability\ndistribution learned from historical data, use them for grid partition, and\nthen publish real-time data under this partitioning with differential privacy.\nThis realizes that most privacy budget is allocated to the worker count of each\ncell and yields an improved Private Spatial Decomposition approach. Moreover,\nwe introduce some strategies for geocast region construction, including quality\nscoring function and local maximum geocast radius. A series of experimental\nresults on real-world datasets shows that R-HT attains a stable success rate of\ntask assignment, saves performance overhead and fits for dynamic assignment on\ncrowdsourcing platforms.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.11366,regular,pre_llm,2020,8,"{'ai_likelihood': 8.477105034722223e-06, 'text': 'An Energy Efficient Authentication Scheme using Chebyshev Chaotic Map\n  for Smart Grid Environment\n\n  As one of the important applications of Smart grid, charging between electric\nvehicles has attracted much attention. However, authentication between vehicle\nusers and an aggregator may be vulnerable to various attacks due to the usage\nof wireless communications. In order to reduce the computational costs yet\npreserve required security, the Chebyshev chaotic map based authentication\nschemes are proposed. However, the security requirements of Chebyshev\npolynomials bring a new challenge to the design of authentication schemes based\non Chebyshev chaotic maps. To solve this issue, we propose a practical\nChebyshev polynomial algorithm by using a binary exponentiation algorithm based\non square matrix to achieve secure and efficient Chebyshev polynomial\ncomputation. We further apply the proposed algorithm to construct an\nenergy-efficient authentication and key agreement scheme for smart grid\nenvironments. Compared with state-of-the-art schemes, the proposed\nauthentication scheme effectively reduces the computational costs and\ncommunication costs by adopting the proposed Chebyshev polynomial algorithm.\nFurthermore, the ProVerif tool is employed to analyze the security of the\nproposed authentication scheme. Our experimental results justified that our\nproposed authentication scheme can outperform state-of-the-art schemes in terms\nof the computational overhead while achieving privacy protection.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2008.04863,regular,pre_llm,2020,8,"{'ai_likelihood': 1.4901161193847656e-06, 'text': 'Security Analysis on Tangle-based Blockchain through Simulation\n\n  The Tangle-based structure becomes one of the most promising solutions when\ndesigning DAG-based blockchain systems. The approach improves the scalability\nby directly confirming multiple transactions in parallel instead of single\nblocks in linear. However, the performance gain may bring potential security\nrisks. In this paper, we construct three types of attacks with comprehensive\nevaluations, namely parasite attack (PS), double spending attack (DS), and\nhybrid attack (HB). To achieve that, we deconstruct the Tangle-based projects\n(e.g. IOTA) and abstract the main components to rebuild a simple but flexible\nnetwork for the simulation. Then, we informally define three smallest actions\nto build up the attack strategies layer by layer. Based on that, we provide\nanalyses to evaluate different types of attacks. To the best of our knowledge,\nthis is the first study to provide a comprehensive security analysis of\nTangle-based blockchains.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.0203,regular,pre_llm,2020,9,"{'ai_likelihood': 6.622738308376736e-08, 'text': 'Evaluating the Security and Economic Effects of Moving Target Defense\n  Techniques on the Cloud\n\n  Moving Target Defense (MTD) is a proactive security mechanism which changes\nthe attack surface aiming to confuse attackers. Cloud computing leverages MTD\ntechniques to enhance cloud security posture against cyber threats. While many\nMTD techniques have been applied to cloud computing, there has not been a joint\nevaluation of the effectiveness of MTD techniques with respect to security and\neconomic metrics. In this paper, we first introduce mathematical definitions\nfor the combination of three MTD techniques: \\emph{Shuffle}, \\emph{Diversity},\nand \\emph{Redundancy}. Then, we utilize four security metrics including system\nrisk, attack cost, return on attack, and reliability to assess the\neffectiveness of the combined MTD techniques applied to large-scale cloud\nmodels. Secondly, we focus on a specific context based on a cloud model for\nE-health applications to evaluate the effectiveness of the MTD techniques using\nsecurity and economic metrics. We introduce (1) a strategy to effectively\ndeploy Shuffle MTD technique using a virtual machine placement technique and\n(2) two strategies to deploy Diversity MTD technique through operating system\ndiversification. As deploying Diversity incurs cost, we formulate the\n\\emph{Optimal Diversity Assignment Problem (O-DAP)} and solve it as a binary\nlinear programming model to obtain the assignment which maximizes the expected\nnet benefit.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.02626,regular,pre_llm,2020,9,"{'ai_likelihood': 9.602970547146267e-07, 'text': 'On Decidability of Existence of Nonblocking Supervisors Resilient to\n  Smart Sensor Attacks\n\n  Cybersecurity of discrete event systems (DES) has been gaining more and more\nattention recently, due to its high relevance to the so-called 4th industrial\nrevolution that heavily relies on data communication among networked systems.\nOne key challenge is how to ensure system resilience to sensor and/or actuator\nattacks, which may tamper data integrity and service availability. In this\npaper we focus on some key decidability issues related to smart sensor attacks.\nWe first present a sufficient and necessary condition that ensures the\nexistence of a smart sensor attack, which reveals a novel demand-supply\nrelationship between an attacker and a controlled plant, represented as a set\nof risky pairs. Each risky pair consists of a damage string desired by the\nattacker and an observable sequence feasible in the supervisor such that the\nlatter induces a sequence of control patterns, which allows the damage string\nto happen. It turns out that each risky pair can induce a smart weak sensor\nattack. Next, we show that, when the plant, supervisor and damage language are\nregular, it is computationally feasible to remove all such risky pairs from the\nplant behaviour, via a genuine encoding scheme, upon which we are able to\nestablish our key result that the existence of a nonblocking supervisor\nresilient to smart sensor attacks is decidable. To the best of our knowledge,\nthis is the first result of its kind in the DES literature on cyber attacks.\nThe proposed decision process renders a specific synthesis procedure that\nguarantees to compute a resilient supervisor whenever it exists, which so far\nhas not been achieved in the literature.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.05679,regular,pre_llm,2020,9,"{'ai_likelihood': 3.973642985026042e-07, 'text': ""Strengthening Order Preserving Encryption with Differential Privacy\n\n  Ciphertexts of an order-preserving encryption (OPE) scheme preserve the order\nof their corresponding plaintexts. However, OPEs are vulnerable to inference\nattacks that exploit this preserved order. At another end, differential privacy\nhas become the de-facto standard for achieving data privacy. One of the most\nattractive properties of DP is that any post-processing (inferential)\ncomputation performed on the noisy output of a DP algorithm does not degrade\nits privacy guarantee. In this paper, we propose a novel differentially private\norder preserving encryption scheme, OP$\\epsilon$. Under OP$\\epsilon$, the\nleakage of order from the ciphertexts is differentially private. As a result,\nin the least, OP$\\epsilon$ ensures a formal guarantee (specifically, a relaxed\nDP guarantee) even in the face of inference attacks. To the best of our\nknowledge, this is the first work to combine DP with a property-preserving\nencryption scheme. We demonstrate OP$\\epsilon$'s practical utility in answering\nrange queries via extensive empirical evaluation on four real-world datasets.\nFor instance, OP$\\epsilon$ misses only around $4$ in every $10K$ correct\nrecords on average for a dataset of size $\\sim732K$ with an attribute of domain\nsize $\\sim18K$ and $\\epsilon= 1$.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.04263,regular,pre_llm,2020,9,"{'ai_likelihood': 1.6722414228651258e-05, 'text': 'Real-World Snapshots vs. Theory: Questioning the t-Probing Security\n  Model\n\n  Due to its sound theoretical basis and practical efficiency, masking has\nbecome the most prominent countermeasure to protect cryptographic\nimplementations against physical side-channel attacks (SCAs). The core idea of\nmasking is to randomly split every sensitive intermediate variable during\ncomputation into at least t+1 shares, where t denotes the maximum number of\nshares that are allowed to be observed by an adversary without learning any\nsensitive information. In other words, it is assumed that the adversary is\nbounded either by the possessed number of probes (e.g., microprobe needles) or\nby the order of statistical analyses while conducting higher-order SCA attacks\n(e.g., differential power analysis). Such bounded models are employed to prove\nthe SCA security of the corresponding implementations. Consequently, it is\nbelieved that given a sufficiently large number of shares, the vast majority of\nknown SCA attacks are mitigated. In this work, we present a novel\nlaser-assisted SCA technique, called Laser Logic State Imaging (LLSI), which\noffers an unlimited number of contactless probes, and therefore, violates the\nprobing security model assumption. This technique enables us to take snapshots\nof hardware implementations, i.e., extract the logical state of all registers\nat any arbitrary clock cycle with a single measurement. To validate this, we\nmount our attack on masked AES hardware implementations and practically\ndemonstrate the extraction of the full-length key in two different scenarios.\nFirst, we assume that the location of the registers (key and/or state) is\nknown, and hence, their content can be directly read by a single snapshot.\nSecond, we consider an implementation with unknown register locations, where we\nmake use of multiple snapshots and a SAT solver to reveal the secrets.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.13914,review,pre_llm,2020,9,"{'ai_likelihood': 1.655684577094184e-06, 'text': 'SoK: On the Security Challenges and Risks of Multi-Tenant FPGAs in the\n  Cloud\n\n  In their continuous growth and penetration into new markets, Field\nProgrammable Gate Arrays (FPGAs) have recently made their way into hardware\nacceleration of machine learning among other specialized compute-intensive\nservices in cloud data centers, such as Amazon and Microsoft. To further\nmaximize their utilization in the cloud, several academic works propose the\nspatial multi-tenant deployment model, where the FPGA fabric is simultaneously\nshared among mutually mistrusting clients. This is enabled by leveraging the\npartial reconfiguration property of FPGAs, which allows to split the FPGA\nfabric into several logically isolated regions and reconfigure the\nfunctionality of each region independently at runtime. In this paper, we survey\nindustrial and academic deployment models of multi-tenant FPGAs in the cloud\ncomputing settings, and highlight their different adversary models and security\nguarantees, while shedding light on their fundamental shortcomings from a\nsecurity standpoint. We further survey and classify existing academic works\nthat demonstrate a new class of remotely exploitable physical attacks on\nmulti-tenant FPGA devices, where these attacks are launched remotely by\nmalicious clients sharing physical resources with victim users. Through\ninvestigating the problem of end-to-end multi-tenant FPGA deployment more\ncomprehensively, we reveal how these attacks actually represent only one\ndimension of the problem, while various open security and privacy challenges\nremain unaddressed. We conclude with our insights and a call for future\nresearch to tackle these challenges.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.08772,review,pre_llm,2020,9,"{'ai_likelihood': 1.158979203965929e-06, 'text': ""The Boon and Bane of Cross-Signing: Shedding Light on a Common Practice\n  in Public Key Infrastructures\n\n  Public Key Infrastructures (PKIs) with their trusted Certificate Authorities\n(CAs) provide the trust backbone for the Internet: CAs sign certificates which\nprove the identity of servers, applications, or users. To be trusted by\noperating systems and browsers, a CA has to undergo lengthy and costly\nvalidation processes. Alternatively, trusted CAs can cross-sign other CAs to\nextend their trust to them. In this paper, we systematically analyze the\npresent and past state of cross-signing in the Web PKI. Our dataset (derived\nfrom passive TLS monitors and public CT logs) encompasses more than 7 years and\n225 million certificates with 9.3 billion trust paths. We show benefits and\nrisks of cross-signing. We discuss the difficulty of revoking trusted CA\ncertificates where, worrisome, cross-signing can result in valid trust paths to\nremain after revocation; a problem for non-browser software that often blindly\ntrusts all CA certificates and ignores revocations. However, cross-signing also\nenables fast bootstrapping of new CAs, e.g., Let's Encrypt, and achieves a\nnon-disruptive user experience by providing backward compatibility. In this\npaper, we propose new rules and guidance for cross-signing to preserve its\npositive potential while mitigating its risks.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.08401,regular,pre_llm,2020,9,"{'ai_likelihood': 2.1523899502224394e-06, 'text': 'Password similarity using probabilistic data structures\n\n  Passwords should be easy to remember, yet expiration policies mandate their\nfrequent change. Caught in the crossfire between these conflicting\nrequirements, users often adopt creative methods to perform slight variations\nover time. While easily fooling the most basic checks for similarity, these\nschemes lead to a substantial decrease in actual security, because leaked\npasswords, albeit expired, can be effectively exploited as seeds for crackers.\nThis work describes an approach based on Bloom filters to detect password\nsimilarity, which can be used to discourage password reuse habits. The proposed\nscheme intrinsically obfuscates the stored passwords to protect them in case of\ndatabase leaks, and can be tuned to be resistant to common cryptanalytic\ntechniques, making it suitable for usage on exposed systems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.06893,regular,pre_llm,2020,9,"{'ai_likelihood': 7.119443681504991e-06, 'text': 'Privacy-Preserving Image Retrieval Based on Additive Secret Sharing\n\n  The rapid growth of digital images motivates individuals and organizations to\nupload their images to the cloud server. To preserve privacy, image owners\nwould prefer to encrypt the images before uploading, but it would strongly\nlimit the efficient usage of images. Plenty of existing schemes on\nprivacy-preserving Content-Based Image Retrieval (PPCBIR) try to seek the\nbalance between security and retrieval ability. However, compared to the\nadvanced technologies in CBIR like Convolutional Neural Network (CNN), the\nexisting PPCBIR schemes are far deficient in both accuracy and efficiency. With\nmore cloud service providers, the collaborative secure image retrieval service\nprovided by multiple cloud servers becomes possible. In this paper, inspired by\nadditive secret sharing technology, we propose a series of additive secure\ncomputing protocols on numbers and matrices with better efficiency, and then\nshow their application in PPCBIR. Specifically, we extract CNN features,\ndecrease the dimension of features and build the index securely with the help\nof our protocols, which include the full process of image retrieval in the\nplaintext domain. The experiments and security analysis demonstrate the\nefficiency, accuracy, and security of our scheme.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.11546,regular,pre_llm,2020,9,"{'ai_likelihood': 1.2252065870496963e-05, 'text': ""BCMIX: A Dynamic Self-organizing Blockchain-based Mix Anonymous System\n\n  Increasing awareness of privacy-preserving has led to a strong focus on\nanonymous systems protecting anonymity. By studying early schemes, we summarize\nsome intractable problems of anonymous systems. Centralization setting is a\nuniversal problem since most anonymous system rely on central proxies or\npresetting nodes to forward and mix messages, which compromises users' privacy\nin some way. Besides, availability becomes another important factor limiting\nthe development of anonymous system due to the large requirement of additional\nadditional resources (i.e. bandwidth and storage) and high latency. Moreover,\nexisting anonymous systems may suffer from different attacks including\nabominable Man-in-the-Middle (MitM) attacks, Distributed Denial-of-service\n(DDoS) attacks and so on. In this context, we first come up with a\nBlockChain-based Mix-Net (BCMN) protocol and theoretically demonstrate its\nsecurity and anonymity. Then we construct a concrete dynamic self-organizing\nBlockChain-based MIX anonymous system (BCMIX). In the system, users and mix\nnodes utilize the blockchain transactions and their addresses to negotiate keys\nwith each other, which can resist the MitM attacks. In addition, we design an\nIP sharding algorithm to mitigate Sybil attacks. To evaluate the BCMIX system,\nwe leverage the distribution of mining pools in the real world to test the\nsystem's performance and ability to resistant attacks. Compared with other\nsystems, BCMIX provides better resilience to known attacks, while achieving low\nlatency anonymous communication without significant bandwidth or storage\nresources.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.02114,review,pre_llm,2020,9,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'Authentication and authorization in microservice-based systems: survey\n  of architecture patterns\n\n  Context. Service-oriented architecture and its microservice-based approach\nincrease an attack surface of applications. Exposed microservices become a\npivot point for advanced persistent threats and completely change the threat\nlandscape. Correctly implemented authentication and authorization architecture\npatterns are basis of any software maturity program. Objective. The aim of this\nstudy is to provide a helpful resource to application security architect and\ndevelopers on existing architecture patterns to implement authentication and\nauthorization in microservices-based systems. Method. In this paper, we conduct\na review of major electronic databases and libraries as well as security\nstandards and presentations at the major security conferences. Results. In this\nwork based on research papers and major security conferences presentations\nanalysis we identified industry best practices in authentication and\nauthorization patterns and its applicability depending on environment\ncharacteristic. For each described patterns we reviewed its advantages and\ndisadvantages that could be used as decision-making criteria for application\nsecurity architects during architecture design phase.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.09959,regular,pre_llm,2020,9,"{'ai_likelihood': 1.6887982686360678e-06, 'text': ""Domain-Embeddings Based DGA Detection with Incremental Training Method\n\n  DGA-based botnet, which uses Domain Generation Algorithms (DGAs) to evade\nsupervision, has become a part of the most destructive threats to network\nsecurity. Over the past decades, a wealth of defense mechanisms focusing on\ndomain features have emerged to address the problem. Nonetheless, DGA detection\nremains a daunting and challenging task due to the big data nature of Internet\ntraffic and the potential fact that the linguistic features extracted only from\nthe domain names are insufficient and the enemies could easily forge them to\ndisturb detection. In this paper, we propose a novel DGA detection system which\nemploys an incremental word-embeddings method to capture the interactions\nbetween end hosts and domains, characterize time-series patterns of DNS queries\nfor each IP address and therefore explore temporal similarities between\ndomains. We carefully modify the Word2Vec algorithm and leverage it to\nautomatically learn dynamic and discriminative feature representations for over\n1.9 million domains, and develop an simple classifier for distinguishing\nmalicious domains from the benign. Given the ability to identify temporal\npatterns of domains and update models incrementally, the proposed scheme makes\nthe progress towards adapting to the changing and evolving strategies of DGA\ndomains. Our system is evaluated and compared with the state-of-art system\nFANCI and two deep-learning methods CNN and LSTM, with data from a large\nuniversity's network named TUNET. The results suggest that our system\noutperforms the strong competitors by a large margin on multiple metrics and\nmeanwhile achieves a remarkable speed-up on model updating.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.05945,review,pre_llm,2020,9,"{'ai_likelihood': 8.112854427761502e-06, 'text': 'Stochastic Modeling Approaches for Analyzing Blockchain: A Survey\n\n  Blockchain technology has been attracting much attention from both academia\nand industry. It brings many benefits to various applications like Internet of\nThings. However, there are critical issues to be addressed before its\nwidespread deployment, such as transaction efficiency, bandwidth bottleneck,\nand security. Techniques are being explored to tackle these issues. Stochastic\nmodeling, as one of these techniques, has been applied to analyze a variety of\nblockchain characteristics, but there is a lack of a comprehensive survey on\nit. In this survey, we aim to fill the gap and review the stochastic models\nproposed to address common issues in blockchain. Firstly, this paper provides\nthe basic knowledge of blockchain technology and stochastic models. Then,\naccording to different objects, the stochastic models for blockchain analysis\nare divided into network-oriented and application-oriented (mainly refer to\ncryptocurrency). The network-oriented stochastic models are further classified\ninto two categories, namely, performance and security. About the\napplication-oriented stochastic models, the widest adoption mainly concentrates\non the price prediction of cryptocurrency. Moreover, we provide analysis and\ncomparison in detail on every taxonomy and discuss the strengths and weaknesses\nof the related works to serve guides for further researches. Finally,\nchallenges and future research directions are given to apply stochastic\nmodeling approaches to study blockchain. By analyzing and classifying the\nexisting researches, we hope that our survey can provide suggestions for the\nresearchers who are interested in blockchain and good at using stochastic\nmodels as a tool to address problems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.12116,regular,pre_llm,2020,9,"{'ai_likelihood': 1.953707800971137e-06, 'text': ""Beyond PS-LTE: Security Model Design Framework for PPDR Operational\n  Environment\n\n  National disasters can threaten national security and require several\norganizations to integrate the functionalities to correspond to the event. Many\ncountries are constructing a nationwide mobile communication network\ninfrastructure to share information and promptly communicate with corresponding\norganizations. Public Safety Long-Term Evolution (PS-LTE) is a communication\nmechanism adopted in many countries to achieve such a purpose. Organizations\ncan increase the efficiency of public protection and disaster relief (PPDR)\noperations by securely connecting the services run on their legacy networks to\nthe PS-LTE infrastructure. This environment allows the organizations to\ncontinue facilitating the information and system functionalities provided by\nthe legacy network. The vulnerabilities in the environment, which differ from\ncommercial LTE, need to be resolved to connect the network securely. In this\nstudy, we propose a security model design framework to derive the system\narchitecture and the security requirements targeting the restricted environment\napplied by certain technologies for a particular purpose. After analyzing the\nPPDR operation environment's characteristics under the PS-LTE infrastructure,\nwe applied the framework to derive the security model for organizations using\nPPDR services operated in their legacy networks through this infrastructure.\nAlthough the proposed security model design framework is applied to the\nspecific circumstance in this research, it can be generally adopted for the\napplication environment.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.05413,regular,pre_llm,2020,9,"{'ai_likelihood': 2.317958407931858e-07, 'text': 'Defending Against Malicious Reorgs in Tezos Proof-of-Stake\n\n  Blockchains are intended to be immutable, so an attacker who is able to\ndelete transactions through a chain reorganization (a malicious reorg) can\nperform a profitable double-spend attack. We study the rate at which an\nattacker can execute reorgs in the Tezos Proof-of-Stake protocol. As an\nexample, an attacker with 40% of the staking power is able to execute a\n20-block malicious reorg at an average rate of once per day, and the attack\nprobability increases super-linearly as the staking power grows beyond 40%.\nMoreover, an attacker of the Tezos protocol knows in advance when an attack\nopportunity will arise, and can use this knowledge to arrange transactions to\ndouble-spend. We show that in particular cases, the Tezos protocol can be\nadjusted to protect against deep reorgs. For instance, we demonstrate protocol\nparameters that reduce the rate of length-20 reorg opportunities for a 40%\nattacker by two orders of magnitude. We also observe a trade-off between\noptimizing for robustness to deep reorgs (costly deviations that may be net\nprofitable because they enable double-spends) and robustness to selfish mining\n(mining deviations that result in typically short reorgs that are profitable\neven without double-spends). That is, the parameters that optimally protect\nagainst one make the other attack easy. Finally, we develop a method that\nmonitors the Tezos blockchain health with respect to malicious reorgs using\nonly publicly available information.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.13243,regular,pre_llm,2020,9,"{'ai_likelihood': 9.271833631727431e-07, 'text': ""Generating End-to-End Adversarial Examples for Malware Classifiers Using\n  Explainability\n\n  In recent years, the topic of explainable machine learning (ML) has been\nextensively researched. Up until now, this research focused on regular ML users\nuse-cases such as debugging a ML model. This paper takes a different posture\nand show that adversaries can leverage explainable ML to bypass multi-feature\ntypes malware classifiers. Previous adversarial attacks against such\nclassifiers only add new features and not modify existing ones to avoid harming\nthe modified malware executable's functionality. Current attacks use a single\nalgorithm that both selects which features to modify and modifies them blindly,\ntreating all features the same. In this paper, we present a different approach.\nWe split the adversarial example generation task into two parts: First we find\nthe importance of all features for a specific sample using explainability\nalgorithms, and then we conduct a feature-specific modification,\nfeature-by-feature. In order to apply our attack in black-box scenarios, we\nintroduce the concept of transferability of explainability, that is, applying\nexplainability algorithms to different classifiers using different features\nsubsets and trained on different datasets still result in a similar subset of\nimportant features. We conclude that explainability algorithms can be leveraged\nby adversaries and thus the advocates of training more interpretable\nclassifiers should consider the trade-off of higher vulnerability of those\nclassifiers to adversarial attacks.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.12115,regular,pre_llm,2020,9,"{'ai_likelihood': 2.6490953233506944e-06, 'text': 'Towards Reconstructing Multi-Step Cyber Attacks in Modern Cloud\n  Environments with Tripwires\n\n  Rapidly-changing cloud environments that consist of heavily interconnected\ncomponents are difficult to secure. Existing solutions often try to correlate\nmany weak indicators to identify and reconstruct multi-step cyber attacks. The\nlack of a true, causal link between most of these indicators still leaves\nadministrators with a lot of false-positives to browse through. We argue that\ncyber deception can improve the precision of attack detection systems, if used\nin a structured, and automatic way, i.e., in the form of so-called tripwires\nthat ultimately span an attack graph, which assists attack reconstruction\nalgorithms. This paper proposes an idea for a framework that combines cyber\ndeception, automatic tripwire injection and attack graphs, which eventually\nenables us to reconstruct multi-step cyber attacks in modern cloud\nenvironments.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.11572,regular,pre_llm,2020,9,"{'ai_likelihood': 2.9802322387695312e-06, 'text': 'Lic-Sec: an enhanced AppArmor Docker security profile generator\n\n  Along with the rapid development of cloud computing technology,\ncontainerization technology has drawn much attention from both industry and\nacademia. In this paper, we perform a comparative measurement analysis of\nDocker-sec, which is a Linux Security Module proposed in 2018, and a new\nAppArmor profile generator called Lic-Sec, which combines Docker-sec with a\nmodified version of LiCShield, which is also a Linux Security Module proposed\nin 2015. Docker-sec and LiCShield can be used to enhance Docker container\nsecurity based on mandatory access control and allows protection of the\ncontainer without manually configurations. Lic-Sec brings together their\nstrengths and provides stronger protection. We evaluate the effectiveness and\nperformance of Docker-sec and Lic-Sec by testing them with real-world attacks.\nWe generate an exploit database with 42 exploits effective on Docker containers\nselected from the latest 400 exploits on Exploit-db. We launch these exploits\non containers spawned with Docker-sec and Lic-Sec separately. Our evaluations\nshow that for demanding images, Lic-Sec gives protection for all privilege\nescalation attacks for which Docker-sec failed to give protection.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.01939,regular,pre_llm,2020,9,"{'ai_likelihood': 2.086162567138672e-06, 'text': 'Accurate TLS Fingerprinting using Destination Context and Knowledge\n  Bases\n\n  Network fingerprinting is used to identify applications, provide insight into\nnetwork traffic, and detect malicious activity. With the broad adoption of TLS,\ntraditional fingerprinting techniques that rely on clear-text data are no\nlonger viable. TLS-specific techniques have been introduced that create a\nfingerprint string from carefully selected data features in the client_hello to\nfacilitate process identification before data is exchanged. Unfortunately, this\napproach fails in practice because hundreds of processes can map to the same\nfingerprint string. We solve this problem by presenting a TLS fingerprinting\nsystem that makes use of the destination address, port, and server name in\naddition to a carefully constructed fingerprint string. The destination context\nis used to disambiguate the set of processes that match a fingerprint string by\napplying a weighted naive Bayes classifier, resulting in far greater\nperformance.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.06299,regular,pre_llm,2020,9,"{'ai_likelihood': 2.980232238769531e-07, 'text': 'DAICS: A Deep Learning Solution for Anomaly Detection in Industrial\n  Control Systems\n\n  Deep Learning is emerging as an effective technique to detect sophisticated\ncyber-attacks targeting Industrial Control Systems (ICSs). The conventional\napproach to detection in literature is to learn the ""normal"" behaviour of the\nsystem, to be then able to label noteworthy deviations from it as anomalies.\nHowever, during operations, ICSs inevitably and continuously evolve their\nbehaviour, due to e.g., replacement of devices, workflow modifications, or\nother reasons. As a consequence, the accuracy of the anomaly detection process\nmay be dramatically affected with a considerable amount of false alarms being\ngenerated. This paper presents DAICS, a novel deep learning framework with a\nmodular design to fit in large ICSs. The key component of the framework is a\n2-branch neural network that learns the changes in the ICS behaviour with a\nsmall number of data samples and a few gradient updates. This is supported by\nan automatic tuning mechanism of the detection threshold that takes into\naccount the changes in the prediction error under normal operating conditions.\nIn this regard, no specialised human intervention is needed to update the other\nparameters of the system. DAICS has been evaluated using publicly available\ndatasets and shows an increased detection rate and accuracy compared to state\nof the art approaches, as well as higher robustness to additive noise.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2009.14007,regular,pre_llm,2020,9,"{'ai_likelihood': 8.609559800889757e-07, 'text': 'Tracking Mixed Bitcoins\n\n  Mixer services purportedly remove all connections between the input\n(deposited) Bitcoins and the output (withdrawn) mixed Bitcoins, seemingly\nrendering taint analysis tracking ineffectual. In this paper, we introduce and\nexplore a novel tracking strategy, called \\emph{Address Taint Analysis}, that\nadapts from existing transaction-based taint analysis techniques for tracking\nBitcoins that have passed through a mixer service. We also investigate the\npotential of combining address taint analysis with address clustering and\nbackward tainting. We further introduce a set of filtering criteria that reduce\nthe number of false-positive results based on the characteristics of withdrawn\ntransactions and evaluate our solution with verifiable mixing transactions of\nnine mixer services from previous reverse-engineering studies. Our finding\nshows that it is possible to track the mixed Bitcoins from the deposited\nBitcoins using address taint analysis and the number of potential transaction\noutputs can be significantly reduced with the filtering criteria.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.10088,regular,pre_llm,2020,10,"{'ai_likelihood': 3.642506069607205e-07, 'text': ""How Did That Get In My Phone? Unwanted App Distribution on Android\n  Devices\n\n  Android is the most popular operating system with billions of active devices.\nUnfortunately, its popularity and openness makes it attractive for unwanted\napps, i.e., malware and potentially unwanted programs (PUP). In Android, app\ninstallations typically happen via the official and alternative markets, but\nalso via other smaller and less understood alternative distribution vectors\nsuch as Web downloads, pay-per-install (PPI) services, backup restoration,\nbloatware, and IM tools. This work performs a thorough investigation on\nunwanted app distribution by quantifying and comparing distribution through\ndifferent vectors. At the core of our measurements are reputation logs of a\nlarge security vendor, which include 7.9M apps observed in 12M devices between\nJune and September 2019. As a first step, we measure that between 10% and 24%\nof users devices encounter at least one unwanted app, and compare the\nprevalence of malware and PUP. An analysis of the who-installs-who\nrelationships between installers and child apps reveals that the Play market is\nthe main app distribution vector, responsible for 87% of all installs and 67%\nof unwanted app installs, but it also has the best defenses against unwanted\napps. Alternative markets distribute instead 5.7% of all apps, but over 10% of\nunwanted apps. Bloatware is also a significant unwanted app distribution vector\nwith 6% of those installs. And, backup restoration is an unintentional\ndistribution vector that may even allow unwanted apps to survive users' phone\nreplacement. We estimate unwanted app distribution via PPI to be smaller than\non Windows. Finally, we observe that Web downloads are rare, but provide a\nriskier proposition even compared to alternative markets.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.03465,regular,pre_llm,2020,10,"{'ai_likelihood': 3.112687004937066e-06, 'text': ""Hiding the Access Pattern is Not Enough: Exploiting Search Pattern\n  Leakage in Searchable Encryption\n\n  Recent Searchable Symmetric Encryption (SSE) schemes enable secure searching\nover an encrypted database stored in a server while limiting the information\nleaked to the server. These schemes focus on hiding the access pattern, which\nrefers to the set of documents that match the client's queries. This provides\nprotection against current attacks that largely depend on this leakage to\nsucceed. However, most SSE constructions also leak whether or not two queries\naim for the same keyword, also called the search pattern.\n  In this work, we show that search pattern leakage can severely undermine\ncurrent SSE defenses. We propose an attack that leverages both access and\nsearch pattern leakage, as well as some background and query distribution\ninformation, to recover the keywords of the queries performed by the client.\nOur attack follows a maximum likelihood estimation approach, and is easy to\nadapt against SSE defenses that obfuscate the access pattern. We empirically\nshow that our attack is efficient, it outperforms other proposed attacks, and\nit completely thwarts two out of the three defenses we evaluate it against,\neven when these defenses are set to high privacy regimes. These findings\nhighlight that hiding the search pattern, a feature that most constructions are\nlacking, is key towards providing practical privacy guarantees in SSE.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.09303,regular,pre_llm,2020,10,"{'ai_likelihood': 3.1524234347873265e-05, 'text': 'Private-Yet-Verifiable Contact Tracing\n\n  We propose PrYVeCT, a private-yet-verifiable contact tracing system. PrYVeCT\nworks also as an authorization framework allowing for the definition of\nfine-grained policies, which a certain facility can define and apply to better\nmodel its own access rules. Users are authorized to access the facility only\nwhen they exhibit a contact trace that complies with the policy. The policy\nevaluation process is carried out without disclosing the personal data of the\nuser. At the same time, each user can prove to a third party (e.g., a public\nauthority) that she received a certain authorization. PrYVeCT takes advantage\nof oblivious automata evaluation to implement a privacy-preserving policy\nenforcement mechanism.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.07555,regular,pre_llm,2020,10,"{'ai_likelihood': 4.337893591986763e-06, 'text': 'Garou: An Efficient and Secure Off-Blockchain Multi-Party Payment Hub\n\n  To mitigate the scalability problem of decentralized cryptocurrencies such as\nBitcoin and Ethereum, the payment channel, which allows two parties to perform\nsecure coin transfers without involving the blockchain, has been proposed. The\npayment channel increases the transaction throughput of two parties to a level\nthat is only limited by their network bandwidth. Recent proposals focus on\nextending the two-party payment channel to the N-party payment hub.\nUnfortunately, none of them can achieve efficiency, flexibility in the absence\nof a trusted third-party. In this paper, we propose Garou, a secure N-party\npayment hub that allows multiple parties to perform secure off-chain coin\ntransfers. Except in the case of disputes, participants within the payment hub\ncan make concurrent and direct coin transfers with each other without the\ninvolvement of the blockchain or any third-party intermediaries. This allows\nGarou to achieve both high-performance and flexibility. Garou also guarantees\nthat an honest party always maintains its balance security against strong\nadversarial capabilities. To demonstrate the feasibility of the Garou protocol,\nwe develop a proof of concept prototype for the Ethereum network. Our\nevaluation results show that the maximum transaction throughput of Garou is 20\ntimes higher than that of state-of-art payment hubs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.03482,regular,pre_llm,2020,10,"{'ai_likelihood': 1.079506344265408e-05, 'text': 'Fuzzing Based on Function Importance by Interprocedural Control Flow\n  Graph\n\n  Coverage-based graybox fuzzer (CGF), such as AFL has gained great success in\nvulnerability detection thanks to its ease-of-use and bug-finding power. Since\nsome code fragments such as memory allocation are more vulnerable than others,\nvarious improving techniques have been proposed to explore the more vulnerable\nareas by collecting extra information from the program under test or its\nexecutions. However, these improvements only consider limited types of\ninformation sources and ignore the fact that the priority a seed input to be\nfuzzed may be influenced by all the code it covers. Based on the above\nobservations, we propose a fuzzing method based on the importance of functions.\nFirst, a data structure called Attributed Interprocedural Control Flow Graph\n(AICFG) is devised to combine different features of code fragments. Second, the\nimportance of each node in the AICFG is calculated based on an improved\nPageRank algorithm, which also models the influence between connected nodes.\nDuring the fuzzing process, the node importance is updated periodically by a\npropagation algorithm. Then the seed selection and energy scheduling of a seed\ninput are determined by the importance of its execution trace. We implement\nthis approach on top of AFL in a tool named FunAFL and conduct an evaluation on\n14 real-world programs against AFL and two of its improvements. FunAFL, with\n17% higher branch coverage than others on average, finds 13 bugs and 3 of them\nare confirmed by CVE after 72 hours.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.0846,regular,pre_llm,2020,10,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'Pitfalls of Provably Secure Systems in Internet The Case of Chronos-NTP\n\n  The critical role that Network Time Protocol (NTP) plays in the Internet led\nto multiple efforts to secure it against time-shifting attacks. A recent\nproposal for enhancing the security of NTP with Chronos against on-path\nattackers seems the most promising one and is on a standardisation track of the\nIETF. In this work we demonstrate off-path attacks against Chronos enhanced NTP\nclients. The weak link is a central security feature of Chronos: The server\npool generation mechanism using DNS. We show that the insecurity of DNS allows\nto subvert the security of Chronos making the time-shifting attacks against\nChronos-NTP even easier than attacks against plain NTP.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.10387,regular,pre_llm,2020,10,"{'ai_likelihood': 1.0927518208821616e-06, 'text': 'A Novel Demodulation Scheme for Secure and Reliable UWB Distance\n  Bounding\n\n  Relay attacks pose an important threat in wireless ranging and authentication\nsystems. Distance bounding protocols have been proposed as an effective\ncountermeasure against these attacks and allow a verifier and a prover to\nestablish an upper bound on the distance between them. However, secure distance\nbounding protocols are hard to realize in practice due to stringent\nimplementation requirements. In this paper, we look into a yet unexplored\nresearch area and show how the security strength of Ultra Wide Band (UWB)\ndistance bounding protocols can be significantly increased by imposing several\nadditional security constraints during demodulation and decoding at the\nreceiver. We demonstrate that for equal reliability metrics as in\nstate-of-the-art UWB distance bounding protocols, our solution achieves a\nreduction of the success probability of a relay attack by a factor of 40.\nMoreover, we also argue that our security solution only needs to be combined\nwith pulse masking and a distance commitment to achieve these security bounds\nand there is no need to have pulse reordering in our modulation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.00852,review,pre_llm,2020,10,"{'ai_likelihood': 1.986821492513021e-06, 'text': 'Current Lightweight Cryptography Protocols in Smart City IoT Networks: A\n  Survey\n\n  With the advent of advanced technology, IoT introduces a vast number of\ndevices connecting with each other and collecting a sheer volume of data. Thus,\nthe demands of IoT security is paramount. Cryptography is being used to secure\nthe networks for authentication, confidentiality, data integrity and access\ncontrol. However, due to the resource constraint nature of IoT devices, the\ntraditional cryptographic protocols may not be suited in all IoT environments.\nResearchers, as a result, have been proposing various lightweight cryptographic\nalgorithms and protocols. In this paper, we discuss the state of the art\nlightweight cryptographic protocols for IoT networks and present a comparative\nanalysis of the existing protocols. In doing so, this paper has classified the\nmost current algorithm into two parts, such as symmetric and asymmetric\nlightweight cryptography. Additionally, we consider several recent developed\nblock cipher and stream cipher algorithms. Furthermore, various research\nchallenges of lightweight cryptography have been addressed.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.11079,review,pre_llm,2020,10,"{'ai_likelihood': 7.28501213921441e-07, 'text': 'Security Issues and Challenges in Service Meshes -- An Extended Study\n\n  Service meshes have emerged as an attractive DevOps solution for collecting,\nmanaging, and coordinating microservice deployments. However, current service\nmeshes leave fundamental security mechanisms missing or incomplete. The\nsecurity burden means service meshes may actually cause additional workload and\noverhead for administrators over traditional monolithic systems. By assessing\nthe effectiveness and practicality of service mesh tools, this work provides\nnecessary insights into the available security of service meshes. We evaluate\nservice meshes from two perspectives: skilled system administrators (who deploy\noptimal configurations of available security mechanisms) and default\nconfigurations. Under these two models, we consider a comprehensive set of\nadversarial scenarios and uncover important design flaws with contradicting\ngoals, as well as the limitations and challenges encountered in employing\nservice mesh tools for operational environments.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.06198,review,pre_llm,2020,10,"{'ai_likelihood': 8.609559800889758e-06, 'text': 'Visual Security Evaluation of Learnable Image Encryption Methods against\n  Ciphertext-only Attacks\n\n  Various visual information protection methods have been proposed for\nprivacy-preserving deep neural networks (DNNs). In contrast, attack methods on\nsuch protection methods have been studied simultaneously. In this paper, we\nevaluate state-of-the-art visual protection methods for privacy-preserving DNNs\nin terms of visual security against ciphertext-only attacks (COAs). We focus on\nbrute-force attack, feature reconstruction attack (FR-Attack), inverse\ntransformation attack (ITN-Attack), and GAN-based attack (GAN-Attack), which\nhave been proposed to reconstruct visual information on plain images from the\nvisually-protected images. The detail of various attack is first summarized,\nand then visual security of the protection methods is evaluated. Experimental\nresults demonstrate that most of protection methods, including pixel-wise\nencryption, have not enough robustness against GAN-Attack, while a few\nprotection methods are robust enough against GAN-Attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.05658,regular,pre_llm,2020,10,"{'ai_likelihood': 2.5166405571831597e-06, 'text': 'PoisonIvy: (In)secure Practices of Enterprise IoT Systems in Smart\n  Buildings\n\n  The rise of IoT devices has led to the proliferation of smart buildings,\noffices, and homes worldwide. Although commodity IoT devices are employed by\nordinary end-users, complex environments such as smart buildings, smart\noffices, conference rooms, or hospitality require customized and highly\nreliable solutions. Those systems called Enterprise Internet of Things (EIoT)\nconnect such environments to the Internet and are professionally managed\nsolutions usually offered by dedicated vendors. As EIoT systems require\nspecialized training, software, and equipment to deploy, this has led to very\nlittle research investigating the security of EIoT systems and their\ncomponents. In effect, EIoT systems in smart settings such as smart buildings\npresent an unprecedented and unexplored threat vector for an attacker. In this\nwork, we explore EIoT system vulnerabilities and insecure development\npractices. Specifically, focus on the usage of drivers as an attack mechanism,\nand introduce PoisonIvy, a number of novel attacks that demonstrate an attacker\ncan easily compromise EIoT system controllers using malicious drivers.\nSpecifically, we show how drivers used to integrate third-party devices to EIoT\nsystems can be misused in a systematic fashion. To demonstrate the capabilities\nof attackers, we implement and evaluate PoisonIvy using a testbed of real EIoT\ndevices. We show that an attacker can perform DoS attacks, gain remote control,\nand maliciously abuse system resources of EIoT systems. To the best of our\nknowledge, this is the first work to analyze the (in)securities of EIoT\ndeployment practices and demonstrate the associated vulnerabilities in this\necosystem. With this work, we raise awareness on the (in)secure development\npractices used for EIoT systems, the consequences of which can largely impact\nthe security, privacy, reliability, and performance of millions of EIoT systems\nworldwide.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.05683,review,pre_llm,2020,10,"{'ai_likelihood': 4.967053731282552e-07, 'text': ""Cybersecurity Dynamics: A Foundation for the Science of Cybersecurity\n\n  Cybersecurity Dynamics is new concept that aims to achieve the modeling,\nanalysis, quantification, and management of cybersecurity from a holistic\nperspective, rather than from a building-blocks perspective. It is centered at\nmodeling and analyzing the attack-defense interactions in cyberspace, which\ncause a ``natural'' phenomenon -- the evolution of the global cybersecurity\nstate. In this Chapter, we systematically introduce and review the\nCybersecurity Dynamics foundation for the Science of Cybersecurity. We review\nthe core concepts, technical approaches, research axes, and results that have\nbeen obtained in this endeavor. We outline a research roadmap towards the\nultimate research goal, including a systematic set of technical barriers.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.02524,regular,pre_llm,2020,10,"{'ai_likelihood': 9.602970547146267e-07, 'text': ""Secure Collaborative Training and Inference for XGBoost\n\n  In recent years, gradient boosted decision tree learning has proven to be an\neffective method of training robust models. Moreover, collaborative learning\namong multiple parties has the potential to greatly benefit all parties\ninvolved, but organizations have also encountered obstacles in sharing\nsensitive data due to business, regulatory, and liability concerns.\n  We propose Secure XGBoost, a privacy-preserving system that enables\nmultiparty training and inference of XGBoost models. Secure XGBoost protects\nthe privacy of each party's data as well as the integrity of the computation\nwith the help of hardware enclaves. Crucially, Secure XGBoost augments the\nsecurity of the enclaves using novel data-oblivious algorithms that prevent\naccess side-channel attacks on enclaves induced via access pattern leakage.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.15394,review,pre_llm,2020,10,"{'ai_likelihood': 1.158979203965929e-06, 'text': 'Smart Homes: Security Challenges and Privacy Concerns\n\n  Development and growth of Internet of Things (IoT) technology has\nexponentially increased over the course of the last 10 years since its\ninception, and as a result has directly influenced the popularity and size of\nsmart homes. In this article we present the main technologies and applications\nthat constitute a smart home, we identify the main security and privacy\nchallenges that smart home face and we provide good practices to mitigate those\nthreats.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.01235,regular,pre_llm,2020,10,"{'ai_likelihood': 2.4073653750949437e-05, 'text': 'DCDChain: A Credible Architecture of Digital Copyright Detection Based\n  on Blockchain\n\n  Copyright detection is an effective method to prevent piracy. However,\nuntrustworthy detection parties may lead to falsified detection results. Due to\nits credibility and tamper resistance, blockchain has been applied to copyright\nprotection. Previous works mainly utilized blockchain for reliable copyright\ninformation storage or copyrighted digital media trading. As far as we know,\nthe problem of credible copyright detection has not been addressed. In this\npaper, we propose a credible copyright detection architecture based on the\nblockchain, called DCDChain. In this architecture, the detection agency first\ndetects copyrights off the chain, then uploads the detection records to the\nblockchain. Since data on the blockchain are publicly accessible, media\nproviders can verify the correctness of the copyright detection, and appeal to\na smart contract if there is any dissent. The smart contract then arbitrates\nthe disputes by verifying the correctness of detection on the chain. The\ndetect-verify-and-arbitrate mechanism guarantees the credibility of copyright\ndetection. Security analysis and experimental simulations show that the digital\ncopyright detection architecture is credible, secure and efficient. The\nproposed credible copyright detection scheme is highly important for copyright\nprotection. The future work is to improve the scheme by designing more\neffective locality sensitive hash algorithms for various digital media.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.05296,regular,pre_llm,2020,10,"{'ai_likelihood': 4.6690305074055995e-06, 'text': 'Improved Fault Analysis on SIMECK Ciphers\n\n  The advances of the Internet of Things (IoT) have had a fundamental impact\nand influence in sharping our rich living experiences. However, since IoT\ndevices are usually resource-constrained, lightweight block ciphers have played\na major role in serving as a building block for secure IoT protocols. In CHES\n2015, SIMECK, a family of block ciphers, was designed for resource-constrained\nIoT devices. Since its publication, there have been many analyses on its\nsecurity. In this paper, under the one bit-flip model, we propose a new\nefficient fault analysis attack on SIMECK ciphers. Compared to those previously\nreported attacks, our attack can recover the full master key by injecting\nfaults into only a single round of all SIMECK family members. This property is\ncrucial, as it is infeasible for an attacker to inject faults into different\nrounds of a SIMECK implementation on IoT devices in the real world.\nSpecifically, our attack is characterized by exercising a deep analysis of\ndifferential trail between the correct and faulty immediate ciphertexts.\nExtensive simulation evaluations are conducted, and the results demonstrate the\neffectiveness and correctness of our proposed attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.05586,regular,pre_llm,2020,10,"{'ai_likelihood': 3.741847144232856e-06, 'text': ""Inaccessible Entropy I: Inaccessible Entropy Generators and\n  Statistically Hiding Commitments from One-Way Functions\n\n  We put forth a new computational notion of entropy, measuring the\n(in)feasibility of sampling high-entropy strings that are consistent with a\ngiven generator. Specifically, the i'th output block of a generator G has\naccessible entropy at most k if the following holds: when conditioning on its\nprior coin tosses, no polynomial-time strategy $\\widetilde{G}$ can generate\nvalid output for G's i'th output block with entropy greater than k. A generator\nhas inaccessible entropy if the total accessible entropy (summed over the\nblocks) is noticeably smaller than the real entropy of G's output.\n  As an application of the above notion, we improve upon the result of Haitner,\nNguyen, Ong, Reingold, and Vadhan [Sicomp '09], presenting a much simpler and\nmore efficient construction of statistically hiding commitment schemes from\narbitrary one-way functions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.05692,regular,pre_llm,2020,10,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'On the Security of Group Communication Schemes\n\n  Secure group communications are a mechanism facilitating protected\ntransmission of messages from a sender to multiple receivers, and many emerging\napplications in both wired and wireless networks need the support of such a\nmechanism. There have been many secure group communication schemes in wired\nnetworks, which can be directly adopted in, or appropriately adapted to,\nwireless networks such as mobile ad hoc networks (MANETs) and sensor networks.\nIn this paper we show that the popular group communication schemes that we have\nexamined are vulnerable to the following attack: An outside adversary who\ncompromises a certain legitimate group member could obtain {\\em all} past and\npresent group keys (and thus all the messages protected by them); this is in\nsharp contrast to the widely-accepted belief that a such adversary can only\nobtain the present group key (and thus the messages protected by it). In order\nto understand and deal with the attack, we formalize two security models for\nstateful and stateless group communication schemes. We show that some practical\nmethods can make a {\\em subclass} of existing group communication schemes\nimmune to the attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.07094,regular,pre_llm,2020,10,"{'ai_likelihood': 2.2517310248480903e-06, 'text': ""Exploiting Interfaces of Secure Encrypted Virtual Machines\n\n  Cloud computing is a convenient model for processing data remotely. However,\nusers must trust their cloud provider with the confidentiality and integrity of\nthe stored and processed data. To increase the protection of virtual machines,\nAMD introduced SEV, a hardware feature which aims to protect code and data in a\nvirtual machine. This allows to store and process sensitive data in cloud\nenvironments without the need to trust the cloud provider or the underlying\nsoftware. However, the virtual machine still depends on the hypervisor for\nperforming certain activities, such as the emulation of special CPU\ninstructions, or the emulation of devices. Yet, most code that runs in virtual\nmachines was not written with an attacker model which considers the hypervisor\nas malicious. In this work, we introduce a new class of attacks in which a\nmalicious hypervisor manipulates external interfaces of an SEV or SEV-ES\nvirtual machine to make it act against its own interests. We start by showing\nhow we can make use of virtual devices to extract encryption keys and secret\ndata of a virtual machine. We then show how we can reduce the entropy of\nprobabilistic kernel defenses in the virtual machine by carefully manipulating\nthe results of the CPUID and RDTSC instructions. We continue by showing an\napproach for secret data exfiltration and code injection based on the forgery\nof MMIO regions over the VM's address space. Finally, we show another attack\nwhich forces decryption of the VM's stack and uses Return Oriented Programming\nto execute arbitrary code inside the VM. While our approach is also applicable\nto traditional virtualization environments, its severity significantly\nincreases with the attacker model of SEV-ES, which aims to protect a virtual\nmachine from a benign but vulnerable hypervisor.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2010.10788,review,pre_llm,2020,10,"{'ai_likelihood': 1.3245476616753473e-07, 'text': '""Are you home alone?"" ""Yes"" Disclosing Security and Privacy\n  Vulnerabilities in Alexa Skills\n\n  The home voice assistants such as Amazon Alexa have become increasingly\npopular due to many interesting voice-activated services provided through\nspecial applications called skills. These skills, though useful, have also\nintroduced new security and privacy challenges. Prior work has verified that\nAlexa is vulnerable to multiple types of voice attacks, but the security and\nprivacy risk of using skills has not been fully investigated. In this work, we\nstudy an adversary model that covers three severe privacy-related\nvulnerabilities, namely,over-privileged resource access, hidden\ncode-manipulation and hidden content-manipulation. By exploiting these\nvulnerabilities, malicious skills can not only bypass the security tests in the\nvetting process, but also surreptitiously change their original functions in an\nattempt to steal users\' personal information. What makes the situation even\nworse is that the attacks can be extended from virtual networks to the physical\nworld. We systematically study the security issues from the feasibility and\nimplementation of the attacks to the design of countermeasures. We also made a\ncomprehensive survey study of 33,744 skills in Alex Skills Store.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.05322,regular,pre_llm,2020,11,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Guarding Serverless Applications with SecLambda\n\n  As an emerging application paradigm, serverless computing attracts attention\nfrom more and more attackers. Unfortunately, security tools for conventional\napplications cannot be easily ported to serverless, and existing serverless\nsecurity solutions are inadequate. In this paper, we present \\emph{SecLambda},\nan extensible security framework that leverages local function state and global\napplication state to perform sophisticated security tasks to protect an\napplication. We show how SecLambda can be used to achieve control flow\nintegrity, credential protection, and rate limiting in serverless applications.\nWe evaluate the performance overhead and security of SecLambda using realistic\nopen-source applications, and our results suggest that SecLambda can mitigate\nseveral attacks while introducing relatively low performance overhead.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.02607,regular,pre_llm,2020,11,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Towards a Theory of Special-purpose Program Obfuscation\n\n  Most recent theoretical literature on program obfuscation is based on notions\nlike Virtual Black Box (VBB) obfuscation and indistinguishability Obfuscation\n(iO). These notions are very strong and are hard to satisfy. Further, they\noffer far more protection than is typically required in practical applications.\nOn the other hand, the security notions introduced by software security\nresearchers are suitable for practical designs but are not formal or precise\nenough to enable researchers to provide a quantitative security assurance.\nHence, in this paper, we introduce a new formalism for practical program\nobfuscation that still allows rigorous security proofs. We believe our\nformalism will make it easier to analyse the security of obfuscation schemes.\nTo show the flexibility and power of our formalism, we give a number of\nexamples. Moreover, we explain the close relationship between our formalism and\nthe task of providing obfuscation challenges.\n  This is the full version of the paper. In this version, we also give a new\nrigorous analysis of several obfuscation techniques and we provide directions\nfor future research.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.10012,regular,pre_llm,2020,11,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'KeyGuard: Using Selective Encryption to Mitigate Keylogging in\n  Third-Party IME\n\n  As mobile devices become ubiquitous, people around the world have enjoyed the\nconvenience they have brought to our lives. At the same time, the increasing\nsecurity threats that rise from using mobile devices not only have caught\nattention from cyber security agencies but also have become a valid concern for\nmobile users. Keylogging is one of the mobile security threats caused by using\ninsecure third-party IME (input method editor) applications. Keylogging, as the\nname suggests, keeps track of user\\rq s key events performed on the device and\nstores all the events in a log. The log could include highly sensitive data\nsuch as credit card number, social security number, and passwords. This paper\npresents a novel solution by intercepting the keystroke events triggered by a\nuser and encrypting them before sending them to the third-party IME, making the\nthird-party IME unable to log what the users actually entered on the screen.\nInput will be decrypted when showing on text view on the underlying app. This\nsolution addresses the fundamental reason why an IME may leak sensitive\ninformation since an IME will no longer have access to the user\\rq s actual\nsensitive information, which will greatly reduce the chance of leaking\nsensitive information by using a third-party IME while maintaining the\nfunctionalities of the third-party IME at the same time.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.03814,regular,pre_llm,2020,11,"{'ai_likelihood': 1.6887982686360678e-06, 'text': 'Privacy-Preserving and Efficient Data Collection Scheme for AMI Networks\n  Using Deep Learning\n\n  In advanced metering infrastructure (AMI), smart meters (SMs), which are\ninstalled at the consumer side, send fine-grained power consumption readings\nperiodically to the electricity utility for load monitoring and energy\nmanagement. Change and transmit (CAT) is an efficient approach to collect these\nreadings, where the readings are not transmitted when there is no enough change\nin consumption. However, this approach causes a privacy problem that is by\nanalyzing the transmission pattern of an SM, sensitive information on the house\ndwellers can be inferred. For instance, since the transmission pattern is\ndistinguishable when dwellers are on travel, attackers may analyze the pattern\nto launch a presence-privacy attack (PPA) to infer whether the dwellers are\nabsent from home. In this paper, we propose a scheme, called ""STDL"", for\nefficient collection of power consumption readings in AMI networks while\npreserving the consumers\' privacy by sending spoofing transmissions (redundant\nreal readings) using a deep-learning approach. We first use a clustering\ntechnique and real power consumption readings to create a dataset for\ntransmission patterns using the CAT approach. Then, we train an attacker model\nusing deep-learning, and our evaluations indicate that the success rate of the\nattacker is about 91%. Finally, we train a deep-learning-based defense model to\nsend spoofing transmissions efficiently to thwart the PPA. Extensive\nevaluations are conducted, and the results indicate that our scheme can reduce\nthe attacker\'s success rate, to 13.52% in case he knows the defense model and\nto 3.15% in case he does not know the model, while still achieving high\nefficiency in terms of the number of readings that should be transmitted. Our\nmeasurements indicate that the proposed scheme can reduce the number of\nreadings that should be transmitted by about 41% compared to continuously\ntransmitting readings.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.14159,regular,pre_llm,2020,11,"{'ai_likelihood': 0.00016636318630642362, 'text': 'Adamastor: a New Low Latency and Scalable Decentralized Anonymous\n  Payment System\n\n  This paper presents Adamastor, a new low latency and scalable decentralized\nanonymous payment system, which is an extension of Ring Confidential\nTransactions (RingCT) that is compatible with consensus algorithms that use\nDelegated Proof of Stake (DPoS) as a defense mechanism against Sybil attacks.\nAdamastor also includes a new Decoy Selection Algorithm (DSA) that can be of\nindependent interest, called SimpleDSA, a crucial aspect of protocols that use\nring signatures to anonymize the sender. SimpleDSA offers security against\nhomogeneity attacks and chain analysis. Moreover, it enables the pruning of\nspent outputs, addressing the issue of perpetual output growth commonly\nassociated with such schemes. Adamastor is implemented and evaluated using the\nNarwhal consensus algorithm, demonstrating significantly lower latency compared\nto Proof of Work based cryptocurrencies. Adamastor also exhibits ample\nscalability, making it suitable for a decentralized and anonymous payment\nnetwork.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.04412,regular,pre_llm,2020,11,"{'ai_likelihood': 4.635916815863716e-06, 'text': ""Look Before You Leap: Detecting Phishing Web Pages by Exploiting Raw URL\n  And HTML Characteristics\n\n  Phishing websites distribute unsolicited content and are frequently used to\ncommit email and internet fraud; detecting them before any user information is\nsubmitted is critical. Several efforts have been made to detect these phishing\nwebsites in recent years. Most existing approaches use hand-crafted lexical and\nstatistical features from a website's textual content to train classification\nmodels to detect phishing web pages. However, these phishing detection\napproaches have a few challenges, including 1) the tediousness of extracting\nhand-crafted features, which require specialized domain knowledge to determine\nwhich features are useful for a particular platform; and 2) the difficulties\nencountered by models built on hand-crafted features to capture the semantic\npatterns in words and characters in URL and HTML content. To address these\nchallenges, this paper proposes WebPhish, an end-to-end deep neural network\ntrained using embedded raw URLs and HTML content to detect website phishing\nattacks. First, the proposed model automatically employs an embedding technique\nto extract the corresponding characters into homologous dense vectors. Then,\nthe concatenation layer merges the URL and HTML embedding matrices. Following\nthat, Convolutional layers are used to model its semantic dependencies.\nExtensive experiments were conducted with real-world phishing data, which\nyielded an accuracy of 98.1\\%, showing that WebPhish outperforms baseline\ndetection approaches in identifying phishing pages.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.03669,review,pre_llm,2020,11,"{'ai_likelihood': 2.284844716389974e-06, 'text': ""Internet Security Awareness of Filipinos: A Survey Paper\n\n  Purpose. This paper examines the Internet security perception of Filipinos to\nestablish a need and sense of urgency on the part of the government to create a\nculture of cybersecurity for every Filipino. Method. A quantitative survey was\nconducted through traditional, online, and phone interviews among 252\nrespondents using a two-page questionnaire that covers basic demographic\ninformation and two key elements (1) Internet usage and (2) security practices.\nResults. Based on findings, there is a sharp increase in Internet users for the\nlast three years (50%), and most access to the Internet through mobile (94.4%).\nAlthough at home is the most frequent location for Internet access (94.4%), a\ngood percentage still use free WiFi access points available in malls (22.2%),\nrestaurants (11.1%), and other public areas (38.9%) doing Internet services\n(email and downloading) that are vulnerable to cyberattacks. The study also\nrevealed that although respondents may have good knowledge of Internet security\nsoftware, proper implementation is very limited. Conclusion. Filipinos are\nsusceptible to cyberattacks, particularly to phishing and malware attacks.\nAlso, the majority of the respondents' Internet security perception is\nderivative: they practice online measures but with a limited understanding of\nthe purpose. Therefore proper education, through training and awareness, is an\neffective approach to remedy the situation. Recommendations. The Philippine\ngovernment must now take actions and tap industries to educate Filipinos about\nInternet security before any negative consequences happen in the future.\nResearch Implications. The information collected sets a clear picture of the\nimportance of cybersecurity awareness from a regional to a global perspective.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.0585,regular,pre_llm,2020,11,"{'ai_likelihood': 2.384185791015625e-06, 'text': 'Detecting Adversarial Patches with Class Conditional Reconstruction\n  Networks\n\n  Defending against physical adversarial attacks is a rapidly growing topic in\ndeep learning and computer vision. Prominent forms of physical adversarial\nattacks, such as overlaid adversarial patches and objects, share similarities\nwith digital attacks, but are easy for humans to notice. This leads us to\nexplore the hypothesis that adversarial detection methods, which have been\nshown to be ineffective against adaptive digital adversarial examples, can be\neffective against these physical attacks. We use one such detection method\nbased on autoencoder architectures, and perform adversarial patching\nexperiments on MNIST, SVHN, and CIFAR10 against a CNN architecture and two\nCapsNet architectures. We also propose two modifications to the EM-Routed\nCapsNet architecture, Affine Voting and Matrix Capsule Dropout, to improve its\nclassification performance. Our investigation shows that the detector retains\nsome of its effectiveness even against adaptive adversarial patch attacks. In\naddition, detection performance tends to decrease among all the architectures\nwith the increase of dataset complexity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.0626,regular,pre_llm,2020,11,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'Effective Notification Campaigns on the Web: A Matter of Trust, Framing,\n  and Support\n\n  Misconfigurations and outdated software are a major cause of compromised\nwebsites and data leaks. Past research has proposed and evaluated sending\nautomated security notifications to the operators of misconfigured websites,\nbut encountered issues with reachability, mistrust, and a perceived lack of\nimportance. In this paper, we seek to understand the determinants of effective\nnotifications. We identify a data protection misconfiguration that affects 12.7\n% of the 1.3 million websites we scanned and opens them up to legal liability.\nUsing a subset of 4754 websites, we conduct a multivariate randomized\ncontrolled notification experiment, evaluating contact medium, sender, and\nframing of the message. We also include a link to a public web-based\nself-service tool that is run by us in disguise and conduct an anonymous survey\nof the notified website owners (N=477) to understand their perspective.\n  We find that framing a misconfiguration as a problem of legal compliance can\nincrease remediation rates, especially when the notification is sent as a\nletter from a legal research group, achieving remediation rates of 76.3 %\ncompared to 33.9 % for emails sent by computer science researchers warning\nabout a privacy issue. Across all groups, 56.6 % of notified owners remediated\nthe issue, compared to 9.2 % in the control group. In conclusion, we present\nfactors that lead website owners to trust a notification, show what framing of\nthe notification brings them into action, and how they can be supported in\nremediating the issue.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.03732,regular,pre_llm,2020,11,"{'ai_likelihood': 3.5100513034396704e-06, 'text': 'Identifying interception possibilities for WhatsApp communication\n\n  On a daily basis, law enforcement officers struggle with suspects using\nmobile communication applications for criminal activities. These mobile\napplications replaced SMS-messaging and evolved the last few years from\nplain-text data transmission and storage to an encrypted version. Regardless of\nthe benefits for all law abiding citizens, this is considered to be the\ndownside for criminal investigations. Normal smartphone, computer or network\ninvestigations do no longer provide the contents of the communication in\nreal-time when suspects are using apps like WhatsApp, Signal or Telegram. Among\nthem, WhatsApp is one of the most common smartphone applications for\ncommunication, both criminal as well as legal activities. Early 2016 WhatsApp\nintroduced end-to-end encryption for all users, immediately keeping law\nenforcement officers around the world in the dark. Existing research to\nrecuperate the position of law enforcement is limited to a single field of\ninvestigation and often limited to post mortem research on smartphone or\ncomputer while wiretapping is limited to metadata information. Therefore, it\nprovides only historical data or metadata while law enforcement officers want a\ncontinuous stream of live and substantive information. This paper identified\nthat gap in available scenarios for law enforcement investigations and\nidentified a gap in methods available for forensic acquiring and processing\nthese scenarios. In this paper, we propose a forensic approach to create\nreal-time insight in the WhatsApp communication. Our approach is based on the\nwiretapping, decrypting WhatsApp databases, open source intelligence and\nWhatsApp Web communication analysis. We also evaluate our method with different\nscenarios in WhatsApp forensics to prove its feasibility and efficiency.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.02901,regular,pre_llm,2020,11,"{'ai_likelihood': 6.953875223795574e-07, 'text': ""Lessons Learnt from a 2FA roll out within a higher education\n  organisation\n\n  Rolling out a new security mechanism in an organisation requires planning,\ngood communication, adoption from users, iterations of reflection on the\nchallenges experienced and how they were overcome. Our case study elicited\nusers' perceptions to reflect on the adoption and usage of the two factor\nauthentication (2FA) mechanism being rolled out within our higher education\norganisation. This was achieved using a mixed method research approach. Our\nqualitative analysis, using content and thematic coding, revealed that\ninitially SMS was the most popular 'second factor' and the main usability issue\nwith 2FA was the getting the authenticator app to work; this result was\nunexpected by the IT team and led to a change in how the technology was\nsubsequently rolled out to make the authenticator app the default primary\nsecond factor. Several lessons were learnt about the information users needed;\nthis included how to use the technology in different scenarios and also a wider\nappreciation of why the technology was beneficial to a user and the\norganisation. The case study also highlighted a positive impact on the security\nposture of the organisation which was measure using IT service request metrics.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.14163,regular,pre_llm,2020,11,"{'ai_likelihood': 2.228551440768772e-05, 'text': 'A Closer Look at the Tropical Cryptography\n\n  We examine two public key exchange protocols proposed recently by Grigoriev\nand Shpilrain (arXiv:1811.06386), which use tropical algebra. We introduce a\nfast attack on the first protocol, and we show that the second protocol cannot\nbe implemented as described.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.12546,regular,pre_llm,2020,11,"{'ai_likelihood': 8.609559800889757e-07, 'text': ""Developing a Security Testbed for Industrial Internet of Things\n\n  While achieving security for Industrial Internet of Things (IIoT) is a\ncritical and non-trivial task, more attention is required for brownfield IIoT\nsystems. This is a consequence of long life cycles of their legacy devices\nwhich were initially designed without considering security and IoT\nconnectivity, but they are now becoming more connected and integrated with\nemerging IoT technologies and messaging communication protocols. Deploying\ntoday's methodologies and solutions in brownfield IIoT systems is not viable,\nas security solutions must co-exist and fit these systems requirements. This\nnecessitates a realistic standardized IIoT testbed that can be used as an\noptimal format to measure the credibility of security solutions of IIoT\nnetworks, analyze IIoT attack landscapes and extract threat intelligence.\nDeveloping a testbed for brownfield IIoT systems is considered a significant\nchallenge as these systems are comprised of legacy, heterogeneous devices,\ncommunication layers and applications that need to be implemented holistically\nto achieve high fidelity. In this paper, we propose a new generic end-to-end\nIIoT security testbed, with a particular focus on the brownfield system and\nprovide details of the testbed's architectural design and the implementation\nprocess. The proposed testbed can be easily reproduced and reconfigured to\nsupport the testing activities of new processes and various security scenarios.\nThe proposed testbed operation is demonstrated on different connected devices,\ncommunication protocols and applications. The experiments demonstrate that this\ntestbed is effective in terms of its operation and security testing. A\ncomparison with existing testbeds, including a table of features is provided.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.07895,regular,pre_llm,2020,11,"{'ai_likelihood': 9.503629472520617e-06, 'text': ""TDACS: an ABAC and Trust-based Dynamic Access Control Scheme in Hadoop\n\n  The era of big data has promoted the vigorous development of many industries,\nboosting the full potential of holistic data-driven analysis. Hadoop has become\nthe primary choice for mainstream platforms used by stakeholders to process big\ndata. Thereafter, the security of Hadoop platform has arisen tremendous\nattention worldwide. In this paper, we mainly concentrate on enforcing access\ncontrol on users to ensure platform security. First, we leverage access proxy\nintegrated with attribute-based access control (ABAC) model to implement\nfront-end authorization, which can fully reflect and cope with the flexible\nnature of the complex access control process in Hadoop platform, as well as can\nrelease back-end resources from complex authorization process through access\nproxy. Moreover, in order to ensure the fine-granularity of authorization, the\naccess proxy maintains a list composed of trust threshold value provided by\neach resource according to its importance. The access proxy interacts with the\nblockchain network to obtain the user's trust evaluation value, which serves as\nan important basis for dynamic authorization determination. More specifically,\nblockchain network works together on-chain and off-chain modes. The user's\nhistorical behavior data is stored off-chain, and the corresponding hash value\nis anchored on-chain. Consequently, the user's trust value is evaluated based\non his historical behavior stored on the blockchain platform. Meanwhile, the\nauthenticity of user behavior data can be guaranteed, thereby ensuring the\nreliability of trust assessment results. Our experiment demonstrates that the\nproposed model can dynamically and flexibly adjust user permissions to ensure\nthe security of the platform, while time and money are consumed within a\nreasonable range.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.06458,regular,pre_llm,2020,11,"{'ai_likelihood': 1.556343502468533e-06, 'text': 'Golden Grain: Building a Secure and Decentralized Model Marketplace for\n  MLaaS\n\n  ML-as-a-service (MLaaS) becomes increasingly popular and revolutionizes the\nlives of people. A natural requirement for MLaaS is, however, to provide highly\naccurate prediction services. To achieve this, current MLaaS systems integrate\nand combine multiple well-trained models in their services. Yet, in reality,\nthere is no easy way for MLaaS providers, especially for startups, to collect\nsufficiently well-trained models from individual developers, due to the lack of\nincentives. In this paper, we aim to fill this gap by building up a model\nmarketplace, called as Golden Grain, to facilitate model sharing, which\nenforces the fair model-money swapping process between individual developers\nand MLaaS providers. Specifically, we deploy the swapping process on the\nblockchain, and further introduce a blockchain-empowered model benchmarking\nprocess for transparently determining the model prices according to their\nauthentic performances, so as to motivate the faithful contributions of\nwell-trained models. Especially, to ease the blockchain overhead for model\nbenchmarking, our marketplace carefully offloads the heavy computation and\ndesigns a secure off-chain on-chain interaction protocol based on a trusted\nexecution environment (TEE), for ensuring both the integrity and authenticity\nof benchmarking. We implement a prototype of our Golden Grain on the Ethereum\nblockchain, and conduct extensive experiments using standard benchmark datasets\nto demonstrate the practically affordable performance of our design.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.07483,regular,pre_llm,2020,11,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Removable Weak Keys for Discrete Logarithm Based Cryptography\n\n  We describe a novel type of weak cryptographic private key that can exist in\nany discrete logarithm based public-key cryptosystem set in a group of prime\norder $p$ where $p-1$ has small divisors. Unlike the weak private keys based on\n\\textit{numerical size} (such as smaller private keys, or private keys lying in\nan interval) that will \\textit{always} exist in any DLP cryptosystems, our type\nof weak private keys occurs purely due to parameter choice of $p$, and hence,\ncan be removed with appropriate value of $p$. Using the theory of implicit\ngroup representations, we present algorithms that can determine whether a key\nis weak, and if so, recover the private key from the corresponding public key.\nWe analyze several elliptic curves proposed in the literature and in various\nstandards, giving counts of the number of keys that can be broken with\nrelatively small amounts of computation. Our results show that many of these\ncurves, including some from standards, have a considerable number of such weak\nprivate keys. We also use our methods to show that none of the 14 outstanding\nCerticom Challenge problem instances are weak in our sense, up to a certain\nweakness bound.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.01473,regular,pre_llm,2020,11,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'A Framework for Prediction and Storage of Battery Life in IoT Devices\n  using DNN and Blockchain\n\n  As digitization increases, the need to automate various entities becomes\ncrucial for development. The data generated by the IoT devices need to be\nprocessed accurately and in a secure manner. The basis for the success of such\na scenario requires blockchain as a means of unalterable data storage to\nimprove the overall security and trust in the system. By providing trust in an\nautomated system, with real-time data updates to all stakeholders, an improved\nform of implementation takes the stage and can help reduce the stress of\nadaptability to complete automated systems. This research focuses on a use case\nwith respect to the real time Internet of Things (IoT) network which is\ndeployed at the beach of Chicago Park District. This real time data which is\ncollected from various sensors is then used to design a predictive model using\nDeep Neural Networks for estimating the battery life of IoT sensors that is\ndeployed at the beach. This proposed model could help the government to plan\nfor placing orders of replaceable batteries before time so that there can be an\nuninterrupted service. Since this data is sensitive and requires to be secured,\nthe predicted battery life value is stored in blockchain which would be a\ntamper-proof record of the data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.01685,regular,pre_llm,2020,11,"{'ai_likelihood': 2.8808911641438803e-06, 'text': 'Characterising attacks targeting low-cost routers: a MikroTik case study\n  (Extended)\n\n  Attacks targeting network infrastructure devices pose a threat to the\nsecurity of the internet. An attack targeting such devices can affect an entire\nautonomous system. In recent years, malware such as VPNFilter, Navidade, and\nSonarDNS has been used to compromise low-cost routers and commit all sorts of\ncybercrimes from DDoS attacks to ransomware deployments. Routers of the type\nconcerned are used both to provide last-mile access for home users and to\nmanage interdomain routing (BGP). MikroTik is a particular brand of low-cost\nrouter. In our previous research, we found more than 4 million MikroTik routers\navailable on the internet. We have shown that these devices are also popular in\nInternet Exchange infrastructures. Despite their popularity, these devices are\nknown to have numerous vulnerabilities. In this paper, we extend our previous\nanalysis by presenting a long-term investigation of MikroTik-targeted attacks.\nBy using a highly interactive honeypot that we developed, we collected more\nthan 44 million packets over 120 days, from sensors deployed in Australia,\nBrazil, China, India, the Netherlands, and the United States. The incoming\ntraffic was classified on the basis of Common Vulnerabilities and Exposures to\ndetect attacks targeting MikroTik devices. That enabled us to identify a wide\nrange of activities on the system, such as cryptocurrency mining, DNS server\nredirection, and more than 3,000 successfully established tunnels used for\neavesdropping. Although this research focuses on Mikrotik devices, both the\nmethodology and the publicly available scripts can be easily applied to any\nother type of network device.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.02308,review,pre_llm,2020,11,"{'ai_likelihood': 9.934107462565105e-07, 'text': 'Database Intrusion Detection Systems (DIDs): Insider Threat Detection\n  via Behavioural-based Anomaly Detection Systems -- A Brief Survey of Concepts\n  and Approaches\n\n  One of the data security and privacy concerns is of insider threats, where\nlegitimate users of the system abuse the access privileges they hold. The\ninsider threat to data security means that an insider steals or leaks sensitive\npersonal information. Database Intrusion detection systems, specifically\nbehavioural-based database intrusion detection systems, have been shown\neffective in detecting insider attacks. This paper presents background concepts\non database intrusion detection systems in the context of detecting insider\nthreats and examines existing approaches in the literature on detecting\nmalicious accesses by an insider to Database Management Systems (DBMS).\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2011.09646,regular,pre_llm,2020,11,"{'ai_likelihood': 1.655684577094184e-06, 'text': ""Consensus with Preserved Privacy against Neighbor Collusion\n\n  This paper proposes a privacy-preserving algorithm to solve the average\nconsensus problem based on Shamir's secret sharing scheme, in which a network\nof agents reach an agreement on their states without exposing their individual\nstate until an agreement is reached. Unlike other methods, the proposed\nalgorithm renders the network resistant to the collusion of any given number of\nneighbors (even with all neighbors' colluding). Another virtue of this work is\nthat such a method can protect the network consensus procedure from\neavesdropping.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.0996,review,pre_llm,2020,12,"{'ai_likelihood': 4.437234666612413e-06, 'text': 'Understanding The Top 10 OWASP Vulnerabilities\n\n  Understanding the common vulnerabilities in web applications help businesses\nbe better prepared in protecting their data against such attacks. With the\nknowledge gained from research users and developers can be better equipped to\ndeal with the most common attacks and form solutions to prevent future attacks\nagainst their web applications. Vulnerabilities exist in many forms within\nmodern web applications which can be easily mitigated with investment of time\nand research.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.10825,regular,pre_llm,2020,12,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Hashcashed Reputation with Application in Designing Watchtowers\n\n  We propose a novel reputation system to stimulate well-behaviour, and\ncompetition in online markets. Our reputation system is suited for markets\nwhere a publicly-verifiable ""proof-of-misbehaviour"" can be generated when one\nparty misbehaves. Such markets include those that provide blockchain services,\nsuch as monitoring services by watchtowers. Watchtowers are entities that watch\nthe blockchain on behalf of their offline clients to protect the clients\'\ninterests in applications such as payment networks (e.g., the Lightning\nnetwork). In practice, there is no trust between clients and watchtowers, and\nit is challenging to incentivize watchtowers to well-behave (e.g., to refuse\nbribery). To showcase our reputation system, in this work, we create an open\nmarket of watchtowers, where watchtowers are motivated to not only deliver\ntheir promised service but also reduce their service fees in competition with\neach other.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.01159,regular,pre_llm,2020,12,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Smarter Password Guessing Techniques Leveraging Contextual Information\n  and OSINT\n\n  In recent decades, criminals have increasingly used the web to research,\nassist and perpetrate criminal behaviour. One of the most important ways in\nwhich law enforcement can battle this growing trend is through accessing\npertinent information about suspects in a timely manner. A significant\nhindrance to this is the difficulty of accessing any system a suspect uses that\nrequires authentication via password. Password guessing techniques generally\nconsider common user behaviour while generating their passwords, as well as the\npassword policy in place. Such techniques can offer a modest success rate\nconsidering a large/average population. However, they tend to fail when\nfocusing on a single target -- especially when the latter is an educated user\ntaking precautions as a savvy criminal would be expected to do. Open Source\nIntelligence is being increasingly leveraged by Law Enforcement in order to\ngain useful information about a suspect, but very little is currently being\ndone to integrate this knowledge in an automated way within password cracking.\nThe purpose of this research is to delve into the techniques that enable the\ngathering of the necessary context about a suspect and find ways to leverage\nthis information within password guessing techniques.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.06884,regular,pre_llm,2020,12,"{'ai_likelihood': 1.466936535305447e-05, 'text': 'AIR-FI: Generating Covert Wi-Fi Signals from Air-Gapped Computers\n\n  In this paper, we show that attackers can exfiltrate data from air-gapped\ncomputers via Wi-Fi signals. Malware in a compromised air-gapped computer can\ngenerate signals in the Wi-Fi frequency bands. The signals are generated\nthrough the memory buses - no special hardware is required. Sensitive data can\nbe modulated and secretly exfiltrated on top of the signals. We show that\nnearby Wi-Fi capable devices (e.g., smartphones, laptops, IoT devices) can\nintercept these signals, decode them, and send them to the attacker over the\nInternet. To extract the signals, we utilize the physical layer information\nexposed by the Wi-Fi chips. We implement the transmitter and receiver and\ndiscuss design considerations and implementation details. We evaluate this\ncovert channel in terms of bandwidth and distance and present a set of\ncountermeasures. Our evaluation shows that data can be exfiltrated from\nair-gapped computers to nearby Wi-Fi receivers located a distance of several\nmeters away.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.01971,regular,pre_llm,2020,12,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'IoT DoS and DDoS Attack Detection using ResNet\n\n  The network attacks are increasing both in frequency and intensity with the\nrapid growth of internet of things (IoT) devices. Recently, denial of service\n(DoS) and distributed denial of service (DDoS) attacks are reported as the most\nfrequent attacks in IoT networks. The traditional security solutions like\nfirewalls, intrusion detection systems, etc., are unable to detect the complex\nDoS and DDoS attacks since most of them filter the normal and attack traffic\nbased upon the static predefined rules. However, these solutions can become\nreliable and effective when integrated with artificial intelligence (AI) based\ntechniques. During the last few years, deep learning models especially\nconvolutional neural networks achieved high significance due to their\noutstanding performance in the image processing field. The potential of these\nconvolutional neural network (CNN) models can be used to efficiently detect the\ncomplex DoS and DDoS by converting the network traffic dataset into images.\nTherefore, in this work, we proposed a methodology to convert the network\ntraffic data into image form and trained a state-of-the-art CNN model, i.e.,\nResNet over the converted data. The proposed methodology accomplished 99.99\\%\naccuracy for detecting the DoS and DDoS in case of binary classification.\nFurthermore, the proposed methodology achieved 87\\% average precision for\nrecognizing eleven types of DoS and DDoS attack patterns which is 9\\% higher as\ncompared to the state-of-the-art.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.11072,regular,pre_llm,2020,12,"{'ai_likelihood': 3.013345930311415e-06, 'text': 'A Secured Protocol for IoT Networks\n\n  Researchers in the past have shown that Symmetric key cryptography is\ngenerally considered infeasible and public key cryptography, at times, fails to\nprovide sufficient security and integrity to data. In contrast to this\nprejudice, our paper presents a novel approach that establishes security to\ndata through encryption techniques like RSA and more importantly it identifies\na randomized path to route messages from source to the destination and ensures\nthat packets are delivered safely even when intermediate nodes are attacked by\nidentifying alternate paths between source and the destination.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.10876,regular,pre_llm,2020,12,"{'ai_likelihood': 2.317958407931858e-06, 'text': ""Concrete Evaluation of the Random Probing Security\n\n  We study masked implementation's security when an adversary randomly probes\neach of its internal variables, intending to recover non-trivial knowledge\nabout its secrets. We introduce a novel metric called Secret Recovery\nProbability (SRP) for assessing the informativeness of the probing leakages\nabout the masked secrets. To evaluate SRP, our starting point is to describe\nthe relations of the intermediate variables with a parity equation system where\nthe target secret is an unknown of this system ...\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.13807,regular,pre_llm,2020,12,"{'ai_likelihood': 2.9371844397650824e-05, 'text': ""Secure Hot Path Crowdsourcing with Local Differential Privacy under Fog\n  Computing Architecture\n\n  Crowdsourcing plays an essential role in the Internet of Things (IoT) for\ndata collection, where a group of workers is equipped with Internet-connected\ngeolocated devices to collect sensor data for marketing or research purpose. In\nthis paper, we consider crowdsourcing these worker's hot travel path. Each\nworker is required to report his real-time location information, which is\nsensitive and has to be protected. Encryption-based methods are the most direct\nway to protect the location, but not suitable for resource-limited devices.\nBesides, local differential privacy is a strong privacy concept and has been\ndeployed in many software systems. However, the local differential privacy\ntechnology needs a large number of participants to ensure the accuracy of the\nestimation, which is not always the case for crowdsourcing. To solve this\nproblem, we proposed a trie-based iterative statistic method, which combines\nadditive secret sharing and local differential privacy technologies. The\nproposed method has excellent performance even with a limited number of\nparticipants without the need of complex computation. Specifically, the\nproposed method contains three main components: iterative statistics, adaptive\nsampling, and secure reporting. We theoretically analyze the effectiveness of\nthe proposed method and perform extensive experiments to show that the proposed\nmethod not only provides a strict privacy guarantee, but also significantly\nimproves the performance from the previous existing solutions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.0846,review,pre_llm,2020,12,"{'ai_likelihood': 1.556343502468533e-06, 'text': 'Review and Test of Steganography Techniques\n\n  Steganography is the art of concealing a secret message within an\nappropriate-multimedia carrier such as images, audio, video files, and even\nnetwork packets. Steganographic techniques have been used since ancient times\nto hide the message from third-parties deemed to be enemies. On one hand,\nSteganography is a useful technique that has been applied in various useful\napplications. On the other hand, however, the same technique has been applied\nand used for the wrong purposes by people who have ill intentions. The increase\nin computational power and increase in security-awareness over the past few\nyears have propelled the application of steganography in computational\nsecurity-techniques. Being robust, undetectable, and having a good capacity of\nhidden-data, steganography has been preferred for hiding data than watermarking\nand cryptographic-techniques. This paper clarifies the application of\nsteganography on different multimedia-carriers by using various potential\ntools, methods, and principles to either apply or detect steganography\ntechniques.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.14227,regular,pre_llm,2020,12,"{'ai_likelihood': 1.58283445570204e-05, 'text': 'Detecting Colluding Sybil Attackers in Robotic Networks using\n  Backscatters\n\n  Due to the openness of wireless medium, robotic networks that consist of many\nminiaturized robots are susceptible to Sybil attackers, who can fabricate\nmyriads of fictitious robots. Such detrimental attacks can overturn the\nfundamental trust assumption in robotic collaboration and thus impede\nwidespread deployments of robotic networks in many collaborative tasks.\nExisting solutions rely on bulky multi-antenna systems to passively obtain\nfine-grained physical layer signatures, making them unaffordable to\nminiaturized robots. To overcome this limitation, we present ScatterID, a\nlightweight system that attaches featherlight and batteryless backscatter tags\nto single-antenna robots for Sybil attack mitigation. Instead of passively\n""observing"" signatures, ScatterID actively ""manipulates"" multipath propagation\nby exploiting backscatter tags to intentionally create rich multipath\nsignatures obtainable to single-antenna robots. Particularly, these signatures\nare used to carefully construct similarity vectors to thwart advanced Sybil\nattackers, who further trigger power-scaling and colluding attacks to generate\ndissimilar signatures. Then, a customized random forest model is developed to\naccurately infer the identity legitimacy of each robot. We implement ScatterID\non the iRobot Create platform and evaluate it under various Sybil attacks in\nreal-world environments. The experimental results show that ScatterID achieves\na high AUROC of 0.987 and obtains an overall accuracy of 95.4% under basic and\nadvanced Sybil attacks. Specifically, it can successfully detect 96.1% of fake\nrobots while mistakenly rejecting just 5.7% of legitimate ones.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.04117,regular,pre_llm,2020,12,"{'ai_likelihood': 3.046459621853299e-06, 'text': ""Local Dampening: Differential Privacy for Non-numeric Queries via Local\n  Sensitivity\n\n  Differential privacy is the state-of-the-art formal definition for data\nrelease under strong privacy guarantees. A variety of mechanisms have been\nproposed in the literature for releasing the output of numeric queries (e.g.,\nthe Laplace mechanism and smooth sensitivity mechanism). Those mechanisms\nguarantee differential privacy by adding noise to the true query's output. The\namount of noise added is calibrated by the notions of global sensitivity and\nlocal sensitivity of the query that measure the impact of the addition or\nremoval of an individual on the query's output. Mechanisms that use local\nsensitivity add less noise and, consequently, have a more accurate answer.\nHowever, although there has been some work on generic mechanisms for releasing\nthe output of non-numeric queries using global sensitivity (e.g., the\nExponential mechanism), the literature lacks generic mechanisms for releasing\nthe output of non-numeric queries using local sensitivity to reduce the noise\nin the query's output. In this work, we remedy this shortcoming and present the\nlocal dampening mechanism. We adapt the notion of local sensitivity for the\nnon-numeric setting and leverage it to design a generic non-numeric mechanism.\nWe provide theoretical comparisons to the exponential mechanism and show under\nwhich conditions the local dampening mechanism is more accurate than the\nexponential mechanism. We illustrate the effectiveness of the local dampening\nmechanism by applying it to three diverse problems: (i) percentile selection\nproblem. We report the p-th element in the database; (ii) Influential node\nanalysis. Given an influence metric, we release the top-k most influential\nnodes while preserving the privacy of the relationship between nodes in the\nnetwork; (iii) Decision tree induction. We provide a private adaptation to the\nID3 algorithm to build decision trees from a given tabular dataset.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.10566,regular,pre_llm,2020,12,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'FedServing: A Federated Prediction Serving Framework Based on Incentive\n  Mechanism\n\n  Data holders, such as mobile apps, hospitals and banks, are capable of\ntraining machine learning (ML) models and enjoy many intelligence services. To\nbenefit more individuals lacking data and models, a convenient approach is\nneeded which enables the trained models from various sources for prediction\nserving, but it has yet to truly take off considering three issues: (i)\nincentivizing prediction truthfulness; (ii) boosting prediction accuracy; (iii)\nprotecting model privacy.\n  We design FedServing, a federated prediction serving framework, achieving the\nthree issues. First, we customize an incentive mechanism based on Bayesian game\ntheory which ensures that joining providers at a Bayesian Nash Equilibrium will\nprovide truthful (not meaningless) predictions. Second, working jointly with\nthe incentive mechanism, we employ truth discovery algorithms to aggregate\ntruthful but possibly inaccurate predictions for boosting prediction accuracy.\nThird, providers can locally deploy their models and their predictions are\nsecurely aggregated inside TEEs. Attractively, our design supports popular\nprediction formats, including top-1 label, ranked labels and posterior\nprobability. Besides, blockchain is employed as a complementary component to\nenforce exchange fairness. By conducting extensive experiments, we validate the\nexpected properties of our design. We also empirically demonstrate that\nFedServing reduces the risk of certain membership inference attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.13464,review,pre_llm,2020,12,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'Security of Connected and Automated Vehicles\n\n  The transportation system is rapidly evolving with new connected and\nautomated vehicle (CAV) technologies that integrate CAVs with other vehicles\nand roadside infrastructure in a cyberphysical system (CPS). Through\nconnectivity, CAVs affect their environments and vice versa, increasing the\nsize of the cyberattack surface and the risk of exploitation of security\nvulnerabilities by malicious actors. Thus, greater understanding of potential\nCAV-CPS cyberattacks and of ways to prevent them is a high priority. In this\narticle we describe CAV-CPS cyberattack surfaces and security vulnerabilities,\nand outline potential cyberattack detection and mitigation strategies. We\nexamine emerging technologies - artificial intelligence, software-defined\nnetworks, network function virtualization, edge computing, information-centric\nand virtual dispersive networking, fifth generation (5G) cellular networks,\nblockchain technology, and quantum and postquantum cryptography - as potential\nsolutions aiding in securing CAVs and transportation infrastructure against\nexisting and future cyberattacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.14663,regular,pre_llm,2020,12,"{'ai_likelihood': 1.1258655124240452e-06, 'text': 'Assessing Information Quality in IoT Forensics: Theoretical Framework\n  and Model Implementation\n\n  IoT technologies pose serious challenges to digital Forensics. The\nacquisition of digital evidence is hindered by the number and extreme variety\nof IoT items, often lacking physical interfaces, connected in unprotected\nnetworks, feeding data to uncontrolled cloud services. In this paper we address\n""Information Quality"" in IoT Forensics, taking into account different levels of\ncomplexity and included human factors. After drawing a theoretical framework on\ndata quality and information quality, we focus on forensic analysis challenges\nin IoT environments, providing a use case of evidence collection for\ninvestigative purposes. At the end, we propose a formal framework for assessing\ninformation quality of IoT devices for Forensics analysis.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.03816,regular,pre_llm,2020,12,"{'ai_likelihood': 2.317958407931858e-06, 'text': 'Invisible Backdoor Attack with Sample-Specific Triggers\n\n  Recently, backdoor attacks pose a new security threat to the training process\nof deep neural networks (DNNs). Attackers intend to inject hidden backdoors\ninto DNNs, such that the attacked model performs well on benign samples,\nwhereas its prediction will be maliciously changed if hidden backdoors are\nactivated by the attacker-defined trigger. Existing backdoor attacks usually\nadopt the setting that triggers are sample-agnostic, $i.e.,$ different poisoned\nsamples contain the same trigger, resulting in that the attacks could be easily\nmitigated by current backdoor defenses. In this work, we explore a novel attack\nparadigm, where backdoor triggers are sample-specific. In our attack, we only\nneed to modify certain training samples with invisible perturbation, while not\nneed to manipulate other training components ($e.g.$, training loss, and model\nstructure) as required in many existing attacks. Specifically, inspired by the\nrecent advance in DNN-based image steganography, we generate sample-specific\ninvisible additive noises as backdoor triggers by encoding an\nattacker-specified string into benign images through an encoder-decoder\nnetwork. The mapping from the string to the target label will be generated when\nDNNs are trained on the poisoned dataset. Extensive experiments on benchmark\ndatasets verify the effectiveness of our method in attacking models with or\nwithout defenses.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.02848,regular,pre_llm,2020,12,"{'ai_likelihood': 1.6887982686360678e-06, 'text': ""Deterministic Random Number Generator Attack against the\n  Kirchhoff-Law-Johnson-Noise Secure Key Exchange Protocol\n\n  This paper demonstrates the vulnerability of the Kirchhoff-Law-Johnson-Noise\n(KLJN) secure key exchanger to compromised random number generator(s) even if\nthese random numbers are used solely to generate the noises emulating the\nJohnson noise of Alice's and Bob's resistors. The attacks shown are\ndeterministic in the sense that Eve's knowledge of Alice's and/or Bob's random\nnumbers is basically deterministic. Moreover, no statistical evaluation is\nneeded, except for rarely occurring events of negligible, random waiting time\nand verification time. We explore two situations. In the first case, Eve knows\nboth Alice's and Bob's random noises. We show that, in this situation, Eve can\nquickly crack the secure key bit by using Ohm's Law. In the other situation,\nEve knows only Bob's random noise. Then Eve first can learn Bob's resistance\nvalue by using Ohm's Law. Therefore, she will have the same knowledge as Bob,\nthus at the end of the bit exchange period, she will know Alice's bit.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.03706,regular,pre_llm,2020,12,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Pricing Security in Proof-of-Work Systems\n\n  A key component of security in decentralized blockchains is proof of\nopportunity cost among block producers. In the case of proof-of-work (PoW),\ncurrently used by the most prominent systems, the cost is due to spent\ncomputation. In this paper, we characterize the security investment of miners\nin terms of its cost in fiat money. This enables comparison of security\nallocations across PoW blockchains that generally use different PoW algorithms\nand reward miners in different cryptocurrency units. We prove that there exists\na unique allocation equilibrium, depending on market prices only, that is\nachieved by both strategic miners (who contemplate the actions of others) and\nby miners seeking only short-term profit. In fact, the latter will unknowingly\ncompensate for any attempt to deliberately shift security allocation away from\nequilibrium.\n  Our conclusions are supported analytically through the development of a\nMarkov decision process, game theoretical analysis, and derivation of no\narbitrage conditions. We corroborate those results with empirical evidence from\nmore than two years of blockchain and price data. Overall agreement is strong.\nWe show that between January 1, 2018 and August 1, 2020, market prices\npredicted security allocation between Bitcoin and Bitcoin Cash with error less\nthan 0.6%. And from the beginning of October 2019, until August 1, 2020, market\nprices predicted security allocation between Bitcoin and Litecoin with error of\n0.45%. These results are further corroborated by our establishment of\nGranger-causality between change in market prices and change in security\nallocation.\n  To demonstrate the practicality of our results, we describe a trustless\noracle that leverages the equilibrium to estimate the price ratios of PoW\ncryptocurrencies from on-chain information only.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.08042,review,pre_llm,2020,12,"{'ai_likelihood': 3.7550926208496094e-05, 'text': 'Enhancing Data Security in the User Layer of Mobile Cloud Computing\n  Environment: A Novel Approach\n\n  This paper reviews existing Intrusion Detection Systems (IDS) that target the\nMobile Cloud Computing (MCC), Cloud Computing (CC), and Mobile Device (MD)\nenvironment. The review identifies the drawbacks in existing solutions and\nproposes a novel approach towards enhancing the security of the User Layer (UL)\nin the MCC environment. The approach named MINDPRES (Mobile- Cloud Intrusion\nDetection and Prevention System) combines a host-based IDS and network-based\nIDS using Machine Learning (ML) techniques. It applies dynamic analysis of both\ndevice resources and network traffic in order to detect malicious activities at\nthe UL in the MCC environment. Preliminary investigations show that our\napproach will enhance the security of the UL in the MCC environment. Our future\nwork will include the development and the evaluation of the proposed model\nacross the various mobile platforms in the MCC environment.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.13718,review,pre_llm,2020,12,"{'ai_likelihood': 2.185503641764323e-06, 'text': 'Towards Assessing Critical Infrastructures Cyber-Security Culture During\n  Covid-19 Crisis: A Tailor-Made Survey\n\n  This paper outlines the design and development of a survey targeting the\ncyber-security culture assessment of critical infrastructures during the\nCOVID-19 crisis, when living routine was seriously disturbed and working\nreality fundamentally affected. Its foundations lie on a security culture\nframework consisted of 10 different security dimensions analysed into 52\ndomains examined under two different pillars: organizational and individual. In\nthis paper, a detailed questionnaire building analysis is being presented while\nrevealing the aims, goals and expected outcomes of each question. It concludes\nwith the survey implementation and delivery plan following a number of\npre-survey stages each serving a specific methodological purpose.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2012.12529,regular,pre_llm,2020,12,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'SCOPE: Secure Compiling of PLCs in Cyber-Physical Systems\n\n  Cyber-Physical Systems (CPS) are being widely adopted in critical\ninfrastructures, such as smart grids, nuclear plants, water systems,\ntransportation systems, manufacturing and healthcare services, among others.\nHowever, the increasing prevalence of cyberattacks targeting them raises a\ngrowing security concern in the domain. In particular, memory-safety attacks,\nthat exploit memory-safety vulnerabilities, constitute a major attack vector\nagainst real-time control devices in CPS. Traditional IT countermeasures\nagainst such attacks have limitations when applied to the CPS context: they\ntypically incur in high runtime overheads; which conflicts with real-time\nconstraints in CPS and they often abort the program when an attack is detected,\nthus harming availability of the system, which in turn can potentially result\nin damage to the physical world. In this work, we propose to enforce a\nfull-stack memory-safety (covering user-space and kernel-space attack surfaces)\nbased on secure compiling of PLCs to detect memory-safety attacks in CPS.\nFurthermore, to ensure availability, we enforce a resilient mitigation\ntechnique that bypasses illegal memory access instructions at runtime by\ndynamically instrumenting low-level code. We empirically measure the\ncomputational overhead caused by our approach on two experimental settings\nbased on real CPS. The experimental results show that our approach effectively\nand efficiently detects and mitigates memory-safety attacks in realistic CPS.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.03403,regular,pre_llm,2021,1,"{'ai_likelihood': 1.2616316477457683e-05, 'text': ""CryptoEmu: An Instruction Set Emulator for Computation Over Ciphers\n\n  Fully homomorphic encryption (FHE) allows computations over encrypted data.\nThis technique makes privacy-preserving cloud computing a reality. Users can\nsend their encrypted sensitive data to a cloud server, get encrypted results\nreturned and decrypt them, without worrying about data breaches.\n  This project report presents a homomorphic instruction set emulator,\nCryptoEmu, that enables fully homomorphic computation over encrypted data. The\nsoftware-based instruction set emulator is built upon an open-source,\nstate-of-the-art homomorphic encryption library that supports gate-level\nhomomorphic evaluation. The instruction set architecture supports multiple\ninstructions that belong to the subset of ARMv8 instruction set architecture.\nThe instruction set emulator utilizes parallel computing techniques to emulate\nevery functional unit for minimum latency. This project report includes details\non design considerations, instruction set emulator architecture, and datapath\nand control unit implementation. We evaluated and demonstrated the instruction\nset emulator's performance and scalability on a 48-core workstation. CryptoEmu\nhas shown a significant speedup in homomorphic computation performance when\ncompared with HELib, a state-of-the-art homomorphic encryption library.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.08879,regular,pre_llm,2021,1,"{'ai_likelihood': 7.881058586968316e-06, 'text': ""Privacy-Preserving and Efficient Verification of the Outcome in\n  Genome-Wide Association Studies\n\n  Providing provenance in scientific workflows is essential for reproducibility\nand auditability purposes. Workflow systems model and record provenance\ndescribing the steps performed to obtain the final results of a computation. In\nthis work, we propose a framework that verifies the correctness of the\nstatistical test results that are conducted by a researcher while protecting\nindividuals' privacy in the researcher's dataset. The researcher publishes the\nworkflow of the conducted study, its output, and associated metadata. They keep\nthe research dataset private while providing, as part of the metadata, a\npartial noisy dataset (that achieves local differential privacy). To check the\ncorrectness of the workflow output, a verifier makes use of the workflow, its\nmetadata, and results of another statistical study (using publicly available\ndatasets) to distinguish between correct statistics and incorrect ones. We use\ncase the proposed framework in the genome-wide association studies (GWAS), in\nwhich the goal is to identify highly associated point mutations (variants) with\na given phenotype. For evaluation, we use real genomic data and show that the\ncorrectness of the workflow output can be verified with high accuracy even when\nthe aggregate statistics of a small number of variants are provided. We also\nquantify the privacy leakage due to the provided workflow and its associated\nmetadata in the GWAS use-case and show that the additional privacy risk due to\nthe provided metadata does not increase the existing privacy risk due to\nsharing of the research results. Thus, our results show that the workflow\noutput (i.e., research results) can be verified with high confidence in a\nprivacy-preserving way. We believe that this work will be a valuable step\ntowards providing provenance in a privacy-preserving way while providing\nguarantees to the users about the correctness of the results.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.01395,regular,pre_llm,2021,1,"{'ai_likelihood': 2.615981631808811e-06, 'text': 'Analyzing Cyber-Attack Intention for Digital Forensics Using Case-Based\n  Reasoning\n\n  Cyber-attacks are increasing and varying dramatically day by day. It has\nbecome challenging to control cyber-attacks and to identify the perpetrators\nand their intentions. In general, the analysis of the intentions of\ncyber-attacks is one of the main challenges in digital forensics. In many cases\nof cyber-attacks, the analysis of the intent of the attacks determines the\nstrategy and tools used in the attack, thus facilitating the process of\nidentifying the perpetrator of the attack with greater accuracy. In this paper\na model will be proposed to analyze the intentions of cyber-attacks. In this\nproposal, a set of steps will be conceived by linking them with a case-based\nreasoning methodology. This model will be examined by analyzing the intent of\nattacks for some cases and comparing the results with other methods of\nanalyzing the intent of attacks. Hopefully the results will determine the\nintent of cyber-attacks more accurately.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.09834,review,pre_llm,2021,1,"{'ai_likelihood': 6.953875223795574e-07, 'text': ""Privacy Preserving Techniques Applied to CPNI Data: Analysis and\n  Recommendations\n\n  With mobile phone penetration rates reaching 90%, Consumer Proprietary\nNetwork Information (CPNI) can offer extremely valuable information to\ndifferent sectors, including policymakers. Indeed, as part of CPNI, Call Detail\nRecords have been successfully used to provide real-time traffic information,\nto improve our understanding of the dynamics of people's mobility and so to\nallow prevention and measures in fighting infectious diseases, and to offer\npopulation statistics. While there is no doubt of the usefulness of CPNI data,\nprivacy concerns regarding sharing individuals' data have prevented it from\nbeing used to its full potential. Traditional de-anonymization measures, such\nas pseudonymization and standard de-identification, have been shown to be\ninsufficient to protect privacy. This has been specifically shown on mobile\nphone datasets. As an example, researchers have shown that with only four data\npoints of approximate place and time information of a user, 95% of users could\nbe re-identified in a dataset of 1.5 million mobile phone users. In this\nlandscape paper, we will discuss the state-of-the-art anonymization techniques\nand their shortcomings.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.02556,review,pre_llm,2021,1,"{'ai_likelihood': 9.602970547146267e-07, 'text': ""Spatial K-anonymity: A Privacy-preserving Method for COVID-19 Related\n  Geospatial Technologies\n\n  There is a growing need for spatial privacy considerations in the many\ngeo-spatial technologies that have been created as solutions for\nCOVID-19-related issues. Although effective geo-spatial technologies have\nalready been rolled out, most have significantly sacrificed privacy for\nutility. In this paper, we explore spatial k-anonymity, a privacy-preserving\nmethod that can address this unnecessary tradeoff by providing the best of both\nprivacy and utility. After evaluating its past implications in geo-spatial use\ncases, we propose applications of spatial k-anonymity in the data sharing and\nmanaging of COVID-19 contact tracing technologies as well as heat maps showing\na user's travel history. We then justify our propositions by comparing spatial\nk-anonymity with several other spatial privacy methods, including differential\nprivacy, geo-indistinguishability, and manual consent based redaction. Our hope\nis to raise awareness of the ever-growing risks associated with spatial privacy\nand how they can be solved with Spatial K-anonymity.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.06137,regular,pre_llm,2021,1,"{'ai_likelihood': 7.947285970052084e-07, 'text': 'Quantitative System-Level Security Verification of the IoV\n  Infrastructure\n\n  The Internet of Vehicles (IoV) equips vehicles with connectivity to the\nInternet and the Internet of Things (IoT) to support modern applications such\nas autonomous driving. However, the consolidation of complex computing domains\nof vehicles, the Internet, and the IoT limits the applicability of tailored\nsecurity solutions. In this paper, we propose a new methodology to\nquantitatively verify the security of single or system-level assets of the IoV\ninfrastructure. In detail, our methodology decomposes assets of the IoV\ninfrastructure with the help of reference sub-architectures and the 4+1 view\nmodel analysis to map identified assets into data, software, networking, and\nhardware categories. This analysis includes a custom threat modeling concept to\nperform parameterization of Common Vulnerability Scoring System (CVSS) scores\nper view model domain. As a result, our methodology is able to allocate assets\nfrom attack paths to view model domains. This equips assets of attack paths\nwith our IoV-driven CVSS scores. Our CVSS scores assess the attack likelihood\nwhich we use for Markov Chain transition probabilities. This way, we\nquantitatively verify system-level security among a set of IoV assets. Our\nresults show that our methodology applies to arbitrary IoV attack paths. Based\non our parameterization of CVSS scores and our selection of use cases, remote\nattacks are less likely to compromise location data compared to attacks from\nclose proximity for authorized and unauthorized attackers respectively.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.10063,regular,pre_llm,2021,1,"{'ai_likelihood': 0.0, 'text': 'Few-Shot Website Fingerprinting Attack\n\n  This work introduces a novel data augmentation method for few-shot website\nfingerprinting (WF) attack where only a handful of training samples per website\nare available for deep learning model optimization. Moving beyond earlier WF\nmethods relying on manually-engineered feature representations, more advanced\ndeep learning alternatives demonstrate that learning feature representations\nautomatically from training data is superior. Nonetheless, this advantage is\nsubject to an unrealistic assumption that there exist many training samples per\nwebsite, which otherwise will disappear. To address this, we introduce a\nmodel-agnostic, efficient, and Harmonious Data Augmentation (HDA) method that\ncan improve deep WF attacking methods significantly. HDA involves both\nintra-sample and inter-sample data transformations that can be used in\nharmonious manner to expand a tiny training dataset to an arbitrarily large\ncollection, therefore effectively and explicitly addressing the intrinsic data\nscarcity problem. We conducted expensive experiments to validate our HDA for\nboosting state-of-the-art deep learning WF attack models in both closed-world\nand open-world attacking scenarios, at absence and presence of strong defense.\n{For instance, in the more challenging and realistic evaluation scenario with\nWTF-PAD based defense, our HDA method surpasses the previous state-of-the-art\nresults by more than 4% in absolute classification accuracy in the 20-shot\nlearning case.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.03103,review,pre_llm,2021,1,"{'ai_likelihood': 3.1458006964789497e-06, 'text': 'Blockchain for steganography: advantages, new algorithms and open\n  challenges\n\n  Steganography is a solution for covert communication and blockchain is a p2p\nnetwork for data transmission, so the benefits of blockchain can be used in\nsteganography. In this paper, we discuss the advantages of blockchain in\nsteganography, which include the ability to embed hidden data without manual\nchange in the original data, as well as the readiness of the blockchain\nplatform for data transmission and storage, which eliminates the need for the\nSteganographer to design and implement a new platform for data transmission and\nstorage. We have proposed two algorithms for steganography in blockchain, the\nfirst one is a high-capacity algorithm for the key and the steganography\nalgorithm exchange and switching, and the second one is a medium-capacity\nalgorithm for embedding hidden data. Also, by reviewing the previous three\nsteganography schemes in blockchain, we have examined their drawback and have\nshowed that none of them are practical schemes for steganography in blockchain.\nThen, we have explained the challenges of steganography in blockchain from the\nsteganographers and steganalyzers point of view.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.07328,regular,pre_llm,2021,1,"{'ai_likelihood': 1.3742181989881728e-05, 'text': 'MIMOSA: Reducing Malware Analysis Overhead with Coverings\n\n  There is a growing body of malware samples that evade automated analysis and\ndetection tools. Malware may measure fingerprints (""artifacts"") of the\nunderlying analysis tool or environment and change their behavior when\nartifacts are detected. While analysis tools can mitigate artifacts to reduce\nexposure, such concealment is expensive. However, not every sample checks for\nevery type of artifact-analysis efficiency can be improved by mitigating only\nthose artifacts most likely to be used by a sample. Using that insight, we\npropose MIMOSA, a system that identifies a small set of ""covering"" tool\nconfigurations that collectively defeat most malware samples with increased\nefficiency. MIMOSA identifies a set of tool configurations that maximize\nanalysis throughput and detection accuracy while minimizing manual effort,\nenabling scalable automation to analyze stealthy malware. We evaluate our\napproach against a benchmark of 1535 labeled stealthy malware samples. Our\napproach increases analysis throughput over state of the art on over 95% of\nthese samples. We also investigate cost-benefit tradeoffs between the fraction\nof successfully-analyzed samples and computing resources required. MIMOSA\nprovides a practical, tunable method for efficiently deploying analysis\nresources.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.01495,regular,pre_llm,2021,1,"{'ai_likelihood': 9.934107462565105e-07, 'text': 'LSSD: a Controlled Large JPEG Image Database for Deep-Learning-based\n  Steganalysis ""into the Wild""\n\n  For many years, the image databases used in steganalysis have been relatively\nsmall, i.e. about ten thousand images. This limits the diversity of images and\nthus prevents large-scale analysis of steganalysis algorithms.\n  In this paper, we describe a large JPEG database composed of 2 million colour\nand grey-scale images. This database, named LSSD for Large Scale Steganalysis\nDatabase, was obtained thanks to the intensive use of \\enquote{controlled}\ndevelopment procedures. LSSD has been made publicly available, and we aspire it\ncould be used by the steganalysis community for large-scale experiments.\n  We introduce the pipeline used for building various image database versions.\nWe detail the general methodology that can be used to redevelop the entire\ndatabase and increase even more the diversity. We also discuss computational\ncost and storage cost in order to develop images.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.01077,regular,pre_llm,2021,1,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'HyperDegrade: From GHz to MHz Effective CPU Frequencies\n\n  Performance degradation techniques are an important complement to\nside-channel attacks. In this work, we propose HyperDegrade -- a combination of\nprevious approaches and the use of simultaneous multithreading (SMT)\narchitectures. In addition to the new technique, we investigate the root causes\nof performance degradation using cache eviction, discovering a previously\nunknown slowdown origin. The slowdown produced is significantly higher than\nprevious approaches, which translates into an increased time granularity for\nFlush+Reload attacks. We evaluate HyperDegrade on different Intel\nmicroarchitectures, yielding significant slowdowns that achieve, in select\nmicrobenchmark cases, three orders of magnitude improvement over\nstate-of-the-art. To evaluate the efficacy of performance degradation in\nside-channel amplification, we propose and evaluate leakage assessment metrics.\nThe results evidence that HyperDegrade increases time granularity without a\nmeaningful impact on trace quality. Additionally, we designed a fair experiment\nthat compares three performance degradation strategies when coupled with\nFlush+Reload from an attacker perspective. We developed an attack on an\nunexploited vulnerability in OpenSSL in which HyperDegrade excels -- reducing\nby three times the number of required Flush+Reload traces to succeed. Regarding\ncryptography contributions, we revisit the recently proposed Raccoon attack on\nTLS-DH key exchanges, demonstrating its application to other protocols. Using\nHyperDegrade, we developed an end-to-end attack that shows how a Raccoon-like\nattack can succeed with real data, filling a missing gap from previous\nresearch.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.10008,regular,pre_llm,2021,1,"{'ai_likelihood': 2.980232238769531e-07, 'text': 'SEA-BREW: A Scalable Attribute-Based Encryption Scheme for Low-Bitrate\n  IoT Wireless Networks\n\n  Attribute-Based Encryption (ABE) is an emerging cryptographic technique that\nallows one to embed a fine-grained access control mechanism into encrypted\ndata. In this paper we propose a novel ABE scheme called SEA-BREW (Scalable and\nEfficient Abe with Broadcast REvocation for Wireless networks), which is suited\nfor Internet of Things (IoT) and Industrial IoT (IIoT) applications. In\ncontrast to state-of-the-art ABE schemes, ours is capable of securely\nperforming key revocations with a single short broadcast message, instead of a\nnumber of unicast messages that is linear with the number of nodes. This is\ndesirable for low-bitrate Wireless Sensor and Actuator Networks (WSANs) which\noften are the heart of (I)IoT systems. In SEA-BREW, sensors, actuators, and\nusers can exchange encrypted data via a cloud server, or directly via wireless\nif they belong to the same WSAN. We formally prove that our scheme is secure\nalso in case of an untrusted cloud server that colludes with a set of users,\nunder the generic bilinear group model. We show by simulations that our scheme\nrequires a constant computational overhead on the cloud server with respect to\nthe complexity of the access control policies. This is in contrast to\nstate-of-the-art solutions, which require instead a linear computational\noverhead.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.05735,review,pre_llm,2021,1,"{'ai_likelihood': 1.1920928955078125e-06, 'text': 'The Good, the Bad and the Ugly: Pitfalls and Best Practices in Automated\n  Sound Static Analysis of Ethereum Smart Contracts\n\n  Ethereum smart contracts are distributed programs running on top of the\nEthereum blockchain. Since program flaws can cause significant monetary losses\nand can hardly be fixed due to the immutable nature of the blockchain, there is\na strong need of automated analysis tools which provide formal security\nguarantees. Designing such analyzers, however, proved to be challenging and\nerror-prone. We review the existing approaches to automated, sound, static\nanalysis of Ethereum smart contracts and highlight prevalent issues in the\nstate of the art. Finally, we overview eThor, a recent static analysis tool\nthat we developed following a principled design and implementation approach\nbased on rigorous semantic foundations to overcome the problems of past works.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.05511,regular,pre_llm,2021,1,"{'ai_likelihood': 2.914004855685764e-06, 'text': ""Quantifying Blockchain Extractable Value: How dark is the forest?\n\n  Permissionless blockchains such as Bitcoin have excelled at financial\nservices. Yet, opportunistic traders extract monetary value from the mesh of\ndecentralized finance (DeFi) smart contracts through so-called blockchain\nextractable value (BEV). The recent emergence of centralized BEV relayer\nportrays BEV as a positive additional revenue source. Because BEV was\nquantitatively shown to deteriorate the blockchain's consensus security, BEV\nrelayers endanger the ledger security by incentivizing rational miners to fork\nthe chain. For example, a rational miner with a 10% hashrate will fork Ethereum\nif a BEV opportunity exceeds 4x the block reward.\n  However, related work is currently missing quantitative insights on past BEV\nextraction to assess the practical risks of BEV objectively. In this work, we\nallow to quantify the BEV danger by deriving the USD extracted from sandwich\nattacks, liquidations, and decentralized exchange arbitrage. We estimate that\nover 32 months, BEV yielded 540.54M USD in profit, divided among 11,289\naddresses when capturing 49,691 cryptocurrencies and 60,830 on-chain markets.\nThe highest BEV instance we find amounts to 4.1M USD, 616.6x the Ethereum block\nreward.\n  Moreover, while the practitioner's community has discussed the existence of\ngeneralized trading bots, we are, to our knowledge, the first to provide a\nconcrete algorithm. Our algorithm can replace unconfirmed transactions without\nthe need to understand the victim transactions' underlying logic, which we\nestimate to have yielded a profit of 57,037.32 ETH (35.37M USD) over 32 months\nof past blockchain data.\n  Finally, we formalize and analyze emerging BEV relay systems, where miners\naccept BEV transactions from a centralized relay server instead of the\npeer-to-peer (P2P) network. We find that such relay systems aggravate the\nconsensus layer attacks and therefore further endanger blockchain security.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.07078,review,pre_llm,2021,1,"{'ai_likelihood': 9.735425313313803e-06, 'text': ""SoK: Fully Homomorphic Encryption Compilers\n\n  Fully Homomorphic Encryption (FHE) allows a third party to perform arbitrary\ncomputations on encrypted data, learning neither the inputs nor the computation\nresults. Hence, it provides resilience in situations where computations are\ncarried out by an untrusted or potentially compromised party. This powerful\nconcept was first conceived by Rivest et al. in the 1970s. However, it remained\nunrealized until Craig Gentry presented the first feasible FHE scheme in 2009.\n  The advent of the massive collection of sensitive data in cloud services,\ncoupled with a plague of data breaches, moved highly regulated businesses to\nincreasingly demand confidential and secure computing solutions. This demand,\nin turn, has led to a recent surge in the development of FHE tools. To\nunderstand the landscape of recent FHE tool developments, we conduct an\nextensive survey and experimental evaluation to explore the current state of\nthe art and identify areas for future development.\n  In this paper, we survey, evaluate, and systematize FHE tools and compilers.\nWe perform experiments to evaluate these tools' performance and usability\naspects on a variety of applications. We conclude with recommendations for\ndevelopers intending to develop FHE-based applications and a discussion on\nfuture directions for FHE tools development.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.10921,review,pre_llm,2021,1,"{'ai_likelihood': 4.76837158203125e-06, 'text': 'Blockchain Technology: Introduction, Integration and Security Issues\n  with IoT\n\n  Blockchain was mainly introduced for secure transactions in connection with\nthe mining of cryptocurrency Bitcoin. This article discusses the fundamental\nconcepts of blockchain technology and its components, such as block header,\ntransaction, smart contracts, etc. Blockchain uses the distributed databases,\nso this article also explains the advantages of distributed Blockchain over a\ncentrally located database. Depending on the application, Blockchain is broadly\ncategorized into two categories; Permissionless and Permissioned. This article\nelaborates on these two categories as well. Further, it covers the consensus\nmechanism and its working along with an overview of the Ethereum platform.\nBlockchain technology has been proved to be one of the remarkable techniques to\nprovide security to IoT devices. An illustration of how Blockchain will be\nuseful for IoT devices has been given. A few applications are also illustrated\nto explain the working of Blockchain with IoT.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.06043,regular,pre_llm,2021,1,"{'ai_likelihood': 8.311536577012805e-06, 'text': 'Bulwark: Holistic and Verified Security Monitoring of Web Protocols\n\n  Modern web applications often rely on third-party services to provide their\nfunctionality to users. The secure integration of these services is a\nnon-trivial task, as shown by the large number of attacks against Single Sign\nOn and Cashier-as-a-Service protocols. In this paper we present Bulwark, a new\nautomatic tool which generates formally verified security monitors from applied\npi-calculus specifications of web protocols. The security monitors generated by\nBulwark offer holistic protection, since they can be readily deployed both at\nthe client side and at the server side, thus ensuring full visibility of the\nattack surface against web protocols. We evaluate the effectiveness of Bulwark\nby testing it against a pool of vulnerable web applications that use the OAuth\n2.0 protocol or integrate the PayPal payment system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.10474,regular,pre_llm,2021,1,"{'ai_likelihood': 9.934107462565105e-07, 'text': 'Towards an Open Format for Scalable System Telemetry\n\n  A data representation for system behavior telemetry for scalable big data\nsecurity analytics is presented, affording telemetry consumers comprehensive\nvisibility into workloads at reduced storage and processing overheads. The new\nabstraction, SysFlow, is a compact open data format that lifts the\nrepresentation of system activities into a flow-centric, object-relational\nmapping that records how applications interact with their environment, relating\nprocesses to file accesses, network activities, and runtime information. The\ntelemetry format supports single-event and volumetric flow representations of\nprocess control flows, file interactions, and network communications.\nEvaluation on enterprise-grade benchmarks shows that SysFlow facilitates deeper\nintrospection into attack kill chains while yielding traces orders of magnitude\nsmaller than current state-of-the-art system telemetry approaches --\ndrastically reducing storage requirements and enabling feature-filled system\nanalytics, process-level provenance tracking, and long-term data archival for\ncyber threat discovery and forensic analysis on historical data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.10386,regular,pre_llm,2021,1,"{'ai_likelihood': 4.76837158203125e-06, 'text': 'ProbLock: Probability-based Logic Locking\n\n  Integrated circuit (IC) piracy and overproduction are serious issues that\nthreaten the security and integrity of a system. Logic locking is a type of\nhardware obfuscation technique where additional key gates are inserted into the\ncircuit. Only the correct key can unlock the functionality of that circuit\notherwise the system produces the wrong output. In an effort to hinder these\nthreats on ICs, we have developed a probability-based logic locking technique\nto protect the design of a circuit. Our proposed technique called ""ProbLock""\ncan be applied to combinational and sequential circuits through a critical\nselection process. We used a filtering process to select the best location of\nkey gates based on various constraints. Each step in the filtering process\ngenerates a subset of nodes for each constraint. We also analyzed the\ncorrelation between each constraint and adjusted the strength of the\nconstraints before inserting key gates. We have tested our algorithm on 40\nbenchmarks from the ISCAS \'85 and ISCAS \'89 suite.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2101.07113,regular,pre_llm,2021,1,"{'ai_likelihood': 4.635916815863716e-07, 'text': ""Applying High-Performance Bioinformatics Tools for Outlier Detection in\n  Log Data\n\n  Most of today's security solutions, such as security information and event\nmanagement (SIEM) and signature based IDS, require the operator to evaluate\npotential attack vectors and update detection signatures and rules in a timely\nmanner. However, today's sophisticated and tailored advanced persistent threats\n(APT), malware, ransomware and rootkits, can be so complex and diverse, and\noften use zero day exploits, that a pure signature-based blacklisting approach\nwould not be sufficient to detect them. Therefore, we could observe a major\nparadigm shift towards anomaly-based detection mechanisms, which try to\nestablish a system behavior baseline -- either based on netflow data or system\nlogging data -- and report any deviations from this baseline. While these\napproaches look promising, they usually suffer from scalability issues. As the\namount of log data generated during IT operations is exponentially growing,\nhigh-performance analysis methods are required that can handle this huge amount\nof data in real-time. In this paper, we demonstrate how high-performance\nbioinformatics tools can be applied to tackle this issue. We investigate their\napplication to log data for outlier detection to timely reveal anomalous system\nbehavior that points to cyber attacks. Finally, we assess the detection\ncapability and run-time performance of the proposed approach.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.02394,regular,pre_llm,2021,2,"{'ai_likelihood': 1.0960631900363498e-05, 'text': 'Refined Grey-Box Fuzzing with SIVO\n\n  We design and implement from scratch a new fuzzer called SIVO that refines\nmultiple stages of grey-box fuzzing. First, SIVO refines data-flow fuzzing in\ntwo ways: (a) it provides a new taint inference engine that requires only\nlogarithmic in the input size number of tests to infer the dependency of all\nprogram branches on the input bytes, and (b) it deploys a novel method for\ninverting branches by solving directly and efficiently systems of inequalities.\nSecond, our fuzzer refines accurate tracking and detection of code coverage\nwith simple and easily implementable methods. Finally, SIVO refines selection\nof parameters and strategies by parameterizing all stages of fuzzing and then\ndynamically selecting optimal values during fuzzing. Thus the fuzzer can easily\nadapt to a target program and rapidly increase coverage. We compare our fuzzer\nto 11 other state-of-the-art grey-box fuzzers on 27 popular benchmarks. Our\nevaluation shows that SIVO scores the highest both in terms of code coverage\nand in terms of number of found vulnerabilities.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.07869,regular,pre_llm,2021,2,"{'ai_likelihood': 2.284844716389974e-06, 'text': 'Technical Report -- Expected Exploitability: Predicting the Development\n  of Functional Vulnerability Exploits\n\n  Assessing the exploitability of software vulnerabilities at the time of\ndisclosure is difficult and error-prone, as features extracted via technical\nanalysis by existing metrics are poor predictors for exploit development.\nMoreover, exploitability assessments suffer from a class bias because ""not\nexploitable"" labels could be inaccurate. To overcome these challenges, we\npropose a new metric, called Expected Exploitability (EE), which reflects, over\ntime, the likelihood that functional exploits will be developed. Key to our\nsolution is a time-varying view of exploitability, a departure from existing\nmetrics. This allows us to learn EE using data-driven techniques from artifacts\npublished after disclosure, such as technical write-ups and proof-of-concept\nexploits, for which we design novel feature sets. This view also allows us to\ninvestigate the effect of the label biases on the classifiers. We characterize\nthe noise-generating process for exploit prediction, showing that our problem\nis subject to the most challenging type of label noise, and propose techniques\nto learn EE in the presence of noise. On a dataset of 103,137 vulnerabilities,\nwe show that EE increases precision from 49% to 86% over existing metrics,\nincluding two state-of-the-art exploit classifiers, while its precision\nsubstantially improves over time. We also highlight the practical utility of EE\nfor predicting imminent exploits and prioritizing critical vulnerabilities. We\ndevelop EE into an online platform which is publicly available at\nhttps://exploitability.app/.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.09301,regular,pre_llm,2021,2,"{'ai_likelihood': 1.4868047502305773e-05, 'text': 'The CNAME of the Game: Large-scale Analysis of DNS-based Tracking\n  Evasion\n\n  Online tracking is a whack-a-mole game between trackers who build and\nmonetize behavioral user profiles through intrusive data collection, and\nanti-tracking mechanisms, deployed as a browser extension, built-in to the\nbrowser, or as a DNS resolver. As a response to pervasive and opaque online\ntracking, more and more users adopt anti-tracking tools to preserve their\nprivacy. Consequently, as the information that trackers can gather on users is\nbeing curbed, some trackers are looking for ways to evade these tracking\ncountermeasures. In this paper we report on a large-scale longitudinal\nevaluation of an anti-tracking evasion scheme that leverages CNAME records to\ninclude tracker resources in a same-site context, effectively bypassing\nanti-tracking measures that use fixed hostname-based block lists. Using\nhistorical HTTP Archive data we find that this tracking scheme is rapidly\ngaining traction, especially among high-traffic websites. Furthermore, we\nreport on several privacy and security issues inherent to the technical setup\nof CNAME-based tracking that we detected through a combination of automated and\nmanual analyses. We find that some trackers are using the technique against the\nSafari browser, which is known to include strict anti-tracking configurations.\nOur findings show that websites using CNAME trackers must take extra\nprecautions to avoid leaking sensitive information to third parties.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.12621,review,pre_llm,2021,2,"{'ai_likelihood': 8.046627044677734e-06, 'text': 'Discrete Distribution Estimation with Local Differential Privacy: A\n  Comparative Analysis\n\n  Local differential privacy is a promising privacy-preserving model for\nstatistical aggregation of user data that prevents user privacy leakage from\nthe data aggregator. This paper focuses on the problem of estimating the\ndistribution of discrete user values with Local differential privacy. We review\nand present a comparative analysis on the performance of the existing discrete\ndistribution estimation algorithms in terms of their accuracy on benchmark\ndatasets. Our evaluation benchmarks include real-world and synthetic datasets\nof categorical individual values with the number of individuals from hundreds\nto millions and the domain size up to a few hundreds of values. The\nexperimental results show that the Basic RAPPOR algorithm generally performs\nbest for the benchmark datasets in the high privacy regime while the k-RR\nalgorithm often gives the best estimation in the low privacy regime. In the\nmedium privacy regime, the performance of the k-RR, the k-subset, and the HR\nalgorithms are fairly competitive with each other and generally better than the\nperformance of the Basic RAPPOR and the CMS algorithms.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.04685,regular,pre_llm,2021,2,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'Fair Peer-to-Peer Content Delivery via Blockchain\n\n  Peer-to-peer (p2p) content delivery is promising to provide benefits like\ncost-saving and scalable peak-demand handling in comparison with conventional\ncontent delivery networks (CDNs) and complement the decentralized storage\nnetworks such as Filecoin. However, reliable p2p delivery requires proper\nenforcement of delivery fairness, i.e., the deliverers should be rewarded\naccording to their in-time delivery. Unfortunately, most existing studies on\ndelivery fairness are based on non-cooperative game-theoretic assumptions that\nare arguably unrealistic in the ad-hoc p2p setting. We for the first time put\nforth the expressive yet still minimalist securities for p2p content delivery,\nand give two efficient solutions FairDownload and FairStream via the blockchain\nfor p2p downloading and p2p streaming scenarios, respectively. Our designs not\nonly guarantee delivery fairness to ensure deliverers be paid (nearly)\nproportional to his in-time delivery, but also ensure the content consumers and\ncontent providers to be fairly treated. The fairness of each party can be\nguaranteed when the other two parties collude to arbitrarily misbehave.\nMoreover, the systems are efficient in the sense of attaining asymptotically\noptimal on-chain costs and optimal deliverer communication. We implement the\nprotocols to build the prototype systems atop the Ethereum Ropsten network.\nExtensive experiments done in LAN and WAN settings showcase their high\npracticality.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.08896,review,pre_llm,2021,2,"{'ai_likelihood': 6.622738308376736e-08, 'text': 'Blockchain-based Security Services for Fog Computing\n\n  Fog computing is a paradigm for distributed computing that enables sharing of\nresources such as computing, storage and network services. Unlike cloud\ncomputing, fog computing platforms primarily support {\\em non-functional\nproperties} such as location awareness, mobility and reduced latency. This\nemerging paradigm has many potential applications in domains such as smart\ngrids, smart cities, and transport management.\n  Most of these domains collect and monitor personal information through edge\ndevices to offer personalized services. A {\\em centralized} server either at\nthe level of cloud or fog, has been found ineffective to provide a high degree\nof security and privacy-preserving services.\n  Blockchain technology supports the development of {\\em decentralized}\napplications designed around the principles of immutability, cryptography,\nconsistency preserving consensus protocols and smart contracts. Hence\nblockchain technology has emerged as a preferred technology in recent times to\nbuild trustworthy distributed applications.\n  The chapter describes the potential of blockchain technology to realize\nsecurity services such as authentication, secured communication, availability,\nprivacy and trust management to support the development of dependable fog\nservices.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.12273,regular,pre_llm,2021,2,"{'ai_likelihood': 2.0199351840549047e-06, 'text': 'Scaling Distributed Ledgers and Privacy-Preserving Applications\n\n  This thesis proposes techniques aiming to make blockchain technologies and\nsmart contract platforms practical by improving their scalability, latency, and\nprivacy. This thesis starts by presenting the design and implementation of\nChainspace, a distributed ledger that supports user defined smart contracts and\nexecute user-supplied transactions on their objects. The correct execution of\nsmart contract transactions is publicly verifiable. Chainspace is scalable by\nsharding state; it is secure against subsets of nodes trying to compromise its\nintegrity or availability properties through Byzantine Fault Tolerance (BFT).\nThis thesis also introduces a family of replay attacks against sharded\ndistributed ledgers targeting cross-shard consensus protocols; they allow an\nattacker, with network access only, to double-spend resources with minimal\nefforts. We then build Byzcuit, a new cross-shard consensus protocol that is\nimmune to those attacks and that is tailored to run at the heart of Chainspace.\nNext, we propose FastPay, a high-integrity settlement system for pre-funded\npayments that can be used as a financial side-infrastructure for Chainspace to\nsupport low-latency retail payments. This settlement system is based on\nByzantine Consistent Broadcast as its core primitive, foregoing the expenses of\nfull atomic commit channels (consensus). The resulting system has extremely\nlow-latency for both confirmation and payment finality. Finally, this thesis\nproposes Coconut, a selective disclosure credential scheme supporting\ndistributed threshold issuance, public and private attributes,\nre-randomization, and multiple unlinkable selective attribute revelations. It\nensures authenticity and availability even when a subset of credential issuing\nauthorities are malicious or offline, and natively integrates with Chainspace\nto enable a number of scalable privacy-preserving applications.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.02583,review,pre_llm,2021,2,"{'ai_likelihood': 5.629327562120226e-07, 'text': 'Optimizing Blockchain Based Smart Grid Auctions: A Green Revolution\n\n  Traditional smart grid energy auctions cannot directly be integrated in\nblockchain due to its decentralized nature. Therefore, research works are being\ncarried out to propose efficient decentralized auctions for energy trading.\nSince, blockchain is a novel paradigm which ensures trust, but it also comes up\nwith a curse of high computation and communication complexity which eventually\ncauses resource scarcity. Therefore, there is a need to develop and encourage\ndevelopment of greener and computational-friendly auctions to carry out\ndecentralized energy trading. In this paper, we first provide a thorough\nmotivation of decentralized auctions over traditional auctions. Afterwards, we\nprovide in-depth design requirements that can be taken into consideration while\ndeveloping such auctions. After that, we analyze technical works that have\ndeveloped blockchain based energy auctions from green perspective. Finally, we\nsummarize the article by providing challenges and possible future research\ndirections of blockchain based energy auction from green viewpoint.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.11849,review,pre_llm,2021,2,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Usability and Security of Different Authentication Methods for an\n  Electronic Health Records System\n\n  We conducted a survey of 67 graduate students enrolled in the Privacy and\nSecurity in Healthcare course at Indiana University Purdue University\nIndianapolis. This was done to measure user preference and their understanding\nof usability and security of three different Electronic Health Records\nauthentication methods: single authentication method (username and password),\nSingle sign-on with Central Authentication Service (CAS) authentication method,\nand a bio-capsule facial authentication method. This research aims to explore\nthe relationship between security and usability, and measure the effect of\nperceived security on usability in these three aforementioned authentication\nmethods. We developed a formative-formative Partial Least Square Structural\nEquation Modeling (PLS-SEM) model to measure the relationship between the\nlatent variables of Usability, and Security. The measurement model was\ndeveloped using five observed variables (measures). - Efficiency and\nEffectiveness, Satisfaction, Preference, Concerns, and Confidence. The results\nobtained highlight the importance and impact of these measures on the latent\nvariables and the relationship among the latent variables. From the PLS-SEM\nanalysis, it was found that security has a positive impact on usability for\nSingle sign-on and bio-capsule facial authentication methods. We conclude that\nthe facial authentication method was the most secure and usable among the three\nauthentication methods. Further, descriptive analysis was done to draw out the\ninteresting findings from the survey regarding the observed variables.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.06829,regular,pre_llm,2021,2,"{'ai_likelihood': 1.2914339701334636e-06, 'text': 'Systematic Mutation-based Evaluation of the Soundness of\n  Security-focused Android Static Analysis Techniques\n\n  Mobile application security has been a major area of focus for security\nresearch over the course of the last decade. Numerous application analysis\ntools have been proposed in response to malicious, curious, or vulnerable apps.\nHowever, existing tools, and specifically, static analysis tools, trade\nsoundness of the analysis for precision and performance and are hence soundy.\nUnfortunately, the specific unsound choices or flaws in the design of these\ntools is often not known or well-documented, leading to misplaced confidence\namong researchers, developers, and users. This paper describes the\nMutation-based Soundness Evaluation ($\\mu$SE) framework, which systematically\nevaluates Android static analysis tools to discover, document, and fix flaws,\nby leveraging the well-founded practice of mutation analysis. We implemented\n$\\mu$SE and applied it to a set of prominent Android static analysis tools that\ndetect private data leaks in apps. In a study conducted previously, we used\n$\\mu$SE to discover $13$ previously undocumented flaws in FlowDroid, one of the\nmost prominent data leak detectors for Android apps. Moreover, we discovered\nthat flaws also propagated to other tools that build upon the design or\nimplementation of FlowDroid or its components. This paper substantially extends\nour $\\mu$SE framework and offers an new in-depth analysis of two more major\ntools in our 2020 study, we find $12$ new, undocumented flaws and demonstrate\nthat all $25$ flaws are found in more than one tool, regardless of any\ninheritance-relation among the tools. Our results motivate the need for\nsystematic discovery and documentation of unsound choices in soundy tools and\ndemonstrate the opportunities in leveraging mutation testing in achieving this\ngoal.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.03,review,pre_llm,2021,2,"{'ai_likelihood': 1.3113021850585938e-05, 'text': ""Designing a Cyber-security Culture Assessment Survey Targeting Critical\n  Infrastructures During Covid-19 Crisis\n\n  The paper at hand presents the design of a survey aiming at the\ncyber-security culture assessment of critical infrastructures during the\nCOVID-19 crisis, when living reality was heavily disturbed and working\nconditions fundamentally affected. The survey is rooted in a security culture\nframework layered into two levels, organizational and individual, further\nanalyzed into 10 different security dimensions consisted of 52 domains. An\nin-depth questionnaire building analysis is presented focusing on the aims,\ngoals, and expected results. It concludes with the survey implementation\napproach while underlining the framework's first application and its revealing\ninsights during a global crisis.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.12869,regular,pre_llm,2021,2,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""Understanding Worldwide Private Information Collection on Android\n\n  Mobile phones enable the collection of a wealth of private information, from\nunique identifiers (e.g., email addresses), to a user's location, to their text\nmessages. This information can be harvested by apps and sent to third parties,\nwhich can use it for a variety of purposes. In this paper we perform the\nlargest study of private information collection (PIC) on Android to date.\nLeveraging an anonymized dataset collected from the customers of a popular\nmobile security product, we analyze the flows of sensitive information\ngenerated by 2.1M unique apps installed by 17.3M users over a period of 21\nmonths between 2018 and 2019. We find that 87.2% of all devices send private\ninformation to at least five different domains, and that actors active in\ndifferent regions (e.g., Asia compared to Europe) are interested in collecting\ndifferent types of information. The United States (62% of the total) and China\n(7% of total flows) are the countries that collect most private information.\nOur findings raise issues regarding data regulation, and would encourage\npolicymakers to further regulate how private information is used by and shared\namong the companies and how accountability can be truly guaranteed.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.04796,regular,pre_llm,2021,2,"{'ai_likelihood': 4.006756676567926e-06, 'text': 'Avaddon ransomware: an in-depth analysis and decryption of infected\n  systems\n\n  The commoditization of Malware-as-a-Service (MaaS) allows criminals to obtain\nfinancial benefits at a low risk and with little technical background. One such\npopular product in the underground economy is ransomware. In ransomware\nattacks, data from infected systems is held hostage (encrypted) until a fee is\npaid to the criminals. This modus operandi disrupts legitimate businesses,\nwhich may become unavailable until the data is restored. A recent blackmailing\nstrategy adopted by criminals is to leak data online from the infected systems\nif the ransom is not paid. Besides reputational damage, data leakage might\nproduce further economical losses due to fines imposed by data protection laws.\nThus, research on prevention and recovery measures to mitigate the impact of\nsuch attacks is needed to adapt existing countermeasures to new strains.\n  In this work, we perform an in-depth analysis of Avaddon, a ransomware\noffered in the underground economy as an affiliate program business. This has\ninfected and leaked data from at least 23 organizations. Additionally, it runs\nDistributed Denial-of-Service (DDoS) attacks against victims that do not pay\nthe ransom. We first provide an analysis of the criminal business model from\nthe underground economy. Then, we identify and describe its technical\ncapabilities. We provide empirical evidence of links between this variant and a\nprevious family, suggesting that the same group was behind the development and,\npossibly, the operation of both campaigns.\n  Finally, we describe a method to decrypt files encrypted with Avaddon in real\ntime. We implement and test the decryptor in a tool that can recover the\nencrypted data from an infected system, thus mitigating the damage caused by\nthe ransomware. The tool is released open-source so it can be incorporated in\nexisting Antivirus engines.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.11442,review,pre_llm,2021,2,"{'ai_likelihood': 3.5100513034396704e-06, 'text': ""A Survey on Amazon Alexa Attack Surfaces\n\n  Since being launched in 2014, Alexa, Amazon's versatile cloud-based voice\nservice, is now active in over 100 million households worldwide. Alexa's\nuser-friendly, personalized vocal experience offers customers a more natural\nway of interacting with cutting-edge technology by allowing the ability to\ndirectly dictate commands to the assistant. Now in the present year, the Alexa\nservice is more accessible than ever, available on hundreds of millions of\ndevices from not only Amazon but third-party device manufacturers.\nUnfortunately, that success has also been the source of concern and\ncontroversy. The success of Alexa is based on its effortless usability, but in\nturn, that has led to a lack of sufficient security. This paper surveys various\nattacks against Amazon Alexa ecosystem including attacks against the frontend\nvoice capturing and the cloud backend voice command recognition and processing.\nOverall, we have identified six attack surfaces covering the lifecycle of Alexa\nvoice interaction that spans several stages including voice data collection,\ntransmission, processing and storage. We also discuss the potential mitigation\nsolutions for each attack surface to better improve Alexa or other voice\nassistants in terms of security and privacy.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.09455,review,pre_llm,2021,2,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'To Improve Cyber Resilience, Measure It\n\n  We are not very good at measuring -- rigorously and quantitatively -- the\ncyber security of systems. Our ability to measure cyber resilience is even\nworse. And without measuring cyber resilience, we can neither improve it nor\ntrust its efficacy. It is difficult to know if we are improving or degrading\ncyber resilience when we add another control, or a mix of controls, to harden\nthe system. The only way to know is to specifically measure cyber resilience\nwith and without a particular set of controls. What needs to be measured are\ntemporal patterns of recovery and adaptation, and not time-independent failure\nprobabilities. In this paper, we offer a set of criteria that would ensure\ndecision-maker confidence in the reliability of the methodology used in\nobtaining a meaningful measurement.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.05631,review,pre_llm,2021,2,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""A Survey on Industrial Control System Testbeds and Datasets for Security\n  Research\n\n  The increasing digitization and interconnection of legacy Industrial Control\nSystems (ICSs) open new vulnerability surfaces, exposing such systems to\nmalicious attackers. Furthermore, since ICSs are often employed in critical\ninfrastructures (e.g., nuclear plants) and manufacturing companies (e.g.,\nchemical industries), attacks can lead to devastating physical damages. In\ndealing with this security requirement, the research community focuses on\ndeveloping new security mechanisms such as Intrusion Detection Systems (IDSs),\nfacilitated by leveraging modern machine learning techniques. However, these\nalgorithms require a testing platform and a considerable amount of data to be\ntrained and tested accurately. To satisfy this prerequisite, Academia,\nIndustry, and Government are increasingly proposing testbed (i.e., scaled-down\nversions of ICSs or simulations) to test the performances of the IDSs.\nFurthermore, to enable researchers to cross-validate security systems (e.g.,\nsecurity-by-design concepts or anomaly detectors), several datasets have been\ncollected from testbeds and shared with the community. In this paper, we\nprovide a deep and comprehensive overview of ICSs, presenting the architecture\ndesign, the employed devices, and the security protocols implemented. We then\ncollect, compare, and describe testbeds and datasets in the literature,\nhighlighting key challenges and design guidelines to keep in mind in the design\nphases. Furthermore, we enrich our work by reporting the best performing IDS\nalgorithms tested on every dataset to create a baseline in state of the art for\nthis field. Finally, driven by knowledge accumulated during this survey's\ndevelopment, we report advice and good practices on the development, the\nchoice, and the utilization of testbeds, datasets, and IDSs.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.10049,regular,pre_llm,2021,2,"{'ai_likelihood': 7.616149054633247e-07, 'text': 'PCaaD: Towards Automated Determination and Exploitation of Industrial\n  Processes\n\n  Over the last decade, Programmable Logic Controllers (PLCs) have been\nincreasingly targeted by attackers to obtain control over industrial processes\nthat support critical services. Such targeted attacks typically require\ndetailed knowledge of system-specific attributes, including hardware\nconfigurations, adopted protocols, and PLC control-logic, i.e. process\ncomprehension. The consensus from both academics and practitioners suggests\nstealthy process comprehension obtained from a PLC alone, to conduct targeted\nattacks, is impractical. In contrast, we assert that current PLC programming\npractices open the door to a new vulnerability class based on control-logic\nconstructs. To support this, we propose the concept of Process Comprehension at\na Distance (PCaaD), as a novel methodological and automatable approach for\nsystem-agnostic exploitation of PLC library functions, leading to the targeted\nexfiltration of operational data, manipulation of control-logic behavior, and\nestablishment of covert command and control channels through unused memory. We\nvalidate PCaaD on widely used PLCs, by identification of practical attacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.00647,regular,pre_llm,2021,2,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'Intelligent Network Layer for Cyber-Physical Systems Security\n\n  Cyber-Physical System (CPS) has made a tremendous progress in recent years\nand also disrupted many technical fields such as smart industries, smart\nhealth, smart transportation etc. to flourish the nations economy. However, CPS\nSecurity is still one of the concerns for wide adoption owing to high number of\ndevices connecting to the internet and the traditional security solutions may\nnot be suitable to protect the advanced, application specific attacks. This\npaper presents a programmable device network layer architecture to combat\nattacks and efficient network monitoring in heterogeneous environment CPS\napplications. We leverage Industrial control systems (ICS) to discuss the\nexisting issues, highlighting the importance of advanced network layer for CPS.\nThe programmable data plane language (P4) is introduced to detect well known\nHELLO Flood attack with minimal efforts in the network level and also used to\nfeaturing the potential solutions for security.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.01722,review,pre_llm,2021,2,"{'ai_likelihood': 1.8874804178873699e-06, 'text': 'A Historical and Statistical Studyof the Software Vulnerability\n  Landscape\n\n  Understanding the landscape of software vulnerabilities is key for developing\neffective security solutions. Fortunately, the evaluation of vulnerability\ndatabases that use a framework for communicating vulnerability attributes and\ntheir severity scores, such as the Common Vulnerability Scoring System (CVSS),\ncan help shed light on the nature of publicly published vulnerabilities. In\nthis paper, we characterize the software vulnerability landscape by performing\na historical and statistical analysis of CVSS vulnerability metrics over the\nperiod of 2005 to 2019 through using data from the National Vulnerability\nDatabase. We conduct three studies analyzing the following: the distribution of\nCVSS scores (both empirical and theoretical), the distribution of CVSS metric\nvalues and how vulnerability characteristics change over time, and the relative\nrankings of the most frequent metric value over time. Our resulting analysis\nshows that the vulnerability threat landscape has been dominated by only a few\nvulnerability types and has changed little during the time period of the study.\nThe overwhelming majority of vulnerabilities are exploitable over the network.\nThe complexity to successfully exploit these vulnerabilities is dominantly low;\nvery little authentication to the target victim is necessary for a successful\nattack. And most of the flaws require very limited interaction with users.\nHowever on the positive side, the damage of these vulnerabilities is mostly\nconfined within the security scope of the impacted components. A discussion of\nlessons that could be learned from this analysis is presented.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2102.13023,regular,pre_llm,2021,2,"{'ai_likelihood': 1.4172659979926217e-05, 'text': 'Deep Adversarial Learning on Google Home devices\n\n  Smart speakers and voice-based virtual assistants are core components for the\nsuccess of the IoT paradigm. Unfortunately, they are vulnerable to various\nprivacy threats exploiting machine learning to analyze the generated encrypted\ntraffic. To cope with that, deep adversarial learning approaches can be used to\nbuild black-box countermeasures altering the network traffic (e.g., via packet\npadding) and its statistical information. This letter showcases the inadequacy\nof such countermeasures against machine learning attacks with a dedicated\nexperimental campaign on a real network dataset. Results indicate the need for\na major re-engineering to guarantee the suitable protection of commercially\navailable smart speakers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.10021,regular,pre_llm,2021,3,"{'ai_likelihood': 1.7881393432617188e-06, 'text': ""Secure Watermark for Deep Neural Networks with Multi-task Learning\n\n  Deep neural networks are playing an important role in many real-life\napplications. After being trained with abundant data and computing resources, a\ndeep neural network model providing service is endowed with economic value. An\nimportant prerequisite in commercializing and protecting deep neural networks\nis the reliable identification of their genuine author. To meet this goal,\nwatermarking schemes that embed the author's identity information into the\nnetworks have been proposed. However, current schemes can hardly meet all the\nnecessary requirements for securely proving the authorship and mostly focus on\nmodels for classification. To explicitly meet the formal definitions of the\nsecurity requirements and increase the applicability of deep neural network\nwatermarking schemes, we propose a new framework based on multi-task learning.\nBy treating the watermark embedding as an extra task, most of the security\nrequirements are explicitly formulated and met with well-designed regularizers,\nthe rest is guaranteed by using components from cryptography. Moreover, a\ndecentralized verification protocol is proposed to standardize the ownership\nverification. The experiment results show that the proposed scheme is flexible,\nsecure, and robust, hence a promising candidate in deep learning model\nprotection.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.1636,regular,pre_llm,2021,3,"{'ai_likelihood': 5.960464477539062e-07, 'text': 'Looney Tunes: Exposing the Lack of DRM Protection in Indian Music\n  Streaming Services\n\n  Numerous studies have shown that streaming is now the most preferred way of\nconsuming multimedia content and this is evidenced by the proliferation in the\nnumber of streaming service providers as well as the exponential growth in\ntheir subscriber base. Riding on the advancements in low cost electronics, high\nspeed communication and extremely cheap data, Over-The-Top (OTT) music\nstreaming is now the norm in the music industry and is worth millions of\ndollars. This is especially true in India where major players offer the so\ncalled freemium models which have active monthly user bases running in to the\nmillions. These services namely, Gaana, Airtel Wynk and JioSaavn attract a\nsignificantly bigger audience than their 100% subscription based peers like\nAmazon Prime Music, Apple Music etc. Given their ubiquity and market dominance,\nit is pertinent to do a systematic analysis of these platforms so as to\nascertain their potential as hotbeds of piracy. This work investigates the\nresilience of the content protection systems of the four biggest music\nstreaming services (by subscriber base) from India, namely Airtel Wynk, Ganna,\nJioSaavn and Hungama. By considering the Digital Rights Management (DRM) system\nemployed by Spotify as a benchmark, we analyse the security of these platforms\nby attempting to steal the streamed content efficiently. Finally, we present a\nholistic overview of the flaws in their security mechanisms and discuss\npossible mitigation strategies. To the best of our knowledge, this work\nconstitutes the first attempt to analyze security of OTT music services from\nIndia. Our results further confirm the time tested belief that security through\nobscurity is not a long term solution and leaves such platforms open to piracy\nand a subsequent loss of revenue for all the stakeholders.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.05072,regular,pre_llm,2021,3,"{'ai_likelihood': 6.953875223795574e-07, 'text': ""Multiparty Protocol that Usually Shuffles\n\n  Multiparty computation is raising importance because it's primary objective\nis to replace any trusted third party in the distributed computation. This work\npresents two multiparty shuffling protocols where each party, possesses a\nprivate input, agrees on a random permutation while keeping the permutation\nsecret. The proposed shuffling protocols are based on permutation network,\nthereby data-oblivious. The first proposal is $n\\text{-}permute$ that permutes\n$n$ inputs in all $n!$ possible ways. $n$-permute network consists of\n$2\\log{n}-1$ layers, and in each layer there are $n/2$ gates. Our second\nprotocol is $n_{\\pi}$-permute shuffling that defines a permutation set\n$\\Pi=\\{\\pi_1,\\dots,\\pi_N\\}$ where $|\\Pi| < n!$, and the resultant shuffling is\na random permutation $\\pi_i \\in \\Pi$. The $n_{\\pi}$-permute network contains\nleases number of layers compare to $n$-permute network. Let $n=n_1n_2$, the\n$n_{\\pi}$-permute network would define $2\\log{n_1}-1+\\log{n_2}$ layers. \\par\nThe proposed shuffling protocols are unconditionally secure against malicious\nadversary who can corrupt at most $t<n/3$ parties. The probability that\nadversary can learn the outcome of $n$-permute is upper bound by\n$((n-t)!)^{-1}$. Whereas, the probability that adversary can learn the outcome\nof $n_{\\pi}$-permute is upper bounded by\n$\\big(f_{\\Pi}(n_1-\\theta_1)^{n_2}2^{\\theta_2}\\big)^{-1}$, for some positive\ninteger $\\theta_1, \\theta_2$, and a recursive definition of $f_{\\Pi}$. The\nprotocols allow the parties to build quorums, and distribute the load among the\nquorums.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.06767,regular,pre_llm,2021,3,"{'ai_likelihood': 2.980232238769531e-07, 'text': 'Mobile Access Control System Based on RFID Tags And Facial Information\n\n  Better access control system security comes at a higher price. It many cases\nthe price is too high for small companies, leaving them vulnerable with cheap\nand insecure systems. In this work we introduce an alternative access control\nscheme, which improves access control security while lowering the cost. In the\nproposed model, passive RFID tags are mounted near a turnstile or a smart door.\nTag reading and programming is done via NFC chip directly on the users\nsmartphone. To enhance security, together with smartphone-based authorization\nwe require the user to provide his photograph while entering a secure gate. The\nphotograph is then displayed on a monitoring dashboard side-by-side with the\nregistration picture, so that the two can be matched against each other. The\ndeveloped client-server application offers administrative system used to\nconfigure gate access policies and monitor entrances with filters by access\ntime, user and gate. Also, we propose a mobile application that allows gate\nregistration and serves as a door unlock key. The suggested access control\nmodel reduces installation costs required, while maintaining good security. The\nsystem is fully wireless and uses cheap autonomous RFID-tags as its main\ncomponent. We hope, that the proposed system architecture will find its\napplication in small to medium-sized companies.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.02637,regular,pre_llm,2021,3,"{'ai_likelihood': 1.158979203965929e-06, 'text': ""SkillVet: Automated Traceability Analysis of Amazon Alexa Skills\n\n  Third-party software, or skills, are essential components in Smart Personal\nAssistants (SPA). The number of skills has grown rapidly, dominated by a\nchanging environment that has no clear business model. Skills can access\npersonal information and this may pose a risk to users. However, there is\nlittle information about how this ecosystem works, let alone the tools that can\nfacilitate its study. In this paper, we present the largest systematic\nmeasurement of the Amazon Alexa skill ecosystem to date. We study developers'\npractices in this ecosystem, including how they collect and justify the need\nfor sensitive information, by designing a methodology to identify\nover-privileged skills with broken privacy policies. We collect 199,295 Alexa\nskills and uncover that around 43% of the skills (and 50% of the developers)\nthat request these permissions follow bad privacy practices, including\n(partially) broken data permissions traceability. In order to perform this kind\nof analysis at scale, we present SkillVet that leverages machine learning and\nnatural language processing techniques, and generates high-accuracy prediction\nsets. We report a number of concerning practices including how developers can\nbypass Alexa's permission system through account linking and conversational\nskills, and offer recommendations on how to improve transparency, privacy and\nsecurity. Resulting from the responsible disclosure we have conducted, 13% of\nthe reported issues no longer pose a threat at submission time.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.12365,regular,pre_llm,2021,3,"{'ai_likelihood': 1.1920928955078125e-06, 'text': 'Risk Analysis and Policy Enforcement of Function Interactions in Robot\n  Apps\n\n  Robot apps are becoming more automated, complex and diverse. An app usually\nconsists of many functions, interacting with each other and the environment.\nThis allows robots to conduct various tasks. However, it also opens a new door\nfor cyber attacks: adversaries can leverage these interactions to threaten the\nsafety of robot operations. Unfortunately, this issue is rarely explored in\npast works.\n  We present the first systematic investigation about the function interactions\nin common robot apps. First, we disclose the potential risks and damages caused\nby malicious interactions. We introduce a comprehensive graph to model the\nfunction interactions in robot apps by analyzing 3,100 packages from the Robot\nOperating System (ROS) platform. From this graph, we identify and categorize\nthree types of interaction risks. Second, we propose RTron, a novel system to\ndetect and mitigate these risks and protect the operations of robot apps. We\nintroduce security policies for each type of risks, and design coordination\nnodes to enforce the policies and regulate the interactions. We conduct\nextensive experiments on 110 robot apps from the ROS platform and two complex\napps (Baidu Apollo and Autoware) widely adopted in industry. Evaluation results\nindicated RTron can correctly identify and mitigate all potential risks with\nnegligible performance cost. To validate the practicality of the risks and\nsolutions, we implement and evaluate RTron on a physical UGV (Turtlebot) with\nreal-word apps and environments.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.09345,regular,pre_llm,2021,3,"{'ai_likelihood': 1.158979203965929e-06, 'text': ""Compatible Certificateless and Identity-Based Cryptosystems for\n  Heterogeneous IoT\n\n  Certificates ensure the authenticity of users' public keys, however their\noverhead (e.g., certificate chains) might be too costly for some IoT systems\nlike aerial drones. Certificate-free cryptosystems, like identity-based and\ncertificateless systems, lift the burden of certificates and could be a\nsuitable alternative for such IoTs. However, despite their merits, there is a\nresearch gap in achieving compatible identity-based and certificateless systems\nto allow users from different domains (identity-based or certificateless) to\ncommunicate seamlessly. Moreover, more efficient constructions can enable their\nadoption in resource-limited IoTs.\n  In this work, we propose new identity-based and certificateless cryptosystems\nthat provide such compatibility and efficiency. This feature is beneficial for\nheterogeneous IoT settings (e.g., commercial aerial drones), where different\nlevels of trust/control is assumed on the trusted third party. Our schemes are\nmore communication efficient than their public key based counterparts, as they\ndo not need certificate processing. Our experimental analysis on both commodity\nand embedded IoT devices show that, only with the cost of having a larger\nsystem public key, our cryptosystems are more computation and communication\nefficient than their certificate-free counterparts. We prove the security of\nour schemes (in the random oracle model) and open-source our cryptographic\nframework for public testing/adoption.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.04889,regular,pre_llm,2021,3,"{'ai_likelihood': 1.9205941094292534e-06, 'text': 'Design and implementation of Energy Efficient Lightweight Encryption\n  (EELWE) algorithm for medical applications\n\n  Proportional to the growth in the usage of Human Sensor Networks (HSN), the\nvolume of the data exchange between Sensor devices is increasing at a rapid\npace. In this paper, we have proposed an Energy Efficient Lightweight\nEncryption (EELWE) algorithm for providing the confidentiality of data at the\nsensor level, particularly suitable for resource-constrained environments.\nResults obtained have proved that an EELWE consumes less energy relative to\npresent lightweight ciphers and it supports multiple block sizes of 32-bit,\n48-bit, and 64-bit.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.04952,regular,pre_llm,2021,3,"{'ai_likelihood': 9.602970547146267e-07, 'text': 'Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel\n  Defenses\n\n  The ""eternal war in cache"" has reached browsers, with multiple cache-based\nside-channel attacks and countermeasures being suggested. A common approach for\ncountermeasures is to disable or restrict JavaScript features deemed essential\nfor carrying out attacks. To assess the effectiveness of this approach, in this\nwork we seek to identify those JavaScript features which are essential for\ncarrying out a cache-based attack. We develop a sequence of attacks with\nprogressively decreasing dependency on JavaScript features, culminating in the\nfirst browser-based side-channel attack which is constructed entirely from\nCascading Style Sheets (CSS) and HTML, and works even when script execution is\ncompletely blocked. We then show that avoiding JavaScript features makes our\ntechniques architecturally agnostic, resulting in microarchitectural website\nfingerprinting attacks that work across hardware platforms including Intel\nCore, AMD Ryzen, Samsung Exynos, and Apple M1 architectures. As a final\ncontribution, we evaluate our techniques in hardened browser environments\nincluding the Tor browser, Deter-Fox (Cao el al., CCS 2017), and Chrome Zero\n(Schwartz et al., NDSS 2018). We confirm that none of these approaches\ncompletely defend against our attacks. We further argue that the protections of\nChrome Zero need to be more comprehensively applied, and that the performance\nand user experience of Chrome Zero will be severely degraded if this approach\nis taken.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.04816,regular,pre_llm,2021,3,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Efficient Error Prediction for Differentially Private Algorithms\n\n  Differential privacy is a strong mathematical notion of privacy. Still, a\nprominent challenge when using differential privacy in real data collection is\nunderstanding and counteracting the accuracy loss that differential privacy\nimposes. As such, the accuracy/privacy trade-off of differential privacy needs\nto be balanced on a case-by-case basis. Applications in the literature tend to\nfocus solely on analytical accuracy bounds, not include data in error\nprediction, or use arbitrary settings to measure error empirically.\n  To fill the gap in the literature, we propose a novel application of factor\nexperiments to create data aware error predictions. Basically, factor\nexperiments provide a systematic approach to conducting empirical experiments.\nTo demonstrate our methodology in action, we conduct a case study where error\nis dependent on arbitrarily complex tree structures. We first construct a tool\nto simulate poll data. Next, we use our simulated data to construct a least\nsquares model to predict error. Last, we show how to validate the model.\nConsequently, our contribution is a method for constructing error prediction\nmodels that are data aware.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.10756,regular,pre_llm,2021,3,"{'ai_likelihood': 9.271833631727431e-07, 'text': ""On-Chain IoT Data Modification in Blockchains\n\n  In recent years, the interest growth in the Blockchains (BC) and\nInternet-of-Things (IoT) integration -- termed as BIoT -- for more trust via\ndecentralization has led to great potentials in various use cases such as\nhealth care, supply chain tracking, and smart cities. A key element of BIoT\necosystems is the data transactions (TX) that include the data collected by IoT\ndevices. BIoT applications face many challenges to comply with the European\nGeneral Data Protection Regulation (GDPR) i.e., enabling users to hold on to\ntheir rights for deleting or modifying their data stored on publicly accessible\nand immutable BCs. In this regard, this paper identifies the requirements of\nBCs for being GDPR compliant in BIoT use cases. Accordingly, an on-chain\nsolution is proposed that allows fine-grained modification (update and erasure)\noperations on TXs' data fields within a BC. The proposed solution is based on a\ncryptographic primitive called Chameleon Hashing. The novelty of this approach\nis manifold. BC users have the authority to update their data, which are\naddressed at the TX level with no side-effects on the block or chain. By\nperforming and storing the data updates, all on-chain, traceability and\nverifiability of the BC are preserved. Moreover, the compatibility with TX\naggregation mechanisms that allow the compression of the BC size is maintained.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.11585,review,pre_llm,2021,3,"{'ai_likelihood': 9.934107462565105e-07, 'text': 'Blockchain-based Digital Twins: Research Trends, Issues, and Future\n  Challenges\n\n  Industrial processes rely on sensory data for decision-making processes, risk\nassessment, and performance evaluation. Extracting actionable insights from the\ncollected data calls for an infrastructure that can ensure the dissemination of\ntrustworthy data. For the physical data to be trustworthy, it needs to be\ncross-validated through multiple sensor sources with overlapping fields of\nview. Cross-validated data can then be stored on the blockchain, to maintain\nits integrity and trustworthiness. Once trustworthy data is recorded on the\nblockchain, product lifecycle events can be fed into data-driven systems for\nprocess monitoring, diagnostics, and optimized control. In this regard, Digital\nTwins (DTs) can be leveraged to draw intelligent conclusions from data by\nidentifying the faults and recommending precautionary measures ahead of\ncritical events. Empowering DTs with blockchain in industrial use-cases targets\nkey challenges of disparate data repositories, untrustworthy data\ndissemination, and the need for predictive maintenance. In this survey, while\nhighlighting the key benefits of using blockchain-based DTs, we present a\ncomprehensive review of the state-of-the-art research results for\nblockchain-based DTs. Based on the current research trends, we discuss a\ntrustworthy blockchain-based DTs framework. We highlight the role of Artificial\nIntelligence (AI) in blockchain-based DTs. Furthermore, we discuss current and\nfuture research and deployment challenges of blockchain-supported DTs that\nrequire further investigation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.0699,regular,pre_llm,2021,3,"{'ai_likelihood': 1.4238887363009983e-06, 'text': 'Quantifying the Efficacy of Logic Locking Methods\n\n  The outsourced manufacturing of integrated circuits has increased the risk of\nintellectual property theft. In response, logic locking techniques have been\ndeveloped for protecting designs by adding programmable elements to the\ncircuit. These techniques differ significantly in both overhead and resistance\nto various attacks, leaving designers unable to discern their efficacy. To\novercome this critical impediment for the adoption of logic locking, we propose\ntwo metrics, key corruption and minimum corruption, that capture the goals of\nlocking under different attack scenarios. We develop a flow for approximating\nthese metrics on generic locked circuits and evaluate several locking\ntechniques.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.0856,regular,pre_llm,2021,3,"{'ai_likelihood': 7.28501213921441e-07, 'text': 'Take a Bite of the Reality Sandwich: Revisiting the Security of\n  Progressive Message Authentication Codes\n\n  Message authentication guarantees the integrity of messages exchanged over\nuntrusted channels. However, to achieve this goal, message authentication\nconsiderably expands packet sizes, which is especially problematic in\nconstrained wireless environments. To address this issue, progressive message\nauthentication provides initially reduced integrity protection that is often\nsufficient to process messages upon reception. This reduced security is then\nsuccessively improved with subsequent messages to uphold the strong guarantees\nof traditional integrity protection. However, contrary to previous claims, we\nshow in this paper that existing progressive message authentication schemes are\nhighly susceptible to packet loss induced by poor channel conditions or jamming\nattacks. Thus, we consider it imperative to rethink how authentication tags\ndepend on the successful reception of surrounding packets. To this end, we\npropose R2-D2, which uses randomized dependencies with parameterized security\nguarantees to increase the resilience of progressive authentication against\npacket loss. To deploy our approach to resource-constrained devices, we\nintroduce SP-MAC, which implements R2-D2 using efficient XOR operations. Our\nevaluation shows that SP-MAC is resilient to sophisticated network-level\nattacks and operates as resources-conscious and fast as existing, yet insecure,\nprogressive message authentication schemes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.04794,regular,pre_llm,2021,3,"{'ai_likelihood': 1.7881393432617188e-06, 'text': 'Packet-Level Adversarial Network Traffic Crafting using Sequence\n  Generative Adversarial Networks\n\n  The surge in the internet of things (IoT) devices seriously threatens the\ncurrent IoT security landscape, which requires a robust network intrusion\ndetection system (NIDS). Despite superior detection accuracy, existing machine\nlearning or deep learning based NIDS are vulnerable to adversarial examples.\nRecently, generative adversarial networks (GANs) have become a prevailing\nmethod in adversarial examples crafting. However, the nature of discrete\nnetwork traffic at the packet level makes it hard for GAN to craft adversarial\ntraffic as GAN is efficient in generating continuous data like image synthesis.\nUnlike previous methods that convert discrete network traffic into a grayscale\nimage, this paper gains inspiration from SeqGAN in sequence generation with\npolicy gradient. Based on the structure of SeqGAN, we propose Attack-GAN to\ngenerate adversarial network traffic at packet level that complies with domain\nconstraints. Specifically, the adversarial packet generation is formulated into\na sequential decision making process. In this case, each byte in a packet is\nregarded as a token in a sequence. The objective of the generator is to select\na token to maximize its expected end reward. To bypass the detection of NIDS,\nthe generated network traffic and benign traffic are classified by a black-box\nNIDS. The prediction results returned by the NIDS are fed into the\ndiscriminator to guide the update of the generator. We generate malicious\nadversarial traffic based on a real public available dataset with attack\nfunctionality unchanged. The experimental results validate that the generated\nadversarial samples are able to deceive many existing black-box NIDS.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.14414,regular,pre_llm,2021,3,"{'ai_likelihood': 5.0001674228244356e-06, 'text': ""HyperSec: Visual Analytics for blockchain security monitoring\n\n  Today, permissioned blockchains are being adopted by large organizations for\nbusiness critical operations. Consequently, they are subject to attacks by\nmalicious actors. Researchers have discovered and enumerated a number of\nattacks that could threaten availability, integrity and confidentiality of\nblockchain data. However, currently it remains difficult to detect these\nattacks. We argue that security experts need appropriate visualizations to\nassist them in detecting attacks on blockchain networks. To achieve this, we\ndevelop HyperSec, a visual analytics monitoring tool that provides relevant\ninformation at a glance to detect ongoing attacks on Hyperledger Fabric. For\nevaluation, we connect the HyperSec prototype to a Hyperledger Fabric test\nnetwork. The results show that common attacks on Fabric can be detected by a\nsecurity expert using HyperSec's visualizations.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.14839,regular,pre_llm,2021,3,"{'ai_likelihood': 1.457002427842882e-06, 'text': 'Teaching Information Security Management in Postgraduate Tertiary\n  Education: The Case of Horizon Automotive Industries\n\n  Teaching cases based on stories about real organizations are a powerful means\nof storytelling. These cases closely parallel real-world situations and can\ndeliver on pedagogical objectives as writers can use their creative license to\ncraft a storyline that better focuses on the specific principles, concepts, and\nchallenges they want to address in their teaching. The method instigates\ncritical discussion, draws out relevant experiences from students, encourages\nquestioning of accepted practices, and creates dialogue between theory and\npractice. We present Horizon, a case study of a firm that suffers a\ncatastrophic incident of Intellectual Property (IP) theft. The case study was\ndeveloped to teach information security management (ISM) principles in key\nareas such as strategy, risk, policy and training to postgraduate Information\nSystems and Information Technology students at the University of Melbourne,\nAustralia.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.13809,regular,pre_llm,2021,3,"{'ai_likelihood': 7.450580596923828e-06, 'text': 'TrustCross: Enabling Confidential Interoperability across Blockchains\n  Using Trusted Hardware\n\n  With the rapid development of blockchain technology, different types of\nblockchains are adopted and interoperability across blockchains has received\nwidespread attention. There have been many cross-chain solutions proposed in\nrecent years, including notary scheme, sidechain, and relay chain. However,\nmost of the existing platforms do not take confidentiality into account,\nalthough privacy has become an important concern for blockchain. In this paper,\nwe present TrustCross, a privacy-preserving cross-chain platform to enable\nconfidential interoperability across blockchains. The key insight behind\nTrustCross is to encrypt cross-chain communication data on the relay chain with\nthe assistance of trusted execution environment and employ fine-grained access\ncontrol to protect user privacy. Our experimental results show that TrustCross\nachieves reasonable latency and high scalability on the contract calls across\nheterogeneous blockchains.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.08455,regular,pre_llm,2021,3,"{'ai_likelihood': 4.255109363132053e-05, 'text': ""Achieve Efficient Position-Heap-based Privacy-Preserving\n  Substring-of-Keyword Query over Cloud\n\n  The cloud computing technique, which was initially used to mitigate the\nexplosive growth of data, has been required to take both data privacy and\nusers' query functionality into consideration. Symmetric searchable encryption\n(SSE) is a popular solution to supporting efficient keyword queries over\nencrypted data in the cloud. However, most of the existing SSE schemes focus on\nthe exact keyword query and cannot work well when the user only remembers the\nsubstring of a keyword, i.e., substring-of-keyword query. This paper aims to\ninvestigate this issue by proposing an efficient and privacy-preserving\nsubstring-of-keyword query scheme over cloud. First, we employ the position\nheap technique to design a novel tree-based index to match substrings with\ncorresponding keywords. Based on the tree-based index, we introduce our\nsubstring-of-keyword query scheme, which contains two consecutive phases. The\nfirst phase queries the keywords that match a given substring, and the second\nphase queries the files that match a keyword in which people are really\ninterested. In addition, detailed security analysis and experimental results\ndemonstrate the security and efficiency of our proposed scheme.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2103.04901,regular,pre_llm,2021,3,"{'ai_likelihood': 2.5497542487250434e-06, 'text': ""Socio-Technical Root Cause Analysis of Cyber-enabled Theft of the U.S.\n  Intellectual Property -- The Case of APT41\n\n  Increased connectivity has made us all more vulnerable. Cyberspace, besides\nall its benefits, spawned more devices to hack and more opportunities to commit\ncybercrime. Criminals have found it lucrative to target both individuals and\nbusinesses, by holding or stealing their assets via different types of cyber\nattacks. The cyber-enabled theft of Intellectual Property (IP), as one of the\nmost important and critical intangible assets of nations, organizations and\nindividuals, by foreign countries has been a devastating challenge of the\nUnited States (U.S.) in the past decades. In this study, we conduct a\nsocio-technical root cause analysis to investigate one of the recent cases of\nIP theft by employing a holistic approach. It concludes with a list of root\ncauses and some corrective actions to stop the impact and prevent the\nrecurrence of the problem in the future. Building upon the findings of this\nstudy, the U.S. requires a detailed revision of IP strategies bringing the\nwhole socio-technical regulatory system into focus and strengthen IP rights\nprotection considering China's indigenous innovation policies. It is critical\nthat businesses and other organizations take steps to reduce their exposure to\ncyber attacks. It is particularly important to train employees on how to spot\npotential threats, and to institute policies that encourage workers to report\npotential security failures so that action can be taken quickly. Finally, we\ndiscuss how cyber ranges can provide an efficient and safe platform for dealing\nwith such challenges. The results of this study can be expanded to other\ncountries in order to protect their IP rights and deter or prevent and respond\nto future incidents.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.10017,review,pre_llm,2021,4,"{'ai_likelihood': 1.655684577094184e-06, 'text': ""The Emperor's New Autofill Framework: A Security Analysis of Autofill on\n  iOS and Android\n\n  Password managers help users more effectively manage their passwords,\nencouraging them to adopt stronger passwords across their many accounts. In\ncontrast to desktop systems where password managers receive no system-level\nsupport, mobile operating systems provide autofill frameworks designed to\nintegrate with password managers to provide secure and usable autofill for\nbrowsers and other apps installed on mobile devices. In this paper, we evaluate\nmobile autofill frameworks on iOS and Android, examining whether they achieve\nsubstantive benefits over the ad-hoc desktop environment or become a\nproblematic single point of failure. Our results find that while the frameworks\naddress several common issues, they also enforce insecure behavior and fail to\nprovide password managers sufficient information to override the frameworks'\ninsecure behavior, resulting in mobile managers being less secure than their\ndesktop counterparts overall. We also demonstrate how these frameworks act as a\nconfused deputy in manager-assisted credential phishing attacks. Our results\ndemonstrate the need for significant improvements to mobile autofill\nframeworks. We conclude the paper with recommendations for the design and\nimplementation of secure autofill frameworks.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.14357,review,pre_llm,2021,4,"{'ai_likelihood': 2.2186173333062066e-06, 'text': ""BlockColdChain: Vaccine Cold Chain Blockchain\n\n  In this paper, we propose a blockchain-based cold chain technology for\nvaccine cooling track. The COVID-19 pandemic has caused the death of millions\nof people. An important step towards ending the pandemic is vaccination.\nVaccines must be kept under control temperature during the whole process, from\nfabrication to the hands of the health professionals who will immunize the\npopulation. However, there are numerous reports of vaccine loss due to\ntemperature variations, and, currently, people getting vaccinated have no\ncontrol if their vaccine was kept safe. Blockchain is a technology solution\nthat can provide public and verifiable records. We review the World Health\nOrganization (WHO) cool chain and Blockchain technology. Moreover, we describe\ncurrent IoT temperature monitoring devices and propose Blockcoldchain to track\nvaccine cold chain using blockchain, thus proving an unalterable vaccine\ntemperature history. Our experimental results using smart contracts demonstrate\nthe system's feasibility.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.09164,regular,pre_llm,2021,4,"{'ai_likelihood': 1.2914339701334636e-06, 'text': 'Secure Human Action Recognition by Encrypted Neural Network Inference\n\n  Advanced computer vision technology can provide near real-time home\nmonitoring to support ""aging in place"" by detecting falls and symptoms related\nto seizures and stroke. Affordable webcams, together with cloud computing\nservices (to run machine learning algorithms), can potentially bring\nsignificant social benefits. However, it has not been deployed in practice\nbecause of privacy concerns. In this paper, we propose a strategy that uses\nhomomorphic encryption to resolve this dilemma, which guarantees information\nconfidentiality while retaining action detection. Our protocol for secure\ninference can distinguish falls from activities of daily living with 86.21%\nsensitivity and 99.14% specificity, with an average inference latency of 1.2\nseconds and 2.4 seconds on real-world test datasets using small and large\nneural nets, respectively. We show that our method enables a 613x speedup over\nthe latency-optimized LoLa and achieves an average of 3.1x throughput increase\nin secure inference compared to the throughput-optimized nGraph-HE2.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.13964,regular,pre_llm,2021,4,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'PrivChain: Provenance and Privacy Preservation in Blockchain enabled\n  Supply Chains\n\n  Blockchain offers traceability and transparency to supply chain event data\nand hence can help overcome many challenges in supply chain management such as:\ndata integrity, provenance and traceability. However, data privacy concerns\nsuch as the protection of trade secrets have hindered adoption of blockchain\ntechnology. Although consortium blockchains only allow authorised supply chain\nentities to read/write to the ledger, privacy preservation of trade secrets\ncannot be ascertained. In this work, we propose a privacy-preservation\nframework, PrivChain, to protect sensitive data on blockchain using zero\nknowledge proofs. PrivChain provides provenance and traceability without\nrevealing any sensitive information to end-consumers or supply chain entities.\nIts novelty stems from: a) its ability to allow data owners to protect trade\nrelated information and instead provide proofs on the data, and b) an\nintegrated incentive mechanism for entities providing valid proofs over\nprovenance data. In particular, PrivChain uses Zero Knowledge Range Proofs\n(ZKRPs), an efficient variant of ZKPs, to provide origin information without\ndisclosing the exact location of a supply chain product. Furthermore, the\nframework allows to compute proofs and commitments off-line, decoupling the\ncomputational overhead from blockchain. The proof verification process and\nincentive payment initiation are automated using blockchain transactions, smart\ncontracts, and events. A proof of concept implementation on Hyperledger Fabric\nreveals a minimal overhead of using PrivChain for blockchain enabled supply\nchains.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.0403,review,pre_llm,2021,4,"{'ai_likelihood': 3.642506069607205e-07, 'text': 'A Mixed-method Study on Security and Privacy Practices in Danish\n  Companies\n\n  Increased levels of digitalization in society expose companies to new\nsecurity threats, requiring them to establish adequate security and privacy\nmeasures. Additionally, the presence of exogenous forces like new regulations,\ne.g., GDPR and the global COVID-19 pandemic, pose new challenges for companies\nthat should preserve an adequate level of security while having to adapt to\nchange. In this paper, we investigate such challenges through a two-phase study\nin companies located in Denmark -- a country characterized by a high level of\ndigitalization and trust -- focusing on software development and tech-related\ncompanies. Our results show a number of issues, most notably i) a misalignment\nbetween software developers and management when it comes to the implementation\nof security and privacy measures, ii) difficulties in adapting company\npractices in light of implementing GDPR compliance, and iii) different views on\nthe need to adapt security measures to cope with the COVID-19 pandemic.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.11234,regular,pre_llm,2021,4,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Methodology proposal for proactive detection of network anomalies in\n  e-learning system during the COVID-19 scenario\n\n  In specific conditions and crisis situations such as the pandemic of\ncoronavirus (SARS-CoV-2), or the COVID-19 disease, e-learning systems be-came\ncrucial for the smooth performing of teaching and other educational pro-cesses.\nIn such scenarios, the availability of e-learning ecosystem elements is further\nhighlighted. An indicator of the importance for securing the availability of\nsuch an ecosystem is evident from the DDoS (Distributed Denial of Service)\nattack on AAI@EduHr as a key authentication service for number of e-learning\nusers in Republic of Croatia. In doing so, numerous users\n(teach-ers/students/administrators) were prevented from implementing and\nparticipat-ing in the planned teaching process. Given that DDoS as an anomaly\nof network traffic has been identified as one of the key threats to the\ne-learning ecosystem in crisis scenarios, this research will focus on overview\nof methodology for de-veloping a model for proactive detection of DDoS traffic.\nThe challenge in de-tection is to effectively differentiate the increased\ntraffic intensity and service requests caused by legitimate user activity\n(flash crowd) from the illegitimate traffic caused by a DDoS attack. The DDoS\ntraffic detection model developed by following analyzed methodology would serve\nas a basis for providing further guidelines and recommendations in the form of\nresponse to events that may negatively affect the availability of e-learning\necosystem elements such as DDoS attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.14993,regular,pre_llm,2021,4,"{'ai_likelihood': 5.629327562120226e-07, 'text': 'FIPAC: Thwarting Fault- and Software-Induced Control-Flow Attacks with\n  ARM Pointer Authentication\n\n  With the improvements of computing technology, more and more applications\nembed powerful ARM processors into their devices. These systems can be attacked\nby redirecting the control-flow of a program to bypass critical pieces of code\nsuch as privilege checks or signature verifications. Control-flow hijacks can\nbe performed using classical software vulnerabilities, physical fault attacks,\nor software-induced fault attacks. To cope with this threat and to protect the\ncontrol-flow, dedicated countermeasures are needed. To counteract control-flow\nhijacks, control-flow integrity~(CFI) aims to be a generic solution. However,\nsoftware-based CFI typically either protects against software or fault attacks,\nbut not against both. While hardware-assisted CFI can mitigate both types of\nattacks, they require extensive hardware modifications. As hardware changes are\nunrealistic for existing ARM architectures, a wide range of systems remains\nunprotected and vulnerable to control-flow attacks.\n  In this work, we present FIPAC, an efficient software-based CFI scheme\nprotecting the execution at basic block granularity of ARM-based devices\nagainst software and fault attacks. FIPAC exploits ARM pointer authentication\nof ARMv8.6-A to implement a cryptographically signed control-flow graph. We\ncryptographically link the correct sequence of executed basic blocks to enforce\nCFI at this granularity. We use an LLVM-based toolchain to automatically\ninstrument programs. The evaluation on SPEC2017 with different security\npolicies shows a code overhead between 54-97\\% and a runtime overhead between\n35-105%. While these overheads are higher than for countermeasures against\nsoftware attacks, FIPAC outperforms related work protecting the control-flow\nagainst fault attacks. FIPAC is an efficient solution to provide protection\nagainst software- and fault-based CFI attacks on basic block level on modern\nARM devices.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.13285,regular,pre_llm,2021,4,"{'ai_likelihood': 2.5497542487250434e-06, 'text': 'KEVLAR-TZ: A Secure Cache for ARM TrustZone\n\n  Edge devices are increasingly in charge of storing privacy-sensitive data, in\nparticular implantables, wearables, and nearables can potentially collect and\nprocess high-resolution vital signs 24/7. Storing and performing computations\nover such data in a privacy-preserving fashion is of paramount importance. We\npresent KEVLAR-TZ, an application-level trusted cache designed to leverage ARM\nTrustZone, a popular trusted execution environment available in consumer-grade\ndevices. To facilitate the integration with existing systems and IoT devices\nand protocols, KEVLAR-TZ exposes a REST-based interface with connection\nendpoints inside the TrustZone enclave. Furthermore, it exploits the on-device\nsecure persistent storage to guarantee durability of data across reboots. We\nfully implemented KEVLAR-TZ on top of the OP-TEE framework, and experimentally\nevaluated its performance. Our results showcase performance trade-offs, for\ninstance in terms of throughput and latency, for various workloads, and we\nbelieve our results can be useful for practitioners and in general developers\nof systems for TrustZone. KEVLAR-TZ is available as open-source at\nhttps://github.com/mqttz/kevlar-tz/.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.05325,regular,pre_llm,2021,4,"{'ai_likelihood': 7.616149054633247e-07, 'text': 'Multi-level reversible encryption for ECG signals using compressive\n  sensing\n\n  Privacy concerns in healthcare have gained interest recently via GDPR, with a\nrising need for privacy-preserving data collection methods that keep personal\ninformation hidden in otherwise usable data. Sometimes data needs to be\nencrypted for several authentication levels, where a semi-authorized user gains\naccess to data stripped of personal or sensitive information, while a\nfully-authorized user can recover the full signal. In this paper, we propose a\ncompressive sensing based multi-level encryption to ECG signals to mask\npossible heartbeat anomalies from semi-authorized users, while preserving the\nbeat structure for heart rate monitoring. Masking is performed both in time and\nfrequency domains. Masking effectiveness is validated using 1D convolutional\nneural networks for heartbeat anomaly classification, while masked signal\nusefulness is validated comparing heartbeat detection accuracy between masked\nand recovered signals. The proposed multi-level encryption method can decrease\nclassification accuracy of heartbeat anomalies by up to 50%, while maintaining\na fairly high R-peak detection accuracy.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.06051,regular,pre_llm,2021,4,"{'ai_likelihood': 9.934107462565105e-08, 'text': ""Security Analysis of Vendor Implementations of the OPC UA Protocol for\n  Industrial Control Systems\n\n  The OPC UA protocol is an upcoming de-facto standard for building Industry\n4.0 processes in Europe, and one of the few industrial protocols that promises\nsecurity features to prevent attackers from manipulating and damaging critical\ninfrastructures. Despite the importance of the protocol, challenges in the\nadoption of OPC UA's security features by product vendors, libraries\nimplementing the standard, and end-users were not investigated so far.\n  In this work, we systematically investigate 48 publicly available artifacts\nconsisting of products and libraries for OPC UA and show that 38 out of the 48\nartifacts have one (or more) security issues. In particular, we show that 7 OPC\nUA artifacts do not support the security features of the protocol at all. In\naddition, 31 artifacts that partially feature OPC UA security rely on\nincomplete libraries and come with misleading instructions. Consequently,\nrelying on those products and libraries will result in vulnerable\nimplementations of OPC UA security features. To verify our analysis, we design,\nimplement, and demonstrate attacks in which the attacker can steal credentials\nexchanged between victims, eavesdrop on process information, manipulate the\nphysical process through sensor values and actuator commands, and prevent the\ndetection of anomalies.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.1281,review,pre_llm,2021,4,"{'ai_likelihood': 1.3113021850585938e-05, 'text': ""Classical and Quantum algorithms for generic Syndrome Decoding problems\n  and applications to the Lee metric\n\n  The security of code-based cryptography usually relies on the hardness of the\nsyndrome decoding (SD) problem for the Hamming weight. The best generic\nalgorithms are all improvements of an old algorithm by Prange, and they are\nknown under the name of Information Set Decoding (ISD) algorithms. This work\naims to extend ISD algorithms' scope by changing the underlying weight function\nand alphabet size of SD. More precisely, we show how to use Wagner's algorithm\nin the ISD framework to solve SD for a wide range of weight functions. We also\ncalculate the asymptotic complexities of ISD algorithms both in the classical\nand quantum case. We then apply our results to the Lee metric, which currently\nreceives a significant amount of attention. By providing the parameters of SD\nfor which decoding in the Lee weight seems to be the hardest, our study could\nhave several applications for designing code-based cryptosystems and their\nsecurity analysis, especially against quantum adversaries.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.1233,regular,pre_llm,2021,4,"{'ai_likelihood': 4.271666208902995e-06, 'text': 'Two-Server Delegation of Computation on Label-Encrypted Data\n\n  Catalano and Fiore propose a scheme to transform a linearly-homomorphic\nencryption into a homomorphic encryption scheme capable of evaluating quadratic\ncomputations on ciphertexts. Their scheme is based on the linearly-homomorphic\nencryption (such as Goldwasser-Micali, Paillier and ElGamal) and need to\nperform large integer operation on servers. Then, their scheme have numerous\ncomputations on the servers. At the same time, their scheme cannot verify the\ncomputations and cannot evaluate more than degree-4 computations. To solve\nthese problems, we no longer use linearly-homomorphic encryption which based on\nnumber theory assumptions. We use label and pseudorandom function to encrypt\nmessage, which significantly reduce the computations on the servers and enable\nus to use homomorphic MACs technology to realize verifiable computations\nnaturally. We also extend the method to construct $d$-server schemes, which\nallow the client to delegate degree-$d$ computations on outsourced data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.01026,regular,pre_llm,2021,4,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'SGBA: A Stealthy Scapegoat Backdoor Attack against Deep Neural Networks\n\n  Outsourced deep neural networks have been demonstrated to suffer from\npatch-based trojan attacks, in which an adversary poisons the training sets to\ninject a backdoor in the obtained model so that regular inputs can be still\nlabeled correctly while those carrying a specific trigger are falsely given a\ntarget label. Due to the severity of such attacks, many backdoor detection and\ncontainment systems have recently, been proposed for deep neural networks. One\nmajor category among them are various model inspection schemes, which hope to\ndetect backdoors before deploying models from non-trusted third-parties. In\nthis paper, we show that such state-of-the-art schemes can be defeated by a\nso-called Scapegoat Backdoor Attack, which introduces a benign scapegoat\ntrigger in data poisoning to prevent the defender from reversing the real\nabnormal trigger. In addition, it confines the values of network parameters\nwithin the same variances of those from clean model during training, which\nfurther significantly enhances the difficulty of the defender to learn the\ndifferences between legal and illegal models through machine-learning\napproaches. Our experiments on 3 popular datasets show that it can escape\ndetection by all five state-of-the-art model inspection schemes. Moreover, this\nattack brings almost no side-effects on the attack effectiveness and guarantees\nthe universal feature of the trigger compared with original patch-based trojan\nattacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.00033,regular,pre_llm,2021,4,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'Isolation Without Taxation: Near Zero Cost Transitions for SFI\n\n  Software sandboxing or software-based fault isolation (SFI) is a lightweight\napproach to building secure systems out of untrusted components. Mozilla, for\nexample, uses SFI to harden the Firefox browser by sandboxing third-party\nlibraries, and companies like Fastly and Cloudflare use SFI to safely co-locate\nuntrusted tenants on their edge clouds. While there have been significant\nefforts to optimize and verify SFI enforcement, context switching in SFI\nsystems remains largely unexplored: almost all SFI systems use\n\\emph{heavyweight transitions} that are not only error-prone but incur\nsignificant performance overhead from saving, clearing, and restoring registers\nwhen context switching. We identify a set of \\emph{zero-cost conditions} that\ncharacterize when sandboxed code has sufficient structured to guarantee\nsecurity via lightweight \\emph{zero-cost} transitions (simple function calls).\nWe modify the Lucet Wasm compiler and its runtime to use zero-cost transitions,\neliminating the undue performance tax on systems that rely on Lucet for\nsandboxing (e.g., we speed up image and font rendering in Firefox by up to\n29.7\\% and 10\\% respectively). To remove the Lucet compiler and its correct\nimplementation of the Wasm specification from the trusted computing base, we\n(1) develop a \\emph{static binary verifier}, VeriZero, which (in seconds)\nchecks that binaries produced by Lucet satisfy our zero-cost conditions, and\n(2) prove the soundness of VeriZero by developing a logical relation that\ncaptures when a compiled Wasm function is semantically well-behaved with\nrespect to our zero-cost conditions. Finally, we show that our model is useful\nbeyond Wasm by describing a new, purpose-built SFI system, SegmentZero32, that\nuses x86 segmentation and LLVM with mostly off-the-shelf passes to enforce our\nzero-cost conditions; our prototype performs on-par with the state-of-the-art\nNative Client SFI system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.10034,regular,pre_llm,2021,4,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'On Generating and Labeling Network Traffic with Realistic,\n  Self-Propagating Malware\n\n  Research and development of techniques which detect or remediate malicious\nnetwork activity require access to diverse, realistic, contemporary data sets\ncontaining labeled malicious connections. In the absence of such data, said\ntechniques cannot be meaningfully trained, tested, and evaluated. Synthetically\nproduced data containing fabricated or merged network traffic is of limited\nvalue as it is easily distinguishable from real traffic by even simple machine\nlearning (ML) algorithms. Real network data is preferable, but while ubiquitous\nis broadly both sensitive and lacking in ground truth labels, limiting its\nutility for ML research.\n  This paper presents a multi-faceted approach to generating a data set of\nlabeled malicious connections embedded within anonymized network traffic\ncollected from large production networks. Real-world malware is defanged and\nintroduced to simulated, secured nodes within those networks to generate\nrealistic traffic while maintaining sufficient isolation to protect real data\nand infrastructure. Network sensor data, including this embedded malware\ntraffic, is collected at a network edge and anonymized for research use.\n  Network traffic was collected and produced in accordance with the\naforementioned methods at two major educational institutions. The result is a\nhighly realistic, long term, multi-institution data set with embedded data\nlabels spanning over 1.5 trillion connections and over a petabyte of sensor log\ndata. The usability of this data set is demonstrated by its utility to our\nartificial intelligence and machine learning (AI/ML) research program.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.09562,regular,pre_llm,2021,4,"{'ai_likelihood': 3.642506069607205e-07, 'text': 'FLAW3D: A Trojan-based Cyber Attack on the Physical Outcomes of Additive\n  Manufacturing\n\n  Additive Manufacturing (AM) systems such as 3D printers use inexpensive\nmicrocontrollers that rarely feature cybersecurity defenses. This is a risk,\nespecially given the rising threat landscape within the larger digital\nmanufacturing domain. In this work we demonstrate this risk by presenting the\ndesign and study of a malicious Trojan (the FLAW3D bootloader) for AVR-based\nMarlin-compatible 3D printers (>100 commercial models). We show that the Trojan\ncan hide from programming tools, and even within tight design constraints (less\nthan 1.7 kilobytes in size), it can compromise the quality of additively\nmanufactured prints and reduce tensile strengths by up to 50%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.14018,review,pre_llm,2021,4,"{'ai_likelihood': 4.072984059651693e-06, 'text': 'Federated Identity Management (FIdM) Systems Limitation And Solutions\n\n  Efficient identity management system has become one of the fundamental\nrequirements for ensuring safe, secure, and transparent use of identifiable\ninformation and attributes. FIdM allows users to distribute their identity\ninformation across security domains which increase the portability of their\ndigital identities. However, it also raises new architectural challenges and\nsignificant security and privacy issues that need to be mitigated. In this\npaper, we presented the limitations and risks in Federated Identity Management\nsystem and discuss the results and proposed solutions.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.10015,regular,pre_llm,2021,4,"{'ai_likelihood': 1.5132957034640844e-05, 'text': 'Voting Classifier-based Intrusion Detection for IoT Networks\n\n  Internet of Things (IoT) is transforming human lives by paving the way for\nthe management of physical devices on the edge. These interconnected IoT\nobjects share data for remote accessibility and can be vulnerable to open\nattacks and illegal access. Intrusion detection methods are commonly used for\nthe detection of such kinds of attacks but with these methods, the\nperformance/accuracy is not optimal. This work introduces a novel intrusion\ndetection approach based on an ensemble-based voting classifier that combines\nmultiple traditional classifiers as a base learner and gives the vote to the\npredictions of the traditional classifier in order to get the final prediction.\nTo test the effectiveness of the proposed approach, experiments are performed\non a set of seven different IoT devices and tested for binary attack\nclassification and multi-class attack classification. The results illustrate\nprominent accuracies on Global Positioning System (GPS) sensors and weather\nsensors to 96% and 97% and for other machine learning algorithms to 85% and\n87%, respectively. Furthermore, comparison with other traditional machine\nlearning methods validates the superiority of the proposed algorithm.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.03586,regular,pre_llm,2021,4,"{'ai_likelihood': 1.0927518208821616e-06, 'text': ""Characterization of Android malware based on opcode analysis\n\n  The Android operating system is the most spread mobile platform in the world.\nTherefor attackers are producing an incredible number of malware applications\nfor Android. Our aim is to detect Android's malware in order to protect the\nuser. To do so really good results are obtained by dynamic analysis of\nsoftware, but it requires complex environments. In order to achieve the same\nlevel of precision we analyze the machine code and investigate the frequencies\nof ngrams of opcodes in order to detect singular code blocks. This allow us to\nconstruct a database of infected code blocks. Then, because attacker may modify\nand organized differently the infected injected code in their new malware, we\nperform not only a semantic comparison of the tested software with the database\nof infected code blocks but also a structured comparison. To do such comparison\nwe compute subgraph isomorphism. It allows us to characterize precisely if the\ntested software is a malware and if so in witch family it belongs. Our method\nis tested both on a laboratory database and a set of real data. It achieves an\nalmost perfect detection rate.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2104.15068,regular,pre_llm,2021,4,"{'ai_likelihood': 1.3079908159044055e-05, 'text': ""DeFiRanger: Detecting Price Manipulation Attacks on DeFi Applications\n\n  The rapid growth of Decentralized Finance (DeFi) boosts the Ethereum\necosystem. At the same time, attacks towards DeFi applications (apps) are\nincreasing. However, to the best of our knowledge, existing smart contract\nvulnerability detection tools cannot be directly used to detect DeFi attacks.\nThat's because they lack the capability to recover and understand high-level\nDeFi semantics, e.g., a user trades a token pair X and Y in a Decentralized\nEXchange (DEX).\n  In this work, we focus on the detection of two types of new attacks on DeFi\napps, including direct and indirect price manipulation attacks. The former one\nmeans that an attacker directly manipulates the token price in DEX by\nperforming an unwanted trade in the same DEX by attacking the vulnerable DeFi\napp. The latter one means that an attacker indirectly manipulates the token\nprice of the vulnerable DeFi app (e.g., a lending app). To this end, we propose\na platform-independent way to recover high-level DeFi semantics by first\nconstructing the cash flow tree from raw Ethereum transactions and then lifting\nthe low-level semantics to high-level ones, including token trade, liquidity\nmining, and liquidity cancel. Finally, we detect price manipulation attacks\nusing the patterns expressed with the recovered DeFi semantics.\n  We have implemented a prototype named \\tool{} and applied it to more than 350\nmillion transactions. It successfully detected 432 real-world attacks in the\nwild. We confirm that they belong to four known security incidents and five\nzero-day ones. We reported our findings. Two CVEs have been assigned. We\nfurther performed an attack analysis to reveal the root cause of the\nvulnerability, the attack footprint, and the impact of the attack. Our work\nurges the need to secure the DeFi ecosystem.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.07176,regular,pre_llm,2021,5,"{'ai_likelihood': 1.1258655124240452e-06, 'text': 'The Laplace Mechanism has optimal utility for differential privacy over\n  continuous queries\n\n  Differential Privacy protects individuals\' data when statistical queries are\npublished from aggregated databases: applying ""obfuscating"" mechanisms to the\nquery results makes the released information less specific but, unavoidably,\nalso decreases its utility. Yet it has been shown that for discrete data (e.g.\ncounting queries), a mandated degree of privacy and a reasonable interpretation\nof loss of utility, the Geometric obfuscating mechanism is optimal: it loses as\nlittle utility as possible. For continuous query results however (e.g. real\nnumbers) the optimality result does not hold. Our contribution here is to show\nthat optimality is regained by using the Laplace mechanism for the obfuscation.\nThe technical apparatus involved includes the earlier discrete result by Ghosh\net al., recent work on abstract channels and their geometric representation as\nhyper-distributions, and the dual interpretations of distance between\ndistributions provided by the Kantorovich-Rubinstein Theorem.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.03135,regular,pre_llm,2021,5,"{'ai_likelihood': 2.980232238769531e-07, 'text': 'argXtract: Deriving IoT Security Configurations via Automated Static\n  Analysis of Stripped ARM Binaries\n\n  Recent high-profile attacks on the Internet of Things (IoT) have brought to\nthe forefront the vulnerability of ""smart"" devices, and have resulted in\nnumerous IoT-focused security analyses. Many of the attacks had weak device\nconfiguration as the root cause. One potential source of rich and definitive\ninformation about the configuration of an IoT device is the device\'s firmware.\nHowever, firmware analysis is complex and automated firmware analyses have thus\nfar been confined to devices with more traditional operating systems such as\nLinux or VxWorks. Most IoT peripherals, due to lacking traditional operating\nsystems and implementing a wide variety of communication technologies, have\nonly been the subject of smaller-scale analyses. Peripheral firmware analysis\nis further complicated by the fact that such firmware files are predominantly\navailable as stripped binaries, without the ELF headers and symbol tables that\nwould simplify reverse engineering.\n  In this paper, we present argXtract, an open-source automated static analysis\ntool, which extracts security-relevant configuration information from stripped\nIoT peripheral firmware. Specifically, we focus on binaries that target the ARM\nCortex-M architecture, due to its growing popularity among IoT peripherals.\nargXtract overcomes the challenges associated with stripped Cortex-M analysis\nand is able to retrieve arguments to security-relevant supervisor and function\ncalls, enabling automated bulk analysis of firmware files. We demonstrate this\nvia three real-world case studies. The largest case study covers a dataset of\n243 Bluetooth Low Energy binaries targeting Nordic Semiconductor chipsets,\nwhile the other two focus on Nordic ANT and STMicroelectronics BlueNRG\nbinaries. The results reveal widespread lack of security and privacy controls\nin IoT, such as minimal or no protection for data, fixed passkeys and trackable\ndevice addresses.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.12224,regular,pre_llm,2021,5,"{'ai_likelihood': 3.874301910400391e-06, 'text': 'Leaky Frontends: Security Vulnerabilities in Processor Frontends\n\n  This paper evaluates new security threats due to the processor frontend in\nmodern Intel processors. The root causes of the security threats are the\nmultiple paths in the processor frontend that the micro-operations can take:\nthrough the Micro-Instruction Translation Engine (MITE), through the Decode\nStream Buffer (DSB), also called the Micro-operation Cache, or through the Loop\nStream Detector (LSD). Each path has its own unique timing and power\nsignatures, which lead to the side- and covert-channel attacks presented in\nthis work. Especially, the switching between the different paths leads to\nobservable timing or power differences which, as this work demonstrates, could\nbe exploited by attackers. Because of the different paths, the switching, and\nway the components are shared in the frontend between hardware threads, two\nseparate threads are able to be mutually influenced and timing or power can\nreveal activity on the other thread. The security threats are not limited to\nmulti-threading, and this work further demonstrates new ways for leaking\nexecution information about SGX enclaves or a new in-domain Spectre variant in\nsingle-thread setting. Finally, this work demonstrates a new method for\nfingerprinting the microcode patches of the processor by analyzing the behavior\nof different paths in the frontend. The findings of this work highlight the\nsecurity threats associated with the processor frontend and the need for\ndeployment of defenses for the modern processor frontend.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.03502,regular,pre_llm,2021,5,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Conversational Code Analysis: The Future of Secure Coding\n\n  The area of software development and secure coding can benefit significantly\nfrom advancements in virtual assistants. Research has shown that many coders\nneglect security in favor of meeting deadlines. This shortcoming leaves systems\nvulnerable to attackers. While a plethora of tools are available for\nprogrammers to scan their code for vulnerabilities, finding the right tool can\nbe challenging. It is therefore imperative to adopt measures to get programmers\nto utilize code analysis tools that will help them produce more secure code.\nThis chapter looks at the limitations of existing approaches to secure coding\nand proposes a methodology that allows programmers to scan and fix\nvulnerabilities in program code by communicating with virtual assistants on\ntheir smart devices. With the ubiquitous move towards virtual assistants, it is\nimportant to design systems that are more reliant on voice than on standard\npoint-and-click and keyboard-driven approaches. Consequently, we propose\nMyCodeAnalyzer, a Google Assistant app and code analysis framework, which was\ndesigned to interactively scan program code for vulnerabilities and flaws using\nvoice commands during development. We describe the proposed methodology,\nimplement a prototype, test it on a vulnerable project and present our results.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.04485,review,pre_llm,2021,5,"{'ai_likelihood': 6.953875223795574e-07, 'text': ""T-Cash: Transferable Fiat Backed Coins\n\n  Numerous electronic cash schemes have been proposed over the years - however\nnone have been embraced by financial institutions as an alternative to fiat\ncurrency. David Chaum's ecash scheme was the closest to something that mimicked\na modern day currency system, with the important property that it provided\nanonymity for users when purchasing coins from a bank, and subsequently\nspending them at a merchant premises. However it lacked a crucial element\npresent in current fiat-based systems - the ability to continuously spend or\ntransfer coins. Bitcoin reignited the interest in cryptocurrencies in the last\ndecade but is now seen as more of an asset store as opposed to a financial\ninstrument. One interesting thing that has come out of the Bitcoin system is\nblockchains and the associated distributed consensus protocols. In this paper\nwe propose a transferable electronic cash scheme using blockchain technology\nwhich allows users to continuously reuse coins within the system.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.06974,review,pre_llm,2021,5,"{'ai_likelihood': 0.0, 'text': 'A Survey of Security Vulnerabilities in Ethereum Smart Contracts\n\n  Ethereum Smart Contracts based on Blockchain Technology (BT)enables monetary\ntransactions among peers on a blockchain network independent of a central\nauthorizing agency. Ethereum smart contracts are programs that are deployed as\ndecentralized applications, having the building blocks of the blockchain\nconsensus protocol. This enables consumers to make agreements in a transparent\nand conflict-free environment. However, there exist some security\nvulnerabilities within these smart contracts that are a potential threat to the\napplications and their consumers and have shown in the past to cause huge\nfinancial losses. In this study, we review the existing literature and broadly\nclassify the BT applications. As Ethereum smart contracts find their\napplication mostly in e-commerce applications, we believe these are more\ncommonly vulnerable to attacks. In these smart contracts, we mainly focus on\nidentifying vulnerabilities that programmers and users of smart contracts must\navoid. This paper aims at explaining eight vulnerabilities that are specific to\nthe application level of BT by analyzing the past exploitation case scenarios\nof these security vulnerabilities. We also review some of the available tools\nand applications that detect these vulnerabilities in terms of their approach\nand effectiveness. We also investigated the availability of detection tools for\nidentifying these security vulnerabilities and lack thereof to identify some of\nthem\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.10426,regular,pre_llm,2021,5,"{'ai_likelihood': 5.629327562120226e-07, 'text': 'SCSGuard: Deep Scam Detection for Ethereum Smart Contracts\n\n  Smart contract is the building block of blockchain systems that enables\nautomated peer-to-peer transactions and decentralized services. With the\nincreasing popularity of smart contracts, blockchain systems, in particular\nEthereum, have been the ""paradise"" of versatile fraud activities in which\nPonzi, Honeypot and Phishing are the prominent ones. Formal verification and\nsymbolic analysis have been employed to combat these destructive scams by\nanalyzing the codes and function calls, yet the vulnerability of each\n\\emph{individual} scam should be predefined discreetly. In this work, we\npresent SCSGuard, a novel deep learning scam detection framework that harnesses\nthe automatically extractable bytecodes of smart contracts as their new\nfeatures. We design a GRU network with attention mechanism to learn from the\n\\emph{N-gram bytecode} patterns, and determines whether a smart contract is\nfraudulent or not. Our framework is advantageous over the baseline algorithms\nin three aspects. Firstly, SCSGuard provides a unified solution to different\nscam genres, thus relieving the need of code analysis skills. Secondly, the\ninference of SCSGuard is faster than the code analysis by several order of\nmagnitudes. Thirdly, experimental results manifest that SCSGuard achieves high\naccuracy (0.92$\\sim$0.94), precision (0.94$\\sim$0.96\\%) and recall\n(0.97$\\sim$0.98) for both Ponzi and Honeypot scams under similar settings, and\nis potentially useful to detect new Phishing smart contracts.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.06545,review,pre_llm,2021,5,"{'ai_likelihood': 9.569856855604385e-06, 'text': 'What Clinical Trials Can Teach Us about the Development of More\n  Resilient AI for Cybersecurity\n\n  Policy-mandated, rigorously administered scientific testing is needed to\nprovide transparency into the efficacy of artificial intelligence-based\n(AI-based) cyber defense tools for consumers and to prioritize future research\nand development. In this article, we propose a model that is informed by our\nexperience, urged forward by massive scale cyberattacks, and inspired by\nparallel developments in the biomedical field and the unprecedentedly fast\ndevelopment of new vaccines to combat global pathogens.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.01262,regular,pre_llm,2021,5,"{'ai_likelihood': 6.722079383002388e-06, 'text': ""Quantifying the Tradeoff Between Cybersecurity and Location Privacy\n\n  When it comes to location-based services (LBS), user privacy protection can\nbe in conflict with security of both users and trips. While LBS providers could\nadopt privacy preservation mechanisms to obfuscate customer data, the accuracy\nof vehicle location data and trajectories is crucial for detecting anomalies,\nespecially when machine learning methods are adopted by LBS. This paper aims to\ntackle this dilemma by evaluating the tradeoff between location privacy and\nsecurity in LBS. In particular, we investigate the impact of applying location\ndata privacy-preservation techniques on the performance of two detectors,\nnamely a Density-based spatial clustering of applications with noise (DBSCAN),\nand a Recurrent Neural Network (RNN). The experimental results suggest that, by\napplying privacy on location data, DBSCAN is more sensitive to Laplace noise\nthan RNN, although they achieve similar detection accuracy on the trip data\nwithout privacy preservation. Further experiments reveal that DBSCAN is not\nscalable to large size datasets containing millions of trips, because of the\nlarge number of computations needed for clustering trips. On the other hand,\nDBSCAN only requires less than 10 percent of the data used by RNN to achieve\nsimilar performance when applied to vehicle data without obfuscation,\ndemonstrating that clustering-based methods can be easily applied to small\ndatasets. Based on the results, we recommend usage scenarios of the two types\nof trajectory anomaly detectors when applying privacy preservation, by taking\ninto account customers' need for privacy, the size of the available vehicle\ntrip data, and real-time constraints of the LBS application.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.10879,regular,pre_llm,2021,5,"{'ai_likelihood': 6.02669186062283e-06, 'text': 'Precise Approximation of Convolutional Neural Networks for\n  Homomorphically Encrypted Data\n\n  Homomorphic encryption is one of the representative solutions to\nprivacy-preserving machine learning (PPML) classification enabling the server\nto classify private data of clients while guaranteeing privacy. This work\nfocuses on PPML using word-wise fully homomorphic encryption (FHE). In order to\nimplement deep learning on word-wise homomorphic encryption (HE), the ReLU and\nmax-pooling functions should be approximated by some polynomials for\nhomomorphic operations. Most of the previous studies focus on HE-friendly\nnetworks, where the ReLU and max-pooling functions are approximated using\nlow-degree polynomials. However, for the classification of the CIFAR-10\ndataset, using a low-degree polynomial requires designing a new deep learning\nmodel and training. In addition, this approximation by low-degree polynomials\ncannot support deeper neural networks due to large approximation errors. Thus,\nwe propose a precise polynomial approximation technique for the ReLU and\nmax-pooling functions. Precise approximation using a single polynomial requires\nan exponentially high-degree polynomial, which results in a significant number\nof non-scalar multiplications. Thus, we propose a method to approximate the\nReLU and max-pooling functions accurately using a composition of minimax\napproximate polynomials of small degrees. If we replace the ReLU and\nmax-pooling functions with the proposed approximate polynomials, well-studied\ndeep learning models such as ResNet and VGGNet can still be used without\nfurther modification for PPML on FHE. Even pre-trained parameters can be used\nwithout retraining. We approximate the ReLU and max-pooling functions in the\nResNet-152 using the composition of minimax approximate polynomials of degrees\n15, 27, and 29. Then, we succeed in classifying the plaintext ImageNet dataset\nwith 77.52% accuracy, which is very close to the original model accuracy of\n78.31%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.04264,review,pre_llm,2021,5,"{'ai_likelihood': 1.2914339701334636e-06, 'text': 'Threat Landscape for Smart Grid Systems\n\n  Smart Grids are energy delivery networks, constituting an evolution of power\ngrids, in which a bidirectional flow between power providers and consumers is\nestablished. These flows support the transfer of electricity and information,\nin order to support automation actions in the context of the energy delivery\nnetwork. Insofar, many smart grid implementations and implementation proposals\nhave emerged, with varying degrees of feature delivery and sophistication.\nWhile smart grids offer many advantages, their distributed nature and\ninformation flow streams between energy producers and consumers enable the\nlaunching of a number of attacks against the smart grid infrastructure, where\nthe related consequences may range from economic loss to complete failure of\nthe smart grid. In this paper, we survey the threat landscape of smart grids,\nidentifying threats that are specific to this infrastructure, providing an\nassessment of the severity of the consequences of each attack type, discerning\nfeatures that can be utilized to detect attacks and listing methods that can be\nused to mitigate them.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.13755,regular,pre_llm,2021,5,"{'ai_likelihood': 2.6490953233506946e-07, 'text': ""The Generation of Security Scoring Systems Leveraging Human Expert\n  Opinion\n\n  While the existence of many security elements can be measured (e.g.,\nvulnerabilities, security controls, or privacy controls), it is challenging to\nmeasure their relative security impact. In the physical world we can often\nmeasure the impact of individual elements to a system. However, in cyber\nsecurity we often lack ground truth (i.e., the ability to directly measure\nsignificance). In this work we propose to solve this by leveraging human expert\nopinion to provide ground truth. Experts are iteratively asked to compare pairs\nof security elements to determine their relative significance. On the back end\nour knowledge encoding tool performs a form of binary insertion sort on a set\nof security elements using each expert as an oracle for the element\ncomparisons. The tool not only sorts the elements (note that equality may be\npermitted), but it also records the strength or degree of each relationship.\nThe output is a directed acyclic 'constraint' graph that provides a total\nordering among the sets of equivalent elements. Multiple constraint graphs are\nthen unified together to form a single graph that is used to generate a scoring\nor prioritization system. For our empirical study, we apply this\ndomain-agnostic measurement approach to generate scoring/prioritization systems\nin the areas of vulnerability scoring, privacy control prioritization, and\ncyber security control evaluation.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.04919,regular,pre_llm,2021,5,"{'ai_likelihood': 1.986821492513021e-06, 'text': 'Agatha: Smart Contract for DNN Computation\n\n  Smart contract is one of the core features of Ethereum and has inspired many\nblockchain descendants. Since its advent, the verification paradigm of smart\ncontract has been improving toward high scalability. It shifts from the\nexpensive on-chain verification to the orchestration of off-chain VM (virtual\nmachine) execution and on-chain arbitration with the pinpoint protocol. The\nrepresentative projects are TrueBit, Arbitrum, YODA, ACE, and Optimism.\nInspired by visionaries in academia and industry, we consider the DNN\ncomputation to be promising but on the next level of complexity for the\nverification paradigm of smart contract. Unfortunately, even for the\nstate-of-the-art verification paradigm, off-chain VM execution of DNN\ncomputation has an orders-of-magnitude slowdown compared to the native\noff-chain execution.\n  To enable the native off-chain execution of verifiable DNN computation, we\npresent Agatha system, which solves the significant challenges of misalignment\nand inconsistency: (1) Native DNN computation has a graph-based computation\nparadigm misaligned with previous VM-based execution and arbitration; (2)\nNative DNN computation may be inconsistent cross platforms which invalidates\nthe verification paradigm. In response, we propose the graph-based pinpoint\nprotocol (GPP) which enables the pinpoint protocol on computational graphs, and\nbridges the native off-chain execution and the contract arbitration. We also\ndevelop a technique named Cross-evaluator Consistent Execution (XCE), which\nguarantees cross-platform consistency and forms the correctness foundation of\nGPP. We showcase Agatha for the DNN computation of popular models (MobileNet,\nResNet50 and VGG16) on Ethereum. Agatha achieves a negligible on-chain\noverhead, and an off-chain execution overhead of 3.0%, which represents an\noff-chain latency reduction of at least 602x compared to the state-of-the-art\nverification paradigm.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.04454,review,pre_llm,2021,5,"{'ai_likelihood': 9.338061014811199e-06, 'text': ""Physical Fault Injection and Side-Channel Attacks on Mobile Devices: A\n  Comprehensive Analysis\n\n  Today's mobile devices contain densely packaged system-on-chips (SoCs) with\nmulti-core, high-frequency CPUs and complex pipelines. In parallel,\nsophisticated SoC-assisted security mechanisms have become commonplace for\nprotecting device data, such as trusted execution environments, full-disk and\nfile-based encryption. Both advancements have dramatically complicated the use\nof conventional physical attacks, requiring the development of specialised\nattacks. In this survey, we consolidate recent developments in physical fault\ninjections and side-channel attacks on modern mobile devices. In total, we\ncomprehensively survey over 50 fault injection and side-channel attack papers\npublished between 2009-2021. We evaluate the prevailing methods, compare\nexisting attacks using a common set of criteria, identify several challenges\nand shortcomings, and suggest future directions of research.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.10794,regular,pre_llm,2021,5,"{'ai_likelihood': 4.867712656656901e-06, 'text': 'AOT: Anonymization by Oblivious Transfer\n\n  We introduce AOT, an anonymous communication system based on mix network\narchitecture that uses oblivious transfer (OT) to deliver messages. Using OT to\ndeliver messages helps AOT resist blending ($n-1$) attacks and helps AOT\npreserve receiver anonymity, even if a covert adversary controls all nodes in\nAOT. AOT comprises three levels of nodes, where nodes at each level perform a\ndifferent function and can scale horizontally. The sender encrypts their\npayload and a tag, derived from a secret shared between the sender and\nreceiver, with the public key of a Level-2 node and sends them to a Level-1\nnode. On a public bulletin board, Level-3 nodes publish tags associated with\nmessages ready to be retrieved. Each receiver checks the bulletin board,\nidentifies tags, and receives the associated messages using OT. A receiver can\nreceive their messages even if the receiver is offline when messages are ready.\nThrough what we call a ""handshake"" process, communicants can use the AOT\nprotocol to establish shared secrets anonymously. Users play an active role in\ncontributing to the unlinkability of messages: periodically, users initiate\nrequests to AOT to receive dummy messages, such that an adversary cannot\ndistinguish real and dummy requests.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.09157,regular,pre_llm,2021,5,"{'ai_likelihood': 1.1755360497368707e-05, 'text': 'Hunter in the Dark: Discover Anomalous Network Activity Using Deep\n  Ensemble Network\n\n  Machine learning (ML)-based intrusion detection systems (IDSs) play a\ncritical role in discovering unknown threats in a large-scale cyberspace. They\nhave been adopted as a mainstream hunting method in many organizations, such as\nfinancial institutes, manufacturing companies and government agencies. However,\nexisting designs achieve a high threat detection performance at the cost of a\nlarge number of false alarms, leading to alert fatigue. To tackle this issue,\nin this paper, we propose a neural-network-based defense mechanism named\nDarkHunter. DarkHunter incorporates both supervised learning and unsupervised\nlearning in the design. It uses a deep ensemble network (trained through\nsupervised learning) to detect anomalous network activities and exploits an\nunsupervised learning-based scheme to trim off mis-detection results. For each\ndetected threat, DarkHunter can trace to its source and present the threat in\nits original traffic format. Our evaluations, based on the UNSW-NB15 dataset,\nshow that DarkHunter outperforms the existing ML-based IDSs and is able to\nachieve a high detection accuracy while keeping a low false positive rate.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.08902,regular,pre_llm,2021,5,"{'ai_likelihood': 6.622738308376736e-08, 'text': ""LNGate: Powering IoT with Next Generation Lightning Micro-payments using\n  Threshold Cryptography\n\n  Bitcoin has emerged as a revolutionary payment system with its decentralized\nledger concept however it has significant problems such as high transaction\nfees and long confirmation times. Lightning Network (LN), which was introduced\nmuch later, solves most of these problems with an innovative concept called\noff-chain payments. With this advancement, Bitcoin has become an attractive\nvenue to perform micro-payments which can also be adopted in many IoT\napplications (e.g. toll payments). Nevertheless, it is not feasible to host LN\nand Bitcoin on IoT devices due to the storage, memory, and processing\nrequirements. Therefore, in this paper, we propose an efficient and secure\nprotocol that enables an IoT device to use LN through an untrusted gateway\nnode. The gateway hosts LN and Bitcoin nodes and can open & close LN channels,\nsend LN payments on behalf of the IoT device. This delegation approach is\npowered by a (2,2)-threshold scheme that requires the IoT device and the LN\ngateway to jointly perform all LN operations which in turn secures both\nparties' funds. Specifically, we propose to thresholdize LN's Bitcoin public\nand private keys as well as its commitment points. With these and several other\nprotocol level changes, IoT device is protected against revoked state\nbroadcast, collusion, and ransom attacks. We implemented the proposed protocol\nby changing LN's source code and thoroughly evaluated its performance using a\nRaspberry Pi. Our evaluation results show that computational and communication\ndelays associated with the protocol are negligible. To the best of our\nknowledge, this is the first work that implemented threshold cryptography in\nLN.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.07447,review,pre_llm,2021,5,"{'ai_likelihood': 1.2252065870496963e-06, 'text': 'Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and\n  Challenges\n\n  The Non-Fungible Token (NFT) market is mushrooming in recent years. The\nconcept of NFT originally comes from a token standard of Ethereum, aiming to\ndistinguish each token with distinguishable signs. This type of token can be\nbound with virtual/digital properties as their unique identifications. With\nNFTs, all marked properties can be freely traded with customized values\naccording to their ages, rarity, liquidity, etc. It has greatly stimulated the\nprosperity of the decentralized application (DApp) market. At the time of\nwriting (May 2021), the total money used on completed NFT sales has reached\n$34,530,649.86$ USD. The thousandfold return on its increasing market draws\nhuge attention worldwide. However, the development of the NFT ecosystem is\nstill in its early stage, and the technologies of NFTs are pre-mature.\nNewcomers may get lost in their frenetic evolution due to the lack of\nsystematic summaries. In this technical report, we explore the NFT ecosystems\nin several aspects. We start with an overview of state-of-the-art NFT\nsolutions, then provide their technical components, protocols, standards, and\ndesired proprieties. Afterward, we give a security evolution, with discussions\non the perspectives of their design models, opportunities, and challenges. To\nthe best of our knowledge, this is the first systematic study on the current\nNFT ecosystems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.12935,regular,pre_llm,2021,5,"{'ai_likelihood': 4.271666208902995e-06, 'text': 'SDN-based Runtime Security Enforcement Approach for Privacy Preservation\n  of Dynamic Web Service Composition\n\n  Aiming at the privacy preservation of dynamic Web service composition, this\npaper proposes a SDN-based runtime security enforcement approach for privacy\npreservation of dynamic Web service composition. The main idea of this approach\nis that the owner of service composition leverages the security policy model\n(SPM) to define the access control relationships that service composition must\ncomply with in the application plane, then SPM model is transformed into the\nlow-level security policy model (RSPM) containing the information of SDN data\nplane, and RSPM model is uploaded into the SDN controller. After uploading, the\nvirtual machine access control algorithm integrated in the SDN controller\nmonitors all of access requests towards service composition at runtime. Only\nthe access requests that meet the definition of RSPM model can be forwarded to\nthe target terminal. Any access requests that do not meet the definition of\nRSPM model will be automatically blocked by Openflow switches or deleted by SDN\ncontroller, Thus, this approach can effectively solve the problems of\nnetwork-layer illegal accesses, identity theft attacks and service leakages\nwhen Web service composition is running. In order to verify the feasibility of\nthis approach, this paper implements an experimental system by using POX\ncontroller and Mininet virtual network simulator, and evaluates the\neffectiveness and performance of this approach by using this system. The final\nexperimental results show that the method is completely effective, and the\nmethod can always get the correct calculation results in an acceptable time\nwhen the scale of RSPM model is gradually increasing.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2105.13769,regular,pre_llm,2021,5,"{'ai_likelihood': 3.642506069607205e-07, 'text': 'ARMORY: Fully Automated and Exhaustive Fault Simulation on ARM-M\n  Binaries\n\n  Embedded systems are ubiquitous. However, physical access of users and\nlikewise attackers makes them often threatened by fault attacks: a single fault\nduring the computation of a cryptographic primitive can lead to a total loss of\nsystem security. This can have serious consequences, e.g., in safetycritical\nsystems, including bodily harm and catastrophic technical failures. However,\ncountermeasures often focus on isolated fault models and high layers of\nabstraction. This leads to a dangerous sense of security, because exploitable\nfaults that are only visible at machine code level might not be covered by\ncountermeasures. In this work we present ARMORY, a fully automated open source\nframework for exhaustive fault simulation on binaries of the ubiquitous ARM-M\nclass. It allows engineers and analysts to efficiently scan a binary for\npotential weaknesses against arbitrary combinations of multi-variate fault\ninjections under a large variety of fault models. Using ARMORY, we demonstrate\nthe power of fully automated fault analysis and the dangerous implications of\napplying countermeasures without knowledge of physical addresses and offsets.\nWe exemplarily analyze two case studies, which are highly relevant for\npractice: a DFA on AES (cryptographic) and a secure bootloader\n(non-cryptographic). Our results show that indeed numerous exploitable faults\nfound by ARMORY which occur in the actual implementations are easily missed in\nmanual inspection. Crucially, most faults are only visible when taking machine\ncode information, i.e., addresses and offsets, into account. Surprisingly, we\nshow that a countermeasure that protects against one type of fault can actually\nlargely increase the vulnerability to other fault models. Our work demonstrates\nthe need for countermeasures that, at least in their evaluation, are not\nrestricted to isolated fault models and consider low-level information [...].\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.06272,review,pre_llm,2021,6,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Model-based Joint Analysis of Safety and Security: Survey and\n  Identification of Gaps\n\n  We survey the state-of-the-art on model-based formalisms for safety and\nsecurity joint analysis, where safety refers to the absence of unintended\nfailures, and security to absence of malicious attacks. We conduct a thorough\nliterature review and - as a result - we consider fourteen model-based\nformalisms and compare them with respect to several criteria: (1) Modelling\ncapabilities and Expressiveness: which phenomena can be expressed in these\nformalisms? To which extent can they capture safety-security interactions? (2)\nAnalytical capabilities: which analysis types are supported? (3) Practical\napplicability: to what extent have the formalisms been used to analyze small or\nlarger case studies? Furthermore, (1) we present more precise definitions for\nsafety-security dependencies in tree-like formalisms; (2) we showcase the\npotential of each formalism by modelling the same toy example from the\nliterature and (3) we present our findings and reflect on possible ways to\nnarrow highlighted gaps. In summary, our key findings are the following: (1)\nthe majority of approaches combine tree-like formal models; (2) the exact\nnature of safety-security interaction is still ill-understood and (3) diverse\nformalisms can capture different interactions; (4) analyzed formalisms merge\nmodelling constructs from existing safety- and security-specific formalisms,\nwithout introducing ad hoc constructs to model safety-security interactions, or\n(5) metrics to analyze trade offs. Moreover, (6) large case studies\nrepresenting safety-security interactions are still missing.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.15387,regular,pre_llm,2021,6,"{'ai_likelihood': 1.5232298109266494e-06, 'text': ""undeSErVed trust: Exploiting Permutation-Agnostic Remote Attestation\n\n  The ongoing trend of moving data and computation to the cloud is met with\nconcerns regarding privacy and protection of intellectual property. Cloud\nService Providers (CSP) must be fully trusted to not tamper with or disclose\nprocessed data, hampering adoption of cloud services for many sensitive or\ncritical applications. As a result, CSPs and CPU manufacturers are rushing to\nfind solutions for secure outsourced computation in the Cloud. While enclaves,\nlike Intel SGX, are strongly limited in terms of throughput and size, AMD's\nSecure Encrypted Virtualization (SEV) offers hardware support for transparently\nprotecting code and data of entire VMs, thus removing the performance, memory\nand software adaption barriers of enclaves. Through attestation of boot code\nintegrity and means for securely transferring secrets into an encrypted VM,\nCSPs are effectively removed from the list of trusted entities. There have been\nseveral attacks on the security of SEV, by abusing I/O channels to encrypt and\ndecrypt data, or by moving encrypted code blocks at runtime. Yet, none of these\nattacks have targeted the attestation protocol, the core of the secure\ncomputing environment created by SEV. We show that the current attestation\nmechanism of Zen 1 and Zen 2 architectures has a significant flaw, allowing us\nto manipulate the loaded code without affecting the attestation outcome. An\nattacker may abuse this weakness to inject arbitrary code at startup -- and\nthus take control over the entire VM execution, without any indication to the\nVM's owner. Our attack primitives allow the attacker to do extensive\nmodifications to the bootloader and the operating system, like injecting spy\ncode or extracting secret data. We present a full end-to-end attack, from the\ninitial exploit to leaking the key of the encrypted disk image during boot,\ngiving the attacker unthrottled access to all of the VM's persistent data.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.07416,review,pre_llm,2021,6,"{'ai_likelihood': 5.298190646701389e-07, 'text': 'Cheatsheets for Authentication and Key Agreements in 2G, 3G, 4G, and 5G\n\n  Authentication and Key Agreement (AKA) is a type of security protocol, used\nin 3GPP mobile networks, that provides two security capabilities. The first\ncapability, called authentication, is to cryptographically assert that a mobile\nphone or a network is indeed who it claims to be, and the second capability,\ncalled key agreement, is to put necessary cryptographic keys in place for\nprotection of traffic between the mobile phone and the network. Jointly, these\ntwo capabilities lay the foundation of secure 3GPP mobile networks. From 2G-5G,\nthere are eight main versions of AKA, details of which are spread over and\nembedded deep in multiple technical specifications. It is getting increasingly\ndifficult to quickly check a certain property of a certain AKA, let alone grasp\nthe full picture of all AKAs. Therefore, I have prepared cheatsheets for all\nAKA versions and listed their main properties. I hope these will benefit\nuniversity students, security researchers, and 3GPP standardization community.\nI welcome any corrections and feedback.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.04974,regular,pre_llm,2021,6,"{'ai_likelihood': 2.0133124457465277e-05, 'text': ""Grand Theft App: Digital Forensics of Vehicle Assistant Apps\n\n  Due to the increasing connectivity of modern vehicles, collected data is no\nlonger only stored in the vehicle itself but also transmitted to car\nmanufacturers and vehicle assistant apps. This development opens up new\npossibilities for digital forensics in criminal investigations involving modern\nvehicles. This paper deals with the digital forensic analysis of vehicle\nassistant apps of eight car manufacturers. We reconstruct the driver's\nactivities based on the data stored on the smartphones and in the\nmanufacturer's backend.\n  For this purpose, data of the Android and iOS apps of the car manufacturers\nAudi, BMW, Ford, Mercedes, Opel, Seat, Tesla, and Volkswagen were extracted\nfrom the smartphone and examined using digital forensic methods in accordance\nwith lawful government-approved forensics guidelines. Additionally,\nmanufacturer data was retrieved using Subject Access Requests. Using the\nextensive data gathered, we successfully reconstruct trips and refueling\nprocesses, determine parking positions and duration, and track the locking and\nunlocking of the vehicle.\n  These findings show that the digital forensic investigation of smartphone\napplications is a useful addition to vehicle forensics and should therefore be\ntaken into account in the strategic preparation of future digital forensic\ninvestigations.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.14253,regular,pre_llm,2021,6,"{'ai_likelihood': 8.112854427761502e-06, 'text': 'An efficient and secure scheme of verifiable computation for Intel SGX\n\n  Cloud computing offers resource-constrained users big-volume data storage and\nenergy-consuming complicated computation. However, owing to the lack of full\ntrust in the cloud, the cloud users prefer privacy-preserving outsourced data\ncomputation with correctness verification. However, cryptography-based schemes\nintroduce high computational costs to both the cloud and its users for\nverifiable computation with privacy preservation, which makes it difficult to\nsupport complicated computations in practice.\n  Intel Software Guard Extensions (SGX) as a trusted execution environment is\nwidely researched in various fields (such as secure data analytics and\ncomputation), and is regarded as a promising way to achieve efficient\noutsourced data computation with privacy preservation over the cloud. But we\nfind two types of threats towards the computation with SGX: Disarranging\nData-Related Code threat and Output Tampering and Misrouting threat. In this\npaper, we depict these threats using formal methods and successfully conduct\nthe two threats on the enclave program constructed by Rust SGX SDK to\ndemonstrate their impacts on the correctness of computations over SGX enclaves.\nIn order to provide countermeasures, we propose an efficient and secure scheme\nto resist the threats and realize verifiable computation for Intel SGX. We\nprove the security and show the efficiency and correctness of our proposed\nscheme through theoretic analysis and extensive experiments. Furthermore, we\ncompare the performance of our scheme with that of some cryptography-based\nschemes to show its high efficiency.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.06136,review,pre_llm,2021,6,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'Security and Privacy for Healthcare Blockchains\n\n  Healthcare blockchains provide an innovative way to store healthcare\ninformation, execute healthcare transactions, and build trust for healthcare\ndata sharing and data integration in a decentralized open healthcare network\nenvironment. Although the healthcare blockchain technology has attracted broad\ninterests and attention in industry, government and academia, the security and\nprivacy concerns remain the focus of debate when deploying blockchains for\ninformation sharing in the healthcare sector from business operation to\nresearch collaboration. This paper focuses on the security and privacy\nrequirements for medical data sharing using blockchain, and provides a\ncomprehensive analysis of the security and privacy risks and requirements,\naccompanied by technical solution techniques and strategies. First, we discuss\nthe security and privacy requirements and attributes required for electronic\nmedical data sharing by deploying the healthcare blockchain. Second, we\ncategorize existing efforts into three reference blockchain usage scenarios for\nelectronic medical data sharing, and discuss the technologies for implementing\nthese security and privacy properties in the three categories of usage\nscenarios for healthcare blockchain, such as anonymous signatures,\nattribute-based encryption, zero-knowledge proofs, verification techniques for\nsmart contract security. Finally, we discuss other potential blockchain\napplication scenarios in healthcare sector. We conjecture that this survey will\nhelp healthcare professionals, decision makers, and healthcare service\ndevelopers to gain technical and intuitive insights into the security and\nprivacy of healthcare blockchains in terms of concepts, risks, requirements,\ndevelopment and deployment technologies and systems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.15934,regular,pre_llm,2021,6,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Extending On-chain Trust to Off-chain -- Trustworthy Blockchain Data\n  Collection using Trusted Execution Environment (TEE)\n\n  Blockchain creates a secure environment on top of strict cryptographic\nassumptions and rigorous security proofs. It permits on-chain interactions to\nachieve trustworthy properties such as traceability, transparency, and\naccountability. However, current blockchain trustworthiness is only confined to\non-chain, creating a ""trust gap"" to the physical, off-chain environment. This\nis due to the lack of a scheme that can truthfully reflect the physical world\nin a real-time and consistent manner. Such an absence hinders further\nreal-world blockchain applications, especially for security-sensitive ones.\n  In this paper, we propose a scheme to extend blockchain trust from on-chain\nto off-chain, and take trustworthy vaccine transportation as an example. Our\nscheme consists of 1) a Trusted Execution Environment (TEE)-enabled trusted\nenvironment monitoring system built with the Arm Cortex-M33 microcontroller\nthat continuously senses the inside of a vaccine box through trusted sensors\nand generates anti-forgery data; and 2) a consistency protocol to upload the\nenvironment status data from the TEE system to blockchain in a truthful,\nreal-time consistent, continuous and fault-tolerant fashion. Our security\nanalysis indicates that no adversary can tamper with the vaccine in any way\nwithout being captured. We carry out an experiment to record the internal\nstatus of a vaccine shipping box during transportation, and the results\nindicate that the proposed system incurs an average latency of 84 ms in local\nsensing and processing followed by an average latency of 130 ms to have the\nsensed data transmitted to and available in the blockchain.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.05395,regular,pre_llm,2021,6,"{'ai_likelihood': 2.6490953233506946e-07, 'text': ""Impact of Blockchain Technology on Electric Power Grids -- A case study\n  in LO3 Energy\n\n  The increasing amount of distributed energy resources including renewable\nenergy systems and electric vehicles is expected to change electric power grids\nsignificantly, where conventional consumers are transformed to prosumers since\nthey can produce electricity as well. In such an ecosystem, prosumers can start\noffering their excess energy to supply demands of the other customers on the\ngrids behind the meter without interference of distribution system operators\n(DSO). Besides, DSOs require more accurate and more frequent data form\nprosumers' net demand to be able to operate their network efficiently. The main\nchallenge in these new distribution grids is the amount of data that needs to\nbe collected in this platform is unbelievably high, and more immortally,\nprosumers will likely refuse to share their information with DSOs due to their\npotential privacy and economic concerns. Blockchain technology as an efficient\ndistributed solution for management of data and financial transactions, has\nbeen considered to solve this trust issue. With blockchain-based solutions,\ndata and financial transactions between all parties will take placed through\ndistributed ledgers without any interference from an intermediary. In this\npaper, impacts of blockchain technologies on electric power industry is\nstudied. The paper specifically focuses on LO3 Energy -- one of startups\napplying blockchain to electric power grids -- their blockchain-based solution\ncalled Exergy, and their use cases to implement such solutions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.09565,review,pre_llm,2021,6,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'Interval Privacy: A Framework for Privacy-Preserving Data Collection\n\n  The emerging public awareness and government regulations of data privacy\nmotivate new paradigms of collecting and analyzing data that are transparent\nand acceptable to data owners. We present a new concept of privacy and\ncorresponding data formats, mechanisms, and theories for privatizing data\nduring data collection. The privacy, named Interval Privacy, enforces the raw\ndata conditional distribution on the privatized data to be the same as its\nunconditional distribution over a nontrivial support set. Correspondingly, the\nproposed privacy mechanism will record each data value as a random interval\n(or, more generally, a range) containing it. The proposed interval privacy\nmechanisms can be easily deployed through survey-based data collection\ninterfaces, e.g., by asking a respondent whether its data value is within a\nrandomly generated range. Another unique feature of interval mechanisms is that\nthey obfuscate the truth but do not perturb it. Using narrowed range to convey\ninformation is complementary to the popular paradigm of perturbing data. Also,\nthe interval mechanisms can generate progressively refined information at the\ndiscretion of individuals, naturally leading to privacy-adaptive data\ncollection. We develop different aspects of theory such as composition,\nrobustness, distribution estimation, and regression learning from\ninterval-valued data. Interval privacy provides a new perspective of\nhuman-centric data privacy where individuals have a perceptible, transparent,\nand simple way of sharing sensitive data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.13123,regular,pre_llm,2021,6,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'The Queen\'s Guard: A Secure Enforcement of Fine-grained Access Control\n  In Distributed Data Analytics Platforms\n\n  Distributed data analytics platforms (i.e., Apache Spark, Hadoop) provide\nhigh-level APIs to programmatically write analytics tasks that are run\ndistributedly in multiple computing nodes. The design of these frameworks was\nprimarily motivated by performance and usability. Thus, the security takes a\nback seat. Consequently, they do not inherently support fine-grained access\ncontrol or offer any plugin mechanism to enable it, making them risky to be\nused in multi-tier organizational settings.\n  There have been attempts to build ""add-on"" solutions to enable fine-grained\naccess control for distributed data analytics platforms. In this paper, first,\nwe show that straightforward enforcement of ``add-on\'\' access control is\ninsecure under adversarial code execution. Specifically, we show that an\nattacker can abuse platform-provided APIs to evade access controls without\nleaving any traces. Second, we designed a two-layered (i.e., proactive and\nreactive) defense system to protect against API abuses. On submission of a user\ncode, our proactive security layer statically screens it to find potential\nattack signatures prior to its execution. The reactive security layer employs\ncode instrumentation-based runtime checks and sandboxed execution to throttle\nany exploits at runtime. Next, we propose a new fine-grained access control\nframework with an enhanced policy language that supports map and filter\nprimitives. Finally, we build a system named SecureDL with our new access\ncontrol framework and defense system on top of Apache Spark, which ensures\nsecure access control policy enforcement under adversaries capable of executing\ncode.\n  To the best of our knowledge, this is the first fine-grained attribute-based\naccess control framework for distributed data analytics platforms that is\nsecure against platform API abuse attacks. Performance evaluation showed that\nthe overhead due to added security is low.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.13499,review,pre_llm,2021,6,"{'ai_likelihood': 4.967053731282552e-07, 'text': 'SaSeVAL: A Safety/Security-Aware Approach for Validation of\n  Safety-Critical Systems\n\n  Increasing communication and self-driving capabilities for road vehicles lead\nto threats imposed by attackers. Especially attacks leading to safety\nviolations have to be identified to address them by appropriate measures. The\nimpact of an attack depends on the threat exploited, potential countermeasures\nand the traffic situation. In order to identify such attacks and to use them\nfor testing, we propose the systematic approach SaSeVAL for deriving attacks of\nautonomous vehicles. SaSeVAL is based on threats identification and\nsafety-security analysis. The impact of automotive use cases to attacks is\nconsidered. The threat identification considers the attack interface of\nvehicles and classifies threat scenarios according to threat types, which are\nthen mapped to attack types. The safety-security analysis identifies the\nnecessary requirements which have to be tested based on the architecture of the\nsystem under test. lt determines which safety impact a security violation may\nhave, and in which traffic situations the highest impact is expected. Finally,\nthe results of threat identification and safety-security analysis are used to\ndescribe attacks. The goal of SaSeVAL is to achieve safety validation of the\nvehicle w.r.t. security concerns. lt traces safety goals to threats and to\nattacks explicitly. Hence, the coverage of safety concerns by security testing\nis assured. Two use cases of vehicle communication and autonomous driving are\ninvestigated to prove the applicability of the approach.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.11762,regular,pre_llm,2021,6,"{'ai_likelihood': 5.629327562120226e-07, 'text': ""Modeling of Personalized Privacy Disclosure Behavior: A Formal Method\n  Approach\n\n  In order to create user-centric and personalized privacy management tools,\nthe underlying models must account for individual users' privacy expectations,\npreferences, and their ability to control their information sharing activities.\nExisting studies of users' privacy behavior modeling attempt to frame the\nproblem from a request's perspective, which lack the crucial involvement of the\ninformation owner, resulting in limited or no control of policy management.\nMoreover, very few of them take into the consideration the aspect of\ncorrectness, explainability, usability, and acceptance of the methodologies for\neach user of the system. In this paper, we present a methodology to formally\nmodel, validate, and verify personalized privacy disclosure behavior based on\nthe analysis of the user's situational decision-making process. We use a model\nchecking tool named UPPAAL to represent users' self-reported privacy disclosure\nbehavior by an extended form of finite state automata (FSA), and perform\nreachability analysis for the verification of privacy properties through\ncomputation tree logic (CTL) formulas. We also describe the practical use cases\nof the methodology depicting the potential of formal technique towards the\ndesign and development of user-centric behavioral modeling. This paper, through\nextensive amounts of experimental outcomes, contributes several insights to the\narea of formal methods and user-tailored privacy behavior modeling.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.13339,regular,pre_llm,2021,6,"{'ai_likelihood': 1.4901161193847656e-06, 'text': 'Blockchain-based Security Framework for Critical Industry 4.0\n  Cyber-physical System\n\n  There has been an intense concern for security alternatives because of the\nrecent rise of cyber attacks, mainly targeting critical systems such as\nindustry, medical, or energy ecosystem. Though the latest industry\ninfrastructures largely depend on AI-driven maintenance, the prediction based\non corrupted data undoubtedly results in loss of life and capital. Admittedly,\nan inadequate data-protection mechanism can readily challenge the security and\nreliability of the network. The shortcomings of the conventional cloud or\ntrusted certificate-driven techniques have motivated us to exhibit a unique\nBlockchain-based framework for a secure and efficient industry 4.0 system. The\ndemonstrated framework obviates the long-established certificate authority\nafter enhancing the consortium Blockchain that reduces the data processing\ndelay, and increases cost-effective throughput. Nonetheless, the distributed\nindustry 4.0 security model entails cooperative trust than depending on a\nsingle party, which in essence indulges the costs and threat of the single\npoint of failure. Therefore, multi-signature technique of the proposed\nframework accomplishes the multi-party authentication, which confirms its\napplicability for the real-time and collaborative cyber-physical system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.05756,regular,pre_llm,2021,6,"{'ai_likelihood': 7.28501213921441e-06, 'text': ""Lifting The Grey Curtain: A First Look at the Ecosystem of CULPRITWARE\n\n  Mobile apps are extensively involved in cyber-crimes. Some apps are malware\nwhich compromise users' devices, while some others may lead to privacy leakage.\nApart from them, there also exist apps which directly make profit from victims\nthrough deceiving, threatening or other criminal actions. We name these apps as\nCULPRITWARE. They have become emerging threats in recent years. However, the\ncharacteristics and the ecosystem of CULPRITWARE remain mysterious. This paper\ntakes the first step towards systematically studying CULPRITWARE and its\necosystem. Specifically, we first characterize CULPRITWARE by categorizing and\ncomparing them with benign apps and malware. The result shows that CULPRITWARE\nhave unique features, e.g., the usage of app generators (25.27%) deviates from\nthat of benign apps (5.08%) and malware (0.43%). Such a discrepancy can be used\nto distinguish CULPRITWARE from benign apps and malware. Then we understand the\nstructure of the ecosystem by revealing the four participating entities (i.e.,\ndeveloper, agent, operator and reaper) and the workflow. After that, we further\nreveal the characteristics of the ecosystem by studying the participating\nentities. Our investigation shows that the majority of CULPRITWARE (at least\n52.08%) are propagated through social media rather than the official app\nmarkets, and most CULPRITWARE (96%) indirectly rely on the covert fourth-party\npayment services to transfer the profits. Our findings shed light on the\necosystem, and can facilitate the community and law enforcement authorities to\nmitigate the threats. We will release the source code of our tools to engage\nthe community.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.02623,regular,pre_llm,2021,6,"{'ai_likelihood': 5.960464477539062e-07, 'text': ""The Closer You Look, The More You Learn: A Grey-box Approach to Protocol\n  State Machine Learning\n\n  In this paper, we propose a new approach to infer state machine models from\nprotocol implementations. Our method, STATEINSPECTOR, learns protocol states by\nusing novel program analyses to combine observations of run-time memory and\nI/O. It requires no access to source code and only lightweight execution\nmonitoring of the implementation under test. We demonstrate and evaluate\nSTATEINSPECTOR's effectiveness on numerous TLS and WPA/2 implementations. In\nthe process, we show STATEINSPECTOR enables deeper state discovery, increased\nlearning efficiency, and more insightful post-mortem analyses than existing\napproaches. Further to improved learning, our method led us to discover several\nconcerning deviations from the standards and a high impact vulnerability in a\nprominent Wi-Fi implementation.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.0194,regular,pre_llm,2021,6,"{'ai_likelihood': 2.7484363979763457e-06, 'text': 'THEMIS: A Decentralized Privacy-Preserving Ad Platform with Reporting\n  Integrity\n\n  Online advertising fuels the (seemingly) free internet. However, although\nusers can access most of the web services free of charge, they pay a heavy\ncoston their privacy. They are forced to trust third parties and\nintermediaries, who not only collect behavioral data but also absorb great\namounts of ad revenues. Consequently, more and more users opt out from\nadvertising by resorting to ad blockers, thus costing publishers millions of\ndollars in lost ad revenues. Albeit there are various privacy-preserving\nadvertising proposals (e.g.,Adnostic, Privad, Brave Ads) from both academia and\nindustry, they all rely on centralized management that users have to blindly\ntrust without being able to audit, while they also fail to guarantee the\nintegrity of the per-formance analytics they provide to advertisers.\n  In this paper, we design and deploy THEMIS, a novel, decentralized and\nprivacy-by-design ad platform that requires zero trust by users. THEMIS (i)\nprovides auditability to its participants, (ii) rewards users for viewing ads,\nand (iii) allows advertisers to verify the performance and billing reports of\ntheir ad campaigns. By leveraging smart contracts and zero-knowledge schemes,\nwe implement a prototype of THEMIS and early performance evaluation results\nshow that it can scale linearly on a multi sidechain setup while it supports\nmore than 51M users on a single-sidechain.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.00577,review,pre_llm,2021,6,"{'ai_likelihood': 1.0927518208821616e-06, 'text': ""How many FIDO protocols are needed? Surveying the design, security and\n  market perspectives\n\n  Unequivocally, a single man in possession of a strong password is not enough\nto solve the issue of security. Studies indicate that passwords have been\nsubjected to various attacks, regardless of the applied protection mechanisms\ndue to the human factor. The keystone for the adoption of more efficient\nauthentication methods by the different markets is the trade-off between\nsecurity and usability. To bridge the gap between user-friendly interfaces and\nadvanced security features, the Fast Identity Online (FIDO) alliance defined\nseveral authentication protocols. Although FIDO's biometric-based\nauthentication is not a novel concept, still daunts end users and developers,\nwhich may be a contributor factor obstructing FIDO's complete dominance of the\ndigital authentication market. This paper traces the evolution of FIDO\nprotocols, by identifying the technical characteristics and security\nrequirements of the FIDO protocols throughout the different versions while\nproviding a comprehensive study on the different markets (e.g., digital\nbanking, social networks, e-government, etc.), applicability, ease of use,\nextensibility and future security considerations. From the analysis, we\nconclude that there is currently no dominant version of a FIDO protocol and\nmore importantly, earlier FIDO protocols are still applicable to emerging\nvertical services.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.04951,review,pre_llm,2021,6,"{'ai_likelihood': 1.4238887363009983e-06, 'text': ""Information flow based defensive chain for data leakage detection and\n  prevention: a survey\n\n  Mobile and IoT applications have greatly enriched our daily life by providing\nconvenient and intelligent services. However, these smart applications have\nbeen a prime target of adversaries for stealing sensitive data. It poses a\ncrucial threat to users' identity security, financial security, or even life\nsecurity. Research communities and industries have proposed many Information\nFlow Control (IFC) techniques for data leakage detection and prevention,\nincluding secure modeling, type system, static analysis, dynamic analysis,\n\\textit{etc}. According to the application's development life cycle, although\nmost attacks are conducted during the application's execution phase, data\nleakage vulnerabilities have been introduced since the design phase. With a\nfocus on lifecycle protection, this survey reviews the recent representative\nworks adopted in different phases. We propose an information flow based\ndefensive chain, which provides a new framework to systematically understand\nvarious IFC techniques for data leakage detection and prevention in Mobile and\nIoT applications. In line with the phases of the application life cycle, each\nreviewed work is comprehensively studied in terms of technique, performance,\nand limitation. Research challenges and future directions are also pointed out\nby consideration of the integrity of the defensive chain.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.00217,regular,pre_llm,2021,6,"{'ai_likelihood': 3.311369154188368e-08, 'text': ""Toward a Secure Crowdsourced Location Tracking System\n\n  Low-energy Bluetooth devices have become ubiquitous and widely used for\ndifferent applications. Among these, Bluetooth trackers are becoming popular as\nthey allow users to track the location of their physical objects. To do so,\nBluetooth trackers are often built-in within other commercial products\nconnected to a larger crowdsourced tracking system. Such a system, however, can\npose a threat to the security and privacy of the users, for instance, by\nrevealing the location of a user's valuable object. In this paper, we introduce\na set of security properties and investigate the state of commercial\ncrowdsourced tracking systems, which present common design flaws that make them\ninsecure. Leveraging the results of our investigation, we propose a new design\nfor a secure crowdsourced tracking system (SECrow), which allows devices to\nleverage the benefits of the crowdsourced model without sacrificing security\nand privacy. Our preliminary evaluation shows that SECrow is a practical,\nsecure, and effective crowdsourced tracking solution\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2106.13926,regular,pre_llm,2021,6,"{'ai_likelihood': 9.602970547146267e-07, 'text': 'Cloak: Transitioning States on Legacy Blockchains Using Secure and\n  Publicly Verifiable Off-Chain Multi-Party Computation\n\n  In recent years, the confidentiality of smart contracts has become a\nfundamental requirement for practical applications. While many efforts have\nbeen made to develop architectural capabilities for enforcing confidential\nsmart contracts, a few works arise to extend confidential smart contracts to\nMulti-Party Computation (MPC), i.e., multiple parties jointly evaluate a\ntransaction off-chain and commit the outputs on-chain without revealing their\nsecret inputs/outputs to each other. However, existing solutions lack public\nverifiability and require O(n) transactions to enable negotiation or resist\nadversaries, thus suffering from inefficiency and compromised security. In this\npaper, we propose Cloak, a framework for enabling Multi-Party Transaction (MPT)\non existing blockchains. An MPT refers to transitioning blockchain states by an\npublicly verifiable off-chain MPC. We identify and handle the challenges of\nsecuring MPT by harmonizing TEE and blockchain. Consequently, Cloak secures the\noff-chain nondeterministic negotiation process (a party joins an MPT without\nknowing identities or the total number of parties until the MPT proposal\nsettles), achieves public verifiability (the public can validate that the MPT\ncorrectly handles the secret inputs/outputs from multiple parties and\nreads/writes states on-chain), and resists Byzantine adversaries. According to\nour proof, Cloak achieves better security with only 2 transactions, superior to\nprevious works that achieve compromised security at O(n) transactions cost. By\nevaluating examples and real-world MPTs, the gas cost of Cloak reduces by 32.4%\non average.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.14136,regular,pre_llm,2021,7,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""BIoTA Control-Aware Attack Analytics for Building Internet of Things\n\n  Modern building control systems adopt demand control heating, ventilation,\nand cooling (HVAC) for increased energy efficiency. The integration of the\nInternet of Things (IoT) in the building control system can determine real-time\ndemand, which has made the buildings smarter, reliable, and efficient. As\noccupants in a building are the main source of continuous heat and $CO_2$\ngeneration, estimating the accurate number of people in real-time using\nbuilding IoT (BIoT) system facilities is essential for optimal energy\nconsumption and occupants' comfort. However, the incorporation of less secured\nIoT sensor nodes and open communication network in the building control system\neventually increases the number of vulnerable points to be compromised.\nExploiting these vulnerabilities, attackers can manipulate the controller with\nfalse sensor measurements and disrupt the system's consistency. The attackers\nwith the knowledge of overall system topology and control logics can launch\nattacks without alarming the system. This paper proposes a building internet of\nthings analyzer (BIoTA)\nframework\\footnote{https://github.com/imtiazulhaque/research-implementations/tree/main/biota}\nthat assesses the smart building HVAC control system's security using formal\nattack modeling. We evaluate the proposed attack analyzer's effectiveness on\nthe commercial occupancy dataset (COD) and the KTH live-in lab dataset. To the\nbest of our knowledge, this is the first research attempt to formally model a\nBIoT-based HVAC control system and perform an attack analysis.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.05054,regular,pre_llm,2021,7,"{'ai_likelihood': 1.357661353217231e-06, 'text': ""BLINDTRUST: Oblivious Remote Attestation for Secure Service Function\n  Chains\n\n  With the rapidly evolving next-generation systems-of-systems, we face new\nsecurity, resilience, and operational assurance challenges. In the face of the\nincreasing attack landscape, it is necessary to cater to efficient mechanisms\nto verify software and device integrity to detect run-time modifications.\nTowards this direction, remote attestation is a promising defense mechanism\nthat allows a third party, the verifier, to ensure a remote device's (the\nprover's) integrity. However, many of the existing families of attestation\nsolutions have strong assumptions on the verifying entity's trustworthiness,\nthus not allowing for privacy preserving integrity correctness. Furthermore,\nthey suffer from scalability and efficiency issues. This paper presents a\nlightweight dynamic configuration integrity verification that enables inter and\nintra-device attestation without disclosing any configuration information and\ncan be applied on both resource-constrained edge devices and cloud services.\nOur goal is to enhance run-time software integrity and trustworthiness with a\nscalable solution eliminating the need for federated infrastructure trust.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.05411,review,pre_llm,2021,7,"{'ai_likelihood': 1.0000334845648871e-05, 'text': 'Weakened Random Oracle Models with Target Prefix\n\n  Weakened random oracle models (WROMs) are variants of the random oracle model\n(ROM). The WROMs have the random oracle and the additional oracle which breaks\nsome property of a hash function. Analyzing the security of cryptographic\nschemes in WROMs, we can specify the property of a hash function on which the\nsecurity of cryptographic schemes depends. Liskov (SAC 2006) proposed WROMs and\nlater Numayama et al. (PKC 2008) formalized them as CT-ROM, SPT-ROM, and\nFPT-ROM. In each model, there is the additional oracle to break collision\nresistance, second preimage resistance, preimage resistance respectively. Tan\nand Wong (ACISP 2012) proposed the generalized FPT-ROM (GFPT-ROM) which\nintended to capture the chosen prefix collision attack suggested by Stevens et\nal. (EUROCRYPT 2007). In this paper, in order to analyze the security of\ncryptographic schemes more precisely, we formalize GFPT-ROM and propose\nadditional three WROMs which capture the chosen prefix collision attack and its\nvariants. In particular, we focus on signature schemes such as RSA-FDH, its\nvariants, and DSA, in order to understand essential roles of WROMs in their\nsecurity proofs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.00347,review,pre_llm,2021,7,"{'ai_likelihood': 4.967053731282552e-07, 'text': ""Information Security Analysis in the Passenger-Autonomous Vehicle\n  Interaction\n\n  Autonomous vehicles (AV) are becoming a part of humans' everyday life. There\nare numerous pilot projects of driverless public buses; some car manufacturers\ndeliver their premium-level automobiles with advanced self-driving features.\nThus, assuring the security of a Passenger-Autonomous Vehicle interaction\narises as an important research topic, as along with opportunities, new\ncybersecurity risks and challenges occur that potentially may threaten\nPassenger's privacy and safety on the roads. This study proposes an approach of\nthe security requirements elicitation based on the developed threat model.\nThus, information security risk management helps to fulfil one of the\nprinciples needed to protect data privacy - information security. We\ndemonstrate the process of security requirements elicitation to mitigate\narising security risks. The findings of the paper are case-oriented and are\nbased on the literature review. They are applicable for AV system\nimplementation used by ride-hailing service providers that enable supervisory\nAV control.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.10571,regular,pre_llm,2021,7,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Always on Voting: A Framework for Repetitive Voting on the Blockchain\n\n  Elections repeat commonly after a fixed time interval, ranging from months to\nyears. This results in limitations on governance since elected candidates or\npolicies are difficult to remove before the next elections, if needed, and\nallowed by the corresponding law. Participants may decide (through a public\ndeliberation) to change their choices but have no opportunity to vote for these\nchoices before the next elections. Another issue is the peak-end effect, where\nthe judgment of voters is based on how they felt a short time before the\nelections. To address these issues, we propose Always on Voting (AoV) -- a\nrepetitive voting framework that allows participants to vote and change elected\ncandidates or policies without waiting for the next elections. Participants are\npermitted to privately change their vote at any point in time, while the effect\nof their change is manifested at the end of each epoch, whose duration is\nshorter than the time between two main elections. To thwart the problem of\npeak-end effect in epochs, the ends of epochs are randomized and made\nunpredictable, while preserved within soft bounds. These goals are achieved\nusing the synergy between a Bitcoin puzzle oracle, verifiable delay function,\nand smart contracts.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.09926,regular,pre_llm,2021,7,"{'ai_likelihood': 2.682209014892578e-06, 'text': 'Hygiea: A secure, smart, privacy-preserving and interoperable Blockchain\n  solution for the Covid-19 pandemic\n\n  In this article we present hygiea, an end-to-end blockchain-based solution\nfor the Covid-19 pandemic. hygiea has two main objectives. The first is to\nallow governments to issue Covid-19 related certificates to citizens that can\nbe verified by designated verifiers to ensure safer workplaces. The second is\nto provide the necessary tools to experts and decision makers to better\nunderstand the impact of the pandemic through statistical models built on top\nof the data collected by the platform. This work covers all steps of the\ncertificate issuance, verification and revocation cycles with well-defined\nroles for all stakeholders. We also propose a governance model that is\nimplemented via smart contracts ensuring security, transparency and\nauditability. Finally, we propose techniques for deriving statistical models\nthat can be used by decision makers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.14201,regular,pre_llm,2021,7,"{'ai_likelihood': 3.642506069607205e-07, 'text': ""A Study of Feasibility and Diversity of Web Audio Fingerprints\n\n  Prior measurement studies on browser fingerprinting have unfortunately\nlargely excluded Web Audio API-based fingerprinting in their analysis. We\naddress this issue by conducting the first systematic study of effectiveness of\nweb audio fingerprinting mechanisms. We focus on studying the feasibility and\ndiversity properties of web audio fingerprinting. Along with 3 known audio\nfingerprinting vectors, we designed and implemented 4 new audio fingerprint\nvectors that work by obtaining FFTs of waveforms generated via different\nmethods. Our study analyzed audio fingerprints from 2093 web users and presents\nnew insights into the nature of Web Audio fingerprints. First, we show that\naudio fingeprinting vectors, unlike other prior vectors, reveal an apparent\nfickleness with some users' browsers giving away differing fingerprints in\nrepeated attempts. However, we show that it is possible to devise a graph-based\nanalysis mechanism to collectively consider all the different fingerprints of\nusers and thus craft a stable fingerprinting mechanism. Our analysis also shows\nthat it is possible to do this in a timely fashion.\n  Next, we investigate the diversity of audio fingerprints and compare this\nwith prior techniques. Our results show that audio fingerprints are much less\ndiverse than other vectors with only 95 distinct fingerprints among 2093 users.\nAt the same time, further analysis shows that web audio fingerprinting can\npotentially bring considerable additive value (in terms of entropy) to existing\nfingerprinting mechanisms. We also show that our results contradict the current\nsecurity and privacy recommendations provided by W3C regarding audio\nfingerprinting. Overall, our systematic study allows browser developers to\ngauge the degree of privacy invasion presented by audio fingerprinting thus\nhelping them take a more informed stance when designing privacy protection\nfeatures in the future.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.0181,review,pre_llm,2021,7,"{'ai_likelihood': 2.3510720994737412e-06, 'text': 'Comparative Analysis of Impact of Cryptography Algorithms on Wireless\n  Sensor Networks\n\n  Cryptography techniques are essential for a robust and stable security design\nof a system to mitigate the risk of external attacks and thus improve its\nefficiency. Wireless Sensor Networks (WSNs) play a pivotal role in sensing,\nmonitoring, processing, and accumulating raw data to enhance the performance of\nthe actuators, micro-controllers, embedded architectures, IoT devices, and\ncomputing machines to which they are connected. With so much threat of\npotential adversaries, it is essential to scale up the security level of WSN\nwithout affecting its primary goal of seamless data collection and\ncommunication with relay devices. This paper intends to explore the past and\nongoing research activities in this domain. An extensive study of these\nalgorithms referred here, are studied and analyzed. Based on these findings\nthis paper will illustrate the best possible cryptography algorithms which will\nbe most suited to implement the security aspects of the WSN and protect it from\nany threat and reduce its vulnerabilities. This study will pave the way for\nfuture research on this topic since it will provide a comprehensive and\nholistic view of the subject.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.07297,regular,pre_llm,2021,7,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'Shard Scheduler: object placement and migration in sharded account-based\n  blockchains\n\n  We propose Shard Scheduler, a system for object placement and migration in\naccount-based sharded blockchains. Our system calculates optimal placement and\ndecides of object migrations across shards and supports complex multi-account\ntransactions caused by smart contracts. Placement and migration decisions made\nby Shard Scheduler are fully deterministic, verifiable, and can be made part of\nthe consensus protocol. Shard Scheduler reduces the number of costly\ncross-shard transactions, ensures balanced load distribution and maximizes the\nnumber of processed transactions for the blockchain as a whole. It leverages a\nnovel incentive model motivating miners to maximize the global throughput of\nthe entire blockchain rather than the throughput of a specific shard. Shard\nScheduler reduces the number of costly cross-shard transactions by half in our\nsimulations, ensuring equal load and increasing the throughput 3 fold when\nusing 60 shards. We also implement and evaluate Shard Scheduler on Chainspace,\nmore than doubling its throughput and reducing user-perceived latency by 70%\nwhen using 10 shards.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.00078,regular,pre_llm,2021,7,"{'ai_likelihood': 5.298190646701389e-07, 'text': 'Technical Report for HW2VEC -- A Graph Learning Tool for Automating\n  Hardware Security\n\n  In this technical report, we present HW2VEC [11], an open-source graph\nlearning tool for hardware security, and its implementation details (Figure 1).\nHW2VEC provides toolboxes for graph representation extraction in the form of\nData Flow Graphs (DFGs) or Abstract Syntax Trees (ASTs) from hardware designs\nat RTL and GLN levels. Besides, HW2VEC also offers graph learning tools for\nrepresenting hardware designs in vectors that preserve both structural features\nand behavioral features. To the best of our knowledge, HW2VEC is the first\nopen-source research tool that supports applying graph learning methods to\nhardware designs in different abstraction levels for hardware security. We\norganize the remainder of this technical report as follows: Section 2\nintroduces the architecture of HW2VEC; Section 3 gives information about the\nuse-case implementations; Section 4 provides the experimental results and\ndemonstrates the performance of HW2VEC for two hardware security applications:\nHT detection and IP piracy detection; finally, Section 5 will conclude this\nreport.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.0491,review,pre_llm,2021,7,"{'ai_likelihood': 4.967053731282553e-06, 'text': ""Cyber-Security Challenges in Aviation Industry: A Review of Current and\n  Future Trends\n\n  The integration of Information and Communication Technology (ICT) tools into\nmechanical devices found in aviation industry has raised security concerns. The\nmore integrated the system, the more vulnerable due to the inherent\nvulnerabilities found in ICT tools and software that drives the system. The\nsecurity concerns have become more heightened as the concept of\nelectronic-enabled aircraft and smart airports get refined and implemented\nunderway. In line with the above, this paper undertakes a review of\ncyber-security incidence in the aviation sector over the last 20 years. The\nessence is to understand the common threat actors, their motivations, the type\nof attacks, aviation infrastructure that is commonly attacked and then match\nthese so as to provide insight on the current state of the cyber-security in\nthe aviation sector. The review showed that the industry's threats come mainly\nfrom Advance Persistent Threat (APT) groups that work in collaboration with\nsome state actors to steal intellectual property and intelligence, in order to\nadvance their domestic aerospace capabilities as well as possibly monitor,\ninfiltrate and subvert other nations' capabilities. The segment of the aviation\nindustry commonly attacked is the Information Technology infrastructure, and\nthe prominent type of attacks is malicious hacking activities that aim at\ngaining unauthorised access using known malicious password cracking techniques\nsuch as Brute force attacks, Dictionary attacks and so on. The review further\nanalysed the different attack surfaces that exist in aviation industry, threat\ndynamics, and use these dynamics to predict future trends of cyberattacks in\nthe industry. The aim is to provide information for the cybersecurity\nprofessionals and aviation stakeholders for proactive actions in protecting\nthese critical infrastructures against cyberincidence for an optimal customer\nservice oriented industry.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.00679,regular,pre_llm,2021,7,"{'ai_likelihood': 4.172325134277344e-06, 'text': ""Efficient Attribute-Based Smart Contract Access Control Enhanced by\n  Reputation Assessment\n\n  Blockchain's immutability can resist unauthorized changes of ledgers, thus it\ncan be used as a trust enhancement mechanism to a shared system. Indeed,\nblockchain has been considered to solve the security and privacy issues of the\nInternet of Things (IoT). In this regard, most researches currently focus on\nthe realization of various access control models and architectures, and are\nworking towards making full use of the blockchain to secure IoT systems. It is\nworth noting that there has been an increasingly heavy pressure on the\nblockchain storage caused by dealing with massive IoT data and handling\nmalicious access behaviors in the system, and not many countermeasures have\nbeen seen to curb the increase. However, this problem has not been paid enough\nattention. In this paper, we implement an attribute-based access control scheme\nusing smart contracts in Quorum blockchain. It provides basic access control\nfunctions and conserves storage by reducing the number of smart contracts. In\naddition, a reputation-based technique is introduced to cope with malicious\nbehaviors. Certain illegal transactions can be blocked by the credit-assessment\nalgorithm, which deters possibly malicious nodes and gives more chance to\nwell-behaved nodes. The feasibility of our proposed scheme is demonstrated by\ndoing experiment on a testbed and conducting a case study. Finally, the system\nperformance is assessed based on experimental measurement.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.11537,regular,pre_llm,2021,7,"{'ai_likelihood': 5.529986487494575e-06, 'text': 'Secure Links: Secure-by-Design Communications in IEC 61499 Industrial\n  Control Applications\n\n  Increasing automation and external connectivity in industrial control systems\n(ICS) demand a greater emphasis on software-level communication security. In\nthis article, we propose a secure-by-design development method for building ICS\napplications, where requirements from security standards like ISA/IEC 62443 are\nfulfilled by design-time abstractions called secure links. Proposed as an\nextension to the IEC 61499 development standard, secure links incorporate both\nlight-weight and traditional security mechanisms into applications with\nnegligible effort. Applications containing secure links can be automatically\ncompiled into fully IEC 61499-compliant software. Experimental results show\nsecure links significantly reduce design and code complexity and improve\napplication maintainability and requirements traceability.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.08279,regular,pre_llm,2021,7,"{'ai_likelihood': 2.7749273512098527e-05, 'text': ""Anonymous Blockchain-based System for Consortium\n\n  Blockchain brings various advantages to online transactions. However, the\ntotal transparency of these transactions may leakage users' sensitive\ninformation. Requirements on both cooperation and anonymity for\ncompanies/organizations become necessary. In this paper, we propose a\nMulti-center Anonymous Blockchain-based (MAB) system, with joint management for\nthe consortium and privacy protection for the participants. To achieve that, we\nformalize the syntax used by the MAB system and present a general construction\nbased on a modular design. By applying cryptographic primitives to each module,\nwe instantiate our scheme with anonymity and decentralization. Furthermore, we\ncarry out a comprehensive formal analysis of the proposed solution. The results\ndemonstrate our constructed scheme is secure and efficient.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.10232,regular,pre_llm,2021,7,"{'ai_likelihood': 2.1192762586805556e-06, 'text': 'A low-overhead approach for self-sovereign identity in IoT\n\n  We present a low-overhead mechanism for self-sovereign identification and\ncommunication of IoT agents in constrained networks. Our main contribution is\nto enable native use of Decentralized Identifiers (DIDs) and DID-based secure\ncommunication on constrained networks, whereas previous works either did not\nconsider the issue or relied on proxy-based architectures. We propose a new\nextension to DIDs along with a more concise serialization method for DID\nmetadata. Moreover, in order to reduce the security overhead over transmitted\nmessages, we adopted a binary message envelope. We implemented these proposals\nwithin the context of Swarm Computing, an approach for decentralized IoT.\nResults showed that our proposal reduces the size of identity metadata in\nalmost four times and security overhead up to five times. We observed that both\ntechniques are required to enable operation on constrained networks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.02362,regular,pre_llm,2021,7,"{'ai_likelihood': 7.384353213840061e-06, 'text': 'A Low-Cost Machine Learning Based Network Intrusion Detection System\n  with Data Privacy Preservation\n\n  Network intrusion is a well-studied area of cyber security. Current machine\nlearning-based network intrusion detection systems (NIDSs) monitor network data\nand the patterns within those data but at the cost of presenting significant\nissues in terms of privacy violations which may threaten end-user privacy.\nTherefore, to mitigate risk and preserve a balance between security and\nprivacy, it is imperative to protect user privacy with respect to intrusion\ndata. Moreover, cost is a driver of a machine learning-based NIDS because such\nsystems are increasingly being deployed on resource-limited edge devices. To\nsolve these issues, in this paper we propose a NIDS called PCC-LSM-NIDS that is\ncomposed of a Pearson Correlation Coefficient (PCC) based feature selection\nalgorithm and a Least Square Method (LSM) based privacy-preserving algorithm to\nachieve low-cost intrusion detection while providing privacy preservation for\nsensitive data. The proposed PCC-LSM-NIDS is tested on the benchmark intrusion\ndatabase UNSW-NB15, using five popular classifiers. The experimental results\nshow that the proposed PCC-LSM-NIDS offers advantages in terms of less\ncomputational time, while offering an appropriate degree of privacy protection.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.11202,regular,pre_llm,2021,7,"{'ai_likelihood': 3.046459621853299e-06, 'text': 'A Characterisation of Smart Grid DoS Attacks\n\n  Traditional power grids are evolving to keep pace with the demands of the\nmodern age. Smart grids contain integrated IT systems for better management and\nefficiency, but in doing so, also inherit a plethora of cyber-security threats\nand vulnerabilities. Denial-of-Service (DoS) is one such threat. At the same\ntime, the smart grid has particular characteristics (e.g. minimal delay\ntolerance), which can influence the nature of threats and so require special\nconsideration. In this paper, we identify a set of possible smart grid-specific\nDoS scenarios based on current research, and analyse them in the context of the\ngrid components they target. Based on this, we propose a novel target-based\nclassification scheme and further characterise each scenario by qualitatively\nexploring it in the context of the underlying grid infrastructure. This\nculminates in a smart grid-centric analysis of the threat to reveal the nature\nof DoS in this environment.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.08094,regular,pre_llm,2021,7,"{'ai_likelihood': 7.947285970052084e-07, 'text': ""LAORAM: A Look Ahead ORAM Architecture for Training Large Embedding\n  Tables\n\n  Data confidentiality is becoming a significant concern, especially in the\ncloud computing era. Memory access patterns have been demonstrated to leak\ncritical information such as security keys and a program's spatial and temporal\ninformation. This information leak poses an even more significant privacy\nchallenge in machine learning models with embedding tables. Embedding tables\nare routinely used to learn categorical features from training data. Even\nknowing the locations of the embedding table entries accessed, not the data\nwithin the embedding table, will compromise categorical input data to the\nmodel. Embedding entries are privacy-sensitive since they disclose valuable\nproperties about the user. Oblivious RAM (ORAM), and its enhanced variants such\nas PathORAM have emerged as viable solutions to hide leakage from memory access\nstreams.\n  In this work, we present LAORAM, an ORAM framework explicitly designed to\nprotect user privacy during embedding table training. LAORAM exploits the\nunique property of training, the training samples used in the future are known\nbeforehand. LAORAM preprocesses the training samples to identify the memory\nblocks which are accessed together in the near future. The system tries to\nassign these blocks to as few paths as possible within the PathORAM\ninfrastructure.\n  LAORAM does this operation by combining multiple blocks accessed together as\nsuperblocks. To further increase performance, LAORAM uses a fat-tree structure\nfor PathORAM reducing the number of background evictions required, which\nimproves the stash usage. We have evaluated LAORAM using both a recommendation\nmodel (DLRM) and a NLP model (XLM-R) embedding table configurations. LAORAM\nperforms 5 times faster than PathORAM on a recommendation dataset (Kaggle) and\n5.4x faster on a NLP dataset (XNLI), while guaranteeing the same security\nguarantees as the original PathORAM.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.10139,review,pre_llm,2021,7,"{'ai_likelihood': 7.28501213921441e-06, 'text': 'Generative Models for Security: Attacks, Defenses, and Opportunities\n\n  Generative models learn the distribution of data from a sample dataset and\ncan then generate new data instances. Recent advances in deep learning has\nbrought forth improvements in generative model architectures, and some\nstate-of-the-art models can (in some cases) produce outputs realistic enough to\nfool humans.\n  We survey recent research at the intersection of security and privacy and\ngenerative models. In particular, we discuss the use of generative models in\nadversarial machine learning, in helping automate or enhance existing attacks,\nand as building blocks for defenses in contexts such as intrusion detection,\nbiometrics spoofing, and malware obfuscation. We also describe the use of\ngenerative models in diverse applications such as fairness in machine learning,\nprivacy-preserving data synthesis, and steganography. Finally, we discuss new\nthreats due to generative models: the creation of synthetic media such as\ndeepfakes that can be used for disinformation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2107.09113,regular,pre_llm,2021,7,"{'ai_likelihood': 6.556510925292969e-06, 'text': 'The approach with the Data Protection and Privacy Relationships Model\n  (DAPPREMO)\n\n  We describe the Data Protection and Privacy Relationships Model (DAPPREMO),\nwhich is based on the set theory, considering that both the data protection and\nprivacy regulation and Ethics principles in those domains belong to a set.\nDAPPREMO is a new and innovative solution to adopt a model in any data\nprotection and privacy activities. We theorise that DAPPREMO is an innovative\napproach to have a broad overview of all the objects related to a specific case\nor more cases from data protection and privacy perspective. We describe\nDAPPREMO as a solution for a multidisciplinary approach to address any data\nprotection and privacy issue.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.10344,regular,pre_llm,2021,8,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Issuing Green Bonds on the Algorand Blockchain\n\n  Green bonds have been shown to be effective tool for sustainability however\nmarket growth is impeded by high issuance and transaction costs. The lack of\nappropriate standardisation and frameworks raise fear of greenwashing.\n  In this paper, we propose a platform for green bond issuance on the Algorand\nblockchain. It offers ""Green Bonds as a Service"", increasing accessibility\nthrough automation. The solution has minimal associated costs and supports\nfractional asset ownership, both of which will help adoption especially in\ndeveloping countries. A financial regulator must preapprove an investor and can\nfreeze assets in the case of financial irregularities. Green bonds can be\nbought directly from an issuer or in the secondary market. We also introduce a\nnovel mechanism whereby an issuer can upload proof of impact reports. A green\nverifier uses these to submit a green rating; poor green ratings result in\nreputational damage and economic penalties.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.08581,regular,pre_llm,2021,8,"{'ai_likelihood': 9.602970547146267e-07, 'text': ""F-PKI: Enabling Innovation and Trust Flexibility in the HTTPS Public-Key\n  Infrastructure\n\n  We present F-PKI, an enhancement to the HTTPS public-key infrastructure (or\nweb PKI) that gives trust flexibility to both clients and domain owners, and\nenables certification authorities (CAs) to enforce stronger security measures.\nIn today's web PKI, all CAs are equally trusted, and security is defined by the\nweakest link. We address this problem by introducing trust flexibility in two\ndimensions: with F-PKI, each domain owner can define a domain policy\n(specifying, for example, which CAs are authorized to issue certificates for\ntheir domain name) and each client can set or choose a validation policy based\non trust levels. F-PKI thus supports a property that is sorely needed in\ntoday's Internet: trust heterogeneity. Different parties can express different\ntrust preferences while still being able to verify all certificates. In\ncontrast, today's web PKI only allows clients to fully distrust\nsuspicious/misbehaving CAs, which is likely to cause collateral damage in the\nform of legitimate certificates being rejected. Our contribution is to present\na system that is backward compatible, provides sensible security properties to\nboth clients and domain owners, ensures the verifiability of all certificates,\nand prevents downgrade attacks. Furthermore, F-PKI provides a ground for\ninnovation, as it gives CAs an incentive to deploy new security measures to\nattract more customers, without having these measures undercut by vulnerable\nCAs.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.05582,review,pre_llm,2021,8,"{'ai_likelihood': 1.7881393432617188e-06, 'text': 'Digital Forensics Domain and Metamodeling Development Approaches\n\n  Metamodeling is used as a general technique for integrating and defining\nmodels from different domains. This technique can be used in diverse\napplication domains, especially for purposes of standardization. Also, this\nprocess mainly has a focus on the identification of general concepts that exist\nin various problem domain and their relations and to solve complexity,\ninteroperability, and heterogeneity aspects of different domains. Several\ndiverse metamodeling development approaches have been proposed in the\nliterature to develop metamodels. Each metamodeling development process has\nsome advantages and disadvantages too. Therefore, the objective of this paper\nis to provide a comprehensive review of existing metamodeling development\napproaches and conduct a comparative study among them-eventually selecting the\nbest approach for metamodel development in the perspective of digital\nforensics.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.12079,regular,pre_llm,2021,8,"{'ai_likelihood': 2.682209014892578e-06, 'text': 'Dimming Down LED: An Open-source Threshold Implementation on Light\n  Encryption Device (LED) Block Cipher\n\n  Lightweight block ciphers have been widely used in applications such as RFID\ntags, IoTs, and network sensors. Among them, with comparable parameters, the\nLight Encryption Device (LED) block cipher achieves the smallest area. However,\nimplementation of encryption algorithms manifest side-channel leakage,\ntherefore, it is crucial to protect their design against side-channel analyses.\nIn this paper, we present a threshold implementation of the LED cipher which\nhas 64-bit data input and 128-bit key. The presented design splits secret\ninformation among multiple shares to achieve a higher security level. We\ndemonstrate that our implementation can protect against first-order power\nside-channel attacks. As a cost, the design area is almost doubled and the\nmaximum operating frequency is degraded by 30%. To make our design verifiable,\nwe have also open-sourced our design online.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.10251,regular,pre_llm,2021,8,"{'ai_likelihood': 2.1523899502224394e-06, 'text': ""Kryptonite: An Adversarial Attack Using Regional Focus\n\n  With the Rise of Adversarial Machine Learning and increasingly robust\nadversarial attacks, the security of applications utilizing the power of\nMachine Learning has been questioned. Over the past few years, applications of\nDeep Learning using Deep Neural Networks(DNN) in several fields including\nMedical Diagnosis, Security Systems, Virtual Assistants, etc. have become\nextremely commonplace, and hence become more exposed and susceptible to attack.\nIn this paper, we present a novel study analyzing the weaknesses in the\nsecurity of deep learning systems. We propose 'Kryptonite', an adversarial\nattack on images. We explicitly extract the Region of Interest (RoI) for the\nimages and use it to add imperceptible adversarial perturbations to images to\nfool the DNN. We test our attack on several DNN's and compare our results with\nstate of the art adversarial attacks like Fast Gradient Sign Method (FGSM),\nDeepFool (DF), Momentum Iterative Fast Gradient Sign Method (MIFGSM), and\nProjected Gradient Descent (PGD). The results obtained by us cause a maximum\ndrop in network accuracy while yielding minimum possible perturbation and in\nconsiderably less amount of time per sample. We thoroughly evaluate our attack\nagainst three adversarial defence techniques and the promising results showcase\nthe efficacy of our attack.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.09508,review,pre_llm,2021,8,"{'ai_likelihood': 8.940696716308594e-07, 'text': 'Data Security and Privacy in Cloud Computing: Concepts and Emerging\n  Trends\n\n  Millions of users across the world leverages data processing and sharing\nbenefits from cloud environment. Data security and privacy are inevitable\nrequirement of cloud environment. Massive usage and sharing of data among users\nopens door to security loopholes. This paper envisages a discussion of cloud\nenvironment, its utilities, challenges, and emerging research trends confined\nto secure processing and sharing of data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.11206,regular,pre_llm,2021,8,"{'ai_likelihood': 4.404120975070529e-06, 'text': 'Towards Dynamic Threat Modelling in 5G Core Networks Based on MITRE\n  ATT&CK\n\n  This article discusses how the gap between early 5G network threat\nassessments and an adversarial Tactics, Techniques, Procedures (TTPs) knowledge\nbase for future use in the MITRE ATT&CK threat modelling framework can be\nbridged. We identify knowledge gaps in the existing framework for key 5G\ntechnology enablers such as SDN, NFV, and 5G specific signalling protocols of\nthe core network. We adopt a pre-emptive approach to identifying adversarial\ntechniques which can be used to launch attacks on the 5G core network (5GCN)\nand map these to its components. Using relevant 5G threat assessments along\nwith industry reports, we study how the domain specific techniques can be\nemployed by APTs in multi-stage attack scenarios based on historic\ntelecommunication network attacks and motivation of APT groups. We emulate this\nmapping in a pre-emptive fashion to facilitate a rigorous cyber risk\nassessment, support intrusion detection, and design defences based on common\nAPT TTPs in a 5GCN.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.11445,regular,pre_llm,2021,8,"{'ai_likelihood': 1.655684577094184e-06, 'text': 'Group Authentication for Drone Swarms\n\n  In parallel with the advances of aerial networks, the use of drones is\nquickly included in daily activities. According to the characteristics of the\noperations to be carried out using the drones, the need for simultaneous use of\none or more drones has arisen. The use of a drone swarm is preferred rather\nthan the use of a single drone to complete activities such as secure crowd\nmonitoring systems, cargo delivery.\n  Due to the limited airtime of the drones, new members may be included in the\nswarm, or there may be a unification of two or more drone swarms when needed.\nAuthentication of the new drone that will take its place in the drone swarm and\nthe rapid mutual-verification of two different swarms of drones are some of the\nsecurity issues in the swarm structures. In this study, group\nauthentication-based solutions have been put forward to solve the identified\nsecurity issues. The proposed methods and 5G new radio (NR) authentication\nmethods were compared in terms of time and a significant time difference was\nobtained. According to the 5G NR standard, it takes 22 ms for a user equipment\n(UE) to be verified by unified data management (UDM), while in the proposed\nmethod, this time varies according to the threshold value of the polynomial\nused and it is substantially lower than 22 ms for most threshold values.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.04575,regular,pre_llm,2021,8,"{'ai_likelihood': 8.377763960096572e-06, 'text': ""One Glitch to Rule Them All: Fault Injection Attacks Against AMD's\n  Secure Encrypted Virtualization\n\n  AMD Secure Encrypted Virtualization (SEV) offers protection mechanisms for\nvirtual machines in untrusted environments through memory and register\nencryption. To separate security-sensitive operations from software executing\non the main x86 cores, SEV leverages the AMD Secure Processor (AMD-SP). This\npaper introduces a new approach to attack SEV-protected virtual machines (VMs)\nby targeting the AMD-SP. We present a voltage glitching attack that allows an\nattacker to execute custom payloads on the AMD-SPs of all microarchitectures\nthat support SEV currently on the market (Zen 1, Zen 2, and Zen 3). The\npresented methods allow us to deploy a custom SEV firmware on the AMD-SP, which\nenables an adversary to decrypt a VM's memory. Furthermore, using our approach,\nwe can extract endorsement keys of SEV-enabled CPUs, which allows us to fake\nattestation reports or to pose as a valid target for VM migration without\nrequiring physical access to the target host. Moreover, we reverse-engineered\nthe Versioned Chip Endorsement Key (VCEK) mechanism introduced with SEV Secure\nNested Paging (SEV-SNP). The VCEK binds the endorsement keys to the firmware\nversion of TCB components relevant for SEV. Building on the ability to extract\nthe endorsement keys, we show how to derive valid VCEKs for arbitrary firmware\nversions. With our findings, we prove that SEV cannot adequately protect\nconfidential data in cloud environments from insider attackers, such as rogue\nadministrators, on currently available CPUs.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.09539,regular,pre_llm,2021,8,"{'ai_likelihood': 3.642506069607205e-06, 'text': 'SAI-BA-IoMT: Secure AI-Based Blockchain-Assisted Internet of Medical\n  Things Tool to Moderate the Outbreak of COVID-19 Crisis\n\n  Recently, an infectious disease, coronavirus disease 2019 (COVID-19), has\nbeen reported in Wuhan, China, and subsequently spread worldwide within a\ncouple of months. On May 16, 2020, the COVID-19 pandemic has affected several\ncountries in the world. In this article, we present how the amalgamation of\nblockchain, cryptography, internet of medical things (IoMT), and artificial\nintelligence (AI) technologies can address such an issue in the event of the\nCOVID-19 pandemic. Further, we propose a secure AI-based blockchain-assisted\nIoMT (SAI-BA-IoMT) model for the healthcare system in the COVID-19 crisis. The\npaper also examines the post-corona crisis that the world could be experienced\nafter the pandemic. Additionally, we exhibit the potential applications of the\nproposed model to resolve the difficulties originated from coronavirus.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.10071,regular,pre_llm,2021,8,"{'ai_likelihood': 1.447068320380317e-05, 'text': 'Elysium: Context-Aware Bytecode-Level Patching to Automatically Heal\n  Vulnerable Smart Contracts\n\n  Fixing bugs is easiest by patching source code. However, source code is not\nalways available: only 0.3% of the ~49M smart contracts that are currently\ndeployed on Ethereum have their source code publicly available. Moreover, since\ncontracts may call functions from other contracts, security flaws in\nclosed-source contracts may affect open-source contracts as well. However,\ncurrent state-of-the-art approaches that operate on closed-source contracts\n(i.e., EVM bytecode), such as EVMPatch and SmartShield, make use of purely\nhard-coded templates that leverage fix patching patterns. As a result, they\ncannot dynamically adapt to the bytecode that is being patched, which severely\nlimits their flexibility and scalability. For instance, when patching integer\noverflows using hard-coded templates, a particular patch template needs to be\nemployed as the bounds to be checked are different for each integer size. In\nthis paper, we propose Elysium, a scalable approach towards automatic smart\ncontract repair at the bytecode level. Elysium combines template-based and\nsemantic-based patching by inferring context information from bytecode. Elysium\nis currently able to patch 7 different types of vulnerabilities in smart\ncontracts automatically and can easily be extended with new templates and new\nbug-finding tools. We evaluate its effectiveness and correctness using 3\ndifferent datasets by replaying more than 500K transactions on patched\ncontracts. We find that Elysium outperforms existing tools by patching at least\n30% more contracts correctly. Finally, we also compare the overhead of Elysium\nin terms of deployment and transaction cost. In comparison to other tools, we\nfind that generally Elysium minimizes the runtime cost (i.e., transaction cost)\nup to a factor of 1.7, for only a marginally higher deployment cost, where\ndeployment cost is a one-time cost as compared to the runtime cost.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.08471,regular,pre_llm,2021,8,"{'ai_likelihood': 6.887647840711806e-06, 'text': 'Decentralized Policy Information Points for Multi-Domain Environments\n\n  Access control models have been developed to control authorized access to\nsensitive resources. This control of access is important as there is now a need\nfor collaborative resource sharing between multiple organizations over open\nenvironments like the internet. Although there are multiple access control\nmodels that are being widely used, these models are providing access control\nwithin a closed environment i.e. within the organization using it. These models\nhave restricted capabilities in providing access control in open environments.\nAttribute-Based Access Control (ABAC) has emerged as a powerful access control\nmodel to bring fine-grained authorization to organizations that possess\nsensitive data and resources and want to collaborate over open environments. In\nan ABAC system, access to resources that an organization possess can be\ncontrolled by applying policies on attributes of the users. These policies are\nconditions that need to be satisfied by the requester in order to gain access\nto the resource. In this paper, we provide an introduction to ABAC and by\ncarrying forward the architecture of ABAC, we propose a Decentralized Policy\nInformation Point (PIP) model. Our model proposes the decentralization of PIP,\nwhich is an entity of the ABAC model that allows the storage and query of user\nattributes and enforces fine-grained access control for controlling the access\nof sensitive resources over multiple domains. Our model makes use of the\nconcept of a cryptographic primitive called Attribute-Based Signature (ABS) to\nkeep the identities of the users involved, private. Our model can be used for\ncollaborative resource sharing over the internet. The evaluation of our model\nis also discussed to reflect the application of the proposed decentralized PIP\nmodel.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.09118,regular,pre_llm,2021,8,"{'ai_likelihood': 2.7914841969807945e-05, 'text': 'CybORG: A Gym for the Development of Autonomous Cyber Agents\n\n  Autonomous Cyber Operations (ACO) involves the development of blue team\n(defender) and red team (attacker) decision-making agents in adversarial\nscenarios. To support the application of machine learning algorithms to solve\nthis problem, and to encourage researchers in this field to attend to problems\nin the ACO setting, we introduce CybORG, a work-in-progress gym for ACO\nresearch. CybORG features a simulation and emulation environment with a common\ninterface to facilitate the rapid training of autonomous agents that can then\nbe tested on real-world systems. Initial testing demonstrates the feasibility\nof this approach.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.04996,review,pre_llm,2021,8,"{'ai_likelihood': 4.6690305074055995e-06, 'text': 'Cybersecurity Incident Response in Organisations: A Meta-level Framework\n  for Scenario-based Training\n\n  Cybersecurity incident response teams mitigate the impact of adverse\ncyber-related events in organisations. Field studies of IR teams suggest that\nat present the process of IR is under-developed with a focus on the\ntechnological dimension with little consideration of practice capability. To\naddress this gap, we develop a scenario-based training approach to assist\norganisations to overcome socio-technical barriers to incident response. The\ntraining approach is informed by a comprehensive list of socio-technical\nbarriers compiled from a comprehensive review of the literature. Our primary\ncontribution is a novel meta-level framework to generate scenarios specifically\ntargeting socio-technical issues. To demonstrate the utility of the framework,\na proof-of-concept scenario is presented.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.06082,regular,pre_llm,2021,8,"{'ai_likelihood': 4.2054388258192275e-06, 'text': 'Asteria: Deep Learning-based AST-Encoding for Cross-platform Binary Code\n  Similarity Detection\n\n  Binary code similarity detection is a fundamental technique for many security\napplications such as vulnerability search, patch analysis, and malware\ndetection. There is an increasing need to detect similar code for vulnerability\nsearch across architectures with the increase of critical vulnerabilities in\nIoT devices. The variety of IoT hardware architectures and software platforms\nrequires to capture semantic equivalence of code fragments in the similarity\ndetection. However, existing approaches are insufficient in capturing the\nsemantic similarity. We notice that the abstract syntax tree (AST) of a\nfunction contains rich semantic information. Inspired by successful\napplications of natural language processing technologies in sentence semantic\nunderstanding, we propose a deep learning-based AST-encoding method, named\nASTERIA, to measure the semantic equivalence of functions in different\nplatforms. Our method leverages the Tree-LSTM network to learn the semantic\nrepresentation of a function from its AST. Then the similarity detection can be\nconducted efficiently and accurately by measuring the similarity between two\nrepresentation vectors. We have implemented an open-source prototype of\nASTERIA. The Tree-LSTM model is trained on a dataset with 1,022,616 function\npairs and evaluated on a dataset with 95,078 function pairs. Evaluation results\nshow that our method outperforms the AST-based tool Diaphora and\nthe-state-of-art method Gemini by large margins with respect to the binary\nsimilarity detection. And our method is several orders of magnitude faster than\nDiaphora and Gemini for the similarity calculation. In the application of\nvulnerability search, our tool successfully identified 75 vulnerable functions\nin 5,979 IoT firmware images.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.09065,review,pre_llm,2021,8,"{'ai_likelihood': 7.516807980007596e-06, 'text': 'Regulating Ownership Verification for Deep Neural Networks: Scenarios,\n  Protocols, and Prospects\n\n  With the broad application of deep neural networks, the necessity of\nprotecting them as intellectual properties has become evident. Numerous\nwatermarking schemes have been proposed to identify the owner of a deep neural\nnetwork and verify the ownership. However, most of them focused on the\nwatermark embedding rather than the protocol for provable verification. To\nbridge the gap between those proposals and real-world demands, we study the\ndeep learning model intellectual property protection in three scenarios: the\nownership proof, the federated learning, and the intellectual property\ntransfer. We present three protocols respectively. These protocols raise\nseveral new requirements for the bottom-level watermarking schemes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.07076,regular,pre_llm,2021,8,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'My Fuzzer Beats Them All! Developing a Framework for Fair Evaluation and\n  Comparison of Fuzzers\n\n  Fuzzing has become one of the most popular techniques to identify bugs in\nsoftware. To improve the fuzzing process, a plethora of techniques have\nrecently appeared in academic literature. However, evaluating and comparing\nthese techniques is challenging as fuzzers depend on randomness when generating\ntest inputs. Commonly, existing evaluations only partially follow best\npractices for fuzzing evaluations. We argue that the reason for this are\ntwofold. First, it is unclear if the proposed guidelines are necessary due to\nthe lack of comprehensive empirical data in the case of fuzz testing. Second,\nthere does not yet exist a framework that integrates statistical evaluation\ntechniques to enable fair comparison of fuzzers. To address these limitations,\nwe introduce a novel fuzzing evaluation framework called SENF (Statistical\nEvaluatioN of Fuzzers). We demonstrate the practical applicability of our\nframework by utilizing the most wide-spread fuzzer AFL as our baseline fuzzer\nand exploring the impact of different evaluation parameters (e.g., the number\nof repetitions or run-time), compilers, seeds, and fuzzing strategies. Using\nour evaluation framework, we show that supposedly small changes of the\nparameters can have a major influence on the measured performance of a fuzzer.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.13307,review,pre_llm,2021,8,"{'ai_likelihood': 2.5166405571831597e-06, 'text': 'Security For System-On-Chip (SoC) Using Neural Networks\n\n  With the growth of embedded systems, VLSI design phases complexity and cost\nfactors across the globe and has become outsourced. Modern computing ICs are\nnow using system-on-chip for better on-chip processing and communication. In\nthe era of Internet-of-Things (IoT), security has become one of the most\ncrucial parts of a System-on-Chip (SoC). Malicious activities generate abnormal\ntraffic patterns which affect the operation of the system and its performance\nwhich cannot be afforded in a computation hungry world. SoCs have a chance of\nfunctionality failure, leakage of information, even a denial of services (DoS),\nHardware Trojan Horses and many more factors which are categorized as security\nthreats. In this paper, we aim to compare and describe different types of\nmalicious security threats and how neural networks can be used to prevent those\nattacks. Spiking Neural Networks (SNN), Runtime Neural Architecture (RTNA) are\nsome of the neural networks which prevent SoCs from attacks. Finally, the\ndevelopment trends in SoC security are also highlighted.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.13333,regular,pre_llm,2021,8,"{'ai_likelihood': 6.953875223795574e-07, 'text': 'A Novel Approach to Detect Phishing Attacks using Binary Visualisation\n  and Machine Learning\n\n  Protecting and preventing sensitive data from being used inappropriately has\nbecome a challenging task. Even a small mistake in securing data can be\nexploited by phishing attacks to release private information such as passwords\nor financial information to a malicious actor. Phishing has now proven so\nsuccessful; it is the number one attack vector. Many approaches have been\nproposed to protect against this type of cyber-attack, from additional staff\ntraining, enriched spam filters to large collaborative databases of known\nthreats such as PhishTank and OpenPhish. However, they mostly rely upon a user\nfalling victim to an attack and manually adding this new threat to the shared\npool, which presents a constant disadvantage in the fightback against phishing.\nIn this paper, we propose a novel approach to protect against phishing attacks\nusing binary visualisation and machine learning. Unlike previous work in this\nfield, our approach uses an automated detection process and requires no further\nuser interaction, which allows a faster and more accurate detection process.\nThe experiment results show that our approach has a high detection rate\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2108.06529,regular,pre_llm,2021,8,"{'ai_likelihood': 2.1523899502224394e-06, 'text': ""SEIGuard: An Authentication-simplified and Deceptive Scheme to Protect\n  Server-side Social Engineering Information Against Brute-force Attacks\n\n  This paper proposes an authentication-simplified and deceptive scheme\n(SEIGuard) to protect server-side social engineering information (SEI) and\nother information against brute-force attacks. In SEIGuard, the password check\nin authentication is omitted and this design is further combined with the SEI\nencryption design using honey encryption. The login password merely serves as a\ntemporary key to encrypt SEI and there is no password plaintext or ciphertext\nstored in the database. During the login, the server doesn't check the login\npasswords, correct passwords decrypt ciphertexts to be correct plaintexts;\nincorrect passwords decrypt ciphertexts to be phony but plausible-looking\nplaintexts (sampled from the same distribution). And these two situations share\nthe same undifferentiated backend procedures. This scheme eliminates the anchor\nthat both online and offline brute-force attacks depending on. Furthermore,\nthis paper presents four SEIGuard scheme designs and algorithms for 4 typical\nsocial engineering information objects (mobile phone number, identification\nnumber, email address, personal name), which represent 4 different types of\nmessage space, i.e. 1) limited and uniformly distributed, 2) limited, complex\nand uniformly distributed, 3) unlimited and uniformly distributed, 4) unlimited\nand non-uniformly distributed message space. Specially, we propose multiple\nsmall mapping files strategies, binary search algorithms, two-part HE (DTE)\ndesign and incremental mapping files solutions for the applications of SEIGuard\nscheme. Finally, this paper develops the SEIGuard system based on the proposed\nschemes, designs and algorithms. Experiment result shows that the SEIGuard\nscheme can effectively protect server-side SEI against brute-force attacks, and\nSEIGuard also has an impressive real-time response performance that is better\nthan conventional PBE server scheme and HE encryption/decryption.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.06127,regular,pre_llm,2021,9,"{'ai_likelihood': 9.834766387939453e-06, 'text': 'Malware MultiVerse: From Automatic Logic Bomb Identification to\n  Automatic Patching and Tracing\n\n  Malware and other suspicious software often hide behaviors and components\nbehind logic bombs and context-sensitive execution paths. Uncovering these is\nessential to react against modern threats, but current solutions are not ready\nto detect these paths in a completely automated manner. To bridge this gap, we\npropose the Malware Multiverse (MalVerse), a solution able to inspect multiple\nexecution paths via symbolic execution aiming to discover function inputs and\nreturns that trigger malicious behaviors. MalVerse automatically patches the\ncontext-sensitive functions with the identified symbolic values to allow the\nsoftware execution in a traditional sandbox. We implemented MalVerse on top of\nangr and evaluated it with a set of Linux and Windows evasive samples. We found\nthat MalVerse was able to generate automatic patches for the most common\nevasion techniques (e.g., ptrace checks).\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.07634,review,pre_llm,2021,9,"{'ai_likelihood': 1.2914339701334636e-06, 'text': 'Summarizing and Analyzing the Privacy-Preserving Techniques in Bitcoin\n  and other Cryptocurrencies\n\n  Bitcoin and many other similar Cryptocurrencies have been in existence for\nover a decade, prominently focusing on decentralized, pseudo-anonymous\nledger-based transactions. Many protocol improvements and changes have resulted\nin new variants of Cryptocurrencies that are known for their peculiar\ncharacteristics. For instance, Storjcoin is a Proof-of-Storage-based\nCryptocurrency that incentivizes its peers based on the amount of storage owned\nby them. Cryptocurrencies like Monero strive for user privacy by using\nprivacy-centric cryptographic algorithms. While Cryptocurrencies strive to\nmaintain peer transparency by making the transactions and the entire ledger\npublic, user privacy is compromised at times. Monero and many other\nprivacy-centric Cryptocurrencies have significantly improved from the original\nBitcoin protocol after several problems were found in the protocol. Most of\nthese deficiencies were related to the privacy of users. Even though Bitcoin\nclaims to have pseudo-anonymous user identities, many attacks have managed to\nsuccessfully de-anonymize users. In this paper, we present some well-known\nattacks and analysis techniques that have compromised the privacy of Bitcoin\nand many other similar Cryptocurrencies. We also analyze and study different\nprivacy-preserving algorithms and the problems these algorithms manage to\nsolve. Lastly, we touch upon the ethics, impact, legality, and acceptance of\nimposing these privacy algorithms.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.09259,regular,pre_llm,2021,9,"{'ai_likelihood': 9.271833631727431e-07, 'text': ""A Deep Learning-based Penetration Testing Framework for Vulnerability\n  Identification in Internet of Things Environments\n\n  The Internet of Things (IoT) paradigm has displayed tremendous growth in\nrecent years, resulting in innovations like Industry 4.0 and smart environments\nthat provide improvements to efficiency, management of assets and facilitate\nintelligent decision making. However, these benefits are offset by considerable\ncybersecurity concerns that arise due to inherent vulnerabilities, which hinder\nIoT-based systems' Confidentiality, Integrity, and Availability. Security\nvulnerabilities can be detected through the application of penetration testing,\nand specifically, a subset of the information-gathering stage, known as\nvulnerability identification. Yet, existing penetration testing solutions can\nnot discover zero-day vulnerabilities from IoT environments, due to the\ndiversity of generated data, hardware constraints, and environmental\ncomplexity. Thus, it is imperative to develop effective penetration testing\nsolutions for the detection of vulnerabilities in smart IoT environments. In\nthis paper, we propose a deep learning-based penetration testing framework,\nnamely Long Short-Term Memory Recurrent Neural Network-Enabled Vulnerability\nIdentification (LSTM-EVI). We utilize this framework through a novel\ncybersecurity-oriented testbed, which is a smart airport-based testbed\ncomprised of both physical and virtual elements. The framework was evaluated\nusing this testbed and on real-time data sources. Our results revealed that the\nproposed framework achieves about 99% detection accuracy for scanning attacks,\noutperforming other four peer techniques.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.00104,regular,pre_llm,2021,9,"{'ai_likelihood': 3.685553868611654e-05, 'text': 'LANTENNA: Exfiltrating Data from Air-Gapped Networks via Ethernet Cables\n\n  Air-gapped networks are wired with Ethernet cables since wireless connections\nare strictly prohibited.\n  In this paper we present LANTENNA - a new type of electromagnetic attack\nallowing adversaries to leak sensitive data from isolated, air-gapped networks.\nMalicious code in air-gapped computers gathers sensitive data and then encodes\nit over radio waves emanating from the Ethernet cables, using them as antennas.\nA nearby receiving device can intercept the signals wirelessly, decode the\ndata, and send it to the attacker. We discuss the exfiltration techniques,\nexamine the covert channel characteristics, and provide implementation details.\nNotably, the malicious code can run in an ordinary user-mode process and\nsuccessfully operate from within a virtual machine. We evaluate the covert\nchannel in different scenarios and present a set of countermeasures. Our\nexperiments show that with the LANTENNA attack, data can be exfiltrated from\nair-gapped computers to a distance of several meters away.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.0995,regular,pre_llm,2021,9,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""3-of-3 Multisignature Approach for Enabling Lightning Network\n  Micro-payments on IoT Devices\n\n  Bitcoin's success as a cryptocurrency enabled it to penetrate into many daily\nlife transactions. Its problems regarding the transaction fees and long\nvalidation times are addressed through an innovative concept called the\nLightning Network (LN) which works on top of Bitcoin by leveraging off-chain\ntransactions. This made Bitcoin an attractive micro-payment solution that can\nalso be used within certain IoT applications (e.g., toll payments) since it\neliminates the need for traditional centralized payment systems. Nevertheless,\nit is not possible to run LN and Bitcoin on resource-constrained IoT devices\ndue to their storage, memory, and processing requirements. Therefore, in this\npaper, we propose an efficient and secure protocol that enables an IoT device\nto use LN's functions through a gateway LN node even if it is not trusted. The\nidea is to involve the IoT device only in signing operations, which is possible\nby replacing LN's original 2-of-2 multisignature channels with 3-of-3\nmultisignature channels. Once the gateway is delegated to open a channel for\nthe IoT device in a secure manner, our protocol enforces the gateway to request\nthe IoT device's cryptographic signature for all further operations on the\nchannel such as sending payments or closing the channel. LN's Bitcoin\ntransactions are revised to incorporate the 3-of-3 multisignature channels. In\naddition, we propose other changes to protect the IoT device's funds from\ngetting stolen in possible revoked state broadcast attempts. We evaluated the\nproposed protocol using a Raspberry Pi considering a toll payment scenario. Our\nresults show that timely payments can be sent and the computational and\ncommunication delays associated with the protocol are negligible.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.1159,regular,pre_llm,2021,9,"{'ai_likelihood': 3.874301910400391e-06, 'text': ""A Tree-based Construction for Verifiable Diplomas with Issuer\n  Transparency\n\n  Still to this day, academic credentials are primarily paper-based, and the\nprocess to verify the authenticity of such documents is costly, time-consuming,\nand prone to human error and fraud. Digitally signed documents facilitate a\ncost-effective verification process. However, vulnerability to fraud remains\ndue to reliance on centralized authorities that lack full transparency. In this\npaper, we present the mechanisms we designed to create secure and\nmachine-verifiable academic credentials. Our protocol models a diploma as an\nevolving set of immutable credentials. The credentials are built as a\ntree-based data structure with linked time-stamping, where portions of\ncredentials are distributed over a set of smart contracts. Our design prevents\nfraud of diplomas and eases the detection of degree mills, while increasing the\ntransparency and trust in the issuer's procedures. Our evaluation shows that\nour solution offers a certification system with strong cryptographic security\nand imposes a high level of transparency of the certification process. We\nachieve these benefits with acceptable costs compared to existing solutions\nthat lack such transparency.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.00094,review,pre_llm,2021,9,"{'ai_likelihood': 3.6093923780653213e-06, 'text': 'RFID Exploitation and Countermeasures\n\n  Radio Frequency Identification (RFID) systems are among the most widespread\ncomputing technologies with technical potential and profitable opportunities in\nnumerous applications worldwide. Further, RFID is the core technology behind\nthe Internet of Things (IoT), which can accomplish the real-time transmission\nof information between objects without manual operation. However, RFID security\nhas been taken for granted for several years, causing multiple vulnerabilities\nthat can even damage human functionalities. The latest ISO/IEC 18000-63:2015\nstandard concerning RFID dates to 2015, and much freedom has been given to\nmanufacturers responsible for making their devices secure. The lack of a\nsubstantial standard for devices that implement RFID technology creates many\nvulnerabilities that expose end-users to elevated risk. Hence, this paper gives\nthe reader a clear overview of the technology, and it analyzes 23 well-known\nRFID attacks such as Reverse Engineering, Buffer Overflow, Eavesdropping, and\nMalware. Moreover, given the exceptional capabilities and utilities of RFID\ndevices, this paper has focused on security measures and defenses for\nprotecting them, such as Active Jamming, Shielding tag, and Authentication.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.03878,regular,pre_llm,2021,9,"{'ai_likelihood': 1.341104507446289e-05, 'text': 'Unsupervised Detection and Clustering of Malicious TLS Flows\n\n  Malware abuses TLS to encrypt its malicious traffic, preventing examination\nby content signatures and deep packet inspection. Network detection of\nmalicious TLS flows is an important, but challenging, problem. Prior works have\nproposed supervised machine learning detectors using TLS features. However, by\ntrying to represent all malicious traffic, supervised binary detectors produce\nmodels that are too loose, thus introducing errors. Furthermore, they do not\ndistinguish flows generated by different malware. On the other hand, supervised\nmulti-class detectors produce tighter models and can classify flows by malware\nfamily, but require family labels, which are not available for many samples.\n  To address these limitations, this work proposes a novel unsupervised\napproach to detect and cluster malicious TLS flows. Our approach takes as input\nnetwork traces from sandboxes. It clusters similar TLS flows using 90 features\nthat capture properties of the TLS client, TLS server, certificate, and\nencrypted payload; and uses the clusters to build an unsupervised detector that\ncan assign a malicious flow to the cluster it belongs to, or determine it is\nbenign. We evaluate our approach using 972K traces from a commercial sandbox\nand 35M TLS flows from a research network. Our clustering shows very high\nprecision and recall with an F1 score of 0.993. We compare our unsupervised\ndetector with two state-of-the-art approaches, showing that it outperforms\nboth. The false detection rate of our detector is 0.032% measured over four\nmonths of traffic.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.01727,regular,pre_llm,2021,9,"{'ai_likelihood': 5.298190646701389e-07, 'text': ""Increasing Adversarial Uncertainty to Scale Private Similarity Testing\n\n  Social media and other platforms rely on automated detection of abusive\ncontent to help combat disinformation, harassment, and abuse. One common\napproach is to check user content for similarity against a server-side database\nof problematic items. However, this method fundamentally endangers user\nprivacy. Instead, we target client-side detection, notifying only the users\nwhen such matches occur to warn them against abusive content. Our solution is\nbased on privacy-preserving similarity testing. Existing approaches rely on\nexpensive cryptographic protocols that do not scale well to large databases and\nmay sacrifice the correctness of the matching. To contend with this challenge,\nwe propose and formalize the concept of similarity-based bucketization~(SBB).\nWith SBB, a client reveals a small amount of information to a database-holding\nserver so that it can generate a bucket of potentially similar items. The\nbucket is small enough for efficient application of privacy-preserving\nprotocols for similarity. To analyze the privacy risk of the revealed\ninformation, we introduce a framework for measuring an adversary's confidence\nin inferring a predicate about the client input correctly. We develop a\npractical SBB protocol for image content, and evaluate its client privacy\nguarantee with real-world social media data. We then combine SBB with various\nsimilarity protocols, showing that the combination with SBB provides a speedup\nof at least 29x on large-scale databases compared to that without, while\nretaining correctness of over 95%.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.07626,regular,pre_llm,2021,9,"{'ai_likelihood': 2.284844716389974e-06, 'text': 'BOSS: A Blockchain Off-State Sharing System\n\n  Blockchain has been applied to data sharing to ensure the integrity of data\nand chain of custody. Sharing big data such as large biomedical data files is a\nchallenge to blockchain systems since the ledger is not designed to maintain\nbig files, access control is an issue, and users may be dishonest. We call big\ndata such as big files stored outside of a ledger that includes the blockchain\nand world state at a blockchain node as ""off-state"" and propose an off-state\nsharing protocol for a blockchain system to share big data between pairs of\nnodes. In our protocol, only encrypted files are transferred. The cryptographic\nkey is stored in the world state in a secure way and can be accessed only by\nauthorized parties. A receiver has to request the corresponding cryptographic\nkey from the sender to decrypt such encrypted files. All requests are run\nthrough transactions to establish reliable chain of custody. We design and\nimplement a prototypical blockchain off-state sharing system, BOSS, with\nHyperledger Fabric. Extensive experiments were performed to validate the\nfeasibility and performance of BOSS.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.09963,regular,pre_llm,2021,9,"{'ai_likelihood': 6.953875223795574e-07, 'text': 'Privacy, Security, and Utility Analysis of Differentially Private CPES\n  Data\n\n  Differential privacy (DP) has been widely used to protect the privacy of\nconfidential cyber physical energy systems (CPES) data. However, applying DP\nwithout analyzing the utility, privacy, and security requirements can affect\nthe data utility as well as help the attacker to conduct integrity attacks\n(e.g., False Data Injection(FDI)) leveraging the differentially private data.\nExisting anomaly-detection-based defense strategies against data integrity\nattacks in DP-based smart grids fail to minimize the attack impact while\nmaximizing data privacy and utility. To address this challenge, it is\nnontrivial to apply a defensive approach during the design process. In this\npaper, we formulate and develop the defense strategy as a part of the design\nprocess to investigate data privacy, security, and utility in a DP-based smart\ngrid network. We have proposed a provable relationship among the DP-parameters\nthat enables the defender to design a fault-tolerant system against FDI\nattacks. To experimentally evaluate and prove the effectiveness of our proposed\ndesign approach, we have simulated the FDI attack in a DP-based grid. The\nevaluation indicates that the attack impact can be minimized if the designer\ncalibrates the privacy level according to the proposed correlation of the\nDP-parameters to design the grid network. Moreover, we analyze the feasibility\nof the DP mechanism and QoS of the smart grid network in an adversarial\nsetting. Our analysis suggests that the DP mechanism is feasible over existing\nprivacy-preserving mechanisms in the smart grid domain. Also, the QoS of the\ndifferentially private grid applications is found satisfactory in adversarial\npresence.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.15037,regular,pre_llm,2021,9,"{'ai_likelihood': 1.986821492513021e-06, 'text': ""A Group Key Establishment Scheme\n\n  Group authentication is a method of confirmation that a set of users belong\nto a group and of distributing a common key among them. Unlike the standard\nauthentication schemes where one central authority authenticates users one by\none, group authentication can handle the authentication process at once for all\nmembers of the group. The recently presented group authentication algorithms\nmainly exploit Lagrange's polynomial interpolation along with elliptic curve\ngroups over finite fields. As a fresh approach, this work suggests use of\nlinear spaces for group authentication and key establishment for a group of any\nsize. The approach with linear spaces introduces a reduced computation and\ncommunication load to establish a common shared key among the group members.\nThe advantages of using vector spaces make the proposed method applicable to\nenergy and resource constrained devices. In addition to providing lightweight\nauthentication and key agreement, this proposal allows any user in a group to\nmake a non-member to be a member, which is expected to be useful for autonomous\nsystems in the future. The scheme is designed in a way that the sponsors of\nsuch members can easily be recognized by anyone in the group. Unlike the other\ngroup authentication schemes based on Lagrange's polynomial interpolation, the\nproposed scheme doesn't provide a tool for adversaries to compromise the whole\ngroup secrets by using only a few members' shares as well as it allows to\nrecognize a non-member easily, which prevents service interruption attacks.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.04337,regular,pre_llm,2021,9,"{'ai_likelihood': 5.099508497450087e-06, 'text': 'PARIOT: Anti-Repackaging for IoT Firmware Integrity\n\n  IoT repackaging refers to an attack devoted to tampering with a legitimate\nfirmware package by modifying its content (e.g., injecting some malicious code)\nand re-distributing it in the wild. In such a scenario, the firmware delivery\nand update processes play a central role in ensuring firmware integrity.\nUnfortunately, several existing solutions lack proper integrity verification,\nexposing firmware to repackaging attacks. If this is not the case, they still\nrequire an external trust anchor (e.g., signing keys or secure storage\ntechnologies), which could limit their adoption in resource-constrained\nenvironments. In addition, state-of-the-art frameworks do not cope with the\nentire firmware production and delivery process, thereby failing to protect the\ncontent generated by the firmware producers through the whole supply chain. To\nmitigate such a problem, in this paper, we introduce PARIOT, a novel\nself-protecting scheme for IoT that allows the injection of integrity checks,\ncalled anti-tampering (AT) controls, directly into the firmware. The AT\ncontrols enable the runtime detection of repackaging attempts without needing\nexternal trust anchors or computationally expensive systems. PARIOT can be\nadopted on top of existing state-of-the-art solutions ensuring the widest\ncompatibility with current IoT ecosystems and update frameworks. Also, we have\nimplemented this scheme into PARIOTIC, a prototype to automatically protect\nC/C++ IoT firmware. The evaluation phase of 50 real-world firmware samples\ndemonstrated the feasibility of the proposed methodology and its robustness\nagainst practical repackaging attacks without altering the firmware behavior or\nsevere overheads.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.00187,regular,pre_llm,2021,9,"{'ai_likelihood': 2.317958407931858e-07, 'text': 'Guarding Machine Learning Hardware Against Physical Side-Channel Attacks\n\n  Machine learning (ML) models can be trade secrets due to their development\ncost. Hence, they need protection against malicious forms of reverse\nengineering (e.g., in IP piracy). With a growing shift of ML to the edge\ndevices, in part for performance and in part for privacy benefits, the models\nhave become susceptible to the so-called physical side-channel attacks.\n  ML being a relatively new target compared to cryptography poses the problem\nof side-channel analysis in a context that lacks published literature. The gap\nbetween the burgeoning edge-based ML devices and the research on adequate\ndefenses to provide side-channel security for them thus motivates our study.\nOur work develops and combines different flavors of side-channel defenses for\nML models in the hardware blocks. We propose and optimize the first defense\nbased on Boolean masking. We first implement all the masked hardware blocks. We\nthen present an adder optimization to reduce the area and latency overheads.\nFinally, we couple it with a shuffle-based defense.\n  We quantify that the area-delay overhead of masking ranges from 5.4$\\times$\nto 4.7$\\times$ depending on the adder topology used and demonstrate first-order\nside-channel security of millions of power traces. Additionally, the shuffle\ncountermeasure impedes a straightforward second-order attack on our first-order\nmasked implementation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.05475,regular,pre_llm,2021,9,"{'ai_likelihood': 7.947285970052084e-07, 'text': ""Strong current-state and initial-state opacity of discrete-event systems\n\n  Opacity, as an important property in information-flow security, characterizes\nthe ability of a system to keep some secret information from an intruder. In\ndiscrete-event systems, based on a standard setting in which an intruder has\nthe complete knowledge of the system's structure, the standard versions of\ncurrent-state opacity and initial-state opacity cannot perfectly characterize\nhigh-level privacy requirements. To overcome such a limitation, in this paper\nwe propose two stronger versions of opacity in partially-observed\ndiscrete-event systems, called \\emph{strong current-state opacity} and\n\\emph{strong initial-state opacity}. Strong current-state opacity describes\nthat an intruder never makes for sure whether a system is in a secret state at\nthe current time, that is, if a system satisfies this property, then for each\nrun of the system ended by a secret state, there exists a non-secret run whose\nobservation is the same as that of the previous run. Strong initial-state\nopacity captures that the visit of a secret state at the initial time cannot be\ninferred by an intruder at any instant. Specifically, a system is said to be\nstrongly initial-state opaque if for each run starting from a secret state,\nthere exists a non-secret run of the system that has the same observation as\nthe previous run has. To verify these two properties, we propose two\ninformation structures using a novel concurrent-composition technique, which\nhas exponential-time complexity\n$O(|X|^4|\\Sigma_o||\\Sigma_{uo}||\\Sigma|2^{|X|})$, where $|X|$ (resp.,\n$|\\Sigma|$, $|\\Sigma_o|$, $|\\Sigma_{uo}|$) is the number of states (resp.,\nevents, observable events, unobservable events) of a system.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.03945,review,pre_llm,2021,9,"{'ai_likelihood': 1.158979203965929e-06, 'text': 'Vulnerabilities and Attacks Against Industrial Control Systems and\n  Critical Infrastructures\n\n  Critical infrastructures (CI) and industrial organizations aggressively move\ntowards integrating elements of modern Information Technology (IT) into their\nmonolithic Operational Technology (OT) architectures. Yet, as OT systems\nprogressively become more and more interconnected, they silently have turned\ninto alluring targets for diverse groups of adversaries. Meanwhile, the\ninherent complexity of these systems, along with their advanced-in-age nature,\nprevents defenders from fully applying contemporary security controls in a\ntimely manner. Forsooth, the combination of these hindering factors has led to\nsome of the most severe cybersecurity incidents of the past years. This work\ncontributes a full-fledged and up-to-date survey of the most prominent threats\nagainst Industrial Control Systems (ICS) along with the communication protocols\nand devices adopted in these environments. Our study highlights that threats\nagainst CI follow an upward spiral due to the mushrooming of commodity tools\nand techniques that can facilitate either the early or late stages of attacks.\nFurthermore, our survey exposes that existing vulnerabilities in the design and\nimplementation of several of the OT-specific network protocols may easily grant\nadversaries the ability to decisively impact physical processes. We provide a\ncategorization of such threats and the corresponding vulnerabilities based on\nvarious criteria. As far as we are aware, this is the first time an exhaustive\nand detailed survey of this kind is attempted.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.02695,review,pre_llm,2021,9,"{'ai_likelihood': 4.6690305074055995e-06, 'text': ""IoT Security and Authentication schemes Based on Machine Learning:\n  Review\n\n  With the latest developments in technology, extra and extra human beings\ndepend on their private gadgets to keep their touchy information. Concurrently,\nthe surroundings in which these gadgets are linked have grown to grow to be\ngreater dynamic and complex. This opens the dialogue of if the modern day\nauthentication strategies being used in these gadgets are dependable ample to\npreserve these user's records safe. This paper examines the distinct consumer\nauthentication schemes proposed to make bigger the protection of exceptional\ndevices. This article is break up into two one of a kind avenues discussing\nauthentication schemes that use both behavioral biometrics or physical layer\nauthentication. This survey will talk about each the blessings and challenges\nthat occur with the accuracy, usability, and standard protection of computing\ndevice getting to know strategies in these authentication systems. This article\ntargets to enhance in addition lookup in this subject via exhibiting the more\nthan a few present day authentication models, their schematics, and their\nresults.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.06068,regular,pre_llm,2021,9,"{'ai_likelihood': 3.1789143880208335e-06, 'text': 'A [in]Seguran\\c{c}a dos Sistemas Governamentais Brasileiros: Um Estudo\n  de Caso em Sistemas Web e Redes Abertas\n\n  Whereas the world relies on computer systems for providing public services,\nthere is a lack of academic work that systematically assess the security of\ngovernment systems. To partially fill this gap, we conducted a security\nevaluation of publicly available systems from public institutions. We revisited\nOWASP top-10 and identified multiple vulnerabilities in deployed services by\nscanning public government networks. Overall, the unprotected services found\nhave inadequate security level, which must be properly discussed and addressed.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.0652,regular,pre_llm,2021,9,"{'ai_likelihood': 3.112687004937066e-06, 'text': 'A Double-Linked Blockchain Approach Based on Proof-of-Refundable-Tax\n  Consensus Algorithm\n\n  In this paper we propose a double-linked blockchain data structure that\ngreatly improves blockchain performance and guarantees single chain with no\nforks. Additionally, with the proposed proof-of-refundable-tax (PoRT) consensus\nalgorithm, our approach can construct highly reliable, efficient, fair and\nstable blockchain operations. The PoRT algorithm adopts a verifiable random\nfunction instead of mining to select future block maintainers with the\nprobability proportional to each participant\'s personal refundable tax. The\nindividual refundable tax serves as an index of the activeness of participation\nand hence PoRT can effectively prevent Sybil attacks. Also, with the\nblock-completion reward deducted from each maintainer\'s refundable tax, our\nblockchain system maintains a stable wealth distribution and avoids the ""rich\nbecome richer"" problem. We have implemented the approach and tested with very\npromising results.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2109.04065,regular,pre_llm,2021,9,"{'ai_likelihood': 1.4901161193847656e-06, 'text': 'Malware Sight-Seeing: Accelerating Reverse-Engineering via\n  Point-of-Interest-Beacons\n\n  New types of malware are emerging at concerning rates. However, analyzing\nmalware via reverse engineering is still a time-consuming and mostly manual\ntask. For this reason, it is necessary to develop techniques that automate\nparts of the reverse engineering process and that can evade the built-in\ncountermeasures of modern malware. The main contribution of this paper is a\nnovel method to automatically find so-called Points-of-Interest (POIs) in\nexecuted programs. POIs are instructions that interact with data that is known\nto an analyst. They can be used as beacons in the analysis of malware and can\nhelp to guide the analyst to the interesting parts of the malware. Furthermore,\nwe propose a metric for POIs , the so-called confidence score that estimates\nhow exclusively a POI will process data relevant to the malware. With the goal\nof automatically extract peers in P2P botnet malware, we demonstrate and\nevaluate our approach by applying it on four botnets (ZeroAccess, Sality,\nNugache, and Kelihos). We looked into the identified POIs for known IPs and\nports and, by using this information, leverage it to successfully monitor the\nbotnets. Furthermore, using our scoring system, we show that we can extract\npeers for each botnet with high accuracy.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.02103,regular,pre_llm,2021,10,"{'ai_likelihood': 1.2252065870496963e-06, 'text': 'Notarial timestamps savings in logs management via Merkle trees and Key\n  Derivation Functions\n\n  Nowadays log files handling imposes to ISPs (intended in their widest scope)\nstrict normative duties apart from common technological issues. This work\nanalyses how retention time policies and timestamping are deeply interlinked\nfrom the point of view of service providers, possibly leading to costs rise. A\nnew schema is proposed trying to mitigate the need for third-party suppliers,\nenforcing cryptographic primitives well established in other fields of\nInformation Technology but perhaps not yet widespread in logs management. The\nfoundations of timestamping are recapped, and properties of cryptographic\nprimitives introduced as a natural way to bypass legacy schema inefficiency and\nas an extra level of protection: these choices are justified by savings\nestimation (with regard to different ISP magnitudes) and by some basic security\nconsiderations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.05118,regular,pre_llm,2021,10,"{'ai_likelihood': 2.0199351840549047e-06, 'text': 'Confidential Token-Based License Management\n\n  In a global economy with many competitive participants, licensing and\ntracking of 3D printed parts is desirable if not mandatory for many use-cases.\nWe investigate a blockchain-based approach, as blockchains provide many\nattractive features, like decentralized architecture and high security\nassurances. An often neglected aspect of the product life-cycle management is\nthe confidentiality of transactions to hide valuable business information from\ncompetitors. To solve the combined problem of trust and confidentiality, we\npresent a confidential licensing and tracking system which works on any\npublicly verifiable, token-based blockchain that supports tokens of different\ntypes representing licenses or attributes of parts. Together with the secure\nintegration of a unique eID in each part, our system provides an efficient,\nimmutable and authenticated transaction log scalable to thousands of\ntransactions per second. With our confidential Token-Based License Management\nsystem (cTLM), large industries such as automotive or aviation can license and\ntrace all parts confidentially.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.11188,regular,pre_llm,2021,10,"{'ai_likelihood': 1.655684577094184e-07, 'text': ""Classification of Encrypted IoT Traffic Despite Padding and Shaping\n\n  It is well known that when IoT traffic is unencrypted it is possible to\nidentify the active devices based on their TCP/IP headers. And when traffic is\nencrypted, packet-sizes and timings can still be used to do so. To defend\nagainst such fingerprinting, traffic padding and shaping were introduced. In\nthis paper we demonstrate that the packet-sizes distribution can still be used\nto successfully fingerprint the active IoT devices when shaping and padding are\nused, as long as the adversary is aware that these mitigations are deployed,\nand even if the values of the padding and shaping parameters are unknown. The\nmain tool we use in our analysis is the full distribution of packet-sizes, as\nopposed to commonly used statistics such as mean and variance. We further show\nhow an external adversary who only sees the padded and shaped traffic as\naggregated and hidden behind a NAT middlebox can accurately identify the subset\nof active devices with Recall and Precision of at least 96%. We also show that\nthe adversary can distinguish time windows containing only bogus cover packets\nfrom windows with real device activity, at a granularity of $1sec$ time\nwindows, with 81% accuracy. Using similar methodology, but now on the\ndefender's side, we are also able to detect anomalous activities in IoT traffic\ndue to the Mirai worm.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.03491,regular,pre_llm,2021,10,"{'ai_likelihood': 1.5894571940104167e-06, 'text': 'Privacy-preserving methods for smart-meter-based network simulations\n\n  Smart-meters are a key component of energy transition. The large amount of\ndata collected in near real-time allows grid operators to observe and simulate\nnetwork states. However, privacy-preserving rules forbid the use of such data\nfor any applications other than network operation and billing. Smart-meter\nmeasurements must be anonymised to transmit these sensitive data to a third\nparty to perform network simulation and analysis. This work proposes two\nmethods for data anonymisation that enable the use of raw active power\nmeasurements for network simulation and analysis. The first is based on an\nallocation of an externally sourced load database. The second consists of\ngrouping smart-meter data with similar electric characteristics, then\nperforming a random permutation of the network load-bus assignment. A benchmark\nof these two methods highlights that both provide similar results in\nbus-voltage magnitude estimation concerning ground-truth voltage.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.15586,regular,pre_llm,2021,10,"{'ai_likelihood': 1.7881393432617188e-06, 'text': 'A hybrid chaos map with two control parameters to secure image\n  encryption algorithms\n\n  In this paper, we introduce a hybrid chaos map for image encryption method\nwith high sensitivity. This new map is sensitive to small changes in the\nstarting point and also in control parameters which result in having more\ncomputational complexity. Also, it has uniform distribution that provides\nresisting of the new system against attacks in security applications. Various\ntests and plots are demonstrated to show more chaotic behavior of the proposed\nsystem. Finally, to show the ability of the generated chaotic map in the\nexistences image cryptography approaches, we further report some results in\nthis area.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.09557,regular,pre_llm,2021,10,"{'ai_likelihood': 3.543164994981554e-06, 'text': 'On-the-fly Code Activation for Attack Surface Reduction\n\n  Modern code reuse attacks are taking full advantage of bloated software.\nAttackers piece together short sequences of instructions in otherwise benign\ncode to carry out malicious actions. Eliminating these reusable code snippets,\nknown as gadgets, has become one of the prime concerns of attack surface\nreduction. The aim is to break these chains of gadgets, thereby making such\ncode reuse attacks impossible or substantially less common. Previous work on\nattack surface reduction has typically tried to eliminate such attacks by\nsubsetting the application, e.g. via user-specified inputs, configurations, or\nfeatures, or by focusing on third-party libraries to achieve high gadget\nreductions with minimal interference to the application.\n  In this work we present a general, whole-program attack surface reduction\ntechnique called OCA that significantly reduces gadgets and has minor\nperformance degradation. OCA requires no user inputs and leaves all features\nintact. OCA identifies specific program points and through analysis determines\nkey function sets to enable/disable at runtime. The runtime system, thus,\ncontrols the set of enabled functions during execution, thereby significantly\nreducing the set of active gadgets an attacker can use, and by extension,\ncutting down the set of active gadget chains dramatically. On SPEC CPU 2017,\nour framework achieves 73.2% total gadget reduction with only 4% average\nslowdown. On 10 GNU coreutils applications, it achieves 87.2% reduction. On the\nnginx server it achieves 80.3% reduction with 2% slowdown. We also provide a\ngadget chain-breaking study across all applications, and show that our\nframework breaks the shell-spawning chain in all cases.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.0952,regular,pre_llm,2021,10,"{'ai_likelihood': 1.4238887363009983e-06, 'text': 'Image Protection against Forgery and Pixel Tampering based on a Triple\n  Hybrid Security Approach\n\n  Due to the widespread of advanced digital imaging devices, forgery of digital\nimages became more serious attack patterns. In this attack scenario, the\nattacker tries to manipulate the digital image to conceal some meaningful\ninformation of the genuine image for malicious purposes. This leads to increase\nsecurity interest about protecting images against integrity tampers. This paper\nproposes a novel technique for protecting colored images against forgery and\npixel tamper. The proposed approach is designed as a hybrid model from three\nsecurity techniques, Message Digest hashing algorithm (MD5), Advanced\nEncryption Standard-128 bits (AES), and Stenography. The proposed approach has\nbeen evaluated using set of image quality metrics for testing the impact of\nembedding the protection code on image quality. The evaluation results proved\nthat protecting image based on Least Significant Bit (LSB) is the best\ntechnique that keep image quality compared with other two bit-substitution\nmethods. Moreover, the results proved the superiority of the proposed approach\ncompared with other technique in the literature.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.04457,regular,pre_llm,2021,10,"{'ai_likelihood': 9.5367431640625e-06, 'text': 'Tailoring the Cyber Security Framework: How to Overcome the Complexities\n  of Secure Live Virtual Machine Migration in Cloud Computing\n\n  This paper proposes a novel secure live virtual machine migration framework\nby using a virtual trusted platform module instance to improve the integrity of\nthe migration process from one virtual machine to another on the same platform.\nThe proposed framework, called Koror\\=a, is designed and developed on a public\ninfrastructure-as-a-service cloud-computing environment and runs concurrently\non the same hardware components (Input/Output, Central Processing Unit, Memory)\nand the same hypervisor (Xen); however, a combination of parameters needs to be\nevaluated before implementing Koror\\=a. The implementation of Koror\\=a is not\npractically feasible in traditional distributed computing environments. It\nrequires fixed resources with high-performance capabilities, connected through\na high-speed, reliable network. The following research objectives were\ndetermined to identify the integrity features of live virtual machine migration\nin the cloud system:\n  To understand the security issues associated with cloud computing, virtual\ntrusted platform modules, virtualization, live virtual machine migration, and\nhypervisors; To identify the requirements for the proposed framework, including\nthose related to live VM migration among different hypervisors; To design and\nvalidate the model, processes, and architectural features of the proposed\nframework; To propose and implement an end-to-end security architectural\nblueprint for cloud environments, providing an integrated view of protection\nmechanisms, and then to validate the proposed framework to improve the\nintegrity of live VM migration. This is followed by a comprehensive review of\nthe evaluation system architecture and the proposed framework state machine.\nThe overarching aim of this paper, therefore, is to present a detailed analysis\nof the cloud computing security problem, from the perspective of cloud\narchitectures and the cloud... [Abridged]\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.12989,regular,pre_llm,2021,10,"{'ai_likelihood': 1.1755360497368707e-05, 'text': 'RoBin: Facilitating the Reproduction of Configuration-Related\n  Vulnerability\n\n  Vulnerability reproduction paves a way in debugging software failures, which\nneed intensive manual efforts. However, some key factors (e.g., software\nconfiguration, trigger method) are often missing, so we can not directly\nreproduce the failure without extra attempts. Even worse, highly customized\nconfiguration options of programs create a barrier for reproducing the\nvulnerabilities that only appear under some specific combinations of\nconfigurations. In this paper, we address the problem mentioned above --\nreproducing the configuration-related vulnerability. We try to solve it by\nproposing a binary similarity-based method to infer the specific building\nconfigurations via the binary from crash report. The main challenges are as\nfollows: precise compilation option inference, program configuration inference,\nand source-code-to-binary matching. To achieve the goal, we implement RoBin, a\nbinary similarity-based building configuration inference tool. To demonstrate\nthe effectiveness, we test RoBin on 21 vulnerable cases upon 4 well-known\nopen-source programs. It shows a strong ability in pinpointing the building\nconfigurations causing the vulnerability. The result can help developers\nreproduce and diagnose the vulnerability, and finally, patch the programs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.14693,regular,pre_llm,2021,10,"{'ai_likelihood': 3.874301910400391e-06, 'text': ""Towards Robust Reasoning over Knowledge Graphs\n\n  Answering complex logical queries over large-scale knowledge graphs (KGs)\nrepresents an important artificial intelligence task, entailing a range of\napplications. Recently, knowledge representation learning (KRL) has emerged as\nthe state-of-the-art approach, wherein KG entities and the query are embedded\ninto a latent space such that entities that answer the query are embedded close\nto the query. Yet, despite its surging popularity, the potential security risks\nof KRL are largely unexplored, which is concerning, given the increasing use of\nsuch capabilities in security-critical domains (e.g., cyber-security and\nhealthcare).\n  This work represents a solid initial step towards bridging this gap. We\nsystematize the potential security threats to KRL according to the underlying\nattack vectors (e.g., knowledge poisoning and query perturbation) and the\nadversary's background knowledge. More importantly, we present ROAR(Reasoning\nOver Adversarial Representations), a new class of attacks that instantiate a\nvariety of such threats. We demonstrate the practicality of ROAR in two\nrepresentative use cases (i.e., cyber-threat hunting and drug repurposing). For\ninstance, ROAR attains over 99% attack success rate in misleading the threat\nintelligence engine to give pre-defined answers for target queries, yet without\nany impact on non-target ones. Further, we discuss potential countermeasures\nagainst ROAR, including filtering of poisoning facts and robust training with\nadversarial queries, which leads to several promising research directions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.03447,regular,pre_llm,2021,10,"{'ai_likelihood': 1.1920928955078125e-05, 'text': 'GPS Spoofing Attacks on Phasor Measurement Units: Practical Feasibility\n  and Countermeasures\n\n  Prior research has demonstrated that global positioning system (GPS) spoofing\nattacks on phasor measurement units (PMUs) can cripple power system operation.\nThis paper provides an experimental evidence of the feasibility of such an\nattack using commonly available digital radios known as software defined radio\n(SDR). It also introduces a novel countermeasure against such attacks using GPS\nsignal redundancy and low power long range (LoRa) spread spectrum modulation\ntechnique. The proposed approach checks the integrity of the GPS signal at\nremote locations and compares the data with the PMUs current output. This\ncountermeasure is a ready-to-deploy system that can provide an instant solution\nto the GPS spoofing detection problem for PMUs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.05619,review,pre_llm,2021,10,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""Towards a Principled Approach for Dynamic Analysis of Android's\n  Middleware\n\n  The Android middleware, in particular the so-called systemserver, is a\ncrucial and central component to Android's security and robustness. To\nunderstand whether the systemserver provides the demanded security properties,\nit has to be thoroughly tested and analyzed. A dedicated line of research\nfocuses exclusively on this task. While static analysis builds on established\ntools, dynamic testing approaches lack a common foundation, which prevents the\ncommunity from comparing, reproducing, or even re-using existing results from\nrelated work. This raises questions about whether the underlying approach of\nany proposed solution is the only possible or optimal one, if it can be re-used\nas a building block for future analyses, or whether results generalize. In this\nwork, we argue that in order to steer away from incompatible custom toolchains\nand towards having comparable analyses with reproducible results, a more\nprincipled approach to dynamically analyzing the Android system is required. As\nan important first step in this direction, we propose a unified dynamic\nanalysis platform that provides re-usable solutions for common challenges as\nthe building blocks for future analyses and allows to compare different\napproaches under the same assumptions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.1409,regular,pre_llm,2021,10,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'Teardown and feasibility study of IronKey -- the most secure USB Flash\n  drive\n\n  There are many solutions for protecting user data on USB Flash drives.\nHowever, the family of IronKey devices was designed with the highest security\nexpectations. They are definitely standing above others by being certified to\nFIPS 140-2 Level 3 and also claimed as certified by NATO for Top-Secret use.\nMany encrypted USB drives had been evaluated and found insecure, however, no\npublic research on IronKey devices was made. This feasibility study fills the\ngap by looking inside the IronKey family of devices. As a result the users of\nthe IronKey devices could be assured about the real level of the security\nprotection they get. Several generations of devices from IronKey family and\ncompetitors are teared down, their hardware solutions discussed and evaluated\nfor possible attacks. Some potential flaws are exposed and those findings are\nlikely to stimulate further research into specific solutions aimed to protect\nuser data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.04795,regular,pre_llm,2021,10,"{'ai_likelihood': 1.6027026706271703e-05, 'text': 'Isogeny-based Group Signatures and Accountable Ring Signatures in QROM\n\n  We present the first provably secure isogeny-based group signature (GS) and\naccountable ring signature (ARS) in the quantum random oracle model (QROM). We\ndo so via introducing and constructing an intermediate primitive called the\nopenable sigma protocol and demonstrating that any such protocol gives rise to\na secure GS and ARS. Furthermore, QROM security is guaranteed if an additional\nperfect unique-response property (which is achieved via our tailored\nconstruction) is satisfied.\n  Previous works by Beullens et al. (Eurocrypt 2022, Asiacrypt 2020) proposed\nisogeny-based GS and ARS with better efficiency but were only analyzed in the\nclassical random oracle model (CROM). It is well-known that CROM security does\nnot generally translate to QROM security; with the growing relevance of\nisogeny-based constructions in post-quantum cryptography, the current state of\nthe art is unsatisfactory. Moreover, the aforementioned existing isogeny-based\nsignatures were recently affected by the Fiat-Shamir with aborts (FSwA) flaw\ndiscovered by Barbosa et al. and Devevey et al. (CRYPTO 2023), leaving the\nprovable security of isogeny-based signatures open to question once again. Our\nconstructions are not only immune to the FSwA flaw but also provide stronger\nQROM security. As current QROM-secure ARS and GS schemes are mostly\nlattice-based, we offer a robust post-quantum alternative should lattice\nassumptions weaken.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.06363,regular,pre_llm,2021,10,"{'ai_likelihood': 1.3510386149088543e-05, 'text': 'A Side-channel Analysis of Sensor Multiplexing for Covert Channels and\n  Application Profiling on Mobile Devices\n\n  Mobile devices often distribute measurements from physical sensors to\nmultiple applications using software multiplexing. On Android devices, the\nhighest requested sampling frequency is returned to all applications, even if\nothers request measurements at lower frequencies. In this paper, we\ncomprehensively demonstrate that this design choice exposes practically\nexploitable side-channels using frequency-key shifting. By carefully modulating\nsensor sampling frequencies in software, we show how unprivileged malicious\napplications can construct reliable spectral covert channels that bypass\nexisting security mechanisms. Additionally, we present a novel variant that\nallows an unprivileged malicious application to profile other active,\nsensor-enabled applications at a coarse-grained level. Both methods do not\nimpose any special assumptions beyond accessing standard mobile services\navailable to developers. As such, our work reports side-channel vulnerabilities\nthat exploit subtle yet insecure design choices in Android sensor stacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.01038,regular,pre_llm,2021,10,"{'ai_likelihood': 4.271666208902995e-06, 'text': 'Generating and Managing Strong Passwords using Hotel Mnemonic\n\n  Weak passwords and availability of supercomputers to password crackers make\nthe financial institutions and businesses at stake. This calls for use of\nstrong passwords and multi factor authentication for secure transactions.\nRemembering a long and complex password by humans is a daunting task and\nmnemonic has helped to mitigate this situation to an extent. This paper\ndiscusses creating and using long random password and storing them securely\nusing a hybrid strategy of hash-encryption method. The hash function uses a\nmnemonic password based on the hotel names and other characteristics like room\nnumber, floor number and breakfast meal preferences to generate the encryption\nkey. The random strong password can be then encrypted using the key and stored\nsafely. A computer program named Hector is developed which demonstrates these\nsteps and can be used to generate and store the passwords.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.00582,regular,pre_llm,2021,10,"{'ai_likelihood': 3.443823920355903e-06, 'text': ""Data Breaches in Healthcare Security Systems\n\n  Providing security to Health Information is considered to be the topmost\npriority when compared to any other field. After the digitalization of the\npatient's records in the medical field, the healthcare/medical field has become\na victim of several internal and external cyberattacks. Data breaches in the\nhealthcare industry have been increasing rapidly. Despite having security\nstandards such as HIPAA (Health Insurance Portability and Accountability Act),\ndata breaches still happen on a daily basis. All various types of data breaches\nhave the same harmful impact on healthcare data, especially on patients'\nprivacy. The main objective of this paper is to analyze why healthcare data\nbreaches occur and what is the impact of these breaches. The paper also\npresents the possible improvements that can be made in the current standards,\nsuch as HIPAA, to increase security in the healthcare field.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.01495,regular,pre_llm,2021,10,"{'ai_likelihood': 1.9205941094292534e-06, 'text': 'Realizing Forward Defense in the Cyber Domain\n\n  With the recognition of cyberspace as an operating domain, concerted effort\nis now being placed on addressing it in the whole-of-domain manner found in\nland, sea, undersea, air, and space domains. Among the first steps in this\neffort is applying the standard supporting concepts of security, defense, and\ndeterrence to the cyber domain. This paper presents an architecture that helps\nrealize forward defense in cyberspace, wherein adversarial actions are repulsed\nas close to the origin as possible. However, substantial work remains in making\nthe architecture an operational reality including furthering fundamental\nresearch cyber science, conducting design trade-off analysis, and developing\nappropriate public policy frameworks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.08517,regular,pre_llm,2021,10,"{'ai_likelihood': 9.271833631727431e-07, 'text': 'Characterizing Improper Input Validation Vulnerabilities of Mobile\n  Crowdsourcing Services\n\n  Mobile crowdsourcing services (MCS), enable fast and economical data\nacquisition at scale and find applications in a variety of domains. Prior work\nhas shown that Foursquare and Waze (a location-based and a navigation MCS) are\nvulnerable to different kinds of data poisoning attacks. Such attacks can be\nupsetting and even dangerous especially when they are used to inject improper\ninputs to mislead users. However, to date, there is no comprehensive study on\nthe extent of improper input validation (IIV) vulnerabilities and the\nfeasibility of their exploits in MCSs across domains. In this work, we leverage\nthe fact that MCS interface with their participants through mobile apps to\ndesign tools and new methodologies embodied in an end-to-end feedback-driven\nanalysis framework which we use to study 10 popular and previously unexplored\nservices in five different domains. Using our framework we send tens of\nthousands of API requests with automatically generated input values to\ncharacterize their IIV attack surface. Alarmingly, we found that most of them\n(8/10) suffer from grave IIV vulnerabilities which allow an adversary to launch\ndata poisoning attacks at scale: 7400 spoofed API requests were successful in\nfaking online posts for robberies, gunshots, and other dangerous incidents,\nfaking fitness activities with supernatural speeds and distances among many\nothers. Lastly, we discuss easy to implement and deploy mitigation strategies\nwhich can greatly reduce the IIV attack surface and argue for their use as a\nnecessary complementary measure working toward trustworthy mobile crowdsourcing\nservices.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2110.03798,regular,pre_llm,2021,10,"{'ai_likelihood': 9.768539004855686e-06, 'text': 'MPD: Moving Target Defense through Communication Protocol Dialects\n\n  Communication protocol security is among the most significant challenges of\nthe Internet of Things (IoT) due to the wide variety of hardware and software\ntechnologies involved. Moving target defense (MTD) has been adopted as an\ninnovative strategy to solve this problem by dynamically changing target system\nproperties and configurations to obfuscate the attack surface. Nevertheless,\nthe existing work of MTD primarily focuses on lower-level properties (e.g., IP\naddresses or port numbers), and only a limited number of variations can be\ngenerated based on these properties. In this paper, we propose a new approach\nof MTD through communication protocol dialects (MPD) - which dynamically\ncustomizes a communication protocol into various protocol dialects and\nleverages them to create a moving target defense. Specifically, MPD harnesses a\ndialect generating function to create protocol dialects and then a mapping\nfunction to select one specific dialect for each packet during communication.\nTo keep different network entities in synchronization, we also design a\nself-synchronization mechanism utilizing a pseudo-random number generator with\nthe input of a pre-shared secret key and previously sent packets. We implement\na prototype of MPD and evaluate its feasibility on standard network protocol\n(i.e., File Transfer Protocol) and internet of things protocol (i.e., Message\nQueuing Telemetry Transport). The results indicate that MPD can create a moving\ntarget defense with protocol dialects to effectively address various attacks -\nincluding the denial of service attack and malicious packet modifications -\nwith negligible overhead.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.1173,regular,pre_llm,2021,11,"{'ai_likelihood': 5.7948960198296445e-06, 'text': 'A Lightweight Encryption Scheme for IoT Devices in the Fog\n\n  The Internet of Things (IoT) is the collection of everyday smart devices\nwhich connect to the Cloud, often through Fog nodes, to transmit and receive\ninformation. These everyday devices are distinct from traditional computers\nbecause they typically have notable constraints on their RAM, flash memory, and\ncomputational power. Due to these constraints, we believe that many of the\nproposed encryption schemes are too heavyweight to be employed in the IoT. In\nthis paper we present a lightweight, flexible encryption scheme that relies on\nthe one-way information loss property of a secure hash function. Our scheme\nimposes minimal computational and storage requirements, and imposes no\nnon-negligible burdens on the encrypting device, except for the hash itself. We\nfind that the encryption algorithm is particularly lightweight, and holds up\nstrongly in terms of its speed and memory efficiency.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.1391,review,pre_llm,2021,11,"{'ai_likelihood': 3.0795733133951826e-06, 'text': ""Assessing the Effectiveness of YARA Rules for Signature-Based Malware\n  Detection and Classification\n\n  Malware often uses obfuscation techniques or is modified slightly to evade\nsignature detection from antivirus software and malware analysis tools.\nTraditionally, to determine if a file is malicious and identify what type of\nmalware a sample is, a cryptographic hash of a file is calculated. A more\nrecent and flexible solution for malware detection is YARA, which enables the\ncreation of rules to identify and classify malware based on a file's binary\npatterns. In this paper, the author will critically evaluate the effectiveness\nof YARA rules for signature-based detection and classification of malware in\ncomparison to alternative methods, which include cryptographic and fuzzy\nhashing.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.12027,review,pre_llm,2021,11,"{'ai_likelihood': 8.940696716308594e-07, 'text': ""Privacy and modern cars through a dual lens\n\n  Modern cars technologies are evolving quickly. They collect a variety of\npersonal data and treat it on behalf of the car manufacturer to improve the\ndrivers' experience. The precise terms of such a treatment are stated within\nthe privacy policies accepted by the user when buying a car or through the\ninfotainment system when it is first started. This paper uses a double lens to\nassess people's privacy while they drive a car. The first approach is objective\nand studies the readability of privacy policies that comes with cars. We\nanalyse the privacy policies of twelve car brands and apply well-known\nreadability indices to evaluate the extent to which privacy policies are\ncomprehensible by all drivers. The second approach targets drivers' opinions to\nextrapolate their privacy concerns and trust perceptions. We design a\nquestionnaire to collect the opinions of 88 participants and draw essential\nstatistics about them. Our combined findings indicate that privacy is\ninsufficiently understood at present as an issue deriving from driving a car,\nhence future technologies should be tailored to make people more aware of the\nissue and to enable them to express their preferences.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.02269,regular,pre_llm,2021,11,"{'ai_likelihood': 1.7219119601779514e-06, 'text': 'Introducing a Framework to Enable Anonymous Secure Multi-Party\n  Computation in Practice (Extended Version)\n\n  Secure Multi-Party Computation (SMPC) allows a set of parties to securely\ncompute a functionality in a distributed fashion without the need for any\ntrusted external party. Usually, it is assumed that the parties know each other\nand have already established authenticated channels among each other. However,\nin practice the parties sometimes must stay anonymous. In this paper, we\nconceptualize a framework that enables the repeated execution of an SMPC\nprotocol for a given functionality such that the parties can keep their\nparticipation in the protocol executions private and at the same time be sure\nthat only authorized parties may take part in a protocol execution. We identify\nthe security properties that an implementation of our framework must meet and\nintroduce a first implementation of the framework that achieves these\nproperties.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.1009,regular,pre_llm,2021,11,"{'ai_likelihood': 5.861123402913412e-06, 'text': 'Quantifying Cybersecurity Effectiveness of Software Diversity\n\n  The deployment of monoculture software stacks can cause a devastating damage\neven by a single exploit against a single vulnerability. Inspired by the\nresilience benefit of biological diversity, the concept of software diversity\nhas been proposed in the security domain. Although it is intuitive that\nsoftware diversity may enhance security, its effectiveness has not been\nquantitatively investigated. Currently, no theoretical or empirical study has\nbeen explored to measure the security effectiveness of network diversity. In\nthis paper, we take a first step towards ultimately tackling the problem. We\npropose a systematic framework that can model and quantify the security\neffectiveness of network diversity. We conduct simulations to demonstrate the\nusefulness of the framework. In contrast to the intuitive belief, we show that\ndiversity does not necessarily improve security from a whole-network\nperspective. The root cause of this phenomenon is that the degree of\nvulnerability in diversified software implementations plays a critical role in\ndetermining the security effectiveness of software diversity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.03573,review,pre_llm,2021,11,"{'ai_likelihood': 3.311369154188368e-06, 'text': ""Security and Privacy Perceptions of Third-Party Application Access for\n  Google Accounts (Extended Version)\n\n  Online services like Google provide a variety of application programming\ninterfaces (APIs). These online APIs enable authenticated third-party services\nand applications (apps) to access a user's account data for tasks such as\nsingle sign-on (SSO), calendar integration, and sending email on behalf of the\nuser, among others. Despite their prevalence, API access could pose significant\nprivacy and security risks, where a third-party could have unexpected\nprivileges to a user's account. To gauge users' perceptions and concerns\nregarding third-party apps that integrate with online APIs, we performed a\nmulti-part online survey of Google users. First, we asked n = 432 participants\nto recall if and when they allowed third-party access to their Google account:\n89% recalled using at least one SSO and 52% remembered at least one third-party\napp. In the second survey, we re-recruited n = 214 participants to ask about\nspecific apps and SSOs they've authorized on their own Google accounts. We\ncollected in-the-wild data about users' actual SSOs and authorized apps: 86%\nused Google SSO on at least one service, and 67% had at least one third-party\napp authorized. After examining their apps and SSOs, participants expressed the\nmost concern about access to personal information like email addresses and\nother publicly shared info. However, participants were less concerned with\nbroader -- and perhaps more invasive -- access to calendars, emails, or cloud\nstorage (as needed by third-party apps). This discrepancy may be due in part to\ntrust transference to apps that integrate with Google, forming an implied\npartnership. Our results suggest opportunities for design improvements to the\ncurrent third-party management tools offered by Google; for example, tracking\nrecent access, automatically revoking access due to app disuse, and providing\npermission controls.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.13484,regular,pre_llm,2021,11,"{'ai_likelihood': 2.0629829830593535e-05, 'text': 'RLWE/PLWE equivalence for the maximal totally real subextension of the\n  $2^rpq$-th cyclotomic field\n\n  We prove the RLWE/PLWE equivalence for the maximal totally real subextension\nof the $2^rpq$-th cyclotomic field and discuss some of its applications to\ncryptoanalysis.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.00703,review,pre_llm,2021,11,"{'ai_likelihood': 5.960464477539062e-07, 'text': ""An Empirical Analysis of HTTPS Configuration Security\n\n  It is notoriously difficult to securely configure HTTPS, and poor server\nconfigurations have contributed to several attacks including the FREAK, Logjam,\nand POODLE attacks. In this work, we empirically evaluate the TLS security\nposture of popular websites and endeavor to understand the configuration\ndecisions that operators make. We correlate several sources of influence on\nsites' security postures, including software defaults, cloud providers, and\nonline recommendations. We find a fragmented web ecosystem: while most websites\nhave secure configurations, this is largely due to major cloud providers that\noffer secure defaults. Individually configured servers are more often insecure\nthan not. This may be in part because common resources available to individual\noperators -- server software defaults and online configuration guides -- are\nfrequently insecure. Our findings highlight the importance of considering SaaS\nservices separately from individually-configured sites in measurement studies,\nand the need for server software to ship with secure defaults.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.09626,regular,pre_llm,2021,11,"{'ai_likelihood': 8.609559800889757e-07, 'text': 'Enhancing the Insertion of NOP Instructions to Obfuscate Malware via\n  Deep Reinforcement Learning\n\n  Current state-of-the-art research for tackling the problem of malware\ndetection and classification is centered on the design, implementation and\ndeployment of systems powered by machine learning because of its ability to\ngeneralize to never-before-seen malware families and polymorphic mutations.\nHowever, it has been shown that machine learning models, in particular deep\nneural networks, lack robustness against crafted inputs (adversarial examples).\nIn this work, we have investigated the vulnerability of a state-of-the-art\nshallow convolutional neural network malware classifier against the dead code\ninsertion technique. We propose a general framework powered by a Double\nQ-network to induce misclassification over malware families. The framework\ntrains an agent through a convolutional neural network to select the optimal\npositions in a code sequence to insert dead code instructions so that the\nmachine learning classifier mislabels the resulting executable. The experiments\nshow that the proposed method significantly drops the classification accuracy\nof the classifier to 56.53% while having an evasion rate of 100% for the\nsamples belonging to the Kelihos_ver3, Simda, and Kelihos_ver1 families. In\naddition, the average number of instructions needed to mislabel malware in\ncomparison to a random agent decreased by 33%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.12026,regular,pre_llm,2021,11,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'CINNAMON: A Module for AUTOSAR Secure Onboard Communication\n\n  This paper introduces CINNAMON, a software module that extends and seamlessly\nintegrates with the AUTOSAR ""Secure Onboard Communication"" (SecOC) module to\nalso account for confidentiality of data in transit. It stands for\nConfidential, INtegral aNd Authentic on board coMunicatiON (CINNAMON). It takes\na resource-efficient and practical approach to ensure, at the same time,\nconfidentiality, integrity and authenticity of frames. The main new requirement\nthat CINNAMON puts forward is the use of encryption and thus, as a result,\nCINNAMON exceeds SecOC against information gathering attacks. This paper sets\nforth the essential requirements and specification of the new module by\ndetailing where and how to position it within AUTOSAR and by emphasizing the\nrelevant upgrades with respect to SecOC. The presentation continues with the\ndefinition of a Security Profile and a summary of a prototype implementation of\nours. While CINNAMON is easily extensible, for example through the definition\nof additional profiles, the current performances obtained on inexpensive boards\nsupport the claim that the approach is feasible.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.10642,regular,pre_llm,2021,11,"{'ai_likelihood': 4.5365757412380644e-06, 'text': 'TOUCAN: A proTocol tO secUre Controller Area Network\n\n  Modern cars are no longer purely mechanical devices but shelter so much\ndigital technology that they resemble a network of computers. Electronic\nControl Units (ECUs) need to exchange a large amount of data for the various\nfunctions of the car to work, and such data must be made secure if we want\nthose functions to work as intended despite malicious activity by attackers.\nTOUCAN is a new security protocol designed to be secure and at the same time\nboth CAN and AUTOSAR compliant. It achieves security in terms of authenticity,\nintegrity and confidentiality, yet without the need to upgrade (the hardware\nof) existing ECUs or enrich the network with novel components. The overhead is\ntiny, namely a reduction of the size of the Data field of a frame. A prototype\nimplementation exhibits promising performance on a STM32F407Discovery board.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.03859,review,pre_llm,2021,11,"{'ai_likelihood': 1.1920928955078125e-05, 'text': 'Cryptography Vulnerabilities on HackerOne\n\n  Previous studies have shown that cryptography is hard for developers to use\nand misusing cryptography leads to severe security vulnerabilities. We studied\nrelevant vulnerability reports on the HackerOne bug bounty platform to\nunderstand what types of cryptography vulnerabilities exist in the wild. We\nextracted eight themes of vulnerabilities from the vulnerability reports and\ndiscussed their real-world implications and mitigation strategies. We hope that\nour findings alert developers, familiarize them with the dire consequences of\ncryptography misuses, and support them in avoiding such mistakes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.08893,review,pre_llm,2021,11,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Understanding Security Issues in the NFT Ecosystem\n\n  Non-Fungible Tokens (NFTs) have emerged as a way to collect digital art as\nwell as an investment vehicle. Despite having been popularized only recently,\nNFT markets have witnessed several high-profile (and high-value) asset sales\nand a tremendous growth in trading volumes over the last year. Unfortunately,\nthese marketplaces have not yet received much security scrutiny. Instead, most\nacademic research has focused on attacks against decentralized finance (DeFi)\nprotocols and automated techniques to detect smart contract vulnerabilities. To\nthe best of our knowledge, we are the first to study the market dynamics and\nsecurity issues of the multi-billion dollar NFT ecosystem.\n  In this paper, we first present a systematic overview of how the NFT\necosystem works, and we identify three major actors: marketplaces, external\nentities, and users. We perform an in-depth analysis of the top 8 marketplaces\n(ranked by transaction volume) to discover potential issues associated with\nsuch marketplaces. Many of these issues can lead to substantial financial\nlosses. We also collected a large amount of asset and event data pertaining to\nthe NFTs being traded in the examined marketplaces. We automatically analyze\nthis data to understand how the entities external to the blockchain are able to\ninterfere with NFT markets, leading to serious consequences, and quantify the\nmalicious trading behaviors carried out by users under the cloak of anonymity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.07093,regular,pre_llm,2021,11,"{'ai_likelihood': 4.172325134277344e-06, 'text': 'AttacKG: Constructing Technique Knowledge Graph from Cyber Threat\n  Intelligence Reports\n\n  Cyber attacks are becoming more sophisticated and diverse, making detection\nincreasingly challenging. To combat these attacks, security practitioners\nactively summarize and exchange their knowledge about attacks across\norganizations in the form of cyber threat intelligence (CTI) reports. However,\nas CTI reports written in natural language texts are not structured for\nautomatic analysis, the report usage requires tedious manual efforts of cyber\nthreat intelligence recovery. Additionally, individual reports typically cover\nonly a limited aspect of attack patterns (techniques) and thus are insufficient\nto provide a comprehensive view of attacks with multiple variants. To take\nadvantage of threat intelligence delivered by CTI reports, we propose AttacKG\nto automatically extract structured attack behavior graphs from CTI reports and\nidentify the adopted attack techniques. We then aggregate cyber threat\nintelligence across reports to collect different aspects of techniques and\nenhance attack behavior graphs into technique knowledge graphs (TKGs). In our\nevaluation against 1,515 real-world CTI reports from diverse intelligence\nsources, AttacKG effectively identifies 28,262 attack techniques with 8,393\nunique Indicators of Compromises (IoCs). To further verify the accuracy of\nAttacKG in extracting threat intelligence, we run AttacKG on 16 manually\nlabeled CTI reports. Empirical results show that AttacKG accurately identifies\nattack-relevant entities, dependencies, and techniques with F1-scores of 0.887,\n0.896, and 0.789, which outperforms the state-of-the-art approaches Extractor\nand TTPDrill. Moreover, the unique technique-level intelligence will directly\nbenefit downstream security tasks that rely on technique specifications, e.g.,\nAPT detection and cyber attack reconstruction.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.02011,review,pre_llm,2021,11,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'Differential Privacy in Cognitive Radio Networks: A Comprehensive Survey\n\n  Background/Introduction: Integrating cognitive radio (CR) with traditional\nwireless networks is helping solve the problem of spectrum scarcity in an\nefficient manner. The opportunistic and dynamic spectrum access features of CR\nprovide the functionality to its unlicensed users to utilize the underutilized\nspectrum at the time of need because CR nodes can sense vacant bands of\nspectrum and can also access them to carry out communication. Various\ncapabilities of CR nodes depend upon efficient and continuous reporting of data\nwith each other and centralized base stations, which in turn can cause leakage\nin privacy. Experimental studies have shown that the privacy of CR users can be\ncompromised easily during the cognition cycle, because they are knowingly or\nunknowingly sharing various personally identifiable information (PII), such as\nlocation, device ID, signal status, etc. In order to preserve this privacy\nleakage, various privacy preserving strategies have been developed by\nresearchers, and according to us differential privacy is the most significant\namong them.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.02583,regular,pre_llm,2021,11,"{'ai_likelihood': 2.317958407931858e-07, 'text': ""CryptoNite: Revealing the Pitfalls of End-to-End Private Inference at\n  Scale\n\n  The privacy concerns of providing deep learning inference as a service have\nunderscored the need for private inference (PI) protocols that protect users'\ndata and the service provider's model using cryptographic methods. Recently\nproposed PI protocols have achieved significant reductions in PI latency by\nmoving the computationally heavy homomorphic encryption (HE) parts to an\noffline/pre-compute phase. Paired with recent optimizations that tailor\nnetworks for PI, these protocols have achieved performance levels that are\ntantalizingly close to being practical. In this paper, we conduct a rigorous\nend-to-end characterization of PI protocols and optimization techniques and\nfind that the current understanding of PI performance is overly optimistic.\nSpecifically, we find that offline storage costs of garbled circuits (GC), a\nkey cryptographic protocol used in PI, on user/client devices are prohibitively\nhigh and force much of the expensive offline HE computation to the online\nphase, resulting in a 10-1000$\\times$ increase to PI latency. We propose a\nmodified PI protocol that significantly reduces client-side storage costs for a\nsmall increase in online latency. Evaluated end-to-end, the modified protocol\noutperforms current protocols by reducing the mean PI latency by $4\\times$ for\nResNet18 on TinyImageNet. We conclude with a discussion of several recently\nproposed PI optimizations in light of the findings and note many actually\nincrease PI latency when evaluated from an end-to-end perspective.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.0519,regular,pre_llm,2021,11,"{'ai_likelihood': 1.1258655124240452e-06, 'text': 'QUDOS: Quorum-Based Cloud-Edge Distributed DNNs for Security Enhanced\n  Industry 4.0\n\n  Distributed machine learning algorithms that employ Deep Neural Networks\n(DNNs) are widely used in Industry 4.0 applications, such as smart\nmanufacturing. The layers of a DNN can be mapped onto different nodes located\nin the cloud, edge and shop floor for preserving privacy. The quality of the\ndata that is fed into and processed through the DNN is of utmost importance for\ncritical tasks, such as inspection and quality control. Distributed Data\nValidation Networks (DDVNs) are used to validate the quality of the data.\nHowever, they are prone to single points of failure when an attack occurs. This\npaper proposes QUDOS, an approach that enhances the security of a distributed\nDNN that is supported by DDVNs using quorums. The proposed approach allows\nindividual nodes that are corrupted due to an attack to be detected or excluded\nwhen the DNN produces an output. Metrics such as corruption factor and success\nprobability of an attack are considered for evaluating the security aspects of\nDNNs. A simulation study demonstrates that if the number of corrupted nodes is\nless than a given threshold for decision-making in a quorum, the QUDOS approach\nalways prevents attacks. Furthermore, the study shows that increasing the size\nof the quorum has a better impact on security than increasing the number of\nlayers. One merit of QUDOS is that it enhances the security of DNNs without\nrequiring any modifications to the algorithm and can therefore be applied to\nother classes of problems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.03537,regular,pre_llm,2021,11,"{'ai_likelihood': 1.457002427842882e-06, 'text': ""A practical analysis of ROP attacks\n\n  Control Flow Hijacking attacks have posed a serious threat to the security of\napplications for a long time where an attacker can damage the control Flow\nIntegrity of the program and execute arbitrary code. These attacks can be\nperformed by injecting code in the program's memory or reusing already existing\ncode in the program (also known as Code-Reuse Attacks). Code-Reuse Attacks in\nthe form of Return-into-libc Attacks or Return-Oriented Programming Attacks are\nsaid to be Turing Complete, providing a guarantee that there will always exist\ncode segments (also called ROP gadgets) within a binary allowing an attacker to\nperform any kind of function by building a suitable ROP chain (chain of ROP\ngadgets). Our goal is to study different techniques of performing ROP Attacks\nand find the difficulties encountered to perform such attacks. For this\npurpose, we have designed an automated tool which works on 64-bit systems and\ngenerates a ROP chain from ROP gadgets to execute arbitrary system calls.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.12323,regular,pre_llm,2021,11,"{'ai_likelihood': 2.980232238769531e-07, 'text': ""Information Dispersal with Provable Retrievability for Rollups\n\n  The ability to verifiably retrieve transaction or state data stored off-chain\nis crucial to blockchain scaling techniques such as rollups or sharding. We\nformalize the problem and design a storage- and communication-efficient\nprotocol using linear erasure-correcting codes and homomorphic vector\ncommitments. Motivated by application requirements for rollups, our solution\nSemi-AVID-PR departs from earlier Verifiable Information Dispersal schemes in\nthat we do not require comprehensive termination properties. Compared to Data\nAvailability Oracles, under no circumstance do we fall back to returning empty\nblocks. Distributing a file of 22 MB among 256 storage nodes, up to 85 of which\nmay be adversarial, requires in total ~70 MB of communication and storage, and\n~41 seconds of single-thread runtime (<3 seconds on 16 threads) on an AMD\nOpteron 6378 processor when using the BLS12-381 curve. Our solution requires no\nmodification to on-chain contracts of Validium rollups such as StarkWare's\nStarkEx. Additionally, it provides privacy of the dispersed data against\nhonest-but-curious storage nodes. Finally, we discuss an application of our\nSemi-AVID-PR scheme to data availability verification schemes based on random\nsampling.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2111.12809,review,pre_llm,2021,11,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'SoK: Plausibly Deniable Storage\n\n  Data privacy is critical in instilling trust and empowering the societal\npacts of modern technology-driven democracies. Unfortunately, it is under\ncontinuous attack by overreaching or outright oppressive governments, including\nsome of the world\'s oldest democracies. Increasingly-intrusive anti-encryption\nlaws severely limit the ability of standard encryption to protect privacy. New\ndefense mechanisms are needed.\n  Plausible deniability (PD) is a powerful property, enabling users to hide the\nexistence of sensitive information in a system under direct inspection by\nadversaries. Popular encrypted storage systems such as TrueCrypt and other\nresearch efforts have attempted to also provide plausible deniability.\nUnfortunately, these efforts have often operated under less well-defined\nassumptions and adversarial models. Careful analyses often uncover not only\nhigh overheads but also outright security compromise. Further, our\nunderstanding of adversaries, the underlying storage technologies, as well as\nthe available plausible deniable solutions have evolved dramatically in the\npast two decades. The main goal of this work is to systematize this knowledge.\nIt aims to:\n  - identify key PD properties, requirements, and approaches;\n  - present a direly-needed unified framework for evaluating security and\nperformance;\n  - explore the challenges arising from the critical interplay between PD and\nmodern system layered stacks;\n  - propose a new ""trace-oriented"" PD paradigm, able to decouple security\nguarantees from the underlying systems and thus ensure a higher level of\nflexibility and security independent of the technology stack.\n  This work is meant also as a trusted guide for system and security\npractitioners around the major challenges in understanding, designing, and\nimplementing plausible deniability into new or existing systems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.06356,review,pre_llm,2021,12,"{'ai_likelihood': 0.0, 'text': ""Evaluation of Security Training and Awareness Programs: Review of\n  Current Practices and Guideline\n\n  Evaluating the effectiveness of security awareness and training programs is\ncritical for minimizing organizations' human security risk. Based on a\nliterature review and industry interviews, we discuss current practices and\ndevise guidelines for measuring the effectiveness of security training and\nawareness initiatives used by organizations\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.13923,regular,pre_llm,2021,12,"{'ai_likelihood': 2.0265579223632812e-05, 'text': 'Forensic Issues and Techniques to Improve Security in SSD with Flex\n  Capacity Feature\n\n  Over-provisioning technology is typically introduced as a means to improve\nthe performance of storage systems, such as databases. The over-provisioning\narea is both hidden and difficult for normal users to access. This paper\nfocuses on attack models for such hidden areas. Malicious hackers use advanced\nover-provisioning techniques that vary capacity according to workload, and as\nsuch, our focus is on attack models that use variable over-provisioning\ntechnology. According to these attack models, it is possible to scan for\ninvalid blocks containing original data or malware code that is hidden in the\nover-provisioning area. In this paper, we outline the different forensic\nprocesses performed for each memory cell type of the over-provisioning area and\ndisclose security enhancement techniques that increase immunity to these attack\nmodels. This leads to a discussion of forensic possibilities and\ncountermeasures for SSDs that can change the over-provisioning area. We also\npresent information-hiding attacks and information-exposing attacks on the\ninvalidation area of the SSD. Our research provides a good foundation upon\nwhich the performance and security of SSD-based databases can be further\nimproved.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.01815,regular,pre_llm,2021,12,"{'ai_likelihood': 2.185503641764323e-06, 'text': 'A Privacy-Preserving Platform for Recording COVID-19 Vaccine Passports\n\n  Digital vaccine passports are one of the main solutions which would allow the\nrestart of travel in a post COVID-19 world. Trust, scalability and security are\nall key challenges one must overcome in implementing a vaccine passport.\nInitial approaches attempt to solve this problem by using centralised systems\nwith trusted authorities. However, sharing vaccine passport data between\ndifferent organisations, regions and countries has become a major challenge.\nThis paper designs a new platform architecture for creating, storing and\nverifying digital COVID-19 vaccine certifications. The platform makes use of\nthe InterPlanetary File System (IPFS) to guarantee there is no single point of\nfailure and allow data to be securely distributed globally. Blockchain and\nsmart contracts are also integrated into the platform to define policies and\nlog access rights to vaccine passport data while ensuring all actions are\naudited and verifiably immutable. Our proposed platform realises General Data\nProtection Regulation (GDPR) requirements in terms of user consent, data\nencryption, data erasure and accountability obligations. We assess the\nscalability and performance of the platform using IPFS and Blockchain test\nnetworks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.12279,regular,pre_llm,2021,12,"{'ai_likelihood': 2.7484363979763457e-06, 'text': 'Randomize the Future: Asymptotically Optimal Locally Private Frequency\n  Estimation Protocol for Longitudinal Data\n\n  Longitudinal data tracking under Local Differential Privacy (LDP) is a\nchallenging task. Baseline solutions that repeatedly invoke a protocol designed\nfor one-time computation lead to linear decay in the privacy or utility\nguarantee with respect to the number of computations. To avoid this, the recent\napproach of Erlingsson et al. (2020) exploits the potential sparsity of user\ndata that changes only infrequently. Their protocol targets the fundamental\nproblem of frequency estimation protocol for longitudinal binary data, with\n$\\ell_\\infty$ error of $O ( (1 / \\epsilon) \\cdot (\\log d)^{3 / 2} \\cdot k \\cdot\n\\sqrt{ n \\cdot \\log ( d / \\beta ) } )$, where $\\epsilon$ is the privacy budget,\n$d$ is the number of time periods, $k$ is the maximum number of changes of user\ndata, and $\\beta$ is the failure probability. Notably, the error bound scales\npolylogarithmically with $d$, but linearly with $k$.\n  In this paper, we break through the linear dependence on $k$ in the\nestimation error. Our new protocol has error $O ( (1 / \\epsilon) \\cdot (\\log d)\n\\cdot \\sqrt{ k \\cdot n \\cdot \\log ( d / \\beta ) } )$, matching the lower bound\nup to a logarithmic factor. The protocol is an online one, that outputs an\nestimate at each time period. The key breakthrough is a new randomizer for\nsequential data, FutureRand, with two key features. The first is a composition\nstrategy that correlates the noise across the non-zero elements of the\nsequence. The second is a pre-computation technique which, by exploiting the\nsymmetry of input space, enables the randomizer to output the results on the\nfly, without knowing future inputs. Our protocol closes the error gap between\nexisting online and offline algorithms.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.05475,review,pre_llm,2021,12,"{'ai_likelihood': 1.1258655124240452e-06, 'text': 'How to Quantify the Security Level of Embedded Systems? A Taxonomy of\n  Security Metrics\n\n  Embedded Systems (ES) development has been historically focused on\nfunctionality rather than security, and today it still applies in many sectors\nand applications. However, there is an increasing number of security threats\nover ES, and a successful attack could have economical, physical or even human\nconsequences, since many of them are used to control critical applications. A\nstandardized and general accepted security testing framework is needed to\nprovide guidance, common reporting forms, and the possibility to compare the\nresults along the time. This can be achieved by introducing security metrics\ninto the evaluation or assessment process. If carefully designed and chosen,\nmetrics could provide a quantitative, repeatable and reproducible value that\nwould reflect the level of security protection of the ES. This paper analyzes\nthe features that a good security metric should exhibit, introduces a taxonomy\nfor classifying them, and finally, it carries out a literature survey on\nsecurity metrics for the security evaluation of ES. In this review, more than\n500 metrics were collected and analyzed. Then, they were reduced to 169 metrics\nthat have the potential to be applied to ES security evaluation. As expected,\nthe 77.5 % of them is related exclusively to software, and only the 0.6 % of\nthem addresses exclusively hardware security. This work aims to lay the\nfoundations for constructing a security evaluation methodology that uses\nmetrics to quantify the security level of an ES.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.05307,regular,pre_llm,2021,12,"{'ai_likelihood': 9.934107462565105e-07, 'text': ""Are We There Yet? Timing and Floating-Point Attacks on Differential\n  Privacy Systems\n\n  Differential privacy is a de facto privacy framework that has seen adoption\nin practice via a number of mature software platforms. Implementation of\ndifferentially private (DP) mechanisms has to be done carefully to ensure\nend-to-end security guarantees. In this paper we study two implementation flaws\nin the noise generation commonly used in DP systems. First we examine the\nGaussian mechanism's susceptibility to a floating-point representation attack.\nThe premise of this first vulnerability is similar to the one carried out by\nMironov in 2011 against the Laplace mechanism. Our experiments show attack's\nsuccess against DP algorithms, including deep learning models trained using\ndifferentially-private stochastic gradient descent.\n  In the second part of the paper we study discrete counterparts of the Laplace\nand Gaussian mechanisms that were previously proposed to alleviate the\nshortcomings of floating-point representation of real numbers. We show that\nsuch implementations unfortunately suffer from another side channel: a novel\ntiming attack. An observer that can measure the time to draw (discrete) Laplace\nor Gaussian noise can predict the noise magnitude, which can then be used to\nrecover sensitive attributes. This attack invalidates differential privacy\nguarantees of systems implementing such mechanisms.\n  We demonstrate that several commonly used, state-of-the-art implementations\nof differential privacy are susceptible to these attacks. We report success\nrates up to 92.56% for floating-point attacks on DP-SGD, and up to 99.65% for\nend-to-end timing attacks on private sum protected with discrete Laplace.\nFinally, we evaluate and suggest partial mitigations.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.02184,review,pre_llm,2021,12,"{'ai_likelihood': 8.212195502387152e-06, 'text': 'V2X Misbehavior and Collective Perception Service: Considerations for\n  Standardization\n\n  Connected and Automated Vehicles use sensors and wireless communication to\nimprove road safety and efficiency. However, attackers may target\nVehicle-to-Everything communication. Indeed, an attacker may send authenticated\nbut wrong data to send false location information, alert incorrect events or\nreport a bogus object endangering the safety of other CAVs. Currently,\nStandardization Development Organizations are working on developing security\nstandards against such attacks. Unfortunately, current standardization efforts\ndo not include misbehavior specifications for advanced V2X services such as\nCollective Perception yet. This work assesses the security of Collective\nPerception Messages and proposes inputs for consideration in existing\nstandards.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.1279,review,pre_llm,2021,12,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Out to Explore the Cybersecurity Planet\n\n  Security ceremonies still fail despite decades of efforts by researchers and\npractitioners. Attacks are often a cunning amalgam of exploits for technical\nsystems and of forms of human behaviour. For example, this is the case with the\nrecent news headline of a large-scale attack against Electrum Bitcoin wallets,\nwhich manages to spread a malicious update of the wallet app. I therefore set\nout to look at things through a different lens. I make the (metaphorical)\nhypothesis that human ancestors arrived on Earth along with security ceremonies\nfrom a very far planet, the Cybersecurity planet. My hypothesis continues, in\nthat studying (by huge telescopes) the surface of Cybersecurity in combination\nwith the logical projection on that surface of what happens on Earth is\nbeneficial for us earthlings. I have spotted four cities so far on the remote\nplanet. Democratic City features security ceremonies that allow inhabitants to\nfollow personal paths of practice and, for example, make errors or be driven by\nemotions. By contrast, security ceremonies in Dictatorial City compel\ninhabitants to comply, thus behaving like programmed automata. Security\nceremonies in Beautiful City are so beautiful that inhabitants just love to\nfollow them precisely. Invisible City has security ceremonies that are not\nperceivable, hence inhabitants feel like they never encounter any.\nIncidentally, we use the words ""democratic"" and ""dictatorial"" without any\npolitical connotation. A key argument I shall develop is that all cities but\nDemocratic City address the human factor, albeit in different ways. In the\nlight of these findings, I will also discuss security ceremonies of our planet,\nsuch as WhatsApp web login and flight boarding, and explore room for improving\nthem based upon the current understanding of Cybersecurity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.02757,review,pre_llm,2021,12,"{'ai_likelihood': 4.967053731282553e-06, 'text': ""Review of Data Integrity Attacks and Mitigation Methods in Edge\n  computing\n\n  In recent years, edge computing has emerged as a promising technology due to\nits unique feature of real-time computing and parallel processing. They provide\ncomputing and storage capacity closer to the data source and bypass the distant\nlinks to the cloud. The edge data analytics process the ubiquitous data on the\nedge layer to offer real-time interactions for the application. However, this\nprocess can be prone to security threats like gaining malicious access or\nmanipulating sensitive data. This can lead to the intruder's control, alter, or\nadd erroneous data affecting the integrity and data analysis efficiency. Due to\nthe lack of transparency of stakeholders processing edge data, it is\nchallenging to identify the vulnerabilities. Many reviews are available on data\nsecurity issues on the edge layer; however, they do not address integrity\nissues exclusively. Therefore, this paper concentrates only on data integrity\nthreats that directly influence edge data analysis. Further shortcomings in\nexisting work are identified with few research directions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.04838,regular,pre_llm,2021,12,"{'ai_likelihood': 5.629327562120226e-07, 'text': 'How Not to Protect Your IP -- An Industry-Wide Break of IEEE 1735\n  Implementations\n\n  Modern hardware systems are composed of a variety of third-party Intellectual\nProperty (IP) cores to implement their overall functionality. Since hardware\ndesign is a globalized process involving various (untrusted) stakeholders, a\nsecure management of the valuable IP between authors and users is inevitable to\nprotect them from unauthorized access and modification. To this end, the widely\nadopted IEEE standard 1735-2014 was created to ensure confidentiality and\nintegrity.\n  In this paper, we outline structural weaknesses in IEEE 1735 that cannot be\nfixed with cryptographic solutions (given the contemporary hardware design\nprocess) and thus render the standard inherently insecure. We practically\ndemonstrate the weaknesses by recovering the private keys of IEEE 1735\nimplementations from major Electronic Design Automation (EDA) tool vendors,\nnamely Intel, Xilinx, Cadence, Siemens, Microsemi, and Lattice, while results\non a seventh case study are withheld. As a consequence, we can decrypt, modify,\nand re-encrypt all allegedly protected IP cores designed for the respective\ntools, thus leading to an industry-wide break. As part of this analysis, we are\nthe first to publicly disclose three RSA-based white-box schemes that are used\nin real-world products and present cryptanalytical attacks for all of them,\nfinally resulting in key recovery.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.02634,regular,pre_llm,2021,12,"{'ai_likelihood': 7.616149054633247e-07, 'text': 'SCMCI: Secured Click and Mortar Commercial Interaction\n\n  The wide spread of click-and-mortar model offers an opportunity to consider a\nuniversal commercial interaction method. However, issues like privacy\nprotection resist the widespread acceptance. Traditional SET and SSL protocols\nare designed using Public Key Infrastructure (PKI) where extensive computations\nare carried out. Our aim is here to design a protocol to secure any type of\ncommercial interaction for online platform, which also considers mobile\nplatform. Therefore, our focus is on reducing heavy computations and making the\noverall procedure faster. A Secured Click and Mortar Commercial Interaction\n(SCMCI) protocol is proposed here to improve the performance of the commercial\ninteraction procedure through replacing time consuming public key encryption\nand decryption algorithms by hybrid logic including the use of symmetric key.\nComparative analysis has been done with traditional SET protocol using cryptool\nto prove the efficiency of the protocol.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.10173,regular,pre_llm,2021,12,"{'ai_likelihood': 3.8080745273166235e-06, 'text': 'Using data compression and randomization to build an unconditionally\n  secure short key cipher\n\n  We consider the problem of constructing an unconditionally secure cipher for\nthe case when the key length is less than the length of the encrypted message.\n(Unconditional security means that a computationally unbounded adversary cannot\nobtain information about the encrypted message without the key.) In this\narticle, we propose data compression and randomization techniques combined with\nentropically-secure encryption. The resulting cipher can be used for encryption\nin such a way that the key length does not depend on the entropy or the length\nof the encrypted message; instead, it is determined by the required security\nlevel.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.02213,regular,pre_llm,2021,12,"{'ai_likelihood': 1.4437569512261285e-05, 'text': 'Node-wise Hardware Trojan Detection Based on Graph Learning\n\n  In the fourth industrial revolution, securing the protection of the supply\nchain has become an ever-growing concern. One such cyber threat is a hardware\nTrojan (HT), a malicious modification to an IC. HTs are often identified in the\nhardware manufacturing process, but should be removed earlier, when the design\nis being specified. Machine learning-based HT detection in gate-level netlists\nis an efficient approach to identify HTs at the early stage. However,\nfeature-based modeling has limitations in discovering an appropriate set of HT\nfeatures. We thus propose NHTD-GL in this paper, a novel node-wise HT detection\nmethod based on graph learning (GL). Given the formal analysis of HT features\nobtained from domain knowledge, NHTD-GL bridges the gap between graph\nrepresentation learning and feature-based HT detection. The experimental\nresults demonstrate that NHTD-GL achieves 0.998 detection accuracy and\noutperforms state-of-the-art node-wise HT detection methods. NHTD-GL extracts\nHT features without heuristic feature engineering.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.14078,review,pre_llm,2021,12,"{'ai_likelihood': 1.457002427842882e-06, 'text': 'Blockchain Meets AI for Resilient and Intelligent Internet of Vehicles\n\n  The Internet of Vehicles (IoV) is flourishing and offers various applications\nrelating to road safety, traffic and fuel efficiency, and infotainment. Dealing\nwith security and privacy threats and managing the trust (detecting malicious\nand misbehaving peers) in IoV remains the most significant concern. Artificial\nIntelligence is one of the most revolutionizing technologies, and the\npredictive power of its machine learning models can help detect intrusions and\nmisbehaviors. Similarly, empowering the state-of-the-art IoV security framework\nwith blockchain can make it secure and resilient. This article discusses joint\nAI and blockchain for security, privacy and trust-related risks in IoV. This\npaper also presents problems, challenges, requirements and solutions using ML\nand blockchain to address aforementioned issues in IoV.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.09932,regular,pre_llm,2021,12,"{'ai_likelihood': 3.311369154188368e-08, 'text': 'System Attack Modeling Techniques Critical Information Infrastructure\n\n  Every day around the world, various organizations are exposed to more than a\nhundred attacks, most of which are success-fully repelled by information\nsecurity specialists. However, attacks are also carried out that some\ninformation systems or specialists are unable to repel, which is why a large\nnumber of enterprises, as well as individuals, suffer huge monetary and\nreputational losses. The aim of the work is to train specialists through cyber\npolygons and interactive games to a high level of knowledge and skills in the\nfield of information security\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.06324,regular,pre_llm,2021,12,"{'ai_likelihood': 0.0, 'text': 'Pool-Party: Exploiting Browser Resource Pools as Side-Channels for Web\n  Tracking\n\n  We identify class of covert channels in browsers that are not mitigated by\ncurrent defenses, which we call ""pool-party"" attacks. Pool-party attacks allow\nsites to create covert channels by manipulating limited-but-unpartitioned\nresource pools. These class of attacks have been known, but in this work we\nshow that they are both more prevalent, more practical for exploitation, and\nallow exploitation in more ways, than previously identified. These covert\nchannels have sufficient bandwidth to pass cookies and identifiers across site\nboundaries under practical and real-world conditions. We identify pool-party\nattacks in all popular browsers, and show they are practical cross-site\ntracking techniques (i.e., attacks take 0.6s in Chrome and Edge, and 7s in\nFirefox and Tor Browser).\n  In this paper we make the following contributions: first, we describe\npool-party covert channel attacks that exploit limits in application-layer\nresource pools in browsers. Second, we demonstrate that pool-party attacks are\npractical, and can be used to track users in all popular browsers; we also\nshare open source implementations of the attack and evaluate them through a\nrepresentative web crawl. Third, we show that in Gecko based-browsers\n(including the Tor Browser) pool-party attacks can also be used for\ncross-profile tracking (e.g., linking user behavior across normal and private\nbrowsing sessions). Finally, we discuss possible mitigation strategies and\ndefenses\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.14821,regular,pre_llm,2021,12,"{'ai_likelihood': 4.635916815863716e-06, 'text': 'Anomaly Detection in Cyber-Physical Systems: Reconstruction of a\n  Prediction Error Feature Space\n\n  Cyber-physical systems are infrastructures that use digital information such\nas network communications and sensor readings to control entities in the\nphysical world. Many cyber-physical systems in airports, hospitals and nuclear\npower plants are regarded as critical infrastructures since a disruption of its\nnormal functionality can result in negative consequences for the society. In\nthe last few years, some security solutions for cyber-physical systems based on\nartificial intelligence have been proposed. Nevertheless, knowledge domain is\nrequired to properly setup and train artificial intelligence algorithms. Our\nwork proposes a novel anomaly detection framework based on error space\nreconstruction, where genetic algorithms are used to perform hyperparameter\noptimization of machine learning methods. The proposed method achieved an\nF1-score of 87.89% in the SWaT dataset.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.04581,regular,pre_llm,2021,12,"{'ai_likelihood': 9.470515780978732e-06, 'text': ""Building Usable Witness Encryption\n\n  Witness encryption using multilinear maps was first proposed in 2013, and has\ncontinued to evolve since. In this paper, we build on an open-source\nmultilinear map implementation by Carmer and Malozemoff of the graded encoding\nscheme CLT13 with asymmetric modifications. Using this map, we created the\nworld's first ciphertext encoded with a candidate witness encryption scheme.\nFinally, using a reduction from Sudoku to Exact Cover, we encrypted the private\nkey to a Bitcoin wallet with 22,700 Satoshi using a Sudoku.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.09411,regular,pre_llm,2021,12,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Towards Intelligent Context-Aware 6G Security\n\n  Imagine interconnected objects with embedded artificial intelligence (AI),\nempowered to sense the environment, see it, hear it, touch it, interact with\nit, and move. As future networks of intelligent objects come to life,\ntremendous new challenges arise for security, but also new opportunities,\nallowing to address current, as well as future, pressing needs. In this paper\nwe put forward a roadmap towards the realization of a new security paradigm\nthat we articulate as intelligent context-aware security. The premise of this\nroadmap is that sensing and advanced AI will enable context awareness, which in\nturn can drive intelligent security mechanisms, such as adaptation and\nautomation of security controls. This concept not only provides immediate\nanswers to burning open questions, in particular with respect to non-functional\nrequirements, such as energy or latency constraints, heterogeneity of radio\nfrequency (RF) technologies and long life span of deployed devices, but also,\nmore importantly, offers a viable answer to scalability by allowing such\nconstraints to be met even in massive connectivity regimes. Furthermore, the\nproposed roadmap has to be designed ethically, by explicitly placing privacy\nconcerns at its core. The path towards this vision and some of the challenges\nalong the way are discussed in this contribution.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2112.07178,regular,pre_llm,2021,12,"{'ai_likelihood': 2.086162567138672e-06, 'text': 'MuxLink: Circumventing Learning-Resilient MUX-Locking Using Graph Neural\n  Network-based Link Prediction\n\n  Logic locking has received considerable interest as a prominent technique for\nprotecting the design intellectual property from untrusted entities, especially\nthe foundry. Recently, machine learning (ML)-based attacks have questioned the\nsecurity guarantees of logic locking, and have demonstrated considerable\nsuccess in deciphering the secret key without relying on an oracle, hence,\nproving to be very useful for an adversary in the fab. Such ML-based attacks\nhave triggered the development of learning-resilient locking techniques. The\nmost advanced state-of-the-art deceptive MUX-based locking (D-MUX) and the\nsymmetric MUX-based locking techniques have recently demonstrated resilience\nagainst existing ML-based attacks. Both defense techniques obfuscate the design\nby inserting key-controlled MUX logic, ensuring that all the secret inputs to\nthe MUXes are equiprobable.\n  In this work, we show that these techniques primarily introduce local and\nlimited changes to the circuit without altering the global structure of the\ndesign. By leveraging this observation, we propose a novel graph neural network\n(GNN)-based link prediction attack, MuxLink, that successfully breaks both the\nD-MUX and symmetric MUX-locking techniques, relying only on the underlying\nstructure of the locked design, i.e., in an oracle-less setting. Our trained\nGNN model learns the structure of the given circuit and the composition of\ngates around the non-obfuscated wires, thereby generating meaningful link\nembeddings that help decipher the secret inputs to the MUXes. The proposed\nMuxLink achieves key prediction accuracy and precision up to 100% on D-MUX and\nsymmetric MUX-locked ISCAS-85 and ITC-99 benchmarks, fully unlocking the\ndesigns. We open-source MuxLink [1].\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.0792,regular,pre_llm,2022,1,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Shades of Finality and Layer 2 Scaling\n\n  Blockchains combine a distributed append-only log with a virtual machine that\ndefines how log entries are interpreted. By viewing transactions as state\ntransformation functions for the virtual machine, we separate the naming of a\nstate from the computation of its value and reaching consensus on that value.\nThis distinction allows us to separate the notion of transaction order finality\nfrom state value finality. Further consideration of how blockchain governance\nhandles catastrophic failures such as zero day exploits leads us to the notion\nof checkpoint finality.\n  Consensus on the transaction order determines the ground truth. Everything\nelse -- computing the value of a state or handling catastrophic failures such\nas bugs / zero-day based attacks -- are just optimizations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.11368,regular,pre_llm,2022,1,"{'ai_likelihood': 1.9305282168918187e-05, 'text': 'Prediction and Detection of FDIA and DDoS Attacks in 5G Enabled IoT\n\n  Security in the fifth generation (5G) networks has become one of the prime\nconcerns in the telecommunication industry. 5G security challenges come from\nthe fact that 5G networks involve different stakeholders using different\nsecurity requirements and measures. Deficiencies in security management between\nthese stakeholders can lead to security attacks. Therefore, security solutions\nshould be conceived for the safe deployment of different 5G verticals (e.g.,\nindustry 4.0, Internet of Things (IoT), etc.). The interdependencies among 5G\nand fully connected systems, such as IoT, entail some standard security\nrequirements, namely integrity, availability, and confidentiality. In this\narticle, we propose a hierarchical architecture for securing 5G enabled IoT\nnetworks, and a security model for the prediction and detection of False Data\nInjection Attacks (FDIA) and Distributed Denial of Service attacks (DDoS). The\nproposed security model is based on a Markov stochastic process, which is used\nto observe the behavior of each network device, and employ a range-based\nbehavior sifting policy. Simulation results demonstrate the effectiveness of\nthe proposed architecture and model in detecting and predicting FDIA and DDoS\nattacks in the context of 5G enabled IoT.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.05931,regular,pre_llm,2022,1,"{'ai_likelihood': 3.311369154188368e-08, 'text': 'On eliminating blocking interference of RFID unauthorized reader\n  detection system\n\n  RFID as an important component technology of IoT faces important security\nrisks while being rapidly applied, among which the discovery of unauthorized\nreaders in space is crucial. There are some researches proposed the\nunauthorized reader detection algorithm based on commercial off the shell(COTS)\ndevices, but these detection algorithms are often easily affected by moving\nobjects blocking interference in space, causing false alarms. We propose a new\nmethod of eliminating moving object interference, which can reduce the system\nfalse alarm rate to less than 7.9% by experimental testing\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.09035,regular,pre_llm,2022,1,"{'ai_likelihood': 2.7484363979763457e-06, 'text': ""On How Zero-Knowledge Proof Blockchain Mixers Improve, and Worsen User\n  Privacy\n\n  Zero-knowledge proof (ZKP) mixers are one of the most widely-used blockchain\nprivacy solutions, operating on top of smart contract-enabled blockchains. We\nfind that ZKP mixers are tightly intertwined with the growing number of\nDecentralized Finance (DeFi) attacks and Blockchain Extractable Value (BEV)\nextractions. Through coin flow tracing, we discover that 205 blockchain\nattackers and 2,595 BEV extractors leverage mixers as their source of funds,\nwhile depositing a total attack revenue of 412.87M USD. Moreover, the US OFAC\nsanctions against the largest ZKP mixer, Tornado.Cash, have reduced the mixer's\ndaily deposits by more than 80%.\n  Further, ZKP mixers advertise their level of privacy through a so-called\nanonymity set size, which similarly to k-anonymity allows a user to hide among\na set of k other users. Through empirical measurements, we, however, find that\nthese anonymity set claims are mostly inaccurate. For the most popular mixers\non Ethereum (ETH) and Binance Smart Chain (BSC), we show how to reduce the\nanonymity set size on average by 27.34% and 46.02% respectively. Our empirical\nevidence is also the first to suggest a differing privacy-predilection of users\non ETH and BSC.\n  State-of-the-art ZKP mixers are moreover interwoven with the DeFi ecosystem\nby offering anonymity mining (AM) incentives, i.e., users receive monetary\nrewards for mixing coins. However, contrary to the claims of related work, we\nfind that AM does not necessarily improve the quality of a mixer's anonymity\nset. Our findings indicate that AM attracts privacy-ignorant users, who then do\nnot contribute to improving the privacy of other mixer users.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.00099,review,pre_llm,2022,1,"{'ai_likelihood': 8.27842288547092e-07, 'text': ""Differential Privacy Made Easy\n\n  Data privacy is a major issue for many decades, several techniques have been\ndeveloped to make sure individuals' privacy but still world has seen privacy\nfailures. In 2006, Cynthia Dwork gave the idea of Differential Privacy which\ngave strong theoretical guarantees for data privacy. Many companies and\nresearch institutes developed differential privacy libraries, but in order to\nget the differentially private results, users have to tune the privacy\nparameters. In this paper, we minimized these tune-able parameters. The\nDP-framework is developed which compares the differentially private results of\nthree Python based DP libraries. We also introduced a new very simple DP\nlibrary (GRAM-DP), so the people with no background of differential privacy can\nstill secure the privacy of the individuals in the dataset while releasing\nstatistical results in public.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.03135,regular,pre_llm,2022,1,"{'ai_likelihood': 3.112687004937066e-06, 'text': 'The SEED Internet Emulator and Its Applications in Cybersecurity\n  Education\n\n  In cybersecurity courses, it is quite challenging to do hands-on activities\nthat involve many components of the Internet, such as bringing down the\nInternet, attacking a blockchain, etc. To solve this problem, we have developed\nan open-source Internet Emulator, which is a Python library, consisting of the\nclasses for each essential element of the Internet, including autonomous\nsystem, network, host, router, BGP router, Internet exchange, etc. It also\nincludes the classes for a variety of services, including Web server, DNS,\nBotnet, Darknet, Blockchain, and more are being developed. Using these classes,\nusers can construct a mini-Internet to emulate the real-world Internet.\nAlthough it is small, it has all the essential elements of the real Internet.\nThe construction is compiled into Docker container files, and the emulation is\nexecuted by Docker on a single machine, or on multiple cloud machines.\n  With this Internet Emulator, we can develop a variety of hands-on activities\nfor cybersecurity courses, including BGP prefix hijacking, attacks on smart\ncontract, using Darknet to achieve anonymity, launching Botnet and ransomware\nattacks, etc. While the emulator was initially developed for cybersecurity\ncourses, it can also be used for network courses, for students to learn how the\nInternet technologies work, such as routing, BGP, IP Anycast, and DNS. Many\nother interesting network technologies can also be deployed on the emulator,\nsuch as content delivery network and software-defined network.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.10833,regular,pre_llm,2022,1,"{'ai_likelihood': 3.642506069607205e-07, 'text': 'Automatic detection of access control vulnerabilities via API\n  specification processing\n\n  Objective. Insecure Direct Object Reference (IDOR) or Broken Object Level\nAuthorization (BOLA) are one of the critical type of access control\nvulnerabilities for modern applications. As a result, an attacker can bypass\nauthorization checks leading to information leakage, account takeover. Our main\nresearch goal was to help an application security architect to optimize\nsecurity design and testing process by giving an algorithm and tool that allows\nto automatically analyze system API specifications and generate list of\npossible vulnerabilities and attack vector ready to be used as security\nnon-functional requirements. Method. We conducted a multivocal review of\nresearch and conference papers, bug bounty program reports and other grey\nsources of literature to outline patterns of attacks against IDOR\nvulnerability. These attacks are collected in groups proceeding with further\nanalysis common attributes between these groups and what features compose the\ngroup. Endpoint properties and attack techniques comprise a group of attacks.\nMapping between group features and existing OpenAPI specifications is performed\nto implement a tool for automatic discovery of potentially vulnerable\nendpoints. Results and practical relevance. In this work, we provide\nsystematization of IDOR/BOLA attack techniques based on literature review, real\ncases analysis and derive IDOR/BOLA attack groups. We proposed an approach to\ndescribe IDOR/BOLA attacks based on OpenAPI specifications properties. We\ndevelop an algorithm of potential IDOR/BOLA vulnerabilities detection based on\nOpenAPI specification processing. We implemented our novel algorithm using\nPython and evaluated it. The results show that algorithm is resilient and can\nbe used in practice to detect potential IDOR/BOLA vulnerabilities.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.06785,regular,pre_llm,2022,1,"{'ai_likelihood': 1.7881393432617188e-06, 'text': 'Challenges of Return-Oriented-Programming on the Xtensa Hardware\n  Architecture\n\n  This paper shows how the Xtensa architecture can be attacked with\nReturn-Oriented-Programming (ROP). The presented techniques include\npossibilities for both supported Application Binary Interfaces (ABIs).\nEspecially for the windowed ABI a powerful mechanism is presented that not only\nallows to jump to gadgets but also to manipulate registers without relying on\nspecific gadgets. This paper purely focuses on how the properties of the\narchitecture itself can be exploited to chain gadgets and not on specific\nattacks or a gadget catalog.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.07765,regular,pre_llm,2022,1,"{'ai_likelihood': 8.609559800889757e-07, 'text': ""Towards Situational Aware Cyber-Physical Systems: A Security-Enhancing\n  Use Case of Blockchain-based Digital Twins\n\n  The complexity of cyberattacks in Cyber-Physical Systems (CPSs) calls for a\nmechanism that can evaluate critical infrastructures' operational behaviour and\nsecurity without affecting the operation of live systems. In this regard,\nDigital Twins (DTs) provide actionable insights through monitoring, simulating,\npredicting, and optimizing the state of CPSs. Through the use cases, including\nsystem testing and training, detecting system misconfigurations, and security\ntesting, DTs strengthen the security of CPSs throughout the product lifecycle.\nHowever, such benefits of DTs depend on an assumption about data integrity and\nsecurity. Data trustworthiness becomes more critical while integrating multiple\ncomponents among different DTs owned by various stakeholders to provide an\naggregated view of the complex physical system. This article envisions a\nblockchain-based DT framework as Trusted Twins for Securing Cyber-Physical\nSystems (TTS-CPS). With the automotive industry as a CPS use case, we\ndemonstrate the viability of the TTS-CPS framework in a proof of concept. To\nutilize reliable system specification data for building the process knowledge\nof DTs, we ensure the trustworthiness of data-generating sources through\nintegrity checking mechanisms. Additionally, the safety and security rules\nevaluated during simulation are stored and retrieved from the blockchain,\nthereby establishing more understanding and confidence in the decisions made by\nthe underlying systems. Finally, we perform formal verification of the TTS-CPS.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.10473,regular,pre_llm,2022,1,"{'ai_likelihood': 1.4901161193847656e-06, 'text': 'Faster multiplication over $\\mathbb{F}_2[X]$ using AVX512 instruction\n  set and VPCLMULQDQ instruction\n\n  Code-based cryptography is one of the main propositions for the post-quantum\ncryptographic context, and several protocols of this kind have been submitted\non the NIST platform. Among them, BIKE and HQC are part of the five alternate\ncandidates selected in the third round of the NIST standardization process in\nthe KEM category. These two schemes make use of multiplication of large\npolynomials over binary rings, and due to the polynomial size (from 10,000 to\n60,000 bits), this operation is one of the costliest during key generation,\nencapsulation, or decapsulation mechanisms. In this work, we revisit the\ndifferent existing constant-time algorithms for arbitrary polynomial\nmultiplication. We explore the different Karatsuba and Toom-Cook constructions\nin order to determine the best combinations for each polynomial degree range,\nin the context of AVX2 and AVX512 instruction sets. This leads to different\nkernels and constructions in each case. In particular, in the context of\nAVX512, we use the VPCLMULQDQ instruction, which is a vectorized binary\npolynomial multiplication instruction. This instruction deals with up to four\npolynomial (of degree up to 63) multiplications, the four results being stored\nin one single 512-bit word. This allows to divide by roughly 3 the retired\ninstruction number of the operation in comparison with the AVX2 instruction set\nimplementations, while the speedup is up to 39% in terms of processor clock\ncycles. These results are different than the ones estimated in Drucker (Fast\nmultiplication of binary polynomials with the forthcoming vectorized vpclmulqdq\ninstruction, 2018). To illustrate the benefit of the new VPCLMULQDQ\ninstruction, we used the HQC code to evaluate our approaches. When implemented\nin the HQC protocol, for the security levels 128, 192, and 256, our approaches\nprovide up to 12% speedup, for key pair generation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.05199,regular,pre_llm,2022,1,"{'ai_likelihood': 8.344650268554688e-06, 'text': 'D-Box: DMA-enabled Compartmentalization for Embedded Applications\n\n  Embedded and Internet-of-Things (IoT) devices have seen an increase in\nadoption in many domains. The security of these devices is of great importance\nas they are often used to control critical infrastructure, medical devices, and\nvehicles. Existing solutions to isolate microcontroller (MCU) resources in\norder to increase their security face significant challenges such as specific\nhardware unavailability, Memory Protection Unit (MPU) limitations and a\nsignificant lack of Direct Memory Access (DMA) support. Nevertheless, DMA is\nfundamental for the power and performance requirements of embedded\napplications. In this paper, we present D-Box, a systematic approach to enable\nsecure DMA operations for compartmentalization solutions of embedded\napplications using real-time operating systems (RTOS). D-Box defines a\nreference architecture and a workflow to protect DMA operations holistically.\nIt provides practical methods to harden the kernel and define capability-based\nsecurity policies for easy definition of DMA operations with strong security\nproperties. We implemented a D-Box prototype for the Cortex-M3/M4 on top of the\npopular FreeRTOS-MPU (F-MPU). The D-Box procedures and a stricter security\nmodel enabled DMA operations, yet it exposed 41 times less ROP\n(return-orienting-programming) gadgets when compared with the standard F-MPU.\nD-Box adds only a 2% processor overhead while reducing the power consumption of\nperipheral operation benchmarks by 18.2%. The security properties and\nperformance of D-Box were tested and confirmed on a real-world case study of a\nProgrammable Logic Controller (PLC) application.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.05671,regular,pre_llm,2022,1,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Zef: Low-latency, Scalable, Private Payments\n\n  We introduce Zef, the first Byzantine-Fault Tolerant (BFT) protocol to\nsupport payments in anonymous digital coins at arbitrary scale. Zef follows the\ncommunication and security model of FastPay: both protocols are asynchronous,\nlow-latency, linearly-scalable, and powered by partially-trusted sharded\nauthorities. Zef further introduces opaque coins represented as off-chain\ncertificates that are bound to user accounts. In order to hide the face values\nof coins when a payment operation consumes or creates them, Zef uses random\ncommitments and NIZK proofs. Created coins are made unlinkable using the blind\nand randomizable threshold anonymous credentials of Coconut. To control storage\ncosts associated with coin replay prevention, Zef accounts are designed so that\ndata can be safely removed once an account is deactivated. Besides the\nspecifications and a detailed analysis of the protocol, we are making available\nan open-source implementation of Zef in Rust. Our extensive benchmarks on AWS\nconfirm textbook linear scalability and demonstrate a confirmation time under\none second at nominal capacity. Compared to existing anonymous payment systems\nbased on a blockchain, this represents a latency speedup of three orders of\nmagnitude, with no theoretical limit on throughput.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.13077,review,pre_llm,2022,1,"{'ai_likelihood': 9.271833631727431e-07, 'text': 'An Overview of Various Biometric Approaches: ECG One of its Trait\n\n  A Bio-metrics system is actually a pattern recognition system that utilizes\nvarious patterns like iris, retina and biological traits like fingerprint,\nvoice recognition, facial geometry and hand geometry. What makes Bio-metrics\nreally attractive is that the various security codes like passwords and ID\ncards can be interchanged, stolen or duplicated. To enhance the security and\nreliability of the system, physiological traits can be used. This paper gives\nthe overview of key bio-metric technologies and basic techniques involved and\ntheir drawbacks. Then the paper illustrates the working of ECG and the various\nopportunities for ECG are also mentioned.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.0812,review,pre_llm,2022,1,"{'ai_likelihood': 7.28501213921441e-07, 'text': ""Survey on Privacy-Preserving Techniques for Data Publishing\n\n  The exponential growth of collected, processed, and shared microdata has\ngiven rise to concerns about individuals' privacy. As a result, laws and\nregulations have emerged to control what organisations do with microdata and\nhow they protect it. Statistical Disclosure Control seeks to reduce the risk of\nconfidential information disclosure by de-identifying them. Such\nde-identification is guaranteed through privacy-preserving techniques. However,\nde-identified data usually results in loss of information, with a possible\nimpact on data analysis precision and model predictive performance. The main\ngoal is to protect the individuals' privacy while maintaining the\ninterpretability of the data, i.e. its usefulness. Statistical Disclosure\nControl is an area that is expanding and needs to be explored since there is\nstill no solution that guarantees optimal privacy and utility. This survey\nfocuses on all steps of the de-identification process. We present existing\nprivacy-preserving techniques used in microdata de-identification, privacy\nmeasures suitable for several disclosure types and, information loss and\npredictive performance measures. In this survey, we discuss the main challenges\nraised by privacy constraints, describe the main approaches to handle these\nobstacles, review taxonomies of privacy-preserving techniques, provide a\ntheoretical analysis of existing comparative studies, and raise multiple open\nissues.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.02007,regular,pre_llm,2022,1,"{'ai_likelihood': 9.602970547146267e-07, 'text': 'Flexible FPGA ECDSA Design with a Field Multiplier Inherently Resistant\n  against HCCA\n\n  In this paper we describe our flexible ECDSA design for elliptic curve over\nbinary extended fields GF(2l). We investigated its resistance against\nHorizontal Collision Correlation Attacks (HCCA). Due to the fact that our\ndesign is based on the Montgomery kP algorithm using Lopez-Dahab projective\ncoordinates the scalar k cannot be successful revealed using HCCA, but this\nkind of attacks can be helpful to divide the measured traces into parts that\ncorrespond to processing of a single bit of the scalar k. The most important\ncontribution of this paper is that our flexible field multiplier is resistant\nagainst horizontal attacks. This inherent resistance makes it a valuable\nbuilding block for designing unified field multipliers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.09956,regular,pre_llm,2022,1,"{'ai_likelihood': 9.602970547146268e-06, 'text': ""DRAWNAPART: A Device Identification Technique based on Remote GPU\n  Fingerprinting\n\n  Browser fingerprinting aims to identify users or their devices, through\nscripts that execute in the users' browser and collect information on software\nor hardware characteristics. It is used to track users or as an additional\nmeans of identification to improve security. In this paper, we report on a new\ntechnique that can significantly extend the tracking time of fingerprint-based\ntracking methods. Our technique, which we call DrawnApart, is a new GPU\nfingerprinting technique that identifies a device based on the unique\nproperties of its GPU stack. Specifically, we show that variations in speed\namong the multiple execution units that comprise a GPU can serve as a reliable\nand robust device signature, which can be collected using unprivileged\nJavaScript. We investigate the accuracy of DrawnApart under two scenarios. In\nthe first scenario, our controlled experiments confirm that the technique is\neffective in distinguishing devices with similar hardware and software\nconfigurations, even when they are considered identical by current\nstate-of-the-art fingerprinting algorithms. In the second scenario, we\nintegrate a one-shot learning version of our technique into a state-of-the-art\nbrowser fingerprint tracking algorithm. We verify our technique through a\nlarge-scale experiment involving data collected from over 2,500 crowd-sourced\ndevices over a period of several months and show it provides a boost of up to\n67% to the median tracking duration, compared to the state-of-the-art method.\nDrawnApart makes two contributions to the state of the art in browser\nfingerprinting. On the conceptual front, it is the first work that explores the\nmanufacturing differences between identical GPUs and the first to exploit these\ndifferences in a privacy context. On the practical front, it demonstrates a\nrobust technique for distinguishing between machines with identical hardware\nand software configurations.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.00484,regular,pre_llm,2022,1,"{'ai_likelihood': 0.0, 'text': 'Secure Spectrum and Resource Sharing for 5G Networks using a\n  Blockchain-based Decentralized Trusted Computing Platform\n\n  The 5G network would fuel next-gen, bandwidth-heavy technologies such as\nautomation, IoT, and AI on the factory floor. It will improve efficiency by\npowering AR overlays in workflows, as well as ensure safer practices and reduce\nthe number of defects through predictive analytics and real-time detection of\ndamage. The Dynamic Spectrum Sharing (DSS) in 5G networks will permit 5G NR and\n4G LTE to coexist and will provide cost-effective and efficient solutions that\nenable a smooth transition from 4G to 5G. However, this increases the attack\nsurface in the 5G networks. To the best of our knowledge, none of the current\nworks introduces a real-time secure spectrum-sharing mechanism for 5G networks\nto defend spectrum resources and applications. This paper aims to propose a\nBlockchain-based Decentralized Trusted Computing Platform (BTCP) to\nself-protect large-scale 5G spectrum resources against cyberattacks in a\ntimely, dynamic, and accurate way. Furthermore, the platform provides a\ndecentralized, trusted, and non-repudiating platform to enable secure spectrum\nsharing and data exchange between the 5G spectrum resources\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.06335,regular,pre_llm,2022,1,"{'ai_likelihood': 3.2782554626464844e-06, 'text': ""End to End Secure Data Exchange in Value Chains with Dynamic Policy\n  Updates\n\n  Data exchange among value chain partners provides them with a competitive\nadvantage, but the risk of exposing sensitive data is ever-increasing.\nInformation must be protected in storage and transmission to reduce this risk,\nso only the data producer and the final consumer can access or modify it.\nEnd-to-end (E2E) security mechanisms address this challenge, protecting\ncompanies from data breaches resulting from value chain attacks. Moreover,\nvalue chain particularities must also be considered. Multiple entities are\ninvolved in dynamic environments like these, both in data generation and\nconsumption. Hence, a flexible generation of access policies is required to\nensure that they can be updated whenever needed. This paper presents a\nCP-ABE-reliant data exchange system for value chains with E2E security. It\nconsiders the most relevant security and industrial requirements for value\nchains. The proposed solution can protect data according to access policies and\nupdate those policies without breaking E2E security or overloading field\ndevices. In most cases, field devices are IIoT devices, limited in terms of\nprocessing and memory capabilities. The experimental evaluation has shown the\nproposed solution's feasibility for IIoT platforms.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.04803,review,pre_llm,2022,1,"{'ai_likelihood': 2.682209014892578e-06, 'text': 'A Comprehensive Survey on the Applications of Blockchain for Securing\n  Vehicular Networks\n\n  Vehicular networks promise features such as traffic management, route\nscheduling, data exchange, entertainment, and much more. With any large-scale\ntechnological integration comes the challenge of providing security. Blockchain\ntechnology has been a popular choice of many studies for making the vehicular\nnetwork more secure. Its characteristics meet some of the essential security\nrequirements such as decentralization, transparency, tamper-proof nature, and\npublic audit. This study catalogues some of the notable efforts in this\ndirection over the last few years. We analyze around 75 blockchain-based\nsecurity schemes for vehicular networks from an application, security, and\nblockchain perspective. The application perspective focuses on various\napplications which use secure blockchain-based vehicular networks such as\ntransportation, parking, data sharing/ trading, and resource sharing. The\nsecurity perspective focuses on security requirements and attacks. The\nblockchain perspective focuses on blockchain platforms, blockchain types, and\nconsensus mechanisms used in blockchain implementation. We also compile the\npopular simulation tools used for simulating blockchain and for simulating\nvehicular networks. Additionally, to give the readers a broader perspective of\nthe research area, we discuss the role of various state-of-the-art emerging\ntechnologies in blockchain-based vehicular networks. Lastly, we summarize the\nsurvey by listing out some common challenges and the future research directions\nin this field.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2201.0541,regular,pre_llm,2022,1,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'CyberSpec: Intelligent Behavioral Fingerprinting to Detect Attacks on\n  Crowdsensing Spectrum Sensors\n\n  Integrated sensing and communication (ISAC) is a novel paradigm using\ncrowdsensing spectrum sensors to help with the management of spectrum scarcity.\nHowever, well-known vulnerabilities of resource-constrained spectrum sensors\nand the possibility of being manipulated by users with physical access\ncomplicate their protection against spectrum sensing data falsification (SSDF)\nattacks. Most recent literature suggests using behavioral fingerprinting and\nMachine/Deep Learning (ML/DL) for improving similar cybersecurity issues.\nNevertheless, the applicability of these techniques in resource-constrained\ndevices, the impact of attacks affecting spectrum data integrity, and the\nperformance and scalability of models suitable for heterogeneous sensors types\nare still open challenges. To improve limitations, this work presents seven\nSSDF attacks affecting spectrum sensors and introduces CyberSpec, an\nML/DL-oriented framework using device behavioral fingerprinting to detect\nanomalies produced by SSDF attacks affecting resource-constrained spectrum\nsensors. CyberSpec has been implemented and validated in ElectroSense, a real\ncrowdsensing RF monitoring platform where several configurations of the\nproposed SSDF attacks have been executed in different sensors. A pool of\nexperiments with different unsupervised ML/DL-based models has demonstrated the\nsuitability of CyberSpec detecting the previous attacks within an acceptable\ntimeframe.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.11341,regular,pre_llm,2022,2,"{'ai_likelihood': 1.0596381293402778e-06, 'text': 'Distributed and Mobile Message Level Relaying/Replaying of GNSS Signals\n\n  With the introduction of Navigation Message Authentication (NMA), future\nGlobal Navigation Satellite Systems (GNSSs) prevent spoofing by simulation,\ni.e., the generation of forged satellite signals based on public information.\nHowever, authentication does not prevent record-and-replay attacks, commonly\ntermed as meaconing. These attacks are less powerful in terms of adversarial\ncontrol over the victim receiver location and time, but by acting at the signal\nlevel, they are not thwarted by NMA. This makes replaying/relaying attacks a\nsignificant threat for GNSS. While there are numerous investigations on\nmeaconing, the majority does not rely on actual implementation and experimental\nevaluation in real-world settings. In this work, we contribute to the\nimprovement of the experimental understanding of meaconing attacks. We design\nand implement a system capable of real-time, distributed, and mobile meaconing,\nbuilt with off-the-shelf hardware. We extend from basic distributed attacks,\nwith signals from different locations relayed over the Internet and replayed\nwithin range of the victim receiver(s): this has high bandwidth requirements\nand thus depends on the quality of service of the available network to work. To\novercome this limitation, we propose to replay on message level, including the\nauthentication part of the payload. The resultant reduced bandwidth enables the\nattacker to operate in mobile scenarios, as well as to replay signals from\nmultiple GNSS constellations and/or bands simultaneously. Additionally, the\nattacker can delay individually selected satellite signals to potentially\ninfluence the victim position and time solution in a more fine-grained manner.\nOur versatile test-bench, enabling different types of replaying/relaying\nattacks, facilitates testing realistic scenarios towards new and improved\nreplaying/relaying-focused countermeasures in GNSS receivers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.03866,regular,pre_llm,2022,2,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'NFT Wash Trading: Quantifying suspicious behaviour in NFT markets\n\n  The smart contract-based markets for non-fungible tokens (NFTs) on the\nEthereum blockchain have seen tremendous growth in 2021, with trading volumes\npeaking at 3.5b in September 2021. This dramatic surge has led to industry\nobservers questioning the authenticity of on-chain volumes, given the absence\nof identity requirements and the ease with which agents can control multiple\naddresses. We examine potentially illicit trading patterns in the NFT markets\nfrom January 2018 to mid-November 2021, gathering data from the 52 largest\ncollections by volume. Our findings indicate that within our sample 3.93% of\naddresses, processing a total of 2.04% of sale transactions, trigger suspicions\nof market abuse. Flagged transactions contaminate nearly all collections and\nmay have inflated the authentic trading volumes by as much as 149,5m for the\nperiod. Most flagged transaction patterns alternate between a few addresses,\nindicating a predisposition for manual trading. We submit that the results\npresented here may serve as a viable lower bound estimate for NFT wash trading\non Ethereum. Even so, we argue that wash trading may be less common than what\nindustry observers have previously estimated. We contribute to the emerging\ndiscourse on the identification and deterrence of market abuse in the\ncryptocurrency markets.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.10897,regular,pre_llm,2022,2,"{'ai_likelihood': 7.814831203884549e-06, 'text': ""DEMO: Relay/Replay Attacks on GNSS signals\n\n  Global Navigation Satellite Systems (GNSS) are ubiquitously relied upon for\npositioning and timing. Detection and prevention of attacks against GNSS have\nbeen researched over the last decades, but many of these attacks and\ncountermeasures were evaluated based on simulation. This work contributes to\nthe experimental investigation of GNSS vulnerabilities, implementing a\nrelay/replay attack with off-the-shelf hardware. Operating at the signal level,\nthis attack type is not hindered by cryptographically protected transmissions,\nsuch as Galileo's Open Signals Navigation Message Authentication (OS-NMA). The\nattack we investigate involves two colluding adversaries, relaying signals over\nlarge distances, to effectively spoof a GNSS receiver. We demonstrate the\nattack using off-the-shelf hardware, we investigate the requirements for such\nsuccessful colluding attacks, and how they can be enhanced, e.g., allowing for\nfiner adversarial control over the victim receiver.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.10832,regular,pre_llm,2022,2,"{'ai_likelihood': 1.5232298109266494e-06, 'text': 'Multi-service Threats: Attacking and Protecting Network Printers and\n  VoIP Phones alike\n\n  Printing over a network and calling over VoIP technology are routine at\npresent. This article investigates to what extent these services can be\nattacked using freeware in the real world if they are not configured securely.\nIn finding out that attacks of high impact, termed the Printjack and Phonejack\nfamilies, could be mounted at least from insiders, the article also observes\nthat secure configurations do not appear to be widely adopted.\n  Users with the necessary skills may put existing security measures in place\nwith printers, but would need novel measures, which the article prototypes,\nwith phones in order for a pair of peers to call each other securely and\nwithout trusting anyone else, including sysadmins.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.03388,regular,pre_llm,2022,2,"{'ai_likelihood': 1.4371342129177518e-05, 'text': 'Distributed Differentially Private Ranking Aggregation\n\n  Ranking aggregation is commonly adopted in cooperative decision-making to\nassist in combining multiple rankings into a single representative. To protect\nthe actual ranking of each individual, some privacy-preserving strategies, such\nas differential privacy, are often used. This, however, does not consider the\nscenario where the curator, who collects all rankings from individuals, is\nuntrustworthy. This paper proposed a mechanism to solve the above situation\nusing the distribute differential privacy framework. The proposed mechanism\ncollects locally differential private rankings from individuals, then randomly\npermutes pairwise rankings using a shuffle model to further amplify the privacy\nprotection. The final representative is produced by hierarchical rank\naggregation. The mechanism was theoretically analysed and experimentally\ncompared against existing methods, and demonstrated competitive results in both\nthe output accuracy and privacy protection.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.06108,regular,pre_llm,2022,2,"{'ai_likelihood': 2.384185791015625e-06, 'text': 'Mitigating the Effects of Ransomware Attacks on Healthcare Systems\n\n  Healthcare information systems deal with a large amount of Personally\nIdentifiable Information related to patients like dates of birth and social\nsecurity numbers, patients health information and history, and financial\ninformation like credit card details and bank accounts. Most healthcare\ninstitutions purchase information systems from commercial vendors and have\nminimal inhouse expertise required to maintain these systems. Most institutions\nlack the expertise required to research evolving threats and maintain a tough\nsecurity posture. We propose a risk transference based system architecture that\nmoves sensitive data outside the system boundary, into data stores that are\nmanaged with stringent and efficient security protocols.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.12731,regular,pre_llm,2022,2,"{'ai_likelihood': 8.27842288547092e-07, 'text': 'Short Paper: Device- and Locality-Specific Fingerprinting of Shared NISQ\n  Quantum Computers\n\n  Fingerprinting of quantum computer devices is a new threat that poses a\nchallenge to shared, cloud-based quantum computers. Fingerprinting can allow\nadversaries to map quantum computer infrastructures, uniquely identify\ncloud-based devices which otherwise have no public identifiers, and it can\nassist other adversarial attacks. This work shows idle tomography-based\nfingerprinting method based on crosstalk-induced errors in NISQ quantum\ncomputers. The device- and locality-specific fingerprinting results show\nprediction accuracy values of $99.1\\%$ and $95.3\\%$, respectively.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.1008,regular,pre_llm,2022,2,"{'ai_likelihood': 7.318125830756294e-06, 'text': 'bAdvertisement: Attacking Advanced Driver-Assistance Systems Using Print\n  Advertisements\n\n  In this paper, we present bAdvertisement, a novel attack method against\nadvanced driver-assistance systems (ADASs). bAdvertisement is performed as a\nsupply chain attack via a compromised computer in a printing house, by\nembedding a ""phantom"" object in a print advertisement. When the compromised\nprint advertisement is observed by an ADAS in a passing car, an undesired\nreaction is triggered from the ADAS. We analyze state-of-the-art object\ndetectors and show that they do not take color or context into account in\nobject detection. Our validation of these findings on Mobileye 630 PRO shows\nthat this ADAS also fails to take color or context into account. Then, we show\nhow an attacker can take advantage of these findings to execute an attack on a\ncommercial ADAS, by embedding a phantom road sign in a print advertisement,\nwhich causes a car equipped with Mobileye 630 PRO to trigger a false\nnotification to slow down. Finally, we discuss multiple countermeasures which\ncan be deployed in order to mitigate the effect of our proposed attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.10891,review,pre_llm,2022,2,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'Protecting GNSS-based Services using Time Offset Validation\n\n  Global navigation satellite systems (GNSS) provide pervasive accurate\npositioning and timing services for a large gamut of applications, from Time\nbased One-Time Passwords (TOPT), to power grid and cellular systems. However,\nthere can be security concerns for the applications due to the vulnerability of\nGNSS. It is important to observe that GNSS receivers are components of\nplatforms, in principle having rich connectivity to different network\ninfrastructures. Of particular interest is the access to a variety of timing\nsources, as those can be used to validate GNSS-provided location and time.\nTherefore, we consider off-the-shelf platforms and how to detect if the GNSS\nreceiver is attacked or not, by cross-checking the GNSS time and time from\nother available sources. First, we survey different technologies to analyze\ntheir availability, accuracy, and trustworthiness for time synchronization.\nThen, we propose a validation approach for absolute and relative time.\nMoreover, we design a framework and experimental setup for the evaluation of\nthe results. Attacks can be detected based on WiFi supplied time when the\nadversary shifts the GNSS provided time, more than 23.942us; with Network Time\nProtocol (NTP) supplied time when the adversary-induced shift is more than\n2.046ms. Consequently, the proposal significantly limits the capability of an\nadversary to manipulate the victim GNSS receiver.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.0687,regular,pre_llm,2022,2,"{'ai_likelihood': 1.2119611104329428e-05, 'text': ""AnoMili: Spoofing Prevention and Explainable Anomaly Detection for the\n  1553 Military Avionic Bus\n\n  MIL-STD-1553, a standard that defines a communication bus for interconnected\ndevices, is widely used in military and aerospace avionic platforms. Due to its\nlack of security mechanisms, MIL-STD-1553 is exposed to cyber threats. The\nmethods previously proposed to address these threats are very limited,\nresulting in the need for more advanced techniques. Inspired by the defense in\ndepth principle, we propose AnoMili, a novel protection system for the\nMIL-STD-1553 bus, which consists of: (i) a physical intrusion detection\nmechanism that detects unauthorized devices connected to the 1553 bus, even if\nthey are passive (sniffing), (ii) a device fingerprinting mechanism that\nprotects against spoofing attacks (two approaches are proposed: prevention and\ndetection), (iii) a context-based anomaly detection mechanism, and (iv) an\nanomaly explanation engine responsible for explaining the detected anomalies in\nreal time. We evaluate AnoMili's effectiveness and practicability in two real\n1553 hardware-based testbeds. The effectiveness of the anomaly explanation\nengine is also demonstrated. All of the detection and prevention mechanisms\nemployed had high detection rates (over 99.45%) with low false positive rates.\nThe context-based anomaly detection mechanism obtained perfect results when\nevaluated on a dataset used in prior work.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.06459,regular,pre_llm,2022,2,"{'ai_likelihood': 3.311369154188368e-07, 'text': ""Work in progress: Identifying Two-Factor Authentication Support in\n  Banking Sites\n\n  Two-factor authentication (2FA) offers several security benefits that\nsecurity-conscious users might expect from high-value services such as online\nbanks. In this work, we present our preliminary study to develop a scoring\nscheme to automatically recognize when bank sites mention support for\ntwo-factor authentication. We extract information related to security features\n(primarily 2FA) offered by 379 bank domains from 93 countries. We use a subset\nof these sites to refine our scoring scheme to include several heuristics for\nidentifying whether sites offer 2FA. For each bank domain in our dataset, we\nuse our algorithm based on text-analysis to calculate whether the domain offers\n2FA to the users of the domain's online banking platform. Our preliminary\nfindings suggest that 2FA is yet to be widely adopted by banking domains.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.06862,review,pre_llm,2022,2,"{'ai_likelihood': 1.5232298109266494e-06, 'text': 'Threats to Pre-trained Language Models: Survey and Taxonomy\n\n  Pre-trained language models (PTLMs) have achieved great success and\nremarkable performance over a wide range of natural language processing (NLP)\ntasks. However, there are also growing concerns regarding the potential\nsecurity issues in the adoption of PTLMs. In this survey, we comprehensively\nsystematize recently discovered threats to PTLM systems and applications. We\nperform our attack characterization from three interesting perspectives. (1) We\nshow threats can occur at different stages of the PTLM pipeline raised by\ndifferent malicious entities. (2) We identify two types of model\ntransferability (landscape, portrait) that facilitate attacks. (3) Based on the\nattack goals, we summarize four categories of attacks (backdoor, evasion, data\nprivacy and model privacy). We also discuss some open problems and research\ndirections. We believe our survey and taxonomy will inspire future studies\ntowards secure and privacy-preserving PTLMs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.1297,review,pre_llm,2022,2,"{'ai_likelihood': 2.0199351840549047e-06, 'text': 'Critical Infrastructure Cybersecurity Challenges: IoT In Perspective\n\n  A technology platform that is gradually bridging the gap between object\nvisibility and remote accessibility is the Internet of Things (IoT). Rapid\ndeployment of this application can significantly transform the health, housing,\nand power (distribution and generation) sectors, etc. It has considerably\nchanged the power sector regarding operations, services optimization, power\ndistribution, asset management and aided in engaging customers to reduce energy\nconsumption. Despite its societal opportunities and the benefits it presents,\nthe power generation sector is bedeviled with many security challenges on the\ncritical infrastructure. This review discusses the security challenges posed by\nIoT in power generation and critical infrastructure. To achieve this, the\nauthors present the various IoT applications, particularly on the grid\ninfrastructure, from an empirical literature perspective. The authors concluded\nby discussing how the various entities in the sector can overcome these\nsecurity challenges to ensure an exemplary future IoT implementation on the\npower critical infrastructure value chain.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.03966,review,pre_llm,2022,2,"{'ai_likelihood': 2.8014183044433594e-05, 'text': 'Blockchain-based Digital Twin for Supply Chain Management:\n  State-of-the-Art Review and Future Research Directions\n\n  Supply chain management (SCM) plays a vital role in the global economy, as\nevidenced by recent COVID-19 supply chain challenges. Traditional SCM faces\nsecurity and efficiency issues, but they can be addressed by leveraging digital\ntwins (DTs) and blockchain technology. T he combination of blockchain and DTs\ncan refine the concepts of both technologies and reform SCM to advance into\nIndustry 4.0. In this paper, we provide a comprehensive literature review of\nthe blockchain-based digital twin (DT) solutions to optimise the processes of\ndata management, data storage, and data sharing in SCM. We also investigate the\nkey benefits of the integration of blockchain and DTs and examine their\npotential implementation in various SCM areas, including smart manufacturing,\nintelligent maintenance, and blockchain-based DT shop floor, warehouse, and\nlogistics. Finally, we put forward recommendations for future research\ndirections.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.11409,regular,pre_llm,2022,2,"{'ai_likelihood': 1.2252065870496963e-06, 'text': 'ScrawlD: A Dataset of Real World Ethereum Smart Contracts Labelled with\n  Vulnerabilities\n\n  Smart contracts on Ethereum handle millions of U.S. Dollars and other\nfinancial assets. In the past, attackers have exploited smart contracts to\nsteal these assets. The Ethereum community has developed plenty of tools to\ndetect vulnerable smart contracts. However, there is no standardized data set\nto evaluate these existing tools, or any new tools developed. There is a need\nfor an unbiased standard benchmark of real-world Ethereum smart contracts. We\nhave created ScrawlD: an annotated data set of real-world smart contracts taken\nfrom the Ethereum network. The data set is labelled using 5 tools that detect\nvarious vulnerabilities in smart contracts, using majority voting.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.00885,regular,pre_llm,2022,2,"{'ai_likelihood': 7.5499216715494794e-06, 'text': ""Opted Out, Yet Tracked: Are Regulations Enough to Protect Your Privacy?\n\nData protection regulations, such as GDPR and CCPA, require websites and embedded third-parties, especially advertisers, to seek user consent before they can collect and process user data. Only when the users opt in, can these entities collect, process, and share user data. Websites typically incorporate Consent Management Platforms (CMPs), such as OneTrust and CookieBot, to solicit and convey user consent to the embedded advertisers, with the expectation that the consent will be respected. However, neither the websites nor the regulators currently have any mechanism to audit advertisers' compliance with the user consent, i.e., to determine if advertisers indeed do not collect, process, and share user data when the user opts out.\n  In this paper, we propose an auditing framework that leverages advertisers' bidding behavior to empirically assess the violations of data protection regulations. Using our framework, we conduct a measurement study to evaluate four of the most widely deployed CMPs, i.e., Didomi, Quantcast, OneTrust, and CookieBot, as well as advertiser-offered opt-out controls, i.e., National Advertising Initiative's opt-out, under GDPR and CCPA. Our results indicate that in many cases user data is unfortunately still being collected, processed, and shared even when users opt-out. We also find that some CMPs are better than the others at conveying user consent and that several ad platforms ignore user consent. Our results also indicate that advertiser-offered opt-out are equally ineffective at protecting user privacy."", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.04345,regular,pre_llm,2022,2,"{'ai_likelihood': 4.238552517361111e-06, 'text': 'Securing Smart Grids Through an Incentive Mechanism for Blockchain-Based\n  Data Sharing\n\n  Smart grids leverage the data collected from smart meters to make important\noperational decisions. However, they are vulnerable to False Data Injection\n(FDI) attacks in which an attacker manipulates meter data to disrupt the grid\noperations. Existing works on FDI are based on a simple threat model in which a\nsingle grid operator has access to all the data, and only some meters can be\ncompromised.\n  Our goal is to secure smart grids against FDI under a realistic threat model.\nTo this end, we present a threat model in which there are multiple operators,\neach with a partial view of the grid, and each can be fully compromised. An\neffective defense against FDI in this setting is to share data between the\noperators. However, the main challenge here is to incentivize data sharing. We\naddress this by proposing an incentive mechanism that rewards operators for\nuploading data, but penalizes them if the data is missing or anomalous. We\nderive formal conditions under which our incentive mechanism is provably secure\nagainst operators who withhold or distort measurement data for profit. We then\nimplement the data sharing solution on a private blockchain, introducing\nseveral optimizations that overcome the inherent performance limitations of the\nblockchain. Finally, we conduct an experimental evaluation that demonstrates\nthat our implementation has practical performance.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.08576,regular,pre_llm,2022,2,"{'ai_likelihood': 1.8046961890326606e-05, 'text': 'Local Differential Privacy for Belief Functions\n\n  In this paper, we propose two new definitions of local differential privacy\nfor belief functions. One is based on Shafer\'s semantics of randomly coded\nmessages and the other from the perspective of imprecise probabilities. We show\nthat such basic properties as composition and post-processing also hold for our\nnew definitions. Moreover, we provide a hypothesis testing framework for these\ndefinitions and study the effect of ""don\'t know"" in the trade-off between\nprivacy and utility in discrete distribution estimation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.09122,regular,pre_llm,2022,2,"{'ai_likelihood': 1.341104507446289e-05, 'text': 'Decentralized Verifiable Mail-in Ballot Counting for Postal Voting\n\n  As computer vision is prevalently used for mail-in ballot processing and\ncounting, it becomes a point of centralized trust in postal voting. We propose\nDVote, a prototype system of postal voting that provides decentralized trust in\ncomputer vision. With blockchain and layer-2 technologies, DVote decentralizes\nthe computation and model training of computer vision to a group of scrutineers\nthat hold the AnyTrust assumption, i.e., at least one member is honest.\nConsequently, the computational integrity is anchored to the trustworthiness of\na large public blockchain such as Ethereum.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2202.09587,review,pre_llm,2022,2,"{'ai_likelihood': 8.609559800889757e-07, 'text': ""Evaluation of Open-source Tools for Differential Privacy\n\n  Differential privacy (DP) defines privacy protection by promising quantified\nindistinguishability between individuals that consent to share their\nprivacy-sensitive information and the ones that do not. DP aims to deliver this\npromise by including well-crafted elements of random noise in the published\ndata and thus there is an inherent trade-off between the degree of privacy\nprotection and the ability to utilize the protected data. Currently, several\nopen-source tools were proposed for DP provision. To the best of our knowledge,\nthere is no comprehensive study for comparing these open-source tools with\nrespect to their ability to balance DP's inherent trade-off as well as the use\nof system resources. This work proposes an open-source evaluation framework for\nprivacy protection solutions and offers evaluation for OpenDP Smartnoise,\nGoogle DP, PyTorch Opacus, Tensorflow Privacy, and Diffprivlib. In addition to\nstudying their ability to balance the above trade-off, we consider discrete and\ncontinuous attributes by quantifying their performance under different data\nsizes. Our results reveal several patterns that developers should have in mind\nwhen selecting tools under different application needs and criteria. This\nevaluation survey can be the basis for an improved selection of open-source DP\ntools and quicker adaptation of DP.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.08424,regular,pre_llm,2022,3,"{'ai_likelihood': 1.3907750447591147e-06, 'text': 'A Language-Independent Analysis Platform for Source Code\n\n  In this paper, we present the CPG analysis platform, which enables the\ntranslation of source code into a programming language-independent\nrepresentation, based on a code property graph. This allows security experts\nand developers to capture language level semantics for security analyses or\nidentify patterns with respect to code compliance. Through the use of fuzzy\nparsing, also incomplete or non-compilable code, written in different\nprogramming languages, can be analyzed. The platform comprises an analysis\nlibrary and interfaces to query, interact with or visualize source code graphs.\nThis set of CPG tools allows finding common weaknesses in heterogeneous\nsoftware environments, independently of the underlying programming language.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.03077,regular,pre_llm,2022,3,"{'ai_likelihood': 7.616149054633247e-07, 'text': 'A Study of Third-party Resources Loading on Web\n\n  This paper performs a large-scale study of dependency chains in the web, to\nfind that around 50% of first-party websites render content that they did not\ndirectly load. Although the majority (84.91%) of websites have short dependency\nchains (below 3 levels), we find websites with dependency chains exceeding 30.\nUsing VirusTotal, we show that 1.2% of these third-parties are classified as\nsuspicious -- although seemingly small, this limited set of suspicious\nthird-parties have remarkable reach into the wider ecosystem. We find that 73%\nof websites under-study load resources from suspicious third-parties, and 24.8%\nof first-party webpages contain at least three third-parties classified as\nsuspicious in their dependency chain. By running sandboxed experiments, we\nobserve a range of activities with the majority of suspicious JavaScript codes\ndownloading malware.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.09843,regular,pre_llm,2022,3,"{'ai_likelihood': 1.357661353217231e-06, 'text': ""Extorsionware: Exploiting Smart Contract Vulnerabilities for Fun and\n  Profit\n\n  Smart Contracts (SCs) publicly deployed on blockchain have been shown to\ninclude multiple vulnerabilities, which can be maliciously exploited by users.\nIn this paper, we present extorsionware, a novel attack exploiting the public\nnature of vulnerable SCs to gain control over the victim's SC assets. Thanks to\nthe control gained over the SC, the attacker obliges the victim to pay a price\nto re-gain exclusive control of the SC.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.00769,regular,pre_llm,2022,3,"{'ai_likelihood': 3.973642985026042e-07, 'text': 'VOLCANO: Detecting Vulnerabilities of Ethereum Smart Contracts Using\n  Code Clone Analysis\n\n  Ethereum Smart Contracts based on Blockchain Technology (BT) enables monetary\ntransactions among peers on a blockchain network independent of a central\nauthorizing agency. Ethereum Smart Contracts are programs that are deployed as\ndecentralized applications, having the building blocks of the blockchain\nconsensus protocol. This enables consumers to make agreements in a transparent\nand conflict-free environment. However, there exist some security\nvulnerabilities within these smart contracts that are a potential threat to the\napplications and their consumers and have shown in the past to cause huge\nfinancial losses. This paper presents a framework and empirical analysis that\nuse code clone detection techniques for identifying vulnerabilities and their\nvariations in smart contracts. Our empirical analysis is conducted using the\nNicad code clone detection tool on a dataset of approximately 50k Ethereum\nsmart contracts. We evaluated VOLCANO on two datasets, one with confirmed\nvulnerabilities and another with approximately 50k random smart contracts\ncollected from the Etherscan. Our approach shows an improvement in the\ndetection of vulnerabilities in terms of coverage and efficiency when compared\nto two of the publicly available static analyzers to detect vulnerabilities in\nsmart contracts. To the best of our knowledge, this is the first study that\nuses a clone detection technique to identify vulnerabilities and their\nevolution in Ethereum smart contracts.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.15968,regular,pre_llm,2022,3,"{'ai_likelihood': 1.9205941094292534e-06, 'text': 'Light Clients for Lazy Blockchains\n\n  Lazy blockchains decouple consensus from transaction verification and\nexecution to increase throughput. Although they can contain invalid\ntransactions (e.g., double spends) as a result, these can easily be filtered\nout by full nodes that check if there have been previous conflicting\ntransactions. However, creating light (SPV) clients that do not see the whole\ntransaction history becomes a challenge: A record of a transaction on the chain\ndoes not necessarily entail transaction confirmation. In this paper, we devise\na protocol that enables the creation of efficient light clients for lazy\nblockchains. The number of interaction rounds and the communication complexity\nof our protocol are logarithmic in the blockchain execution time. Our\nconstruction is based on a bisection game that traverses the Merkle tree\ncontaining the ledger of all - valid or invalid - transactions. We prove that\nour proof system is succinct, complete and sound, and empirically demonstrate\nthe feasibility of our scheme.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.14684,regular,pre_llm,2022,3,"{'ai_likelihood': 1.953707800971137e-06, 'text': 'Investigating transactions in cryptocurrencies\n\n  This thesis presents techniques to investigate transactions in uncharted\ncryptocurrencies and services. Cryptocurrencies are used to securely send\npayments online. Payments via the first cryptocurrency, Bitcoin, use\npseudonymous addresses that have limited privacy and anonymity guarantees.\nResearch has shown that this pseudonymity can be broken, allowing users to be\ntracked using clustering and tagging heuristics. Such tracking allows crimes to\nbe investigated. If a user has coins stolen, investigators can track addresses\nto identify the destination of the coins. This, combined with an explosion in\nthe popularity of blockchain, has led to a vast increase in new coins and\nservices. These offer new features ranging from coins focused on increased\nanonymity to scams shrouded as smart contracts. In this study, we investigated\nthe extent to which transaction privacy has improved and whether users can\nstill be tracked in these new ecosystems. We began by analysing the\nprivacy-focused coin Zcash, a Bitcoin-forked cryptocurrency, that is considered\nto have strong anonymity properties due to its background in cryptographic\nresearch. We revealed that the user anonymity set can be considerably reduced\nusing heuristics based on usage patterns. Next, we analysed cross-chain\ntransactions collected from the exchange ShapeShift, revealing that users can\nbe tracked as they move across different ledgers. Finally, we present a\nmeasurement study on the smart-contract pyramid scheme Forsage, a scam that\ncycled $267 million USD (of Ethereum) within its first year, showing that at\nleast 88% of the participants in the scheme suffered a loss. The significance\nof this study is the revelation that users can be tracked in newer\ncryptocurrencies and services by using our new heuristics, which informs those\nconducting investigations and developing these technologies.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.01823,regular,pre_llm,2022,3,"{'ai_likelihood': 1.357661353217231e-06, 'text': ""Mobile device users' susceptibility to phishing attacks\n\n  The mobile device is one of the fasted growing technologies that is widely\nused in a diversifying sector. Mobile devices are used for everyday life, such\nas personal information exchange - chatting, email, shopping, and mobile\nbanking, contributing to information security threats. Users' behavior can\ninfluence information security threats. More research is needed to understand\nusers' threat avoidance behavior and motivation. Using Technology threat\navoidance theory (TTAT), this study assessed factors that influenced mobile\ndevice users' threat avoidance motivations and behaviors as it relates to\nphishing attacks. From the data collected from 137 mobile device users using a\nquestionnaire, the findings indicate that (1) mobile device users' perceived\nsusceptibility and severity of phishing attacks have a significant correlation\nwith a users' perception of the threat; (2) mobile device users' motivation to\navoid a threat is correlated to a users' behavior in avoiding threat; and (3) a\nmobile device user's susceptibility to phishing attacks can be reduced by their\nperception of the threat. These findings reveal that a user's perception of\nthreat increases if they perceive that the consequence of such threat to their\nmobile devices will be severe, thereby increasing a user's motivation and\nbehavior to avoid phishing attack threats. This study is beneficial to mobile\ndevice users in personal and organizational settings.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.02719,regular,pre_llm,2022,3,"{'ai_likelihood': 9.768539004855686e-06, 'text': ""DroidRL: Reinforcement Learning Driven Feature Selection for Android\n  Malware Detection\n\n  Due to the completely open-source nature of Android, the exploitable\nvulnerability of malware attacks is increasing. Machine learning, leading to a\ngreat evolution in Android malware detection in recent years, is typically\napplied in the classification phase. Since the correlation between features is\nignored in some traditional ranking-based feature selection algorithms,\napplying wrapper-based feature selection models is a topic worth investigating.\nThough considering the correlation between features, wrapper-based approaches\nare time-consuming for exploring all possible valid feature subsets when\nprocessing a large number of Android features. To reduce the computational\nexpense of wrapper-based feature selection, a framework named DroidRL is\nproposed. The framework deploys DDQN algorithm to obtain a subset of features\nwhich can be used for effective malware classification. To select a valid\nsubset of features over a larger range, the exploration-exploitation policy is\napplied in the model training phase. The recurrent neural network (RNN) is used\nas the decision network of DDQN to give the framework the ability to\nsequentially select features. Word embedding is applied for feature\nrepresentation to enhance the framework's ability to find the semantic\nrelevance of features. The framework's feature selection exhibits high\nperformance without any human intervention and can be ported to other feature\nselection tasks with minor changes. The experiment results show a significant\neffect when using the Random Forest as DroidRL's classifier, which reaches\n95.6% accuracy with only 24 features selected.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.10188,regular,pre_llm,2022,3,"{'ai_likelihood': 0.0, 'text': 'Trackers Bounce Back: Measuring Evasion of Partitioned Storage in the\n  Wild\n\n  This work presents a systematic study of navigational tracking, the latest\ndevelopment in the cat-and-mouse game between browsers and online trackers.\nNavigational tracking allows trackers to \'aggregate users\' activities and\nbehaviors across sites by modifying their navigation requests. This technique\nis particularly important because it circumvents the increasing efforts by\nbrowsers to partition or block third-party storage, which was previously\nnecessary for most cross-website tracking. While previous work has studied\nspecific navigational tracking techniques (i.e. ""bounce tracking""), our work is\nthe first effort to systematically study and measure the entire category of\nnavigational tracking techniques. We describe and measure the frequency of two\ndifferent navigational tracking techniques on the Web, and find that\nnavigational tracking is present on slightly more than ten percent of all\nnavigations that we made. Our contributions include identifying 214 domains\nbelonging to at least 104 organizations tracking users across sites through\nlink decoration techniques using direct or indirect navigation flows. We\nidentify a further 23 domains belonging to at least 16 organizations tracking\nusers through bounce tracking (i.e. bouncing users through unrelated third\nparties to generate user profiles). We also improve on prior techniques for\ndifferenting user identifiers from non-sensitive information, which is\nnecessary to detect one class of navigational tracking. We discuss how our\nfindings can used to protect users from navigational tracking, and commit to\nreleasing both our complete dataset and our measurement pipeline\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.02547,review,pre_llm,2022,3,"{'ai_likelihood': 7.28501213921441e-07, 'text': 'Homomorphically Encrypted Computation using Stochastic Encodings\n\n  Homomorphic encryption (HE) is a privacy-preserving technique that enables\ncomputation directly over ciphertext. Unfortunately, a key challenge for HE is\nthat implementations can be impractically slow and have limits on computation\nthat can be efficiently implemented. For instance, in Boolean constructions of\nHE like TFHE, arithmetic operations need to be decomposed into constituent\nelementary logic gates to implement so performance depends on logical circuit\ndepth. For even heavily quantized fixed-point arithmetic operations, these HE\ncircuit implementations can be slow.\n  This paper explores the merit of using stochastic computing (SC) encodings to\nreduce the logical depth required for HE computation to enable more efficient\nimplementations. Contrary to computation in the plaintext space where many\nefficient hardware implementations are available, HE provides support for only\na limited number of primitive operators and their performance may not directly\ncorrelate to their plaintext performance. Our results show that by layering SC\nencodings on top of TFHE, we observe similar challenges and limitations that SC\nfaces in the plaintext space. Additional breakthroughs would require more\nsupport from the HE libraries to make SC with HE a viable solution.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.13662,regular,pre_llm,2022,3,"{'ai_likelihood': 2.3245811462402344e-05, 'text': 'Efficient Strong Privacy-Preserving Conjunctive Keyword Search Over\n  Encrypted Cloud Data\n\n  Searchable symmetric encryption (SSE) supports keyword search over outsourced\nsymmetrically encrypted data. Dynamic searchable symmetric encryption (DSSE), a\nvariant of SSE, further enables data updating. Most DSSE works with conjunctive\nkeyword search primarily consider forward and backward privacy. Ideally, the\nserver should only learn the result sets involving all keywords in the\nconjunction. However, existing schemes suffer from keyword pair result pattern\n(KPRP) leakage, revealing the partial result sets containing two of query\nkeywords. We propose the first DSSE scheme to address aforementioned concerns\nthat achieves strong privacy-preserving conjunctive keyword search.\nSpecifically, our scheme can maintain forward and backward privacy and\neliminate KPRP leakage, offering a higher level of security. The search\ncomplexity scales with the number of documents stored in the database in\nseveral existing schemes. However, the complexity of our scheme scales with the\nupdate frequency of the least frequent keyword in the conjunction, which is\nmuch smaller than the size of the entire database. Besides, we devise a least\nfrequent keyword acquisition protocol to reduce frequent interactions between\nclients. Finally, we analyze the security of our scheme and evaluate its\nperformance theoretically and experimentally. The results show that our scheme\nhas strong privacy preservation and efficiency.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.16058,regular,pre_llm,2022,3,"{'ai_likelihood': 1.655684577094184e-07, 'text': 'Measuring Miner Decentralization in Proof-of-Work Blockchains\n\n  Proof of work cryptocurrencies began with the promise of a more egalitarian\nfuture with a decentralized monetary system with no powerful entities in\ncharge. While this vision is far from realized, these cryptocurrencies are\nstill touted to be much more decentralized than traditional centralized\nsystems. While it is well understood that cryptocurrencies are centralized, it\nis still unclear what the underlying causes are. This work aims to address this\ngap and examines some of the forces behind mining centralization.\n  The internals of cryptocurrency mining is very opaque and difficult to study\nsince it traditionally requires forming relationships with miners, who are\ntypically reticent to share internal information about their competitive\nadvantages. This work takes a different approach by combining large-scale\nstatistical techniques with publicly available blockchain data in order to\nanswer previously intractable questions. The crux of our analysis technique is\nbased on the simple observation that some miners can utilize their hashpower\nmore efficiently due to their position in the network. By teasing out that\neffect, we de-bias the mining power distribution to get a more accurate\nestimate. Using that de-biased mining power distribution, we can answer\nquestions about the network position of miners in each cryptocurrency network.\nFinally, during the course of this study, we observed some unusual mining\nbehaviors which we highlight.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.12566,regular,pre_llm,2022,3,"{'ai_likelihood': 8.17908181084527e-06, 'text': 'Winternitz stack protocols\n\n  This paper proposes and evaluates a new bipartite post-quantum digital\nsignature protocol based on Winternitz chains and the HORS oracle. Mutually\nmistrustful Alice and Bob are able to agree and sign a series of documents in a\nway that makes it impossible (within the assumed security model) to repudiate\ntheir signatures. The number of signatures supported by a single public key is\nlimited by a large number but the security of the signature scheme is not\ndiminished by repeated application. A single public key supports both parties.\nSome ramifications are discussed, security parameters evaluated and an\napplication area delineated for the proposed concept.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.01661,review,pre_llm,2022,3,"{'ai_likelihood': 1.357661353217231e-06, 'text': ""SoK: SCT Auditing in Certificate Transparency\n\n  The Web public key infrastructure is essential to providing secure\ncommunication on the Internet today, and certificate authorities play a crucial\nrole in this ecosystem by issuing certificates. These authorities may misissue\ncertificates or suffer misuse attacks, however, which has given rise to the\nCertificate Transparency (CT) project. The goal of CT is to store all issued\ncertificates in public logs, which can then be checked for the presence of\npotentially misissued certificates. Thus, the requirement that a given\ncertificate is indeed in one (or several) of these logs lies at the core of CT.\nIn its current deployment, however, most individual clients do not check that\nthe certificates they see are in logs, as requesting a proof of inclusion\ndirectly reveals the certificate and thus creates the clear potential for a\nviolation of that client's privacy. In this paper, we explore the techniques\nthat have been proposed for privacy-preserving auditing of certificate\ninclusion, focusing on their effectiveness, efficiency, and suitability in a\nnear-term deployment. In doing so, we also explore the parallels with related\nproblems involving browser clients. Guided by a set of constraints that we\ndevelop, we ultimately observe several key limitations in many proposals,\nranging from their privacy provisions to the fact that they focus on the\ninteraction between a client and a log but leave open the question of how a\nclient could privately report any certificates that are missing.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.04117,regular,pre_llm,2022,3,"{'ai_likelihood': 5.39753172132704e-06, 'text': 'xTag: Mitigating Use-After-Free Vulnerabilities via Software-Based\n  Pointer Tagging on Intel x86-64\n\n  Memory safety in complex applications implemented in unsafe programming\nlanguages such as C/C++ is still an unresolved problem in practice. Many\ndifferent types of defenses have been proposed in the past to mitigate this\nproblem. The most promising next step is a tighter integration of the hardware\nand software level: modern mitigation techniques are either accelerated using\nhardware extensions or implemented in the hardware by extensions of the ISA. In\nparticular, memory tagging, as proposed by ARM or SPARC, promises to solve many\nissues for practical memory safety. Unfortunately, Intel x86-64, which\nrepresents the most important ISA for both the desktop and server domain, lacks\nsupport for hardware-accelerated memory tagging, so memory tagging is not\nconsidered practical for this platform.\n  In this paper, we present the design and implementation of an efficient,\nsoftware-only pointer tagging scheme for Intel x86-64 based on a novel metadata\nembedding scheme. The basic idea is to alias multiple virtual pages to one\nphysical page so that we can efficiently embed tag bits into a pointer.\nFurthermore, we introduce several optimizations that significantly reduce the\nperformance impact of this approach to memory tagging. Based on this scheme, we\npropose a novel use-after-free mitigation scheme, called xTag, that offers\nbetter performance and strong security properties compared to state-of-the-art\nmethods. We also show how double-free vulnerabilities can be mitigated. Our\napproach is highly compatible, allowing pointers to be passed back and forth\nbetween instrumented and non-instrumented code without losing metadata, and it\nis even compatible with inline assembly. We conclude that building exploit\nmitigation mechanisms on top of our memory tagging scheme is feasible on Intel\nx86-64, as demonstrated by the effective prevention of use-after-free bugs in\nthe Firefox web browser.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.01639,regular,pre_llm,2022,3,"{'ai_likelihood': 1.8543667263454863e-06, 'text': 'Sharpening Your Tools: Updating bulk_extractor for the 2020s\n\n  Bulk_extractor is a high-performance digital forensics tool written in C++.\nBetween 2018 and 2022 we updated the program from C++98 to C++17, performed a\ncomplete code refactoring, and adopted a unit test framework. The new version\ntypically runs with 75\\% more throughput than the previous version, which we\nattribute to improved multithreading. We provide lessons and recommendations\nfor other digital forensics tool maintainers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.048,review,pre_llm,2022,3,"{'ai_likelihood': 3.7087334526909726e-06, 'text': 'Usage Control Specification, Enforcement, and Robustness: A Survey\n\n  The management of data and digital assets poses various challenges, including\nthe need to adhere to legal requirements with respect to personal data\nprotection and copyright. Usage control technologies could be used by software\nplatform providers to manage data and digital assets responsibly and to provide\nmore control to data and digital asset owners. In order to better understand\nthe potential of various usage control proposals, we collate and categorize\nusage control requirements, compare the predominant usage control frameworks\nbased on said requirements, and identify existing challenges and opportunities\nthat could be used to guide future research directions.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.06598,regular,pre_llm,2022,3,"{'ai_likelihood': 4.192193349202474e-05, 'text': 'Secret-to-Image Reversible Transformation for Generative Steganography\n\n  Recently, generative steganography that transforms secret information to a\ngenerated image has been a promising technique to resist steganalysis\ndetection. However, due to the inefficiency and irreversibility of the\nsecret-to-image transformation, it is hard to find a good trade-off between the\ninformation hiding capacity and extraction accuracy. To address this issue, we\npropose a secret-to-image reversible transformation (S2IRT) scheme for\ngenerative steganography. The proposed S2IRT scheme is based on a generative\nmodel, i.e., Glow model, which enables a bijective-mapping between latent space\nwith multivariate Gaussian distribution and image space with a complex\ndistribution. In the process of S2I transformation, guided by a given secret\nmessage, we construct a latent vector and then map it to a generated image by\nthe Glow model, so that the secret message is finally transformed to the\ngenerated image. Owing to good efficiency and reversibility of S2IRT scheme,\nthe proposed steganographic approach achieves both high hiding capacity and\naccurate extraction of secret message from generated image. Furthermore, a\nseparate encoding-based S2IRT (SE-S2IRT) scheme is also proposed to improve the\nrobustness to common image attacks. The experiments demonstrate the proposed\nsteganographic approaches can achieve high hiding capacity (up to 4 bpp) and\naccurate information extraction (almost 100% accuracy rate) simultaneously,\nwhile maintaining desirable anti-detectability and imperceptibility.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.14284,regular,pre_llm,2022,3,"{'ai_likelihood': 3.5762786865234375e-06, 'text': 'Privacy-preserving record linkage using local sensitive hash and private\n  set intersection\n\n  The amount of data stored in data repositories increases every year. This\nmakes it challenging to link records between different datasets across\ncompanies and even internally, while adhering to privacy regulations. Address\nor name changes, and even different spelling used for entity data, can prevent\ncompanies from using private deduplication or record-linking solutions such as\nprivate set intersection (PSI). To this end, we propose a new and efficient\nprivacy-preserving record linkage (PPRL) protocol that combines PSI and local\nsensitive hash (LSH) functions, and runs in linear time. We explain the privacy\nguarantees that our protocol provides and demonstrate its practicality by\nexecuting the protocol over two datasets with $2^{20}$ records each, in $11-45$\nminutes, depending on network settings.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2203.01315,regular,pre_llm,2022,3,"{'ai_likelihood': 9.271833631727431e-07, 'text': ""Two Attacks On Proof-of-Stake GHOST/Ethereum\n\n  We present two attacks targeting the Proof-of-Stake (PoS) Ethereum consensus\nprotocol. The first attack suggests a fundamental conceptual incompatibility\nbetween PoS and the Greedy Heaviest-Observed Sub-Tree (GHOST) fork choice\nparadigm employed by PoS Ethereum. In a nutshell, PoS allows an adversary with\na vanishing amount of stake to produce an unlimited number of equivocating\nblocks. While most equivocating blocks will be orphaned, such orphaned `uncle\nblocks' still influence fork choice under the GHOST paradigm, bestowing upon\nthe adversary devastating control over the canonical chain. While the Latest\nMessage Driven (LMD) aspect of current PoS Ethereum prevents a straightforward\napplication of this attack, our second attack shows how LMD specifically can be\nexploited to obtain a new variant of the balancing attack that overcomes a\nrecent protocol addition that was intended to mitigate balancing-type attacks.\nThus, in its current form, PoS Ethereum without and with LMD is vulnerable to\nour first and second attack, respectively.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.07199,regular,pre_llm,2022,4,"{'ai_likelihood': 1.556343502468533e-06, 'text': ""Ear Wearable (Earable) User Authentication via Acoustic Toothprint\n\n  Earables (ear wearables) is rapidly emerging as a new platform encompassing a\ndiverse range of personal applications. The traditional authentication methods\nhence become less applicable and inconvenient for earables due to their limited\ninput interface. Nevertheless, earables often feature rich around-the-head\nsensing capability that can be leveraged to capture new types of biometrics. In\nthis work, we proposeToothSonic which leverages the toothprint-induced sonic\neffect produced by users performing teeth gestures for earable authentication.\nIn particular, we design representative teeth gestures that can produce\neffective sonic waves carrying the information of the toothprint. To reliably\ncapture the acoustic toothprint, it leverages the occlusion effect of the ear\ncanal and the inward-facing microphone of the earables. It then extracts\nmulti-level acoustic features to reflect the intrinsic toothprint information\nfor authentication. The key advantages of ToothSonic are that it is suitable\nfor earables and is resistant to various spoofing attacks as the acoustic\ntoothprint is captured via the user's private teeth-ear channel that modulates\nand encrypts the sonic waves. Our experiment studies with 25 participants show\nthat ToothSonic achieves up to 95% accuracy with only one of the users' tooth\ngestures.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.01601,regular,pre_llm,2022,4,"{'ai_likelihood': 1.026524437798394e-06, 'text': ""Towards Privacy-Preserving and Verifiable Federated Matrix Factorization\n\n  Recent years have witnessed the rapid growth of federated learning (FL), an\nemerging privacy-aware machine learning paradigm that allows collaborative\nlearning over isolated datasets distributed across multiple participants. The\nsalient feature of FL is that the participants can keep their private datasets\nlocal and only share model updates. Very recently, some research efforts have\nbeen initiated to explore the applicability of FL for matrix factorization\n(MF), a prevalent method used in modern recommendation systems and services. It\nhas been shown that sharing the gradient updates in federated MF entails\nprivacy risks on revealing users' personal ratings, posing a demand for\nprotecting the shared gradients. Prior art is limited in that they incur\nnotable accuracy loss, or rely on heavy cryptosystem, with a weak threat model\nassumed. In this paper, we propose VPFedMF, a new design aimed at\nprivacy-preserving and verifiable federated MF. VPFedMF provides guarantees on\nthe confidentiality of individual gradient updates through lightweight and\nsecure aggregation. Moreover, VPFedMF ambitiously and newly supports\ncorrectness verification of the aggregation results produced by the\ncoordinating server in federated MF. Experiments on a real-world movie rating\ndataset demonstrate the practical performance of VPFedMF in terms of\ncomputation, communication, and accuracy.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.11641,regular,pre_llm,2022,4,"{'ai_likelihood': 2.682209014892578e-06, 'text': 'Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals\n\n  Civilian-GNSS is vulnerable to signal spoofing attacks, and countermeasures\nbased on cryptographic authentication are being proposed to protect against\nthese attacks. Both Galileo and GPS are currently testing broadcast\nauthentication techniques based on the delayed key disclosure to validate the\nintegrity of navigation messages. These authentication mechanisms have proven\nsecure against record now and replay later attacks, as navigation messages\nbecome invalid after keys are released. This work analyzes the security\nguarantees of cryptographically protected GNSS signals and shows the\npossibility of spoofing a receiver to an arbitrary location without breaking\nany cryptographic operation. In contrast to prior work, we demonstrate the\nability of an attacker to receive signals close to the victim receiver and\ngenerate spoofing signals for a different target location without modifying the\nnavigation message contents. Our strategy exploits the essential common\nreception and transmission time method used to estimate pseudorange in GNSS\nreceivers, thereby rendering any cryptographic authentication useless. We\nevaluate our attack on a commercial receiver (ublox M9N) and a software-defined\nGNSS receiver (GNSS-SDR) using a combination of open-source tools, commercial\nGNSS signal generators, and software-defined radio hardware platforms. Our\nresults show that it is possible to spoof a victim receiver to locations around\n4000 km away from the true location without requiring any high-speed\ncommunication networks or modifying the message contents. Through this work, we\nfurther highlight the fundamental limitations in securing a broadcast\nsignaling-based localization system even if all communications are\ncryptographically protected.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.04084,regular,pre_llm,2022,4,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'On the Effectiveness of Binary Emulation in Malware Classification\n\n  Malware authors are continuously evolving their code base to include\ncounter-analysis methods that can significantly hinder their detection and\nblocking. While the execution of malware in a sandboxed environment may provide\na lot of insightful feedback about what the malware actually does in a machine,\nanti-virtualisation and hooking evasion methods may allow malware to bypass\nsuch detection methods. The main objective of this work is to complement\nsandbox execution with the use of binary emulation frameworks. The core idea is\nto exploit the fact that binary emulation frameworks may quickly test samples\nquicker than a sandbox environment as they do not need to open a whole new\nvirtual machine to execute the binary. While with this approach, we lose the\ngranularity of the data that can be collected through a sandbox, due to\nscalability issues, one may need to simply determine whether a file is\nmalicious or to which malware family it belongs. To this end, we record the API\ncalls that are performed and use them to explore the efficacy of using them as\nfeatures for binary and multiclass classification. Our extensive experiments\nwith real-world malware illustrate that this approach is very accurate,\nachieving state-of-the art outcomes with a statistically robust set of\nclassification experiments while simultaneously having a relatively low\ncomputational overhead compared to traditional sandbox approaches. In fact, we\ncompare the binary analysis results with a commercial sandbox, and our\nclassification outperforms it at the expense of the fine-grained results that a\nsandbox provides.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.11653,regular,pre_llm,2022,4,"{'ai_likelihood': 9.934107462565105e-08, 'text': 'Interactivity in Constructive Cryptography : Modeling and Applications\n  to Updatable Encryption and Private Information Retrieval\n\n  In this work, we extend the Constructive Cryptography (CC) framework\nintroduced by Maurer in 2011 so as to handle interactive protocols.\n  We design and construct a so-called {\\em Interactive Server Memory Resource}\n(ISMR), that is an augmented version of the basic instantiation of a\nclient-server protocol in CC, namely the Server Memory Resource. We then apply\nour ISMR construction to two types of interactive cryptographic protocols for\nremote storage : Updatable Encryption (UE) and Private Information Retrieval\n(PIR).\n  Concerning UE, our results are a composable version of those protocols,\nclarifying the security guarantees achieved by {\\em any} UE scheme. Namely, we\ngive the relevant security notion to consider according to a given leakage\ncontext. Letting USMR denote our ISMR adapted to the UE application, we prove\nthat $\\mathsf{IND}\\text{-}\\mathsf{UE}\\text{-}\\mathsf{CPA}$ security is\nsufficient for a secure construction of a confidential USMR that hides the age\nof ciphertexts; and\n$\\mathsf{IND}\\text{-}(\\mathsf{ENC}+\\mathsf{UPD})\\text{-}\\mathsf{CPA}$ security\nis sufficient for a secure construction of a confidential USMR in case of\nunrestricted leakage. As a consequence, contrary to what was claimed before,\nthe $\\mathsf{IND}\\text{-}\\mathsf{UE}$ security notion is not always stronger\nthan the $\\mathsf{IND}\\text{-}(\\mathsf{ENC+UPD})$ one.\n  Concerning PIR, we also give a composable version of PIR protocols, yielding\na unique model that unifies different notions of PIR : IT-PIR, C-PIR, one- or\nmulti- server PIR. Using the flexibility of CC, we are also able to model PIR\nvariants, such as SPIR.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.13054,review,pre_llm,2022,4,"{'ai_likelihood': 5.7948960198296445e-06, 'text': 'Systematic Literature Review: Anti-Phishing Defences and Their\n  Application to Before-the-click Phishing Email Detection\n\n  Most research into anti-phishing defence assumes that the mal-actor is\nattempting to harvest end-users\' personally identifiable information or login\ncredentials and, hence, focuses on detecting phishing websites. The defences\nfor this type of attack are usually activated after the end-user clicks on a\nlink, at which point the link is checked. This is known as after-the-click\ndetection. However, more sophisticated phishing attacks (such as spear-phishing\nand whaling) are rarely designed to get the end-user to visit a website.\nInstead, they attempt to get the end-user to perform some other action, for\nexample, transferring money from their bank account to the mal-actors account.\nThese attacks are rarer, and before-the-click defence has been investigated\nless than after-the-click defence. To better integrate and contextualize these\nstudies in the overall anti-phishing research, this paper presents a systematic\nliterature review of proposed anti-phishing defences. From a total of 6330\npapers, 21 primary studies and 335 secondary studies were identified and\nexamined. The current research was grouped into six primary categories,\nblocklist/allowlist, heuristics, content, visual, artificial\nintelligence/machine learning and proactive, with an additional category of\n""other"" for detection techniques that do not fit into any of the primary\ncategories. It then discusses the performance and suitability of using these\ntechniques for detecting phishing emails before the end-user even reads the\nemail. Finally, it suggests some promising areas for further research.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.02571,review,pre_llm,2022,4,"{'ai_likelihood': 3.973642985026042e-07, 'text': 'Post-Quantum Cryptography Algorithms Standardization and Performance\n  Analysis\n\n  Quantum computer is no longer a hypothetical idea. It is the worlds most\nimportant technology and there is a race among countries to get supremacy in\nquantum technology. Its the technology that will reduce the computing time from\nyears to hours or even minutes. The power of quantum computing will be a great\nsupport for the scientific community. However, it raises serious threats to\ncybersecurity. Theoretically, all the cryptography algorithms are vulnerable to\nattack. The practical quantum computers, when available with millions of qubits\ncapacity, will be able to break nearly all modern public-key cryptographic\nsystems. Before the quantum computers arrive with sufficient qubit capacity, we\nmust be ready with quantum-safe cryptographic algorithms, tools, techniques,\nand deployment strategies to protect the ICT infrastructure. This paper\ndiscusses in detail the global effort for the design, development, and\nstandardization of various quantum-safe cryptography algorithms along with the\nperformance analysis of some of the potential quantum-safe algorithms. Most of\nthe quantum-safe algorithms need more CPU cycles, higher runtime memory, and\nlarge key size. The objective of the paper is to analyze the feasibility of the\nvarious quantum-safe cryptography algorithms.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.13885,regular,pre_llm,2022,4,"{'ai_likelihood': 4.404120975070529e-06, 'text': 'Weak-Key Analysis for BIKE Post-Quantum Key Encapsulation Mechanism\n\n  The evolution of quantum computers poses a serious threat to contemporary\npublic-key encryption (PKE) schemes. To address this impending issue, the\nNational Institute of Standards and Technology (NIST) is currently undertaking\nthe Post-Quantum Cryptography (PQC) standardization project intending to\nevaluate and subsequently standardize the suitable PQC scheme(s). One such\nattractive approach, called Bit Flipping Key Encapsulation (BIKE), has made to\nthe final round of the competition. Despite having some attractive features,\nthe IND-CCA security of the BIKE depends on the average decoder failure rate\n(DFR), a higher value of which can facilitate a particular type of side-channel\nattack. Although the BIKE adopts a Black-Grey-Flip (BGF) decoder that offers a\nnegligible DFR, the effect of weak-keys on the average DFR has not been fully\ninvestigated. Therefore, in this paper, we first perform an implementation of\nthe BIKE scheme, and then through extensive experiments show that the weak-keys\ncan be a potential threat to IND-CCA security of the BIKE scheme and thus need\nattention from the research community prior to standardization. We also propose\na key-check algorithm that can potentially supplement the BIKE mechanism and\nprevent users from generating and adopting weak keys to address this issue.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.01634,review,pre_llm,2022,4,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'Evaluation of Computational Approaches of Short Weierstrass Elliptic\n  Curves for Cryptography\n\n  The survey presents the evolution of Short Weierstrass elliptic curves after\ntheir introduction in cryptography. Subsequently, this evolution resulted in\nthe establishment of present elliptic curve computational standards. We discuss\nthe chronology of attacks on Elliptic Curve Discrete Logarithm Problem and\ninvestigate their countermeasures to highlight the evolved selection criteria\nof cryptographically safe elliptic curves. Further, two popular deterministic\nand random approaches for selection of Short Weierstrass elliptic curve for\ncryptography are evaluated from computational, security and trust perspectives\nand a trend in existent computational standards is demonstrated. Finally,\nstandard and non-standard elliptic curves are analysed to add a new insight\ninto their usability. There is no such survey conducted in past to the best of\nour knowledge.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.02753,regular,pre_llm,2022,4,"{'ai_likelihood': 5.960464477539062e-07, 'text': 'Encrypted, Anonymized System for Protected Health Information\n  Verification Built via Proof of Stake\n\n  Digital Health Passes (DHP), systems of digitally validating quarantine and\nvaccination status such as the New York IBM Excelsior Pass, demonstrate a\nlawful means to approach some benefits offered by ""true elimination"" treatment\nstrategies-which focus on the complete elimination of cases instead of\ninvesting more in controlling the progression of the disease-of COVID-19.\nCurrent implementations of DHPs require region-based control and central\nstorage of Protected Health Information (PHI)-creating a challenge to\nwidespread use across different jurisdictions with incompatible data management\nsystems and a lack of standardized patient privacy controls. In this work, a\nmechanism for decentralized PHI storage and validation is proposed through a\nnovel two-stage handshaking mechanism update to blockchain proof-of-stake\nconsensus. The proposed mechanism, when used to support a DHP, allows\nindividuals to validate their quarantine and testing universally with any\njurisdiction while allowing their right of independent movement and the\nprotection of their PHI. Implementational details on the protocol are given,\nand the protocol is shown to withstand a 1% disturbance attack at only 923\nparticipants via a Monte-Carlo simulation: further validating its stability.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.01233,regular,pre_llm,2022,4,"{'ai_likelihood': 5.960464477539062e-07, 'text': ""Clues in Tweets: Twitter-Guided Discovery and Analysis of SMS Spam\n\n  With its critical role in business and service delivery through mobile\ndevices, SMS (Short Message Service) has long been abused for spamming, which\nis still on the rise today possibly due to the emergence of A2P bulk messaging.\nThe effort to control SMS spam has been hampered by the lack of up-to-date\ninformation about illicit activities. In our research, we proposed a novel\nsolution to collect recent SMS spam data, at a large scale, from Twitter, where\nusers voluntarily report the spam messages they receive. For this purpose, we\ndesigned and implemented SpamHunter, an automated pipeline to discover SMS spam\nreporting tweets and extract message content from the attached screenshots.\nLeveraging SpamHunter, we collected from Twitter a dataset of 21,918 SMS spam\nmessages in 75 languages, spanning over four years. To our best knowledge, this\nis the largest SMS spam dataset ever made public. More importantly, SpamHunter\nenables us to continuously monitor emerging SMS spam messages, which\nfacilitates the ongoing effort to mitigate SMS spamming. We also performed an\nin-depth measurement study that sheds light on the new trends in the spammer's\nstrategies, infrastructure and spam campaigns. We also utilized our spam SMS\ndata to evaluate the robustness of the spam countermeasures put in place by the\nSMS ecosystem, including anti-spam services, bulk SMS services, and text\nmessaging apps. Our evaluation shows that such protection cannot effectively\nhandle those spam samples: either introducing significant false positives or\nmissing a large number of newly reported spam messages.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.01635,regular,pre_llm,2022,4,"{'ai_likelihood': 1.8543667263454863e-06, 'text': 'Computation of Trusted Short Weierstrass Elliptic Curves for\n  Cryptography\n\n  Short Weierstrass\'s elliptic curves with underlying hard Elliptic Curve\nDiscrete Logarithm Problems was widely used in Cryptographic applications. This\npaper introduces a new security notation \'trusted security\' for computation\nmethods of elliptic curves for cryptography. Three additional ""trusted security\nacceptance criteria"" is proposed to be met by the elliptic curves aimed for\ncryptography. Further, two cryptographically secure elliptic curves over 256\nbit and 384 bit prime fields are demonstrated which are secure from ECDLP, ECC\nas well as trust perspectives. The proposed elliptic curves are successfully\nsubjected to thorough security analysis and performance evaluation with respect\nto key generation and signing/verification and hence, proven for their\ncryptographic suitability and great feasibility for acceptance by the\ncommunity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.13737,regular,pre_llm,2022,4,"{'ai_likelihood': 2.4504131740993925e-06, 'text': ""Extricating IoT Devices from Vendor Infrastructure with Karl\n\n  Most consumer IoT devices are vertically integrated with cloud-side\ninfrastructure. Such architectures present enormous risk to user data,\nexacerbated by vendor heterogeneity and the inability for users to audit\ncloud-side activity. A more promising approach would be to leverage local\nhardware, providing users control over how their data is processed and why it\ncan be shared with other devices or the Internet.\n  Karl is a new smart-home framework designed to host IoT computation and\nstorage on user-chosen devices. A key insight in Karl's modular programming\nmodel is that a familiar interface (inspired by serverless) can capture most\nmodern cloud-side IoT components under a single framework, which executes\nmodules agnostic of hardware location. While local hosting eliminates many\nflows, modularity enables all remaining flows to be justified using\nfine-grained primitives. We introduce two IoT security mechanisms: pipeline\npermissions that permit device data to be shared given some justification and\nexit policies that block flows unless specific conditions are met. We evaluate\nKarl through two end-to-end applications.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.09106,regular,pre_llm,2022,4,"{'ai_likelihood': 7.947285970052084e-07, 'text': 'Identifying Near-Optimal Single-Shot Attacks on ICSs with Limited\n  Process Knowledge\n\n  Industrial Control Systems (ICSs) rely on insecure protocols and devices to\nmonitor and operate critical infrastructure. Prior work has demonstrated that\npowerful attackers with detailed system knowledge can manipulate exchanged\nsensor data to deteriorate performance of the process, even leading to full\nshutdowns of plants. Identifying those attacks requires iterating over all\npossible sensor values, and running detailed system simulation or analysis to\nidentify optimal attacks. That setup allows adversaries to identify attacks\nthat are most impactful when applied on the system for the first time, before\nthe system operators become aware of the manipulations.\n  In this work, we investigate if constrained attackers without detailed system\nknowledge and simulators can identify comparable attacks. In particular, the\nattacker only requires abstract knowledge on general information flow in the\nplant, instead of precise algorithms, operating parameters, process models, or\nsimulators. We propose an approach that allows single-shot attacks, i.e.,\nnear-optimal attacks that are reliably shutting down a system on the first try.\nThe approach is applied and validated on two use cases, and demonstrated to\nachieve comparable results to prior work, which relied on detailed system\ninformation and simulations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.12227,review,pre_llm,2022,4,"{'ai_likelihood': 3.1458006964789497e-06, 'text': 'Open or not open: Are conventional radio access networks more secure and\n  trustworthy than Open-RAN?\n\n  The Open RAN architecture is a promising and future-oriented architecture. It\nis intended to open up the radio access network (RAN) and enable more\ninnovation and competition in the market. This will lead to RANs for current 5G\nnetworks, but especially for future 6G networks, evolving from the current\nhighly integrated, vendor-specific RAN architecture towards disaggregated\narchitectures with open interfaces that will enable to better tailor RAN\nsolutions to the requirements of 5G and 6G applications. However, the\nintroduction of such an open architecture substantially broadens the attack\npossibilities when compared to conventional RANs. In the past, this has often\nled to negative headlines that in summary have associated Open RAN with faulty\nor inadequate security. In this paper, we analyze what components are involved\nin an Open RAN deployment, how to assess the current state of security, and\nwhat measures need to be taken to ensure secure operation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.13734,regular,pre_llm,2022,4,"{'ai_likelihood': 6.622738308376736e-07, 'text': ""Flexible and scalable privacy assessment for very large datasets, with\n  an application to official governmental microdata\n\n  We present a systematic refactoring of the conventional treatment of privacy\nanalyses, basing it on mathematical concepts from the framework of Quantitative\nInformation Flow (QIF). The approach we suggest brings three principal\nadvantages: it is flexible, allowing for precise quantification and comparison\nof privacy risks for attacks both known and novel; it can be computationally\ntractable for very large, longitudinal datasets; and its results are\nexplainable both to politicians and to the general public. We apply our\napproach to a very large case study: the Educational Censuses of Brazil,\ncurated by the governmental agency INEP, which comprise over 90 attributes of\napproximately 50 million individuals released longitudinally every year since\n2007. These datasets have only very recently (2018-2021) attracted legislation\nto regulate their privacy -- while at the same time continuing to maintain the\nopenness that had been sought in Brazilian society. INEP's reaction to that\nlegislation was the genesis of our project with them. In our conclusions here\nwe share the scientific, technical, and communication lessons we learned in the\nprocess.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.13859,regular,pre_llm,2022,4,"{'ai_likelihood': 0.0, 'text': 'A Digital Twin Framework for Cyber Security in Cyber-Physical Systems\n\n  Currently, most of the research in digital twins focuses on simulation and\noptimization. Digital twins are especially useful for critical systems.\nHowever, digital twins can also be used for safety and cyber security. The idea\nof this paper is motivated by the limitations of cyber security in\nCyber-Physical Systems (CPSs). We introduce an efficient synchronization\napproach to maintain the state between the virtual environment and the physical\nenvironment. In this case, we can receive prompt feedback by conducting\nsecurity analysis in the virtual domain. Thus, helping to enhance the cyber\nsecurity of CPSs, we propose a digital twin-based framework. Based on the\napproach, the security of the CPSs can be protected by the digital twin system.\nMoreover, the proposed architecture has also been optimized to meet the\nsecurity requirements and maintain less network burden for CPSs\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.11639,regular,pre_llm,2022,4,"{'ai_likelihood': 1.556343502468533e-06, 'text': 'Investigating Black-Box Function Recognition Using Hardware Performance\n  Counters\n\n  This paper presents new methods and results for recognising black-box program\nfunctions using hardware performance counters (HPC), where an investigator can\ninvoke and measure function calls. Important use cases include analysing\ncompiled libraries, e.g. static and dynamic link libraries, and trusted\nexecution environment (TEE) applications. We develop a generic approach to\nclassify a comprehensive set of hardware events, e.g. branch mis-predictions\nand instruction retirements, to recognise standard benchmarking and\ncryptographic library functions. This includes various signing, verification\nand hash functions, and ciphers in numerous modes of operation. Three\narchitectures are evaluated using off-the-shelf Intel/X86-64, ARM, and RISC-V\nCPUs. Next, we show that several known CVE-numbered OpenSSL vulnerabilities can\nbe detected using HPC differences between patched and unpatched library\nversions. Further, we demonstrate that standardised cryptographic functions\nwithin ARM TrustZone TEE applications can be recognised using non-secure world\nHPC measurements, applying to platforms that insecurely perturb the performance\nmonitoring unit (PMU) during TEE execution. High accuracy was achieved in all\ncases (86.22-99.83%) depending on the application, architectural, and\ncompilation assumptions. Lastly, we discuss mitigations, outstanding\nchallenges, and directions for future research.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.08032,review,pre_llm,2022,4,"{'ai_likelihood': 4.635916815863716e-07, 'text': ""A Survey of Layer-Two Blockchain Protocols\n\n  After the success of the Bitcoin blockchain, came several cryptocurrencies\nand blockchain solutions in the last decade. Nonetheless, Blockchain-based\nsystems still suffer from low transaction rates and high transaction processing\nlatencies, which hinder blockchains' scalability. An entire class of solutions,\ncalled Layer-1 scalability solutions, have attempted to incrementally improve\nsuch limitations by adding/modifying fundamental blockchain attributes.\nRecently, a completely different class of works, called Layer-2 protocols, have\nemerged to tackle the blockchain scalability issues using unconventional\napproaches. Layer-2 protocols improve transaction processing rates, periods,\nand fees by minimizing the use of underlying slow and costly blockchains. In\nfact, the main chain acts just as an instrument for trust establishment and\ndispute resolution among Layer-2 participants, where only a few transactions\nare dispatched to the main chain. Thus, Layer-2 blockchain protocols have the\npotential to transform the domain. However, rapid and discrete developments\nhave resulted in diverse branches of Layer-2 protocols. In this work, we\nsystematically create a broad taxonomy of such protocols and implementations.\nWe discuss each Layer-2 protocol class in detail and also elucidate their\nrespective approaches, salient features, requirements, etc. Moreover, we\noutline the issues related to these protocols along with a comparative\ndiscussion. Our thorough study will help further systematize the knowledge\ndispersed in the domain and help the readers to better understand the field of\nLayer-2 protocols.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2204.01802,regular,pre_llm,2022,4,"{'ai_likelihood': 3.311369154188368e-08, 'text': 'Generalized Triangular Dynamical System: An Algebraic System for Constructing Cryptographic Permutations over Finite Fields\n\nIn recent years a new class of symmetric-key primitives over $\\mathbb{F}_p$ that are essential to Multi-Party Computation and Zero-Knowledge Proofs based protocols have emerged. Towards improving the efficiency of such primitives, a number of new block ciphers and hash functions over $\\mathbb{F}_p$ were proposed. These new primitives also showed that following alternative design strategies to the classical Substitution-Permutation Network (SPN) and Feistel Networks leads to more efficient cipher and hash function designs over $\\mathbb{F}_p$ specifically for large odd primes $p$.\n  In view of these efforts, in this work we build an \\emph{algebraic framework} that allows the systematic exploration of viable and efficient design strategies for constructing symmetric-key (iterative) permutations over $\\mathbb{F}_p$. We first identify iterative polynomial dynamical systems over finite fields as the central building block of almost all block cipher design strategies. We propose a generalized triangular polynomial dynamical system (GTDS), and based on the GTDS we provide a generic definition of an iterative (keyed) permutation over $\\mathbb{F}_p^n$.\n  Our GTDS-based generic definition is able to describe the three most well-known design strategies, namely SPNs, Feistel networks and Lai--Massey. Consequently, the block ciphers that are constructed following these design strategies can also be instantiated from our generic definition. Moreover, we find that the recently proposed \\texttt{Griffin} design, which neither follows the Feistel nor the SPN design, can be described using the generic GTDS-based definition. We also show that a new generalized Lai--Massey construction can be instantiated from the GTDS-based definition.\n  We further provide generic analysis of the GTDS including an upper bound on the differential uniformity and the correlation.', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.08529,regular,pre_llm,2022,5,"{'ai_likelihood': 1.2252065870496963e-06, 'text': 'F3B: A Low-Overhead Blockchain Architecture with Per-Transaction\n  Front-Running Protection\n\n  Front-running attacks, which benefit from advanced knowledge of pending\ntransactions, have proliferated in the blockchain space since the emergence of\ndecentralized finance. Front-running causes devastating losses to honest\nparticipants and continues to endanger the fairness of the ecosystem. We\npresent Flash Freezing Flash Boys (F3B), a blockchain architecture that\naddresses front-running attacks by using threshold cryptography. In F3B, a user\ngenerates a symmetric key to encrypt their transaction, and once the underlying\nconsensus layer has finalized the transaction, a decentralized\nsecret-management committee reveals this key. F3B mitigates front-running\nattacks because, before the consensus group finalizes it, an adversary can no\nlonger read the content of a transaction, thus preventing the adversary from\nbenefiting from advanced knowledge of pending transactions. Unlike other\nmitigation systems, F3B properly ensures that all unfinalized transactions,\neven with significant delays, remain private by adopting per-transaction\nprotection. Furthermore, F3B addresses front-running at the execution layer;\nthus, our solution is agnostic to the underlying consensus algorithm and\ncompatible with existing smart contracts. We evaluated F3B on Ethereum with a\nmodified execution layer and found only a negligible (0.026%) increase in\ntransaction latency, specifically due to running threshold decryption with a\n128-member secret-management committee after a transaction is finalized; this\nindicates that F3B is both practical and low-cost.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.01052,regular,pre_llm,2022,5,"{'ai_likelihood': 4.337893591986763e-06, 'text': 'HTTPA/2: a Trusted End-to-End Protocol for Web Services\n\n  With the advent of cloud computing and the Internet, the commercialized\nwebsite becomes capable of providing more web services, such as software as a\nservice (SaaS) or function as a service (FaaS), for great user experiences.\nUndoubtedly, web services have been thriving in popularity that will continue\ngrowing to serve modern human life. As expected, there came the ineluctable\nneed for preserving privacy, enhancing security, and building trust. However,\nHTTPS alone cannot provide a remote attestation for building trust with web\nservices, which remains lacking in trust. At the same time, cloud computing is\nactively adopting the use of TEEs and will demand a web-based protocol for\nremote attestation with ease of use. Here, we propose HTTPA/2 as an upgraded\nversion of HTTP-Attestable (HTTPA) by augmenting existing HTTP to enable\nend-to-end trusted communication between endpoints at layer 7 (L7). HTTPA/2\nallows for L7 message protection without relying on TLS. In practice, HTTPA/2\nis designed to be compatible with the in-network processing of the modern cloud\ninfrastructure, including L7 gateway, L7 load balancer, caching, etc. We\nenvision that \\acs{httpa}/2 will further enable trustworthy web services and\ntrustworthy AI applications in the future, accelerating the transformation of\nthe web-based digital world to be more trustworthy.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.05747,regular,pre_llm,2022,5,"{'ai_likelihood': 3.1789143880208335e-06, 'text': ""Trusted Container Extensions for Container-based Confidential Computing\n\n  Cloud computing has emerged as a corner stone of today's computing landscape.\nMore and more customers who outsource their infrastructure benefit from the\nmanageability, scalability and cost saving that come with cloud computing.\nThose benefits get amplified by the trend towards microservices. Instead of\nrenting and maintaining full VMs, customers increasingly leverage container\ntechnologies, which come with a much more lightweight resource footprint while\nalso removing the need to emulate complete systems and their devices.\n  However, privacy concerns hamper many customers from moving to the cloud and\nleveraging its benefits. Furthermore, regulatory requirements prevent the\nadaption of cloud computing in many industries, such as health care or finance.\nStandard software isolation mechanisms have been proven to be insufficient if\nthe host system is not fully trusted, e.g., when the cloud infrastructure gets\ncompromised by malicious third-party actors. Consequently, confidential\ncomputing is gaining increasing relevance in the cloud computing field.\n  We present Trusted Container Extensions (TCX), a novel container security\narchitecture, which combines the manageability and agility of standard\ncontainers with the strong protection guarantees of hardware-enforced Trusted\nExecution Environments (TEEs) to enable confidential computing for container\nworkloads. TCX provides significant performance advantages compared to existing\napproaches while protecting container workloads and the data processed by them.\nOur implementation, based on AMD Secure Encrypted Virtualization (SEV), ensures\nintegrity and confidentiality of data and services during deployment, and\nallows secure interaction between protected containers as well as to external\nentities. Our evaluation shows that our implementation induces a low\nperformance overhead of 5.77% on the standard SPEC2017 benchmark suite.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.1058,regular,pre_llm,2022,5,"{'ai_likelihood': 1.2649430168999566e-05, 'text': ""Secure Order Based Voting Using Distributed Tallying\n\nElectronic voting systems have significant advantages in comparison with physical voting systems. One of the main challenges in e-voting systems is to secure the voting process: namely, to certify that the computed results are consistent with the cast ballots and that the voters' privacy is preserved. We propose herein a secure voting protocol for elections that are governed by order-based voting rules. Our protocol, in which the tallying task is distributed among several independent talliers, offers perfect ballot secrecy in the sense that it issues only the required output while no other information on the cast ballots is revealed. Such perfect secrecy, achieved by employing secure multiparty computation tools, may increase the voters' confidence and, consequently, encourage them to vote according to their true preferences. We implemented a demo of a voting system that is based on our protocol and we describe herein the system's components and its operation. Our implementation demonstrates that our secure order-based voting protocol can be readily implemented in real-life large-scale electronic elections."", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.13576,review,pre_llm,2022,5,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Factors Impacting Resilience of Internet of Things Systems in Critical\n  Infrastructure\n\n  Internet of Things (IoT) systems are recently being employed in various types\nof critical infrastructure, including integrated rescue systems, healthcare,\ndefence, energy and other fields. Recently, the security and safety of IoT\nsystems, in general, has been questioned by a number of studies. Raised\nconcerns do not relate to the IoT technology in principle but to poor\nengineering practices that are mostly preventable. In critical infrastructure,\ndemand for safety and security is strongly present and justifies a discussion\nabout the general resilience of IoT systems. In this context, resilience\nincludes system resistance to cyberattacks and its stability to operating\nconditions and system reliability and safety in terms of present flaws. In this\npaper, we discuss relevant factors impacting the resilience of IoT systems in\nthe critical infrastructure and suggest possible countermeasures and actions\nmitigate the potential effects of these factors. Contrary to the previous work,\nan unique critical system Model-based Testing viewpoint is taken in this\nanalysis.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.09635,regular,pre_llm,2022,5,"{'ai_likelihood': 2.086162567138672e-05, 'text': 'BP-MAC: Fast Authentication for Short Messages\n\n  Resource-constrained devices increasingly rely on wireless communication for\nthe reliable and low-latency transmission of short messages. However,\nespecially the implementation of adequate integrity protection of time-critical\nmessages places a significant burden on these devices. We address this issue by\nproposing BP-MAC, a fast and memory-efficient approach for computing message\nauthentication codes based on the well-established Carter-Wegman construction.\nOur key idea is to offload resource-intensive computations to idle phases and\nthus save valuable time in latency-critical phases, i.e., when new data awaits\nprocessing. Therefore, BP-MAC leverages a universal hash function designed for\nthe bitwise preprocessing of integrity protection to later only require a few\nXOR operations during the latency-critical phase. Our evaluation on embedded\nhardware shows that BP-MAC outperforms the state-of-the-art in terms of latency\nand memory overhead, notably for small messages, as required to adequately\nprotect resource-constrained devices with stringent security and latency\nrequirements.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.13169,regular,pre_llm,2022,5,"{'ai_likelihood': 1.4901161193847656e-06, 'text': 'Revisiting the Efficiency of Asynchronous Multi Party Computation\n  Against General Adversaries\n\n  In this paper, we design secure multi-party computation (MPC) protocols in\nthe asynchronous communication setting with optimal resilience. Our protocols\nare secure against a computationally-unbounded malicious adversary,\ncharacterized by an adversary structure $\\mathcal{Z}$, which enumerates all\npossible subsets of potentially corrupt parties. Our protocols incur a\ncommunication of $\\mathcal{O}(|\\mathcal{Z}|^2)$ and\n$\\mathcal{O}(|\\mathcal{Z}|)$ bits per multiplication for perfect and\nstatistical security respectively. These are the first protocols with this\ncommunication complexity, as such protocols were known only in the synchronous\ncommunication setting (Hirt and Tschudi, ASIACRYPT 2013).\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.05573,regular,pre_llm,2022,5,"{'ai_likelihood': 3.1789143880208335e-06, 'text': ""A Longitudinal Study of Cryptographic API: a Decade of Android Malware\n\n  Cryptography has been extensively used in Android applications to guarantee\nsecure communications, conceal critical data from reverse engineering, or\nensure mobile users' privacy. Various system-based and third-party libraries\nfor Android provide cryptographic functionalities, and previous works mainly\nexplored the misuse of cryptographic API in benign applications. However, the\nrole of cryptographic API has not yet been explored in Android malware. This\npaper performs a comprehensive, longitudinal analysis of cryptographic API in\nAndroid malware. In particular, we analyzed $603\\,937$ Android applications\n(half of them malicious, half benign) released between $2012$ and $2020$,\ngathering more than 1 million cryptographic API expressions. Our results reveal\nintriguing trends and insights on how and why cryptography is employed in\nAndroid malware. For instance, we point out the widespread use of weak hash\nfunctions and the late transition from insecure DES to AES. Additionally, we\nshow that cryptography-related characteristics can help to improve the\nperformance of learning-based systems in detecting malicious applications.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.0441,regular,pre_llm,2022,5,"{'ai_likelihood': 1.357661353217231e-06, 'text': 'Tight Differential Privacy Blanket for Shuffle Model\n\n  With the recent bloom of focus on digital economy, the importance of personal\ndata has seen a massive surge of late. Keeping pace with this trend, the model\nof data market is starting to emerge as a process to obtain high-quality\npersonal information in exchange of incentives. To have a formal guarantee to\nprotect the privacy of the sensitive data involved in digital economy,\n\\emph{differential privacy (DP)} is the go-to technique, which has gained a lot\nof attention by the community recently. However, it is essential to optimize\nthe privacy-utility trade-off by ensuring the highest level of privacy\nprotection is ensured while preserving the utility of the data. In this paper,\nwe theoretically derive sufficient and necessary conditions to have tight\n$(\\epsilon,\\,\\delta)$-DP blankets for the shuffle model, which, to the best of\nour knowledge, have not been proven before, and, thus, characterize the best\npossible DP protection for shuffle models which can be implemented in data\nmarkets to ensure privacy-preserving trading of digital economy.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.13765,regular,pre_llm,2022,5,"{'ai_likelihood': 3.013345930311415e-06, 'text': 'Machine Learning-based Ransomware Detection Using Low-level Memory\n  Access Patterns Obtained From Live-forensic Hypervisor\n\n  Since modern anti-virus software mainly depends on a signature-based static\nanalysis, they are not suitable for coping with the rapid increase in malware\nvariants. Moreover, even worse, many vulnerabilities of operating systems\nenable attackers to evade such protection mechanisms. We, therefore, developed\na thin and lightweight live-forensic hypervisor to create an additional\nprotection layer under a conventional protection layer of operating systems\nwith supporting ransomware detection using dynamic behavioral features. The\ndeveloped live-forensic hypervisor collects low-level memory access patterns\ninstead of high-level information such as process IDs and API calls that modern\nVirtual Machine Introspection techniques have employed. We then created the\nlow-level memory access patterns dataset of three ransomware samples, one wiper\nmalware sample, and four benign applications. We confirmed that our best\nmachine learning classifier using only low-level memory access patterns\nachieved an $F_1$ score of 0.95 in detecting ransomware and wiper malware.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.06661,regular,pre_llm,2022,5,"{'ai_likelihood': 7.28501213921441e-07, 'text': 'FLAD: Adaptive Federated Learning for DDoS Attack Detection\n\n  Federated Learning (FL) has been recently receiving increasing consideration\nfrom the cybersecurity community as a way to collaboratively train deep\nlearning models with distributed profiles of cyber threats, with no disclosure\nof training data. Nevertheless, the adoption of FL in cybersecurity is still in\nits infancy, and a range of practical aspects have not been properly addressed\nyet. Indeed, the Federated Averaging algorithm at the core of the FL concept\nrequires the availability of test data to control the FL process. Although this\nmight be feasible in some domains, test network traffic of newly discovered\nattacks cannot be always shared without disclosing sensitive information. In\nthis paper, we address the convergence of the FL process in dynamic\ncybersecurity scenarios, where the trained model must be frequently updated\nwith new recent attack profiles to empower all members of the federation with\nthe latest detection features. To this aim, we propose FLAD (adaptive Federated\nLearning Approach to DDoS attack detection), an FL solution for cybersecurity\napplications based on an adaptive mechanism that orchestrates the FL process by\ndynamically assigning more computation to those members whose attacks profiles\nare harder to learn, without the need of sharing any test data to monitor the\nperformance of the trained model. Using a recent dataset of DDoS attacks, we\ndemonstrate that FLAD outperforms state-of-the-art FL algorithms in terms of\nconvergence time and accuracy across a range of unbalanced datasets of\nheterogeneous DDoS attacks. We also show the robustness of our approach in a\nrealistic scenario, where we retrain the deep learning model multiple times to\nintroduce the profiles of new attacks on a pre-trained model.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.03083,regular,pre_llm,2022,5,"{'ai_likelihood': 1.357661353217231e-06, 'text': 'Heal the Privacy: Functional Encryption and Privacy-Preserving Analytics\n\n  Secure cloud storage is an issue of paramount importance that both businesses\nand end-users should take into consideration before moving their data to,\npotentially, untrusted clouds. Migrating data to the cloud raises multiple\nprivacy issues, as they are completely controlled by a cloud provider. Hence,\nan untrusted cloud provider can potentially breach users; privacy and gain\naccess to sensitive information. The problem becomes even more pronounced when\nthe could provider is required to store a statistical database and periodically\npublish analytics. In this work, we first present a detailed example showing\nthat the use of cryptography is not enough to ensure the privacy of\nindividuals. Then, we design a hybrid protocol based on Functional Encryption\nand Differential Privacy that allows the computations of statistics in a\nprivacy-preserving way.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.06091,regular,pre_llm,2022,5,"{'ai_likelihood': 1.3841523064507379e-05, 'text': 'Synergia: Hardening High-Assurance Security Systems with Confidential\n  and Trusted Computing\n\n  High-assurance security systems require strong isolation from the untrusted\nworld to protect the security-sensitive or privacy-sensitive data they process.\nExisting regulations impose that such systems must execute in a trustworthy\noperating system (OS) to ensure they are not collocated with untrusted software\nthat might negatively impact their availability or security. However, the\nexisting techniques to attest to the OS integrity fall short due to the cuckoo\nattack. In this paper, we first show a novel defense mechanism against the\ncuckoo attack, and we formally prove it. Then, we implement it as part of an\nintegrity monitoring and enforcement framework that attests to the\ntrustworthiness of the OS from 3.7x to 8.5x faster than the existing integrity\nmonitoring systems. We demonstrate its practicality by protecting the execution\nof a real-world eHealth application, performing micro and macro-benchmarks, and\nassessing the security risk.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.03746,regular,pre_llm,2022,5,"{'ai_likelihood': 2.317958407931858e-07, 'text': ""Reasoning about inter-procedural security requirements in IoT\n  applications\n\n  The importance of information security dramatically increased and will\nfurther grow due to the shape and nature of the modern computing industry.\nSoftware is published at a continuously increasing pace. The Internet of Things\nand security protocols are two examples of domains that pose a great security\nchallenge, due to how diverse the needs for those software may be, and a\ngeneralisation of the capabilities regarding the toolchain necessary for\ntesting is becoming a necessity. Oftentimes, these software are designed\nstarting from a formal model, which can be verified with appropriate model\ncheckers. These models, though, do not represent the actual implementation,\nwhich can deviate from the model and hence certain security properties might\nnot be inherited from the model, or additional issues could be introduced in\nthe implementation. In this paper we describe a proposal for a novel technique\nto assess software security properties from LLVM bitcode. We perform various\nstatic analyses, such as points-to analysis, call graph and control-flow graph,\nwith the aim of deriving from them an 'accurate enough' formal model of the\npaths taken by the program, which are then going to be examined via\nconsolidated techniques by matching them against a set of defined rules. The\nproposed workflow then requires further analysis with more precise methods if a\nrule is violated, in order to assess the actual feasibility of such path(s).\nThis step is required as the analyses performed to derive the model to analyse\nare over-approximating the behaviour of the software.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.04405,regular,pre_llm,2022,5,"{'ai_likelihood': 7.616149054633247e-07, 'text': ""Self-Serviced IoT: Practical and Private IoT Computation Offloading with\n  Full User Control\n\n  The rapid increase in the adoption of Internet-of-Things (IoT) devices raises\ncritical privacy concerns as these devices can access a variety of sensitive\ndata. The current status quo of relying on manufacturers' cloud services to\nprocess this data is especially problematic since users cede control once their\ndata leaves their home. Multiple recent incidents further call into question if\nvendors can indeed be trusted with users' data. At the same time, users desire\ncompelling features supported by IoT devices and ML-based cloud inferences\nwhich compels them to subscribe to manufacturer-managed cloud services. An\nalternative to use a local in-home hub requires substantial hardware\ninvestment, management, and scalability limitations. This paper proposes\nSelf-Serviced IoT (SSIoT), a clean-slate approach of using a hybrid hub-cloud\nsetup to enable privacy-aware computation offload for IoT applications.\nUniquely, SSIoT enables opportunistic computation offload to public cloud\nproviders while still ensuring that the end-user retains complete end-to-end\ncontrol of their private data reducing the trust required from public cloud\nproviders. We show that SSIoT can leverage emerging function-as-a-service\ncomputation (e.g. AWS Lambda) to make these offloads cost-efficient, scalable\nand high performance as long as key limitations of being stateless, limited\nresources, and security isolation can be addressed. We build an end-to-end\nprototype of SSIoT and evaluate it using several micro-benchmarks and example\napplications representing real-world IoT use cases. Our results show that SSIoT\nis highly scalable, as compared to local-only approaches which struggle with as\nlittle as 2-4 apps in parallel. We also show that SSIoT is cost-efficient\n(operating a smart doorbell for $10 a year) at the cost of minimal additional\nlatency as compared to a local-only hub, even with a hardware ML accelerator.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.05121,regular,pre_llm,2022,5,"{'ai_likelihood': 8.377763960096572e-06, 'text': 'Detecting Phishing sites Without Visiting them\n\n  Now-a-days, cyberattacks are increasing at an unprecedented rate. Phishing is\na social engineering attack which has a massive global impact, destroying the\nfinancial and economic value of corporations, government sectors and\nindividuals. In phishing, attackers steal users personal information such as\nusername, passwords, debit card information and so on. In order to detect\nzero-hour attacks and protect end-users from these attacks, various\nanti-phishing techniques are developed, but the end-users have to visit the\nwebsites to know whether they are safe or not, which may lead to infecting\ntheir system. In this paper, we propose a method where end-users can detect the\ngenuineness of the sites without visiting them. The proposed method collects\nlegitimate and phishing URLs and extract features from them. The extracted\nfeatures are given as input to six different classifiers for training and\nconstructing the model. The classifiers used are Naive-Bayes, Logistic\nRegression, Random Forest,CatBoost, XGBoost and Multilayer perceptron. The\nmethod is tested by developing into an extension so that the end-users can use\nit when browsing. In the browser extension when the user takes the cursor over\nany link, a pop-up appears showing the nature of the website i.e., safe site or\ndeceptive site and then a confirm box shows up asking the user whether they\nwant to visit or not. The performance of the approach is tested using a dataset\nconsisting of 2000 phishing and legitimate website URLs and the method is able\nto detect the sites correctly in very little time. Random-Forest is chosen for\nconstructing the model as it gives the highest accuracy of 95%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.03255,review,pre_llm,2022,5,"{'ai_likelihood': 1.105997297498915e-05, 'text': ""Three-Pass Identification Scheme Based on MinRank Problem with Half\n  Cheating Probability\n\n  In Asiacrypt 2001, Courtois proposed the first three-pass zero-knowledge\nidentification (ID) scheme based on the MinRank problem. However, in a single\nround of Courtois' ID scheme, the cheating probability, i.e., the success\nprobability of the cheating prover, is 2/3 which is larger than half. Although\nCourtois also proposed a variant scheme which is claimed to have half cheating\nprobability, its security is not formally proven and it requires another\nhardness assumption on a specific one-way function and that verifier always\ngenerates challenges according to a specific non-uniform distribution. In this\npaper, we propose the first three-pass zero-knowledge ID scheme based on the\nMinRank problem with the cheating probability of exactly half for each round,\neven with only two-bit challenge space, without any additional assumption. Our\nproposed ID scheme requires fewer rounds and less total average communications\ncosts compared to Curtois' under the same security level against impersonation.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.14611,regular,pre_llm,2022,5,"{'ai_likelihood': 4.2054388258192275e-06, 'text': 'Forensic Artefact Discovery and Attribution from Android Cryptocurrency\n  Wallet Applications\n\n  Cryptocurrency has been (ab)used to purchase illicit goods and services such\nas drugs, weapons and child pornography (also referred to as child sexual abuse\nmaterials), and thus mobile devices (where cryptocurrency wallet applications\nare installed) are a potential source of evidence in a criminal investigation.\nNot surprisingly, there has been increased focus on the security of\ncryptocurrency wallets, although forensic extraction and attribution of\nforensic artefacts from such wallets is understudied. In this paper, we examine\nBitcoin and Dogecoin. The latter is increasingly popular partly due to\nendorsements from celebrities and being positioned as an introductory path to\ncryptocurrency for newcomers. Specifically, we demonstrate how one can acquire\nforensic artefacts from Android Bitcoin and Dogecoin cryptocurrency wallets,\nsuch as wallet IDs, transaction IDs, timestamp information, email addresses,\ncookies, and OAuth tokens.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.12897,regular,pre_llm,2022,5,"{'ai_likelihood': 1.1722246805826824e-05, 'text': ""Cryptocurrency Giveaway Scam with YouTube Live Stream\n\n  This paper investigates the cryptocurrency giveaway scam with the YouTube\nlive stream carried out on 5/15/2022 and 5/16/2022. In this scam scheme, the\nscammer plays a recorded video of a famous person in a YouTube live stream\nannotated with a cryptocurrency giveaway announcement. In the annotated\nannouncement, the victims are directed to the scammer's webpage. The scammer's\nwebpage is designed intelligently to deceive victims such that they believe the\nlegitimacy of the giveaway. The scammer claims that whatever donation the\nvictim sends to a cryptocurrency wallet address, the giveaway scheme will\ndouble the donated amount and immediately send it back to the victim. By\nanalyzing the scammers' wallet addresses, it can be seen that scammers could\nsteal a significant amount of money in a short time. After analyzing the\nattackers' techniques, tactics, and procedures, this paper discusses the\ncountermeasures that can be applied to mitigate such a fraudulent activity in\nthe future.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2205.04662,review,pre_llm,2022,5,"{'ai_likelihood': 5.960464477539062e-07, 'text': 'SoK: Rethinking Sensor Spoofing Attacks against Robotic Vehicles from a\n  Systematic View\n\n  Robotic Vehicles (RVs) have gained great popularity over the past few years.\nMeanwhile, they are also demonstrated to be vulnerable to sensor spoofing\nattacks. Although a wealth of research works have presented various attacks,\nsome key questions remain unanswered: are these existing works complete enough\nto cover all the sensor spoofing threats? If not, how many attacks are not\nexplored, and how difficult is it to realize them? This paper answers the above\nquestions by comprehensively systematizing the knowledge of sensor spoofing\nattacks against RVs. Our contributions are threefold. (1) We identify seven\ncommon attack paths in an RV system pipeline. We categorize and assess existing\nspoofing attacks from the perspectives of spoofer property, operation, victim\ncharacteristic and attack goal. Based on this systematization, we identify 4\ninteresting insights about spoofing attack designs. (2) We propose a novel\naction flow model to systematically describe robotic function executions and\nunexplored sensor spoofing threats. With this model, we successfully discover\n103 spoofing attack vectors, 26 of which have been verified by prior works,\nwhile 77 attacks are never considered. (3) We design two novel attack\nmethodologies to verify the feasibility of newly discovered spoofing attack\nvectors.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.03745,regular,pre_llm,2022,6,"{'ai_likelihood': 6.953875223795574e-07, 'text': 'Probing for Passwords -- Privacy Implications of SSIDs in Probe Requests\n\n  Probe requests help mobile devices discover active Wi-Fi networks. They often\ncontain a multitude of data that can be used to identify and track devices and\nthereby their users. The past years have been a cat-and-mouse game of improving\nfingerprinting and introducing countermeasures against fingerprinting. This\npaper analyses the content of probe requests sent by mobile devices and\noperating systems in a field experiment. In it, we discover that users\n(probably by accident) input a wealth of data into the SSID field and find\npasswords, e-mail addresses, names and holiday locations. With these findings\nwe underline that probe requests should be considered sensitive data and be\nwell protected. To preserve user privacy, we suggest and evaluate a\nprivacy-friendly hash-based construction of probe requests and improved user\ncontrols.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.06027,regular,pre_llm,2022,6,"{'ai_likelihood': 3.7749608357747397e-06, 'text': ""Adversarial Models Towards Data Availability and Integrity of\n  Distributed State Estimation for Industrial IoT-Based Smart Grid\n\n  Security issue of distributed state estimation (DSE) is an important prospect\nfor the rapidly growing smart grid ecosystem. Any coordinated cyberattack\ntargeting the distributed system of state estimators can cause unrestrained\nestimation errors and can lead to a myriad of security risks, including failure\nof power system operation. This article explores the security threats of a\nsmart grid arising from the exploitation of DSE vulnerabilities. To this aim,\nnovel adversarial strategies based on two-stage data availability and integrity\nattacks are proposed towards a distributed industrial Internet of Things-based\nsmart grid. The former's attack goal is to prevent boundary data exchange among\ndistributed control centers, while the latter's attack goal is to inject a\nfalsified data to cause local and global system unobservability. The proposed\nframework is evaluated on IEEE standard 14-bus system and benchmarked against\nthe state-of-the-art research. Experimental results show that the proposed\ntwo-stage cyberattack results in an estimated error of approximately 34.74%\ncompared to an error of the order of 10^-3 under normal operating conditions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.00117,regular,pre_llm,2022,6,"{'ai_likelihood': 8.940696716308594e-07, 'text': 'WAKU-RLN-RELAY: Privacy-Preserving Peer-to-Peer Economic Spam Protection\n\n  In this paper, we propose WAKU-RLN-RELAY as a spam-protected gossip-based\nrouting protocol that can run in heterogeneous networks. It features a\nprivacy-preserving peer-to-peer (p2p) economic spam protection mechanism.\nWAKU-RLN-RELAY addresses the performance and privacy issues of the\nstate-of-the-art p2p spam prevention techniques including peer scoring utilized\nby libp2p, and proof-of-work used by e.g., Whisper, the p2p messaging layer of\nEthereum. In WAKU-RLN-RELAY, spam protection works by limiting the messaging\nrate of each network participant. Rate violation is disincentivized since it\nresults in financial punishment where the punishment is cryptographically\nguaranteed. Peers who identify spammers are also rewarded. To enforce the rate\nlimit, we adopt the suggested framework of Semaphore and its extended version,\nhowever, we modify that framework to properly address the unique requirements\nof a network of p2p resource-restricted users. The current work dives into the\nend-to-end integration of Semaphore into WAKU-RLN-RELAY, the modifications\nrequired to make it suitable for resource-limited users, and the open problems\nand future research directions. We also provide a proof-of-concept open-source\nimplementation of WAKU-RLN-RELAY, and its specifications together with a rough\nperformance evaluation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.12447,regular,pre_llm,2022,6,"{'ai_likelihood': 4.337893591986763e-06, 'text': 'XMD: An Expansive Hardware-telemetry based Mobile Malware Detector to\n  enhance Endpoint Detection\n\n  Hardware-based Malware Detectors (HMDs) have shown promise in detecting\nmalicious workloads. However, the current HMDs focus solely on the CPU core of\na System-on-Chip (SoC) and, therefore, do not exploit the full potential of the\nhardware telemetry. In this paper, we propose XMD, an HMD that uses an\nexpansive set of telemetry channels extracted from the different subsystems of\nSoC. XMD exploits the thread-level profiling power of the CPU-core telemetry,\nand the global profiling power of non-core telemetry channels, to achieve\nsignificantly better detection performance than currently used Hardware\nPerformance Counter (HPC) based detectors. We leverage the concept of manifold\nhypothesis to analytically prove that adding non-core telemetry channels\nimproves the separability of the benign and malware classes, resulting in\nperformance gains. We train and evaluate XMD using hardware telemetries\ncollected from 723 benign applications and 1033 malware samples on a commodity\nAndroid Operating System (OS)-based mobile device. XMD improves over currently\nused HPC-based detectors by 32.91% for the in-distribution test data. XMD\nachieves the best detection performance of 86.54% with a false positive rate of\n2.9%, compared to the detection rate of 80%, offered by the best performing\nsignature-based Anti-Virus(AV) on VirusTotal, on the same set of malware\nsamples.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.14107,regular,pre_llm,2022,6,"{'ai_likelihood': 3.2782554626464844e-06, 'text': 'Special subsets of addresses for blockchains using the secp256k1 curve\n\n  In 2020 Sala, Sogiorno and Taufer have been able to find the private keys of\nsome Bitcoin addresses, thus being able to spend the cryptocurrency linked to\nthem. This result was unexpected, since the recovery of non-trivial private\nkeys for blockchain addresses is deemed to be an infeasible problem. In this\npaper we widen this analysis by mounting a similar attack to other small\nsubsets of the set of private keys. We then apply it to other blockchains as\nwell, examining Ethereum, Dogecoin, Litecoin, Dash, Zcash and Bitcoin Cash. In\naddition to the results, we also explain the techniques we have used to perform\nthis exhaustive search for all the addresses that have ever appeared in these\nblockchains.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.04049,regular,pre_llm,2022,6,"{'ai_likelihood': 2.7484363979763457e-06, 'text': 'Hypersyn: A Peer-to-Peer System for Mutual Credit\n\n  The Hypersyn protocol is a new type of permissionless and peer-to-peer\npayment network that is based on the concept of mutual credit and mutual\narbitrage. Unlike blockchain-based systems, Hypersyn does not rely on any\nconsensus algorithm. It does not require a distributed ledger to store the\nhistory of events nor a set of validators. Hypersyn does not have a\nsystem-imposed hard-cap on the number of transactions per second that it can\nperform, and can therefore easily scale up or down depending on network usage.\nUnlike in other payment systems, money in Hypersyn does not get transferred\nfrom person $A$ to person $B$ in the conventional sense. Instead of\ntransferring a token between each other, peers in Hypersyn change their\nexchange value of their credit (i.e. their purchasing power) within the\nnetwork. Just as in centrally-issued fiat systems, money in Hypersyn is treated\nas freely tradable debt, which inherently requires trust. But unlike\ncentrally-issued fiat systems, money issuance in Hypersyn is not controlled by\nan authority, but is instead created on the spot as mutual credit. In\nblockchain-based systems and even in centrally-issued fiat systems, money is\ntreated as a scarce commodity. In the Hypersyn protocol on the other hand,\nmoney supply within the system is elastic in nature. Because of these\nfundamental differences in assumptions, the Hypersyn protocol does not aim to\ncompete with, or substitute blockchain-based systems. Instead, Hypersyn should\nbe viewed as a tool that aims to offer a qualitative change in the way we\nexchange. It has the potential to increase the autonomy and self-organization\nthat people can have, by enabling people to become both the creditors and\ndebtors of their own ""money"" through mutual credit.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.07012,regular,pre_llm,2022,6,"{'ai_likelihood': 1.2252065870496963e-06, 'text': 'Frequency Throttling Side-Channel Attack\n\n  Modern processors dynamically control their operating frequency to optimize\nresource utilization, maximize energy savings, and conform to system-defined\nconstraints. If, during the execution of a software workload, the running\naverage of any electrical or thermal parameter exceeds its corresponding\npredefined threshold value, the power management architecture will reactively\nadjust CPU frequency to ensure safe operating conditions. In this paper, we\ndemonstrate how such power management-based frequency throttling activity forms\na source of timing side-channel information leakage, which can be exploited by\nan attacker to infer secret data even from a constant-cycle victim workload.\nThe proposed frequency throttling side-channel attack can be launched by both\nkernel-space and user-space attackers, thus compromising security guarantees\nprovided by isolation boundaries. We validate our attack methodology across\ndifferent systems and threat models by performing experiments on a\nconstant-cycle implementation of AES algorithm based on AES-NI instructions.\nThe results of our experimental evaluations demonstrate that the attacker can\nsuccessfully recover all bytes of an AES key by measuring encryption execution\ntimes. Finally, we discuss different options to mitigate the threat posed by\nfrequency throttling side-channel attacks, as well as their advantages and\ndisadvantages.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.02384,regular,pre_llm,2022,6,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'Towards Practical Privacy-Preserving Solution for Outsourced Neural\n  Network Inference\n\n  When neural network model and data are outsourced to cloud server for\ninference, it is desired to preserve the confidentiality of model and data as\nthe involved parties (i.e., cloud server, model providing client and data\nproviding client) may not trust mutually. Solutions were proposed based on\nmulti-party computation, trusted execution environment (TEE) and leveled or\nfully homomorphic encryption (LHE/FHE), but their limitations hamper practical\napplication. We propose a new framework based on synergistic integration of LHE\nand TEE, which enables collaboration among mutually-untrusted three parties,\nwhile minimizing the involvement of (relatively) resource-constrained TEE and\nallowing the full utilization of the untrusted but more resource-rich part of\nserver. We also propose a generic and efficient LHE-based inference scheme as\nan important performance-determining component of the framework. We\nimplemented/evaluated the proposed system on a moderate platform and show that,\nour proposed scheme is more applicable/scalable to various settings, and has\nbetter performance, compared to the state-of-the-art LHE-based solutions.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.0601,review,pre_llm,2022,6,"{'ai_likelihood': 2.3974312676323785e-05, 'text': 'Constant-Round Linear-Broadcast Secure Computation with Penalties\n\n  It is known that Bitcoin enables achieving fairness in secure computation by\nimposing monetary penalties on adversarial parties. This functionality is\ncalled secure computation with penalties. Bentov and Kumaresan (Crypto 2014)\nintroduced the claim-or-refund functionality that can be implemented via\nBitcoin. They achieved secure computation with penalties with $O(n)$ rounds and\n$O(n)$ broadcasts for any function, where $n$ is the number of parties. After\nthat, Kumaresan and Bentov (CCS 2014) showed a constant-round protocol.\nUnfortunately, this protocol requires $O(n^2)$ broadcasts. As far as we know,\nno protocol achieves $O(1)$ rounds and $O(n)$ broadcasts based on Bitcoin. This\nwork accomplishes such efficiency in secure computation with penalties. We\nfirst show a protocol in a slightly relaxed setting called secure computation\nwith non-equivalent penalties. This setting is the same as secure computation\nwith penalties except that every honest party receives more than a\npredetermined amount of compensation, while the previous one requires that\nevery honest party receives the same amount of compensation. Namely, our\nsetting allows the compensations for honest parties to be non-equivalent.\nMoreover, we present a technique to remove the non-equivalence of our protocol\nwithout sacrificing efficiency. We then propose a new ideal functionality\ncalled claim-refund-or-give that can be implemented via Bitcoin.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.04141,review,pre_llm,2022,6,"{'ai_likelihood': 1.3907750447591147e-06, 'text': 'Role of Blockchain in Revolutionizing Online Transactional Security\n\n  This paper highlights the necessity to use modern blockchain technology in\ntraditional banking sector to reduce frauds and enable high-security\ntransactions on a permanent blockchain ledger. Reviewing different channels\nthrough which the traditional banking servers could integrate blockchain use,\nit is signified how a huge anti-fraud stand can be taken against bank servers\nallowing fraudulent transactions daily. Usage of a blockchain-based ledger is\nhighly impactful in terms of security of a banking organization.\nBlockchain-based currency tokens, also referred to as Cryptocurrencies are not\nregulated by the government, highly volatile, and anonymous to use.\nFurthermore, there is no security for any funds invested in a cryptocurrency\nmarket. However, the integration of a blockchain ledger in a traditional\nbanking organization would strengthen the security to provide more stability\nand confidence to its customers and at the same time, make blockchain a more\nreliable method to consider due to being trusted by large financial\norganizations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.07019,regular,pre_llm,2022,6,"{'ai_likelihood': 1.5894571940104167e-06, 'text': ""An Attack Resilient PUF-based Authentication Mechanism for Distributed\n  Systems\n\n  In most PUF-based authentication schemes, a central server is usually engaged\nto verify the response of the device's PUF to challenge bit-streams. However,\nthe server availability may be intermittent in practice. To tackle such an\nissue, this paper proposes a new protocol for supporting distributed\nauthentication while avoiding vulnerability to information leakage where CRPs\ncould be retrieved from hacked devices and collectively used to model the PUF.\nThe main idea is to provision for scrambling the challenge bit-stream in a way\nthat is dependent on the verifier. The scrambling pattern varies per\nauthentication round for each device and independently across devices. In\nessence, the scrambling function becomes node- and packet-specific and the\nresponse received by two verifiers of one device for the same challenge\nbit-stream could vary. Thus, neither the scrambling function can be reverted,\nnor the PUF can be modeled even by a collusive set of malicious nodes. The\nvalidation results using data of an FPGA-based implementation demonstrate the\neffectiveness of our approach in thwarting PUF modeling attacks by collusive\nactors. We also discuss the approach resiliency against impersonation, Sybil,\nand reverse engineering attacks.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.07329,review,pre_llm,2022,6,"{'ai_likelihood': 1.4238887363009983e-06, 'text': ""Application-Oriented Selection of Privacy Enhancing Technologies\n\n  To create privacy-friendly software designs, architects need comprehensive\nknowledge of existing privacy-enhancing technologies (PETs) and their\nproperties. Existing works that systemize PETs, however, are outdated or focus\non comparison criteria rather than providing guidance for their practical\nselection. In this short paper we present an enhanced classification of PETs\nthat is more application-oriented than previous proposals. It integrates\nexisting criteria like the privacy protection goal, and also considers\npractical criteria like the functional context, a technology's maturity, and\nits impact on various non-functional requirements. We expect that our\nclassification simplifies the selection of PETs for experts and non-experts.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.0206,regular,pre_llm,2022,6,"{'ai_likelihood': 1.655684577094184e-06, 'text': 'A privacy preserving querying mechanism with high utility for electric\n  vehicles\n\n  Electric vehicles (EVs) are gaining popularity due to the growing awareness\nfor a sustainable future. However, since there are disproportionately fewer\ncharging stations than EVs, range anxiety plays a major role in the rise in the\nnumber of queries made along the journeys to find an available charging\nstation. On the other hand, the use of personal data in various types of\nanalytics is increasing at an unprecedented rate. Hence, the risks of privacy\nviolation are also surging. Geo-indistinguishability is one of the standards\nfor formalising location privacy as a generalisation of the local differential\nprivacy. However, the noise has to be carefully calibrated considering the\nimplications of potential utility-loss. In this paper, we introduce approximate\ngeo-indistinguishability (AGeoI) which allows the EVs to obfuscate the\nindividual query-locations while ensuring that they remain within their\npreferred area of interest. It is vital because journeys are often sensitive to\na sharp drop in QoS, which has a high cost for the extra distance to be\ncovered. We apply AGeoI and dummy data generation to protect the privacy of EVs\nduring their journeys and preserve the QoS. Analytical insights and experiments\nare used to demonstrate that a very high percentage of EVs get privacy for free\nand that the utility-loss caused by the privacy-gain is minuscule. Using the\niterative Bayesian update, our method allows for a private and highly accurate\nprediction of charging station occupancy without disclosing query locations and\nvehicle trajectories, which is vital in unprecedented traffic congestion\nscenarios and efficient route-planning.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.13599,regular,pre_llm,2022,6,"{'ai_likelihood': 4.72863515218099e-05, 'text': 'Nowhere to Hide: Detecting Obfuscated Fingerprinting Scripts\n\n  As the web moves away from stateful tracking, browser fingerprinting is\nbecoming more prevalent. Unfortunately, existing approaches to detect browser\nfingerprinting do not take into account potential evasion tactics such as code\nobfuscation. To address this gap, we investigate the robustness of a\nstate-of-the-art fingerprinting detection approach against various\noff-the-shelf obfuscation tools. Overall, we find that the combination of\nstatic and dynamic analysis is robust against different types of obfuscation.\nWhile some obfuscators are able to induce false negatives in static analysis,\ndynamic analysis is still able detect these cases. Since obfuscation does not\ninduce significant false positives, the combination of static and dynamic\nanalysis is still able to accurately detect obfuscated fingerprinting scripts.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.11586,regular,pre_llm,2022,6,"{'ai_likelihood': 1.457002427842882e-06, 'text': 'MAGIC: A Method for Assessing Cyber Incidents Occurrence\n\n  The assessment of cyber risk plays a crucial role for cybersecurity\nmanagement, and has become a compulsory task for certain types of companies and\norganizations. This makes the demand for reliable cyber risk assessment tools\ncontinuously increasing, especially concerning quantitative tools based on\nstatistical approaches. Probabilistic cyber risk assessment methods, however,\nfollow the general paradigm of probabilistic risk assessment, which requires\nthe magnitude and the likelihood of incidents as inputs. Unfortunately, for\ncyber incidents, the likelihood of occurrence is hard to estimate based on\nhistorical and publicly available data; so, expert evaluations are commonly\nused, which however leave space to subjectivity. In this paper, we propose a\nnovel probabilistic model, called MAGIC (Method for AssessinG cyber Incidents\noCcurrence), to compute the likelihood of occurrence of a cyber incident, based\non the evaluation of the cyber posture of the target organization. This allows\nderiving tailor-made inputs for probabilistic risk assessment methods, like\nHTMA (How To Measure Anything in cybersecurity risk), FAIR (Factor Analysis of\nInformation Risk) and others, thus considerably reducing the margin of\nsubjectivity in the assessment of cyber risk. We corroborate our approach\nthrough a qualitative and a quantitative comparison with several classical\nmethods.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.00716,review,pre_llm,2022,6,"{'ai_likelihood': 2.317958407931858e-07, 'text': 'Not so immutable: Upgradeability of Smart Contracts on Ethereum\n\n  A smart contract that is deployed to a blockchain system like Ethereum is,\nunder reasonable circumstances, expected to be immutable and tamper-proof. This\nis both a feature (promoting integrity and transparency) and a bug (preventing\nsecurity patches and feature updates). Modern smart contracts use software\ntricks to enable upgradeability, raising the research questions of how\nupgradeability is achieved and who is authorized to make changes. In this\npaper, we summarize and evaluate six upgradeability patterns. We develop a\nmeasurement framework for finding how many upgradeable contracts are on\nEthereum that use certain prominent upgrade patters. We find 1.4 million proxy\ncontracts which 8,225 of them are unique upgradeable proxy contracts. We also\nmeasure how they implement access control over their upgradeability: about 50%\nare controlled by a single Externally Owned Address (EOA), and about 14% are\ncontrolled by multi-signature wallets in which a limited number of persons can\nchange the whole logic of the contract.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.0216,regular,pre_llm,2022,6,"{'ai_likelihood': 3.344482845730252e-06, 'text': ""Scrypt Mining with ASICs\n\n  Cryptocurrencies have garnered a lot of attention by governments and internet\nenthusiasts over the past three years. These currencies are celebrated for\ntheir security and speedy transactions in a modern era of digital commerce.\nBitcoin was the first of these currencies to gain a large advantage over\nsubsequent iterations. Bitcoin was first conceived by Satoshi Nakamoto who\nmentioned the concept of a cryptocurrency in his paper titled Bitcoin. It\nfeatured new concepts such as proof of work and transactions which utilized\nhash based encryption. One particular alternative cryptocurrency is known as\nLitecoin. Backed by a memory intensive algorithm known as Scrypt, many\ncryptocurrency enthusiasts have decided to celebrate this particular coin.\nScrypt expands on Bitcoin's proof of work algorithm by adding the amount of\nwork it takes to commit a transaction within the Litecoin network. Scrypt\nforces more work on the device that is being used to perform the algorithm by\nmaking frequent memory requests. This makes it difficult to create specialized\nhardware to create new coins and to commit transactions due to the nature of\nmemory intensive applications.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.02658,review,pre_llm,2022,6,"{'ai_likelihood': 3.1458006964789497e-06, 'text': ""Longitudinal Analysis of Privacy Labels in the Apple App Store\n\n  In December of 2020, Apple started to require app developers to self-report\nprivacy label annotations on their apps indicating what data is collected and\nhow it is used.To understand the adoption and shifts in privacy labels in the\nApp Store, we collected nearly weekly snapshots of over 1.6 million apps for\nover a year (July 15, 2021 -- October 25, 2022) to understand the dynamics of\nprivacy label ecosystem. Nearly two years after privacy labels launched, only\n70.1% of apps have privacy labels, but we observed an increase of 28% during\nthe measurement period. Privacy label adoption rates are mostly driven by new\napps rather than older apps coming into compliance. Of apps with labels, 18.1%\ncollect data used to track users, 38.1% collect data that is linked to a user\nidentity, and 42.0% collect data that is not linked. A surprisingly large share\n(41.8%) of apps with labels indicate that they do not collect any data, and\nwhile we do not perform direct analysis of the apps to verify this claim, we\nobserve that it is likely that many of these apps are choosing a Does Not\nCollect label due to being forced to select a label, rather than this being the\ntrue behavior of the app. Moreover, for apps that have assigned labels during\nthe measurement period nearly all do not change their labels, and when they do,\nthe new labels indicate more data collection than less. This suggests that\nprivacy labels may be a ``set once'' mechanism for developers that may not\nactually provide users with the clarity needed to make informed privacy\ndecisions.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.11974,regular,pre_llm,2022,6,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Keep Your Transactions On Short Leashes\n\n  The adversary\'s goal in mounting Long Range Attacks (LRAs) is to fool\npotential victims into using and relying on a side chain, i.e., a false,\nalternate history of transactions, and into proposing transactions that end up\nharming themselves or others. Previous research work on LRAs on blockchain\nsystems have used, at a high level, one of two approaches. They either try to\n(1) prevent the creation of a bogus side chain or (2) make it possible to\ndistinguish such a side chain from the main consensus chain.\n  In this paper, we take a different approach. We start with the\nindistinguishability of side chains from the consensus chain -- for the\neclipsed victim -- as a given and assume the potential victim will be fooled.\nInstead, we protect the victim via harm reduction applying ""short leashes"" to\ntransactions. The leashes prevent transactions from being used in the wrong\ncontext.\n  The primary contribution of this paper is the design and analysis of leashes.\nA secondary contribution is the careful explication of the LRA threat model in\nthe context of BAR fault tolerance, and using it to analyze related work to\nidentify their limitations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2206.05735,regular,pre_llm,2022,6,"{'ai_likelihood': 1.655684577094184e-07, 'text': ""Fusing Feature Engineering and Deep Learning: A Case Study for Malware\n  Classification\n\n  Machine learning has become an appealing signature-less approach to detect\nand classify malware because of its ability to generalize to never-before-seen\nsamples and to handle large volumes of data. While traditional feature-based\napproaches rely on the manual design of hand-crafted features based on experts\nknowledge of the domain, deep learning approaches replace the manual feature\nengineering process by an underlying system, typically consisting of a neural\nnetwork with multiple layers, that perform both feature learning and\nclassification altogether. However, the combination of both approaches could\nsubstantially enhance detection systems. In this paper we present an hybrid\napproach to address the task of malware classification by fusing multiple types\nof features defined by experts and features learned through deep learning from\nraw data. In particular, our approach relies on deep learning to extract N-gram\nlike features from the assembly language instructions and the bytes of malware,\nand texture patterns and shapelet-based features from malware\\'s grayscale\nimage representation and structural entropy, respectively. These deep features\nare later passed as input to a gradient boosting model that combines the deep\nfeatures and the hand-crafted features using an early-fusion mechanism. The\nsuitability of our approach has been evaluated on the Microsoft Malware\nClassification Challenge benchmark and results show that the proposed solution\nachieves state-of-the-art performance and outperforms gradient boosting and\ndeep learning methods in the literature.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.04503,regular,pre_llm,2022,7,"{'ai_likelihood': 3.940529293484158e-06, 'text': 'BotNet Intrusion Detection System in Internet of Things with Developed\n  Deep Learning\n\n  The rapid growth of technology has led to the creation of computing networks.\nThe applications of the Internet of Things are becoming more and more visible\nwith the expansion and development of sensors and the use of a series of\nequipment to connect to the Internet. Of course, the growth of any network will\nalso provide some challenges. The main challenge of IoT like any other network\nis its security. In the field of security, there are issues such as attack\ndetection, authentication, encryption and the so on. One of the most important\nattack is cyber-attacks that disrupt the network usage. One of the most\nimportant attacks on the IoT is BotNet attack. The most important challenges of\nthis topic include very high computational complexity, lack of comparison with\nprevious methods, lack of scalability, high execution time, lack of review of\nthe proposed approach in terms of accuracy to detect and classify attacks and\nintrusions. Using intrusion detection systems for the IoT is an important step\nin identifying and detecting various attacks. Therefore, an algorithm that can\nsolve these challenges has provided a near-optimal method. Using training-based\nmodels and algorithms such as Deep Dearning-Reinforcement Learning and XGBoost\nlearning in combination (DRL-XGBoost) models can be an interesting approach to\novercoming previous weaknesses. The data of this research is Bot-IoT-2018.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.03346,regular,pre_llm,2022,7,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'Authentication Devices in Fog-Mobile Edge Computing Environments Through\n  a Wireless Grid Resource Sharing Protocol\n\n  The rapid growth of the Internet of Things (IoT), cloud computing, Fog\ncomputing, mobile edge computing and wireless grids has resulted in the\nwidespread deployment of relatively immature technology. These technologies,\nwhich will primarily use 5G wireless communication networks, are becoming\npopular because they can be deployed quickly with little infrastructure and\nlends themselves to environments utilizing numerous internet connected devices\n(ICD). Because of the threat of exploitation, these networks have to be\nprotected by a robust security architecture due to these technologies being\nplagued with security problems. The authentication of smart ICDs to IoT\nnetworks is a critical mechanism for achieving security on these new\ninformation system platforms. This article identifies an authentication process\nrequired for these ICDs, which will need to prove their identity to\nauthenticate to an IoT fog-mobile edge computing (FMEC) cloud network through a\nwireless grid authentication process. The purpose of this article is to\nhypothesize a generic authentication methodology for these FMEC clouds uses in\nan IoT architecture. The proposed methodology, called wg-IoT, must include the\nintegration of Fog computing, wireless grids and mobile edge computing clouds\nto create this new IoT architecture. An authentication process developed from\nthe resource sharing protocol (RSP) from a wireless grid is first developed and\nproposed for the authentication of ICDs. The wireless grid core components must\nbe embedded in IoT devices or sensors depending on their capability to handle\nfive primary functions: management of identification [ID] and presence,\npermissions management, data transferability, application-programming interface\n[API] and security.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.00205,regular,pre_llm,2022,7,"{'ai_likelihood': 1.6656186845567492e-05, 'text': 'BlockScope: Detecting and Investigating Propagated Vulnerabilities in\n  Forked Blockchain Projects\n\n  Due to the open-source nature of the blockchain ecosystem, it is common for\nnew blockchains to fork or partially reuse the code of classic blockchains. For\nexample, the popular Dogecoin, Litecoin, Binance BSC, and Polygon are all\nvariants of Bitcoin/Ethereum. These ""forked"" blockchains thus could encounter\nsimilar vulnerabilities that are propagated from Bitcoin/Ethereum during\nforking or subsequently commit fetching. In this paper, we conduct a systematic\nstudy of detecting and investigating the propagated vulnerabilities in forked\nblockchain projects. To facilitate this study, we propose BlockScope, a novel\ntool that can effectively and efficiently detect multiple types of cloned\nvulnerabilities given an input of existing Bitcoin/Ethereum security patches.\nSpecifically, BlockScope adopts similarity-based code match and designs a new\nway of calculating code similarity to cover all the syntax-wide variant (i.e.,\nType-1, Type-2, and Type-3) clones. Moreover, BlockScope automatically extracts\nand leverages the contexts of patch code to narrow down the search scope and\nlocate only potentially relevant code for comparison. Our evaluation shows that\nBlockScope achieves good precision and high recall both at 91.8% (1.8 times\nhigher recall than that in ReDeBug). BlockScope allows us to discover 101\npreviously unknown vulnerabilities in 13 out of the 16 forked projects of\nBitcoin and Ethereum, including 16 from Dogecoin, 6 from Litecoin, 1 from\nBinance, and 4 from Optimism. We have reported all the vulnerabilities to their\ndevelopers; 40 of them have been patched or accepted, 66 were acknowledged or\nunder pending, and only 4 were rejected. We further investigate the propagation\nand patching processes of discovered vulnerabilities, and reveal three types of\nvulnerability propagation from source to forked projects, as well as the long\ndelay (over 200 days) for releasing patches in Bitcoin forks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.0082,regular,pre_llm,2022,7,"{'ai_likelihood': 2.4835268656412763e-06, 'text': 'Cyber Security Threat Awareness Framework for High School Students in\n  Qatar\n\n  Cyber security is considered a necessity for anyone in todays modern world.\nAwareness of cyber security standards and best practices have become mandatory\nto safeguard ones child in this day and age. High schoolers today do not\nunderstand cyber security threats due to the lack of parental involvement or\nthe lack of educational material and courses in high school. This study\ndeveloped a framework that addresses the lack of cybersecurity awareness for\nhigh school students. The proposed framework gives a flow of steps to provide\neffective awareness approaches for k12. This was achieved using an approach of\ncreating a functional operational framework that consists of four phases which\nare Threats and Attacks Identification, Existing Awareness Discovery, Creating\nAwareness Approach, and Awareness Approach Evaluation. The output resulted in a\ncybersecurity awareness approach specifically for the k-12 age range, which\nleverages cybersecurity emojis. Thus, by exploring this approach, the security\ncommunity can enroll and lure teenagers into cybersecurity and raise the degree\nof security awareness.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.01605,regular,pre_llm,2022,7,"{'ai_likelihood': 2.284844716389974e-06, 'text': ""ID-based self-encryption via Hyperledger Fabric based smart contract\n\n  This paper offers a prototype of a Hyperledger Fabric-IPFS based network\narchitecture including a smart contract based encryption scheme that meant to\nimprove the security of user's data that is being uploaded to the distributed\nledger. A new extension to the self-encryption scheme was deployed by\nintegrating data owner's identity into the encryption process. Such integration\nallows to permanently preserve ownership of the original file and link it to\nthe person/entity who originally uploaded it. Moreover, self-encryption\nprovides strong security guarantees that decryption of a file is\ncomputationally not feasible under the condition that the encrypted file and\nthe key are safely stored.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.10812,regular,pre_llm,2022,7,"{'ai_likelihood': 5.3313043382432725e-06, 'text': 'RSU-Based Online Intrusion Detection and Mitigation for VANET\n\n  Secure vehicular communication is a critical factor for secure traffic\nmanagement. Effective security in intelligent transportation systems (ITS)\nrequires effective and timely intrusion detection systems (IDS). In this paper,\nwe consider false data injection attacks and distributed denial-of-service\n(DDoS) attacks, especially the stealthy DDoS attacks, targeting the integrity\nand availability, respectively, in vehicular ad-hoc networks (VANET). Novel\nstatistical intrusion detection and mitigation techniques based on centralized\ncommunications through roadside units (RSU) are proposed for the considered\nattacks. The performance of the proposed methods are evaluated using a traffic\nsimulator and a real traffic dataset. Comparisons with the state-of-the-art\nsolutions clearly demonstrate the superior performance of the proposed methods\nin terms of quick and accurate detection and localization of cyberattacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.05383,regular,pre_llm,2022,7,"{'ai_likelihood': 5.629327562120226e-06, 'text': 'Opportunistic Wiretapping/Jamming: A New Attack Model in Millimeter-Wave\n  Wireless Networks\n\n  While the millimeter-wave (mmWave) communication is robust against the\nconventional wiretapping attack due to its short transmission range and\ndirectivity, this paper proposes a new opportunistic wiretapping and jamming\n(OWJ) attack model in mmWave wireless networks. With OWJ, an eavesdropper can\nopportunistically conduct wiretapping or jamming to initiate a more hazardous\nattack based on the instantaneous costs of wiretapping and jamming. We also\nprovide three realizations of the OWJ attack, which are mainly determined by\nthe cost models relevant to distance, path loss and received power,\nrespectively. To understand the impact of the new attack on mmWave network\nsecurity, we first develop novel approximation techniques to characterize the\nirregular distributions of wiretappers, jammers and interferers under three OWJ\nrealizations. With the help of the results of node distributions, we then\nderive analytical expressions for the secrecy transmission capacity to depict\nthe network security performance under OWJ. Finally, we provide extensive\nnumerical results to illustrate the effect of OWJ and to demonstrate that the\nnew attack can more significantly degrade the network security performance than\nthe pure wiretapping or jamming attack.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.07385,regular,pre_llm,2022,7,"{'ai_likelihood': 2.9802322387695312e-06, 'text': 'Identifying and Quantifying Trade-offs in Multi-Stakeholder Risk\n  Evaluation with Applications to the Data Protection Impact Assessment of the\n  GDPR\n\n  Cybersecurity risk management consists of several steps including the\nselection of appropriate controls to minimize risks. This is a difficult task\nthat requires to search through all possible subsets of a set of available\ncontrols and identify those that minimize the risks of all stakeholders. Since\nstakeholders may have different perceptions of the risks (especially when\nconsidering the impact of threats), conflicting goals may arise that require to\nfind the best possible trade-offs among the various needs. In this work, we\npropose a quantitative and (semi)automated approach to solve this problem based\non the well-known notion of Pareto optimality. For validation, we show how a\nprototype tool based on our approach can assist in the Data Protection Impact\nAssessment mandated by the General Data Protection Regulation on a simplified\nbut realistic use case scenario. We also evaluate the scalability of the\napproach by conducting an experimental evaluation with the prototype with\nencouraging results.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.01808,regular,pre_llm,2022,7,"{'ai_likelihood': 4.006756676567926e-06, 'text': 'Complexity Analysis of the SAT Attack on Logic Locking\n\n  Due to the adoption of horizontal business models following the globalization\nof semiconductor manufacturing, the overproduction of integrated circuits (ICs)\nand the piracy of intellectual properties (IPs) can lead to significant damage\nto the integrity of the semiconductor supply chain. Logic locking emerges as a\nprimary design-for-security measure to counter these threats, where ICs become\nfully functional only when unlocked with a secret key. However, Boolean\nsatisfiability-based attacks have rendered most locking schemes ineffective.\nThis gives rise to numerous defenses and new locking methods to achieve SAT\nresiliency. This paper provides a unique perspective on the SAT attack\nefficiency based on conjunctive normal form (CNF) stored in SAT solver. First,\nwe show how the attack learns new relations between keys in every iteration\nusing distinguishing input patterns and the corresponding oracle responses. The\ninput-output pairs result in new CNF clauses of unknown keys to be appended to\nthe SAT solver, which leads to an exponential reduction in incorrect key\nvalues. Second, we demonstrate that the SAT attack can break any locking scheme\nwithin linear iteration complexity of key size. Moreover, we show how key\nconstraints on point functions affect the SAT attack complexity. We explain why\nproper key constraint on AntiSAT reduces the complexity effectively to constant\n1. The same constraint helps the breaking of CAS-Lock down to linear iteration\ncomplexity. Our analysis provides a new perspective on the capabilities of SAT\nattack against multiplier benchmark c6288, and we provide new directions to\nachieve SAT resiliency.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.08891,regular,pre_llm,2022,7,"{'ai_likelihood': 4.635916815863716e-07, 'text': 'Wink: Deniable Secure Messaging\n\n  End-to-end encrypted (E2EE) messaging is an essential first step in providing\nmessage confidentiality. Unfortunately, all security guarantees of end-to-end\nencryption are lost when keys or plaintext are disclosed, either due to device\ncompromise or (sometimes lawful) coercion by powerful adversaries. This work\nintroduces Wink, the first plausibly-deniable messaging system protecting\nmessage confidentiality from partial device compromise and compelled key\ndisclosure. Wink can surreptitiously inject hidden messages in standard random\ncoins (e.g., salts, IVs) used by existing E2EE protocols. It does so as part of\nlegitimate secure cryptographic functionality deployed inside the\nwidely-available trusted execution environment (TEE) TrustZone. This results in\nhidden communication using virtually unchanged existing E2EE messaging apps, as\nwell as strong plausible deniability. Wink has been demonstrated with multiple\nexisting E2EE applications (including Telegram and Signal) with minimal\n(external) instrumentation, negligible overheads, and crucially, without\nchanging on-wire message formats.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.01227,review,pre_llm,2022,7,"{'ai_likelihood': 1.026524437798394e-06, 'text': 'Cybersecurity: Past, Present and Future\n\n  The digital transformation has created a new digital space known as\ncyberspace. This new cyberspace has improved the workings of businesses,\norganizations, governments, society as a whole, and day to day life of an\nindividual. With these improvements come new challenges, and one of the main\nchallenges is security. The security of the new cyberspace is called\ncybersecurity. Cyberspace has created new technologies and environments such as\ncloud computing, smart devices, IoTs, and several others. To keep pace with\nthese advancements in cyber technologies there is a need to expand research and\ndevelop new cybersecurity methods and tools to secure these domains and\nenvironments. This book is an effort to introduce the reader to the field of\ncybersecurity, highlight current issues and challenges, and provide future\ndirections to mitigate or resolve them. The main specializations of\ncybersecurity covered in this book are software security, hardware security,\nthe evolution of malware, biometrics, cyber intelligence, and cyber forensics.\nWe must learn from the past, evolve our present and improve the future. Based\non this objective, the book covers the past, present, and future of these main\nspecializations of cybersecurity. The book also examines the upcoming areas of\nresearch in cyber intelligence, such as hybrid augmented and explainable\nartificial intelligence (AI). Human and AI collaboration can significantly\nincrease the performance of a cybersecurity system. Interpreting and explaining\nmachine learning models, i.e., explainable AI is an emerging field of study and\nhas a lot of potentials to improve the role of AI in cybersecurity.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.06686,regular,pre_llm,2022,7,"{'ai_likelihood': 5.231963263617622e-06, 'text': 'Behavioral Model For Live Detection of Apps Based Attack\n\n  Smartphones with the platforms of applications are gaining extensive\nattention and popularity. The enormous use of different applications has paved\nthe way to numerous security threats. The threats are in the form of attacks\nsuch as permission control attacks, phishing attacks, spyware attacks, botnets,\nmalware attacks, privacy leakage attacks. Moreover, other vulnerabilities\ninclude invalid authorization of apps, compromise on the confidentiality of\ndata, invalid access control. In this paper, an application-based attack\nmodeling and attack detection is proposed. Due to A novel attack vulnerability\nis identified based on the app execution on the smartphone. The attack modeling\ninvolves an end-user vulnerable application to initiate an attack. The\nvulnerable application is installed at the background end on the smartphone\nwith hidden visibility from the end-user. Thereby, accessing the confidential\ninformation. The detection model involves the proposed technique of an\nApplication-based Behavioral Model Analysis (ABMA) scheme to address the attack\nmodel. The model incorporates application-based comparative parameter analysis\nto perform the process of intrusion detection. The ABMA is estimated by using\nthe parameters of power, battery level, and the data usage. Based on the source\ninternet accessibility, the analysis is performed using three different\nconfigurations as, WiFi, mobile data, and the combination of the two. The\nsimulation results verify and demonstrates the effectiveness of the proposed\nmodel.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.09127,regular,pre_llm,2022,7,"{'ai_likelihood': 5.132622188991971e-06, 'text': 'Smart Contract Assisted Blockchain based PKI System\n\n  The proposed smart contract can prevent seven cyber attacks, such as Denial\nof Service (DoS), Man in the Middle Attack (MITM), Distributed Denial of\nService (DDoS), 51\\%, Injection attacks, Routing Attack, and Eclipse attack.\nThe Delegated Proof of Stake (DPoS) consensus algorithm used in this model\nreduces the number of validators for each transaction which makes it suitable\nfor lightweight applications. The timing complexity of key/certificate\nvalidation and signature/certificate revocation processes do not depend on the\nnumber of transactions. The comparisons of various timing parameters with\nexisting solutions show that the proposed PKI is competitively better.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.03247,regular,pre_llm,2022,7,"{'ai_likelihood': 1.655684577094184e-07, 'text': 'Local Inversion of maps: Black box Cryptanalysis\n\n  This paper is a short summery of results announced in a previous paper on a\nnew universal method for Cryptanalysis which uses a Black Box linear algebra\napproach to computation of local inversion of nonlinear maps in finite fields.\nIt is shown that one local inverse $x$ of the map equation $y=F(x)$ can be\ncomputed by using the minimal polynomial of the sequence $y(k)$ defined by\niterates (or recursion) $y(k+1)=F(y(k))$ with $y(0)=y$ when the sequence is\nperiodic. This is the only solution in the periodic orbit of the map $F$.\nFurther, when the degree of the minimal polynomial is of polynomial order in\nnumber of bits of the input of $F$ (called low complexity case), the solution\ncan be computed in polynomial time. The method of computation only uses the\nforward computations $F(y)$ for given $y$ which is why this is called a Black\nBox approach. Application of this approach is then shown for cryptanalysis of\nseveral maps arising in cryptographic primitives. It is shown how in the low\ncomplexity cases maps defined by block and stream ciphers can be inverted to\nfind the symmetric key under known plaintext attack. Then it is shown how RSA\nmap can be inverted to find the plaintext as well as an equivalent private key\nto break the RSA algorithm without factoring the modulus. Finally it is shown\nthat the discrete log computation in finite field and elliptic curves can be\nformulated as a local inversion problem and the low complexity cases can be\nsolved in polynomial time.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.10789,regular,pre_llm,2022,7,"{'ai_likelihood': 3.443823920355903e-06, 'text': 'Authentication and Billing Scheme for The Electric Vehicles: EVABS\n\n  The need for different energy sources has increased due to the decrease in\nthe amount and the harm caused to the environment by its usage. Today, fossil\nfuels used as an energy source in land, sea or air vehicles are rapidly being\nreplaced by different energy sources. The number and types of vehicles using\nenergy sources other than fossil fuels are also increasing. Electricity stands\nout among the energy sources used. The possibility of generating electricity\nthat is renewable, compatible with nature and at a lower cost provides a great\nadvantage. For all these reasons, the use of electric vehicles is increasing\nday by day. Various solutions continue to be developed for the charging systems\nand post-charge billing processes of these vehicles. As a result of these\nsolutions, the standards have not yet been fully formed. In this study, an\nauthentication and billing scheme is proposed for charging and post-charging\nbilling processes of electric land vehicles keeping security and privacy in the\nforeground. This scheme is named EVABS, which derives from the phrase ""Electric\nVehicle Authentication and Billing Scheme"". An authentication and billing\nscheme is proposed where data communication is encrypted, payment transactions\nare handled securely and parties can authenticate over wired or wireless. The\nsecurity of the proposed scheme has been examined theoretically and it has been\ndetermined that it is secure against known attacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.09744,regular,pre_llm,2022,7,"{'ai_likelihood': 4.967053731282552e-07, 'text': 'MLMSA: Multi-Label Multi-Side-Channel-Information enabled Deep Learning\n  Attacks on APUF Variants\n\n  To improve the modeling resilience of silicon strong physical unclonable\nfunctions (PUFs), in particular, the APUFs, that yield a very large number of\nchallenge response pairs (CRPs), a number of composited APUF variants such as\nXOR-APUF, interpose-PUF (iPUF), feed-forward APUF (FF-APUF),and OAX-APUF have\nbeen devised. When examining their security in terms of modeling resilience,\nutilizing multiple information sources such as power side channel information\n(SCI) or/and reliability SCI given a challenge is under-explored, which poses a\nchallenge to their supposed modeling resilience in practice. Building upon\nmulti-label/head deep learning model architecture,this work proposes\nMulti-Label Multi-Side-channel-information enabled deep learning Attacks\n(MLMSA) to thoroughly evaluate the modeling resilience of aforementioned APUF\nvariants. Despite its simplicity, MLMSA can successfully break large-scaled\nAPUF variants, which has not previously been achieved. More precisely, the\nMLMSA breaks 128-stage 30-XOR-APUF, (9, 9)- and (2, 18)-iPUFs, and (2, 2,\n30)-OAX-APUF when CRPs, power SCI and reliability SCI are concurrently used. It\nbreaks 128-stage 12-XOR-APUF and (2, 2, 9)-OAX-APUF even when only the\neasy-to-obtain reliability SCI and CRPs are exploited. The 128-stage six-loop\nFF-APUF and one-loop 20-XOR-FF-APUF can be broken by simultaneously using\nreliability SCI and CRPs. All these attacks are normally completed within an\nhour with a standard personalcomputer. Therefore, MLMSA is a useful technique\nfor evaluating other existing or any emerging strong PUF designs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.12482,regular,pre_llm,2022,7,"{'ai_likelihood': 3.1789143880208335e-06, 'text': 'AGAPECert: An Auditable, Generalized, Automated, Privacy-Enabling\n  Certification Framework with Oblivious Smart Contracts\n\n  This paper introduces AGAPECert, an Auditable, Generalized, Automated,\nPrivacy-Enabling, Certification framework capable of performing auditable\ncomputation on private data and reporting real-time aggregate certification\nstatus without disclosing underlying private data. AGAPECert utilizes a novel\nmix of trusted execution environments, blockchain technologies, and a real-time\ngraph-based API standard to provide automated, oblivious, and auditable\ncertification. Our technique allows a privacy-conscious data owner to run\npre-approved Oblivious Smart Contract code in their own environment on their\nown private data to produce Private Automated Certifications. These\ncertifications are verifiable, purely functional transformations of the\navailable data, enabling a third party to trust that the private data must have\nthe necessary properties to produce the resulting certification. Recently, a\nmultitude of solutions for certification and traceability in supply chains have\nbeen proposed. These often suffer from significant privacy issues because they\ntend to take a"" shared, replicated database"" approach: every node in the\nnetwork has access to a copy of all relevant data and contract code to\nguarantee the integrity and reach consensus, even in the presence of malicious\nnodes. In these contexts of certifications that require global coordination,\nAGAPECert can include a blockchain to guarantee ordering of events, while\nkeeping a core privacy model where private data is not shared outside of the\ndata owner\'s own platform. AGAPECert contributes an open-source certification\nframework that can be adopted in any regulated environment to keep sensitive\ndata private while enabling a trusted automated workflow.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.04637,regular,pre_llm,2022,7,"{'ai_likelihood': 1.655684577094184e-07, 'text': ""SIMC 2.0: Improved Secure ML Inference Against Malicious Clients\n\n  In this paper, we study the problem of secure ML inference against a\nmalicious client and a semi-trusted server such that the client only learns the\ninference output while the server learns nothing. This problem is first\nformulated by Lehmkuhl \\textit{et al.} with a solution (MUSE, Usenix\nSecurity'21), whose performance is then substantially improved by Chandran et\nal.'s work (SIMC, USENIX Security'22). However, there still exists a nontrivial\ngap in these efforts towards practicality, giving the challenges of overhead\nreduction and secure inference acceleration in an all-round way.\n  We propose SIMC 2.0, which complies with the underlying structure of SIMC,\nbut significantly optimizes both the linear and non-linear layers of the model.\nSpecifically, (1) we design a new coding method for homomorphic parallel\ncomputation between matrices and vectors. It is custom-built through the\ninsight into the complementarity between cryptographic primitives in SIMC. As a\nresult, it can minimize the number of rotation operations incurred in the\ncalculation process, which is very computationally expensive compared to other\nhomomorphic operations e.g., addition, multiplication). (2) We reduce the size\nof the garbled circuit (GC) (used to calculate nonlinear activation functions,\ne.g., ReLU) in SIMC by about two thirds. Then, we design an alternative\nlightweight protocol to perform tasks that are originally allocated to the\nexpensive GCs. Compared with SIMC, our experiments show that SIMC 2.0 achieves\na significant speedup by up to $17.4\\times $ for linear layer computation, and\nat least $1.3\\times$ reduction of both the computation and communication\noverheads in the implementation of non-linear layers under different data\ndimensions. Meanwhile, SIMC 2.0 demonstrates an encouraging runtime boost by\n$2.3\\sim 4.3\\times$ over SIMC on different state-of-the-art ML models.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.09227,review,pre_llm,2022,7,"{'ai_likelihood': 5.861123402913412e-06, 'text': 'A Survey on EOSIO Systems Security: Vulnerability, Attack, and\n  Mitigation\n\n  EOSIO, as one of the most representative blockchain 3.0 platforms, involves\nlots of new features, e.g., delegated proof of stake consensus algorithm and\nupdatable smart contracts, enabling a much higher transaction per second and\nthe prosperous decentralized applications (DApps) ecosystem. According to the\nstatistics, it has reached nearly 18 billion USD, taking the third place of the\nwhole cryptocurrency market, following Bitcoin and Ethereum. Loopholes,\nhowever, are hiding in the shadows. EOSBet, a famous gambling DApp, was\nattacked twice within a month and lost more than 1 million USD. No existing\nwork has surveyed the EOSIO from a security researcher perspective. To fill\nthis gap, in this paper, we collected all occurred attack events against EOSIO,\nand systematically studied their root causes, i.e., vulnerabilities lurked in\nall relying components for EOSIO, as well as the corresponding attacks and\nmitigations. We also summarized some best practices for DApp developers, EOSIO\nofficial team, and security researchers for future directions.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2207.05623,regular,pre_llm,2022,7,"{'ai_likelihood': 3.973642985026042e-07, 'text': ""Attacking (and defending) the Maritime Radar System\n\n  Operation of radar equipment is one of the key facilities used by navigators\nto gather situational awareness about their surroundings. With an ever\nincreasing need for always-running logistics and tighter shipping schedules,\noperators are relying more and more on computerized instruments and their\nindications. As a result, modern ships have become a complex cyber-physical\nsystem in which sensors and computers constantly communicate and coordinate. In\nthis work, we discuss novel threats related to the radar system, which is one\nof the most security-sensitive component on a ship. In detail, we first discuss\nsome new attacks capable of compromising the integrity of data displayed on a\nradar system, with potentially catastrophic impacts on the crew' situational\nawareness or even safety itself. Then, we present a detection system aimed at\nhighlighting anomalies in the radar video feed, requiring no modifications to\nthe target ship configuration. Finally, we stimulate our detection system by\nperforming the attacks inside of a simulated environment. The experimental\nresults clearly indicate that the attacks are feasible, rather easy to carry\nout, and hard-to-detect. Moreover, they prove that the proposed detection\ntechnique is effective.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.08751,regular,pre_llm,2022,8,"{'ai_likelihood': 2.7815500895182294e-06, 'text': 'MPInspector: A Systematic and Automatic Approach for Evaluating the\n  Security of IoT Messaging Protocols\n\n  Facilitated by messaging protocols (MP), many home devices are connected to\nthe Internet, bringing convenience and accessibility to customers. However,\nmost deployed MPs on IoT platforms are fragmented and are not implemented\ncarefully to support secure communication. To the best of our knowledge, there\nis no systematic solution to perform automatic security checks on MP\nimplementations yet.\n  To bridge the gap, we present MPInspector, the first automatic and systematic\nsolution for vetting the security of MP implementations. MPInspector combines\nmodel learning with formal analysis and operates in three stages: (a) using\nparameter semantics extraction and interaction logic extraction to\nautomatically infer the state machine of an MP implementation, (b) generating\nsecurity properties based on meta properties and the state machine, and (c)\napplying automatic property based formal verification to identify property\nviolations. We evaluate MPInspector on three popular MPs, including MQTT, CoAP\nand AMQP, implemented on nine leading IoT platforms. It identifies 252 property\nviolations, leveraging which we further identify eleven types of attacks under\ntwo realistic attack scenarios. In addition, we demonstrate that MPInspector is\nlightweight (the average overhead of end-to-end analysis is ~4.5 hours) and\neffective with a precision of 100% in identifying property violations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.0706,regular,pre_llm,2022,8,"{'ai_likelihood': 2.5497542487250434e-06, 'text': 'A Blockchain-based Decentralised and Dynamic Authorisation Scheme for\n  the Internet of Things\n\n  An authorisation has been recognised as an important security measure for\npreventing unauthorised access to critical resources, such as devices and data,\nwithin the Internet of Things (IoT) networks. Existing authorisation methods\nfor the IoT network are based on traditional access control models, which have\nseveral drawbacks, including architecture centralisation, policy tampering,\naccess rights validation, malicious third-party policy assignment and control,\nand network-related overheads. The increasing trend of integrating Blockchain\ntechnology with IoT networks demonstrates its importance and potential to\naddress the shortcomings of traditional IoT network authorisation mechanisms.\nThis paper proposes a decentralised, secure, dynamic, and flexible\nauthorisation scheme for IoT networks based on attribute-based access control\n(ABAC) fine-grained policies stored on a distributed immutable ledger. We\ndesign a Blockchain-based ABAC policy management framework divided into\nAttribute Management Authority (AMA) and Policy Management Authority (PMA)\nframeworks that use smart contract features to initialise, store, and manage\nattributes and policies on the Blockchain. To achieve flexibility and\ndynamicity in the authorisation process, we capture and utilise the\nenvironmental-related attributes in conjunction with the subject and object\nattributes of the ABAC model to define the policies. Furthermore, we designed\nthe Blockchain-based Access Management Framework (AMF) to manage user requests\nto access IoT devices while maintaining the privacy and auditability of user\nrequests and assigned policies. We implemented a prototype of our proposed\nscheme and executed it on the local Ethereum Blockchain. Finally, we\ndemonstrated the applicability and flexibility of our proposed scheme for an\nIoT-based smart home scenario, taking into account deployment, execution and\nfinancial costs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.07489,regular,pre_llm,2022,8,"{'ai_likelihood': 3.311369154188368e-08, 'text': ""Single Round-trip Hierarchical ORAM via Succinct Indices\n\n  Access patterns to data stored remotely create a side channel that is known\nto leak information even if the content of the data is encrypted. To protect\nagainst access pattern leakage, Oblivious RAM is a cryptographic primitive that\nobscures the (actual) access trace at the expense of additional access and\nperiodic shuffling of the server's contents. A class of ORAM solutions, known\nas Hierarchical ORAM, has achieved theoretically \\emph{optimal} logarithmic\nbandwidth overhead. However, to date, Hierarchical ORAMs are seen as only\ntheoretical artifacts. This is because they require a large number of\ncommunication round-trips to locate (shuffled) elements at the server and\ninvolve complex building blocks such as cuckoo hash tables.\n  To address the limitations of Hierarchical ORAM schemes in practice, we\nintroduce Rank ORAM; the first Hierarchical ORAM that can retrieve data with a\nsingle round-trip of communication (as compared to a logarithmic number in\nprevious work). To support non-interactive communication, we introduce a\n\\emph{compressed} client-side data structure that stores, implicitly, the\nlocation of each element at the server. In addition, this location metadata\nenables a simple protocol design that dispenses with the need for complex\ncuckoo hash tables.\n  Rank ORAM requires asymptotically smaller memory than existing\n(non-Hierarchical) state-of-the-art practical ORAM schemes (e.g., Ring ORAM)\nwhile maintaining comparable bandwidth performance. Our experiments on real\nnetwork file-system traces demonstrate a reduction in client memory, against\nexisting approaches, of a factor of~$100$. For example, when {outsourcing} a\ndatabase of $17.5$TB, required client-memory is only $290$MB vs. $40$GB for\nstandard approaches.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.12836,regular,pre_llm,2022,8,"{'ai_likelihood': 2.4835268656412763e-06, 'text': ""Living-off-the-Land Abuse Detection Using Natural Language Processing\n  and Supervised Learning\n\n  Living-off-the-Land is an evasion technique used by attackers where native\nbinaries are abused to achieve malicious intent. Since these binaries are often\nlegitimate system files, detecting such abuse is difficult and often missed by\nmodern anti-virus software. This paper proposes a novel abuse detection\nalgorithm using raw command strings. First, natural language processing\ntechniques such as regular expressions and one-hot encoding are utilized for\nencoding the command strings as numerical token vectors. Next, supervised\nlearning techniques are employed to learn the malicious patterns in the token\nvectors and ultimately predict the command's label. Finally, the model is\nevaluated using statistics from the training phase and in a virtual environment\nto compare its effectiveness at detecting new commands to existing anti-virus\nproducts such as Windows Defender.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.14367,regular,pre_llm,2022,8,"{'ai_likelihood': 7.947285970052084e-07, 'text': ""Software Update Practices on Smart Home IoT Devices\n\n  Smart home IoT devices are known to be breeding grounds for security and\nprivacy vulnerabilities. Although some IoT vendors deploy updates, the update\nprocess is mostly opaque to researchers. It is unclear what software components\nare on devices, whether and when these components are updated, and how\nvulnerabilities change alongside the updates. This opaqueness makes it\ndifficult to understand the security of software supply chains of IoT devices.\n  To understand the software update practices on IoT devices, we leverage IoT\nInspector's dataset of network traffic from real-world IoT devices. We analyze\nthe User Agent strings from plain-text HTTP connections. We focus on four\nsoftware components included in User Agents: cURL, Wget, OkHttp, and\npython-requests. By keeping track of what kinds of devices have which of these\ncomponents at what versions, we find that many IoT devices potentially used\noutdated and vulnerable versions of these components - based on the User Agents\n- even though less vulnerable, more updated versions were available; and that\nthe rollout of updates tends to be slow for some IoT devices.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.0854,regular,pre_llm,2022,8,"{'ai_likelihood': 1.3245476616753472e-06, 'text': ""Necessary Conditions in Multi-Server Differential Privacy\n\n  We consider protocols where users communicate with multiple servers to\nperform a computation on the users' data. An adversary exerts semi-honest\ncontrol over many of the parties but its view is differentially private with\nrespect to honest users. Prior work described protocols that required multiple\nrounds of interaction or offered privacy against a computationally bounded\nadversary. Our work presents limitations of non-interactive protocols that\noffer privacy against unbounded adversaries. We show these protocols demand\nexponentially more samples for some learning and estimation tasks than\ncentrally private counterparts. This means performing as well as the central\nmodel requires interactivity or computational differential privacy, or both.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.06147,regular,pre_llm,2022,8,"{'ai_likelihood': 1.0397699144151476e-05, 'text': 'Software implementation of the SNOW 3G Generator on iOS and Android\n  platforms\n\n  The standard for wireless communication of high-speed data in mobile phones\nand data terminals, called LTE (Long-Term Evolution) and marketed as 4G/LTE, is\nquickly being adopted worldwide. The security of this type of communication is\na crucial factor mainly due to its mobile and wireless nature. This work\nincludes a practical analysis of the SNOW 3G generator used to protect the\nconfidentiality and integrity in LTE communications. In particular, several\ntechniques to perform multiplications and LFSR operations have been studied and\nimplemented on both iOS and Android platforms. The evaluation of those\nimplementations led to some conclusions that could be used to improve the\nefficiency of future implementations of the standard.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.04624,regular,pre_llm,2022,8,"{'ai_likelihood': 2.715322706434462e-06, 'text': 'Bottom-up Trust Registry in Self Sovereign Identity\n\n  Self sovereign identity is a form of decentralised credential management.\nDuring credential verification, data exchange only happens between the data\nowner and the verifier without passing through any third parties. While this\napproach offers a privacy-centric solution, it poses a challenge. How do\nverifiers trust that the credential is vouched by a trusted source? More\nspecifically, how do verifiers know that the issuer has the reputation or is\nauthorised to issue the credential? In this paper, we propose a trust registry\ndesign that handles the aspect of human trust in self sovereign identity. We\nalso introduce an incentivisation mechanism for the trust registry in order to\nmotivate each stakeholder to participate actively and honestly.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.0008,regular,pre_llm,2022,8,"{'ai_likelihood': 1.986821492513021e-07, 'text': 'Wiggle: Physical Challenge-Response Verification of Vehicle Platooning\n\n  Autonomous vehicle platooning promises many benefits such as fuel efficiency,\nroad safety, reduced traffic congestion, and passenger comfort. Platooning\nvehicles travel in a single file, in close distance, and at the same velocity.\nThe platoon formation is autonomously maintained by a Cooperative Adaptive\nCruise Control (CACC) system which relies on sensory data and\nvehicle-to-vehicle (V2V) communications. In fact, V2V messages play a critical\nrole in shortening the platooning distance while maintaining safety. Whereas\nV2V message integrity and source authentication can be verified via\ncryptographic methods, establishing the truthfulness of the message contents is\na much harder task.\n  This work establishes a physical access control mechanism to restrict V2V\nmessages to platooning members. Specifically, we aim at tying the digital\nidentity of a candidate requesting to join a platoon to its physical trajectory\nrelative to the platoon. We propose the {\\em Wiggle} protocol that employs a\nphysical challenge-response exchange to prove that a candidate requesting to be\nadmitted into a platoon actually follows it. The protocol name is inspired by\nthe random longitudinal movements that the candidate is challenged to execute.\n{\\em Wiggle} prevents any remote adversary from joining the platoon and\ninjecting fake CACC messages. Compared to prior works, {\\em Wiggle} is\nresistant to pre-recording attacks and can verify that the candidate is\ndirectly behind the verifier at the same lane.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.05125,regular,pre_llm,2022,8,"{'ai_likelihood': 7.60952631632487e-05, 'text': 'Cross-chain between a Parent Chain and Multiple Side Chains\n\n  In certain Blockchain systems, multiple Blockchains are required to operate\ncooperatively for security, performance, and capacity considerations. This\ninvention defines a cross-chain mechanism where a main Blockchain issues the\ntokens, which can then be transferred and used in multiple side Blockchains to\ndrive their operations. A set of witnesses are created to securely manage the\ntoken exchange across the main chain and multiple side chains. The system\ndecouples the consensus algorithms between the main chain and side chains. We\nalso discuss the coexistence of the main tokens and the native tokens in the\nside chains.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.0876,regular,pre_llm,2022,8,"{'ai_likelihood': 2.3610062069363066e-05, 'text': 'Blockchain based digital vaccine passport\n\n  Travel has been challenging recently since different nations have implemented\nvaried immigration and travel policies. For the time being, immigration\nofficials want proof of each person\'s immunity to the virus. A vaccine passport\nserves as evidence that a person has tested negative for or is immune to a\nparticular virus. In terms of COVID-19, those who hold a vaccine passport will\nbe permitted entry into other nations as long as they can provide proof that\nthey have COVID-19 antibodies from prior infections or from full COVID-19\nimmunizations. To reduce time and effort spent managing data, the vaccination\npassport system has been digitalized. The process of contact tracing may be\nfacilitated by digitization. The ""Blockchain technology"" system, which is\ncurrently in use, has demonstrated its security and privacy in systems for data\nexchange among bitcoin users. The Digital Vaccination Passport scheme can use\nBlockchain technology. The end result would be a decentralized, traceable,\ntransparent, reliable, auditable, secure, and trustworthy solution based on the\nEthereum block-chain that would allow tracking of vaccines given and the\nhistory of diseases.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.12497,regular,pre_llm,2022,8,"{'ai_likelihood': 6.291601392957899e-06, 'text': ""Privacy with Good Taste: A Case Study in Quantifying Privacy Risks in\n  Genetic Scores\n\n  Analysis of genetic data opens up many opportunities for medical and\nscientific advances. The use of phenotypic information and polygenic risk\nscores to analyze genetic data is widespread. Most work on genetic privacy\nfocuses on basic genetic data such as SNP values and specific genotypes. In\nthis paper, we introduce a novel methodology to quantify and prevent privacy\nrisks by focusing on polygenic scores and phenotypic information. Our\nmethodology is based on the tool-supported privacy risk analysis method Privug.\nWe demonstrate the use of Privug to assess privacy risks posed by disclosing a\npolygenic trait score for bitter taste receptors, encoded by TAS2R38 and\nTAS2R16, to a person's privacy in regards to their ethnicity. We provide an\nextensive privacy risks analysis of different programs for genetic data\ndisclosure: taster phenotype, tasting polygenic score, and a polygenic score\ndistorted with noise. Finally, we discuss the privacy/utility trade-offs of the\npolygenic score.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.02857,regular,pre_llm,2022,8,"{'ai_likelihood': 1.0596381293402778e-06, 'text': ""Identity-Based Authentication for On-Demand Charging of Electric\n  Vehicles\n\n  Dynamic wireless power transfer provides means for charging Electric Vehicles\n(EVs) while driving, avoiding stopping for charging and hence fostering their\nwidespread adoption. Researchers devoted much effort over the last decade to\nprovide a reliable infrastructure for potential users to improve comfort and\ntime management. Due to the severe security and performance system\nrequirements, the different scheme proposed in last years lack of a unified\nprotocol involving the modern architecture model with merged authentication and\nbilling processes. Furthermore, they require the continuous interaction of the\ntrusted entity during the process, increasing the delay for the communication\nand reducing security due to the large number of message exchanges. In this\npaper, we propose a secure, computationally lightweight, unified protocol for\nfast authentication and billing that provides on-demand dynamic charging to\ncomprehensively deal with all the computational and security constraints. The\nprotocol employs an ID-based public encryption scheme to manage mutual\nauthentication and pseudonyms to preserve the user's identity across multiple\ncharging processes. Compared to state-of-the-art authentication protocols, our\nproposal overcomes the problem of overwhelming interactions and provides public\nscheme security against the use of simple operations in wide open\ncommunications without impacting on performance.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.09235,regular,pre_llm,2022,8,"{'ai_likelihood': 3.4769376118977866e-06, 'text': 'A Pragmatic Methodology for Blind Hardware Trojan Insertion in Finalized\n  Layouts\n\n  A potential vulnerability for integrated circuits (ICs) is the insertion of\nhardware trojans (HTs) during manufacturing. Understanding the practicability\nof such an attack can lead to appropriate measures for mitigating it. In this\npaper, we demonstrate a pragmatic framework for analyzing HT susceptibility of\nfinalized layouts. Our framework is representative of a fabrication-time\nattack, where the adversary is assumed to have access only to a layout\nrepresentation of the circuit. The framework inserts trojans into tapeout-ready\nlayouts utilizing an Engineering Change Order (ECO) flow. The attacked security\nnodes are blindly searched utilizing reverse-engineering techniques. For our\nexperimental investigation, we utilized three crypto-cores (AES-128, SHA-256,\nand RSA) and a microcontroller (RISC-V) as targets. We explored 96 combinations\nof triggers, payloads and targets for our framework. Our findings demonstrate\nthat even in high-density designs, the covert insertion of sophisticated\ntrojans is possible. All this while maintaining the original target logic, with\nminimal impact on power and performance. Furthermore, from our exploration, we\nconclude that it is too naive to only utilize placement resources as a metric\nfor HT vulnerability. This work highlights that the HT insertion success is a\ncomplex function of the placement, routing resources, the position of the\nattacked nodes, and further design-specific characteristics. As a result, our\nframework goes beyond just an attack, we present the most advanced analysis\ntool to assess the vulnerability of HT insertion into finalized layouts.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.06593,regular,pre_llm,2022,8,"{'ai_likelihood': 4.801485273573134e-06, 'text': 'Analysis and implementation of the SNOW 3G generator used in 4G/LTE\n  systems\n\n  The fourth generation of cell phones, marketed as 4G/LTE (Long-Term\nEvolution) is being quickly adopted worldwide. Given the mobile and wireless\nnature of the involved communications, security is crucial. This paper includes\nboth a theoretical study and a practical analysis of the SNOW 3G generator,\nincluded in such a standard for protecting confidentiality and integrity. From\nits implementation and performance evaluation in mobile devices, several\nconclusions about how to improve its efficiency are obtained.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.07604,regular,pre_llm,2022,8,"{'ai_likelihood': 2.914004855685764e-05, 'text': ""Achieve Fully Decentralized End to End Encryption Meeting via Blockchain\n\n  Zoom Meeting is an enterprise online video conferencing solution with\nreal-time messaging and content sharing. However, it's lack of privacy\nprotection since centralized Zoom servers are capable of monitoring user's\nmessages. Thereby, to solve the privacy problem, in May 2020, Zoom acquired\nKeybase so that Keybase's team can help it to build end-to-end encryption\nmeeting while remaining Zoom's current scalability and high-performance.\nNonetheless, according to the latest released Zoom's whitepaper, even with the\nnew design of E2E (end to end) encryption meeting, the security threats can't\nbe erased completely since the new design is not fully decentralized.\n  In this paper, we introduce a fully decentralized design of E2E encryption\nmeeting via blockchain technology. With this new design, Zoom's E2E meeting\nprivacy can be further improved.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.06628,regular,pre_llm,2022,8,"{'ai_likelihood': 4.2054388258192275e-06, 'text': 'CANdito: Improving Payload-based Detection of Attacks on Controller Area\n  Networks\n\n  Over the years, the increasingly complex and interconnected vehicles raised\nthe need for effective and efficient Intrusion Detection Systems against\non-board networks. In light of the stringent domain requirements and the\nheterogeneity of information transmitted on Controller Area Network, multiple\napproaches have been proposed, which work at different abstraction levels and\ngranularities. Among these, RNN-based solutions received the attention of the\nresearch community for their performances and promising results. In this paper,\nwe improve CANnolo, an RNN-based state-of-the-art IDS for CAN, by proposing\nCANdito, an unsupervised IDS that exploits Long Short-Term Memory autoencoders\nto detect anomalies through a signal reconstruction process. We evaluate\nCANdito by measuring its effectiveness against a comprehensive set of synthetic\nattacks injected in a real-world CAN dataset. We demonstrate the improvement of\nCANdito with respect to CANnolo on a real-world dataset injected with a\ncomprehensive set of attacks, both in terms of detection and temporal\nperformances.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.09852,regular,pre_llm,2022,8,"{'ai_likelihood': 9.768539004855686e-06, 'text': 'Efficient Multiparty Protocols Using Generalized Parseval\'s Identity and\n  the Theta Algebra\n\n  We propose a protocol able to show publicly addition and multiplication on\nsecretly shared values. To this aim we developed a protocol based on the use of\nmasks and on the FMPC (Fourier Multi-Party Computation). FMPC is a novel\nmultiparty computation protocol of arithmetic circuits based on secret-sharing,\ncapable to compute addition and multiplication of secrets with no\ncommunication. We achieve this task by introducing the first generalisation of\nParseval\'s identity for Fourier series applicable to an arbitrary number of\ninputs and a new algebra referred to as the ""Theta-algebra"". FMPC operates in a\nsetting where users wish to compute a function over some secret inputs by\nsubmitting the computation to a set of nodes, without revealing them those\ninputs. FMPC offloads most of the computational complexity to the end users,\nand includes an online phase that mainly consists of each node locally\nevaluating specific functions. FMPC paves the way for a new kind of multiparty\ncomputation protocols; making it possible to compute addition and\nmultiplication of secrets stepping away from circuit garbling and the\ntraditional algebra introduced by Donald Beaver in 1991. Our protocol is\ncapable to compute addition and multiplication with no communication and its\nsimplicity provides efficiency and ease of implementation.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.13278,regular,pre_llm,2022,8,"{'ai_likelihood': 1.986821492513021e-06, 'text': ""Shedding Light on the Targeted Victim Profiles of Malicious Downloaders\n\n  Malware affects millions of users worldwide, impacting the daily lives of\nmany people as well as businesses. Malware infections are increasing in\ncomplexity and unfold over a number of stages. A malicious downloader often\nacts as the starting point as it fingerprints the victim's machine and\ndownloads one or more additional malware payloads. Although previous research\nwas conducted on these malicious downloaders and their Pay-Per-Install\nnetworks, limited work has investigated how the profile of the victim machine,\ne.g., its characteristics and software configuration, affect the targeting\nchoice of cybercriminals.\n  In this paper, we operate a large-scale investigation of the relation between\nthe machine profile and the payload downloaded by droppers, through 151,189\nexecutions of malware downloaders over a period of 12 months. We build a fully\nautomated framework which uses Virtual Machines (VMs) in sandboxes to build\ncustom user and machine profiles to test our malicious samples. We then use\nchangepoint analysis to model the behavior of different downloader families,\nand perform analyses of variance (ANOVA) on the ratio of infections per\nprofile. With this, we identify which machine profile is targeted by\ncybercriminals at different points in time.\n  Our results show that a number of downloaders present different behaviors\ndepending on a number of features of a machine. Notably, a higher number of\ninfections for specific malware families were observed when using different\nbrowser profiles, keyboard layouts and operating systems, while one keyboard\nlayout obtained fewer infections of a specific malware family.\n  Our findings bring light to the importance of the features of a machine\nrunning malicious downloader software, particularly for malware research.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2208.11147,review,pre_llm,2022,8,"{'ai_likelihood': 6.688965691460504e-06, 'text': 'SoK: Content Moderation Schemes in End-to-End Encrypted Systems\n\n  This paper aims to survey various techniques utilized for content moderation\nin end-to-end encryption systems. We assess the challenging aspect of content\nmoderation: maintaining a safe platform while assuring user privacy. We study\nthe unique features of some content moderation techniques, such as message\nfranking and perceptual hashing, and highlight their limitations. Currently\nimplemented content moderation techniques violate the goals of end-to-end\nencrypted messaging to some extent. This has led researchers to develop\nremediations and design new security primitives to make content moderation\ncompatible with end-to-end encryption systems. We detail these developments,\nanalyze the proposed research efforts, assess their security guarantees,\ncorrelate them with other proposed solutions, and determine suitable\nimprovements under specific scenarios.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.03622,review,pre_llm,2022,9,"{'ai_likelihood': 2.9802322387695312e-06, 'text': 'Deep Learning Models for Detecting Malware Attacks\n\n  Malware is one of the most common and severe cyber-attack today. Malware\ninfects millions of devices and can perform several malicious activities\nincluding mining sensitive data, encrypting data, crippling system performance,\nand many more. Hence, malware detection is crucial to protect our computers and\nmobile devices from malware attacks. Deep learning (DL) is one of the emerging\nand promising technologies for detecting malware. The recent high production of\nmalware variants against desktop and mobile platforms makes DL algorithms\npowerful approaches for building scalable and advanced malware detection models\nas they can handle big datasets. This work explores current deep learning\ntechnologies for detecting malware attacks on the Windows, Linux, and Android\nplatforms. Specifically, we present different categories of DL algorithms,\nnetwork optimizers, and regularization methods. Different loss functions,\nactivation functions, and frameworks for implementing DL models are presented.\nWe also present feature extraction approaches and a review of recent DL-based\nmodels for detecting malware attacks on the above platforms. Furthermore, this\nwork presents major research issues on malware detection including future\ndirections to further advance knowledge and research in this field.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.14195,regular,pre_llm,2022,9,"{'ai_likelihood': 6.5896246168348525e-06, 'text': 'Secure Indoor Location for Airport Environments\n\n  This work presents a secure novel solution based on inertial measurement\nunits to provide indoor location and positioning in airports. The use of\ndifferent technologies allows to locate people with precision in this kind of\nindoor places where the use of the GPS is not possible. The system has been\ndeveloped thinking in the low cost and in a possible future expansion of this\nkind of systems to improve the Quality of Service of the users in airports. The\nuse of QR codes and low cost IMU devices through the use of people smartphones\nensure this premise. An Android application has been developed to show the\napplicability and performance of the system. The security in this kind of\nsystems is essential. This kind of systems needs to avoid the traceability of\nthe IMU devices when users are using it. To solve this problem, the FourQ\nelliptic curve has been used to generate a shared key using the elliptic curve\nDiffie-Hellman protocol. The key generated with the FourQ is used then to\ncipher all communications through the use of the SNOW 3G stream cipher. The\ndeveloped system offers promising results.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.01894,regular,pre_llm,2022,9,"{'ai_likelihood': 6.953875223795574e-07, 'text': ""Write Me and I'll Tell You Secrets -- Write-After-Write Effects On Intel\n  CPUs\n\n  There is a long history of side channels in the memory hierarchy of modern\nCPUs. Especially the cache side channel is widely used in the context of\ntransient execution attacks and covert channels. Therefore, many secure cache\narchitectures have been proposed. Most of these architectures aim to make the\nconstruction of eviction sets infeasible by randomizing the address-to-cache\nmapping. In this paper, we investigate the peculiarities of write instructions\nin recent CPUs. We identify Write+Write, a new side channel on Intel CPUs that\nleaks whether two addresses contend for the same cache set. We show how\nWrite+Write can be used for rapid construction of eviction sets on current\ncache architectures. Moreover, we replicate the Write+Write effect in gem5 and\ndemonstrate on the example of ScatterCache how it can be exploited to\nefficiently attack state-of-the-art cache randomization schemes. In addition to\nthe Write+Write side channel, we show how Write-After-Write effects can be\nleveraged to efficiently synchronize covert channel communication across CPU\ncores. This yields the potential for much more stealthy covert channel\ncommunication than before.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.11857,regular,pre_llm,2022,9,"{'ai_likelihood': 2.682209014892578e-06, 'text': 'Analysis of the new standard hash function\n\n  On 2$^{nd}$ October 2012 the NIST (National Institute of Standards and\nTechnology) in the United States of America announced the new hashing algorithm\nwhich will be adopted as standard from now on. Among a total of 73 candidates,\nthe winner was Keccak, designed by a group of cryptographers from Belgium and\nItaly. The public selection of a new standard of cryptographic hash function\nSHA (Secure Hash Algorithm) took five years. Its object is to generate a hash a\nfixed size from a pattern with arbitrary length. The first selection on behalf\nof NIST on a standard of this family took place in 1993 when SHA-1 was chosen,\nwhich later on was replaced by SHA-2. This paper is focused on the analysis\nboth from the point of view of security and the implementation of the Keccak\nfunction, which is the base of the new SHA-3 standard. In particular, an\nimplementation in the mobile platform Android is presented here, providing the\nfirst known external library in this mobile operating system so that any\ndeveloper could use the new standard hashing. Finally, the new standard in\napplications in the Internet of Things is analysed.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.12698,regular,pre_llm,2022,9,"{'ai_likelihood': 2.8808911641438803e-06, 'text': 'QuantumSolver: A quantum tool-set for developers\n\n  This paper introduces a new opensource quantum tool-set called QuantumSolver\nbased on Qiskit to help developers without knowledge in quantum computing. The\ndeveloped library includes a set of algorithms with different features: random\nnumber generation, Bernstein-Vazirani algorithm and quantum key distribution\nusing the BB84 protocol. This paper described the main details about the\nimplementation of the toolset, focusing in the challenges that the authors\nfaced. Finally, this document analyzes the results obtained with some\nconclusions that authors compares with the included features.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.12742,review,pre_llm,2022,9,"{'ai_likelihood': 1.612636778089735e-05, 'text': 'Too Many Options: A Survey of ABE Libraries for Developers\n\n  Attribute-based encryption (ABE) comprises a set of one-to-many encryption\nschemes that allow the encryption and decryption of data by associating it with\naccess policies and attributes. Therefore, it is an asymmetric encryption\nscheme, and its computational requirements limit its deployment in IoT devices.\nThere are different types of ABE and many schemes within each type. However,\nthere is no consensus on the default library for ABE, and those that exist\nimplement different schemes. Developers, therefore, face the challenge of\nbalancing efficiency and security by choosing the suitable library for their\nprojects. This paper studies eleven ABE libraries, analyzing their main\nfeatures, the mathematical libraries used, and the ABE schemes they provide.\nThe paper also presents an experimental analysis of the four libraries which\nare still maintained and identifies some of the insecure ABE schemes they\nimplement. In this experimental analysis, we implement the schemes offered by\nthese libraries, measuring their execution times on architectures with\ndifferent capabilities, i.e., ARMv6 and ARMv8. The experiments provide\ndevelopers with the necessary information to choose the most suitable library\nfor their projects, according to objective and well-defined criteria.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.01637,regular,pre_llm,2022,9,"{'ai_likelihood': 1.158979203965929e-06, 'text': 'Joint Linear and Nonlinear Computation across Functions for Efficient\n  Privacy-Preserving Neural Network Inference\n\n  While it is encouraging to witness the recent development in\nprivacy-preserving Machine Learning as a Service (MLaaS), there still exists a\nsignificant performance gap for its deployment in real-world applications. We\nobserve the state-of-the-art frameworks follow a compute-and-share principle\nfor every function output where the summing in linear functions, which is the\nlast of two steps for function output, involves all rotations (which is the\nmost expensive HE operation), and the multiplexing in nonlinear functions,\nwhich is also the last of two steps for function output, introduces noticeable\ncommunication rounds. Therefore, we challenge the conventional\ncompute-and-share logic and introduce the first joint linear and nonlinear\ncomputation across functions that features by 1) the PHE triplet for computing\nthe nonlinear function, with which the multiplexing is eliminated; 2) the\nmatrix encoding to calculate the linear function, with which all rotations for\nsumming is removed; and 3) the network adaptation to reassemble the model\nstructure, with which the joint computation module is utilized as much as\npossible. The boosted efficiency is verified by the numerical complexity, and\nthe experiments demonstrate up to 13x speedup for various functions used in the\nstate-of-the-art models and up to 5x speedup over mainstream neural networks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.11962,regular,pre_llm,2022,9,"{'ai_likelihood': 5.596213870578343e-06, 'text': 'Trace-based cryptanalysis of cyclotomic $R_{q,0}\\times R_q$-PLWE for the\n  non-split case\n\n  We describe a decisional attack against a version of the PLWE problem in\nwhich the samples are taken from a certain proper subring of large dimension of\nthe cyclotomic ring $\\mathbb{F}_q[x]/(\\Phi_{p^k}(x))$ with $k>1$ in the case\nwhere $q\\equiv 1\\pmod{p}$ but $\\Phi_{p^k}(x)$ is not totally split over\n$\\mathbb{F}_q$. Our attack uses the fact that the roots of $\\Phi_{p^k}(x)$ over\nsuitable extensions of $\\mathbb{F}_q$ have zero-trace and has overwhelming\nsuccess probability as a function of the number of input samples. An\nimplementation in Maple and some examples of our attack are also provided.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.07125,regular,pre_llm,2022,9,"{'ai_likelihood': 2.1027194129096137e-05, 'text': ""BadRes: Reveal the Backdoors through Residual Connection\n\n  Generally, residual connections are indispensable network components in\nbuilding CNNs and Transformers for various downstream tasks in CV and VL, which\nencourages skip shortcuts between network blocks. However, the layer-by-layer\nloopback residual connections may also hurt the model's robustness by allowing\nunsuspecting input. In this paper, we proposed a simple yet strong backdoor\nattack method - BadRes, where the residual connections play as a turnstile to\nbe deterministic on clean inputs while unpredictable on poisoned ones. We have\nperformed empirical evaluations on four datasets with ViT and BEiT models, and\nthe BadRes achieves 97% attack success rate while receiving zero performance\ndegradation on clean data. Moreover, we analyze BadRes with state-of-the-art\ndefense methods and reveal the fundamental weakness lying in residual\nconnections.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.09653,review,pre_llm,2022,9,"{'ai_likelihood': 2.2186173333062066e-06, 'text': 'A Framework for Preserving Privacy and Cybersecurity in Brain-Computer\n  Interfacing Applications\n\n  Brain-Computer Interfaces (BCIs) comprise a rapidly evolving field of\ntechnology with the potential of far-reaching impact in domains ranging from\nmedical over industrial to artistic, gaming, and military. Today, these\nemerging BCI applications are typically still at early technology readiness\nlevels, but because BCIs create novel, technical communication channels for the\nhuman brain, they have raised privacy and security concerns. To mitigate such\nrisks, a large body of countermeasures has been proposed in the literature, but\na general framework is lacking which would describe how privacy and security of\nBCI applications can be protected by design, i.e., already as an integral part\nof the early BCI design process, in a systematic manner, and allowing suitable\ndepth of analysis for different contexts such as commercial BCI product\ndevelopment vs. academic research and lab prototypes. Here we propose the\nadoption of recent systems-engineering methodologies for privacy threat\nmodeling, risk assessment, and privacy engineering to the BCI field. These\nmethodologies address privacy and security concerns in a more systematic and\nholistic way than previous approaches, and provide reusable patterns on how to\nmove from principles to actions. We apply these methodologies to BCI and data\nflows and derive a generic, extensible, and actionable framework for\nbrain-privacy-preserving cybersecurity in BCI applications. This framework is\ndesigned for flexible application to the wide range of current and future BCI\napplications. We also propose a range of novel privacy-by-design features for\nBCIs, with an emphasis on features promoting BCI transparency as a prerequisite\nfor informational self-determination of BCI users, as well as design features\nfor ensuring BCI user autonomy. We anticipate that our framework will\ncontribute to the development of privacy-respecting, trustworthy BCI\ntechnologies.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.03319,regular,pre_llm,2022,9,"{'ai_likelihood': 4.304779900444879e-06, 'text': ""Measurement of the Usage of Web Clips in Underground Economy\n\n  In this paper, we study the ecosystem of the abused Web Clips in underground\neconomy. Through this study, we find the Web Clips is wildly used by\nperpetrators to penetrate iOS devices to gain profit. This work starts with\n1,800 user complaint documents about cyber crimes over Web Clips. We firstly\nlook into the ecosystem of abused Web Clips and point out the main participants\nand workflow. In addition, what is the Web Clips used for is demystified. Then\nthe main participants, including creators, distributors, and operators are\ndeeply studied based on our dataset. We try to reveal the prominent features of\nthe illicit Web Clips and give some mitigation measures.\n  Analysis reveals that 1) SSL certificate is overwhelmingly preferred for\nsigning Web Clips instances compared with certificate issued by Apple. The\nwildly used SSL certificates can be aggregated into a limited group. 2) The\ncontent of the abused Web Clips falls into a few categories, `Gambling',\n`Fraud', and `Pornography' are among the top categories. 3) Instant messenger\n(IM) and live streaming platform are the most popular medium to trick victims\ninto deploying the Web Clips. 4) The Web Clips are operated by a small amount\nof perpetrators, and the perpetrators tend to evade detection by taking\ntechnical approach, such as registering domain names through oversea domain\nname service provider, preferring easy-to-acquire new gTLD (global Top Level\nDomain), and deploying anti-crawler tricks.\n  Our study gives hints on investigation of cyber crime over Web Clips, we hope\nthat this work can help stakeholders to stay ahead of the threat.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.14952,regular,pre_llm,2022,9,"{'ai_likelihood': 6.953875223795574e-07, 'text': 'CacheQL: Quantifying and Localizing Cache Side-Channel Vulnerabilities\n  in Production Software\n\n  Cache side-channel attacks extract secrets by examining how victim software\naccesses cache. To date, practical attacks on cryptosystems and media libraries\nare demonstrated under different scenarios, inferring secret keys and\nreconstructing private media data such as images.\n  This work first presents eight criteria for designing a full-fledged detector\nfor cache side-channel vulnerabilities. Then, we propose CacheQL, a novel\ndetector that meets all of these criteria. CacheQL precisely quantifies\ninformation leaks of binary code, by characterizing the distinguishability of\nlogged side channel traces. Moreover, CacheQL models leakage as a cooperative\ngame, allowing information leakage to be precisely distributed to program\npoints vulnerable to cache side channels. CacheQL is meticulously optimized to\nanalyze whole side channel traces logged from production software (where each\ntrace can have millions of records), and it alleviates randomness introduced by\ncryptographic blinding, ORAM, or real-world noises.\n  Our evaluation quantifies side-channel leaks of production cryptographic and\nmedia software. We further localize vulnerabilities reported by previous\ndetectors and also identify a few hundred new leakage sites in recent OpenSSL\n(ver. 3.0.0), MbedTLS (ver. 3.0.0), Libgcrypt (ver. 1.9.4). Many of our\nlocalized program points are within the pre-processing modules of\ncryptosystems, which are not analyzed by existing works due to scalability. We\nalso localize vulnerabilities in Libjpeg (ver. 2.1.2) that leak privacy about\ninput images.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.142,regular,pre_llm,2022,9,"{'ai_likelihood': 2.3510720994737412e-06, 'text': 'Building an Ethereum-Based Decentralized Vehicle Rental System\n\n  Blockchain technology, beyond cryptocurrencies, is called to be the new\ninformation exchange ecosystem due to its unique properties, such as\nimmutability and transparency. The main objective of this work is to introduce\nthe design of a decentralized rental system, which leverages smart contracts\nand the Ethereum public blockchain. The work started from an exhaustive\ninvestigation on the Ethereum platform, emphasizing the aspect of cryptography\nand all the technology behind this platform. In order to test the proposed\nscheme in a realistic use, the implementation of a web application for the\nrental of vehicles has been carried out. The application covers the entire\nvehicle rental process offered in traditional web applications, adding more\nautonomy and ease of use to users. Following Ethereum application development\nguidelines, all business logic is located in the smart contracts implemented in\nthe Ethereum network, where these contracts control the entire vehicle rental\nsystem of customers. While this is a work in progress, the results obtained in\nthe first proof of concept have been very promising.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.06553,regular,pre_llm,2022,9,"{'ai_likelihood': 2.6490953233506944e-06, 'text': ""Collaborative SQL-injections detection system with machine learning\n\n  Data mining and information extraction from data is a field that has gained\nrelevance in recent years thanks to techniques based on artificial intelligence\nand use of machine and deep learning. The main aim of the present work is the\ndevelopment of a tool based on a previous behaviour study of security audit\ntools (oriented to SQL pentesting) with the purpose of creating testing sets\ncapable of performing an accurate detection of a SQL attack. The study is based\non the information collected through the generated web server logs in a\npentesting laboratory environment. Then, making use of the common extracted\npatterns from the logs, each attack vector has been classified in risk levels\n(dangerous attack, normal attack, non-attack, etc.). Finally, a training with\nthe generated data was performed in order to obtain a classifier system that\nhas a variable performance between 97 and 99 percent in positive attack\ndetection. The training data is shared to other servers in order to create a\ndistributed network capable of deciding if a query is an attack or is a real\npetition and inform to connected clients in order to block the petitions from\nthe attacker's IP.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.06447,review,pre_llm,2022,9,"{'ai_likelihood': 4.006756676567926e-06, 'text': 'Security of Virtual Reality Authentication Methods in Metaverse: An\n  Overview\n\n  The metaverse is said to be the future Internet and will consist of several\nworlds called verses. This concept is being discussed a lot lately, however,\nthe security issues of these virtual worlds are not discussed enough. This\nstudy first discusses the privacy and security concerns of the metaverse.\nVirtual reality headsets are the main devices used to access the Metaverse. The\nuser needs to verify their identity to log in to the metaverse platforms, and\nthe security of this phase becomes vital. This paper aims to compare the\nsecurity of the main authentication methods that are used in virtual reality\nenvironments. Information-based, biometric, and multi-model methods are\ncompared and analyzed in terms of security. These methods aim to verify the\nuser with different data types such as 3D patterns, PIN systems, or biometric\ndata. The pros and cons are discussed. The paper also concludes with what work\ncan be done to improve the safety of these authentication methods and future\nwork.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.09835,regular,pre_llm,2022,9,"{'ai_likelihood': 1.0596381293402778e-06, 'text': ""EM-Fault It Yourself: Building a Replicable EMFI Setup for Desktop and\n  Server Hardware\n\n  EMFI has become a popular fault injection (FI) technique due to its ability\nto inject faults precisely considering timing and location. Recently, ARM,\nRISC-V, and even x86 processing units in different packages were shown to be\nvulnerable to electromagnetic fault injection (EMFI) attacks. However, past\npublications lack a detailed description of the entire attack setup, hindering\nresearchers and companies from easily replicating the presented attacks on\ntheir devices. In this work, we first show how to build an automated EMFI setup\nwith high scanning resolution and good repeatability that is large enough to\nattack modern desktop and server CPUs. We structurally lay out all details on\nmechanics, hardware, and software along with this paper. Second, we use our\nsetup to attack a deeply embedded security co-processor in modern AMD systems\non a chip (SoCs), the AMD Secure Processor (AMD-SP). Using a previously\npublished code execution exploit, we run two custom payloads on the AMD-SP that\nutilize the SoC to different degrees. We then visualize these fault locations\non SoC photographs allowing us to reason about the SoC's components under\nattack. Finally, we show that the signature verification process of one of the\nfirst executed firmware parts is susceptible to EMFI attacks, undermining the\nsecurity architecture of the entire SoC. To the best of our knowledge, this is\nthe first reported EMFI attack against an AMD desktop CPU.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.03826,regular,pre_llm,2022,9,"{'ai_likelihood': 1.8212530348036025e-06, 'text': 'Evaluating the Future Device Security Risk Indicator for Hundreds of IoT\n  Devices\n\n  IoT devices are present in many, especially corporate and sensitive, networks\nand regularly introduce security risks due to slow vendor responses to\nvulnerabilities and high difficulty of patching. In this paper, we want to\nevaluate to what extent the development of future risk of IoT devices due to\nnew and unpatched vulnerabilities can be predicted based on historic\ninformation. For this analysis, we build on existing prediction algorithms\navailable in the SAFER framework (prophet and ARIMA) which we evaluate by means\nof a large data-set of vulnerabilities and patches from 793 IoT devices. Our\nanalysis shows that the SAFER framework can predict a correct future risk for\n91% of the devices, demonstrating its applicability. We conclude that this\napproach is a reliable means for network operators to efficiently detect and\nact on risks emanating from IoT devices in their networks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.04502,review,pre_llm,2022,9,"{'ai_likelihood': 2.6490953233506944e-06, 'text': ""A Close Look at a Systematic Method for Analyzing Sets of Security\n  Advice\n\n  We carry out a detailed analysis of the security advice coding method\n(SAcoding) of Barrera et al. (2021), which is designed to analyze security\nadvice in the sense of measuring actionability and categorizing advice items as\npractices, policies, principles, or outcomes. The main part of our analysis\nexplores the extent to which a second coder's assignment of codes to advice\nitems agrees with that of a first, for a dataset of 1013 security advice items\nnominally addressing Internet of Things devices. More broadly, we seek a deeper\nunderstanding of the soundness and utility of the SAcoding method, and the\ndegree to which it meets the design goal of reducing subjectivity in assigning\ncodes to security advice items. Our analysis results in suggestions for\nmodifications to the coding tree methodology, and some recommendations. We\nbelieve the coding tree approach may be of interest for analysis of qualitative\ndata beyond security advice datasets alone.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.03526,regular,pre_llm,2022,9,"{'ai_likelihood': 8.609559800889757e-07, 'text': 'OblivGM: Oblivious Attributed Subgraph Matching as a Cloud Service\n\n  In recent years there has been growing popularity of leveraging cloud\ncomputing for storing and querying attributed graphs, which have been widely\nused to model complex structured data in various applications. Such trend of\noutsourced graph analytics, however, is accompanied with critical privacy\nconcerns regarding the information-rich and proprietary attributed graph data.\nIn light of this, we design, implement, and evaluate OblivGM, a new system\naimed at oblivious graph analytics services outsourced to the cloud. OblivGM\nfocuses on the support for attributed subgraph matching, one popular and\nfundamental graph query functionality aiming to retrieve from a large\nattributed graph subgraphs isomorphic to a small query graph. Built from a\ndelicate synergy of insights from attributed graph modelling and advanced\nlightweight cryptography, OblivGM protects the confidentiality of data content\nassociated with attributed graphs and queries, conceals the connections among\nvertices in attributed graphs, and hides search access patterns. Meanwhile,\nOblivGM flexibly supports oblivious evaluation of varying subgraph queries,\nwhich may contain equality and/or range predicates. Extensive experiments over\na real-world attributed graph dataset demonstrate that while providing strong\nsecurity guarantees, OblivGM achieves practically affordable performance (with\nquery latency on the order of a few seconds).\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2209.06397,regular,pre_llm,2022,9,"{'ai_likelihood': 1.158979203965929e-06, 'text': ""Federated Learning based on Defending Against Data Poisoning Attacks in\n  IoT\n\n  The rapidly expanding number of Internet of Things (IoT) devices is\ngenerating huge quantities of data, but the data privacy and security exposure\nin IoT devices, especially in the automatic driving system. Federated learning\n(FL) is a paradigm that addresses data privacy, security, access rights, and\naccess to heterogeneous message issues by integrating a global model based on\ndistributed nodes. However, data poisoning attacks on FL can undermine the\nbenefits, destroying the global model's availability and disrupting model\ntraining. To avoid the above issues, we build up a hierarchical defense data\npoisoning (HDDP) system framework to defend against data poisoning attacks in\nFL, which monitors each local model of individual nodes via abnormal detection\nto remove the malicious clients. Whether the poisoning defense server has a\ntrusted test dataset, we design the \\underline{l}ocal \\underline{m}odel\n\\underline{t}est \\underline{v}oting (LMTV) and\n\\underline{k}ullback-\\underline{l}eibler divergence \\underline{a}nomaly\nparameters \\underline{d}etection (KLAD) algorithms to defend against\nlabel-flipping poisoning attacks. Specifically, the trusted test dataset is\nutilized to obtain the evaluation results for each classification to recognize\nthe malicious clients in LMTV. More importantly, we adopt the kullback leibler\ndivergence to measure the similarity between local models without the trusted\ntest dataset in KLAD. Finally, through extensive evaluations and against the\nvarious label-flipping poisoning attacks, LMTV and KLAD algorithms could\nachieve the $100\\%$ and $40\\%$ to $85\\%$ successful defense ratios under\ndifferent detection situations.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.11726,review,pre_llm,2022,10,"{'ai_likelihood': 1.1920928955078125e-06, 'text': 'A critical review of cyber-physical security for building automation\n  systems\n\n  Modern Building Automation Systems (BASs), as the brain that enables the\nsmartness of a smart building, often require increased connectivity both among\nsystem components as well as with outside entities, such as optimized\nautomation via outsourced cloud analytics and increased building-grid\nintegrations. However, increased connectivity and accessibility come with\nincreased cyber security threats. BASs were historically developed as closed\nenvironments with limited cyber-security considerations. As a result, BASs in\nmany buildings are vulnerable to cyber-attacks that may cause adverse\nconsequences, such as occupant discomfort, excessive energy usage, and\nunexpected equipment downtime. Therefore, there is a strong need to advance the\nstate-of-the-art in cyber-physical security for BASs and provide practical\nsolutions for attack mitigation in buildings. However, an inclusive and\nsystematic review of BAS vulnerabilities, potential cyber-attacks with impact\nassessment, detection & defense approaches, and cyber-secure resilient control\nstrategies is currently lacking in the literature. This review paper fills the\ngap by providing a comprehensive up-to-date review of cyber-physical security\nfor BASs at three levels in commercial buildings: management level, automation\nlevel, and field level. The general BASs vulnerabilities and protocol-specific\nvulnerabilities for the four dominant BAS protocols are reviewed, followed by a\ndiscussion on four attack targets and seven potential attack scenarios. The\nimpact of cyber-attacks on BASs is summarized as signal corruption, signal\ndelaying, and signal blocking. The typical cyber-attack detection and defense\napproaches are identified at the three levels. Cyber-secure resilient control\nstrategies for BASs under attack are categorized into passive and active\nresilient control schemes. Open challenges and future opportunities are finally\ndiscussed.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.14622,regular,pre_llm,2022,10,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'DEMIS: A Threat Model for Selectively Encrypted Visual Surveillance Data\n\n  The monitoring of individuals/objects has become increasingly possible in\nrecent years due to the convenience of integrated cameras in many devices. Due\nto the important moments or activities of people captured by these devices, it\nhas made it a great asset for attackers to launch attacks against by exploiting\nthe weaknesses in these devices. Different studies proposed na\\""ive/selective\nencryption of the captured visual data for safety but despite the encryption,\nan attacker can still access or manipulate such data. This paper proposed a\nnovel threat model, DEMIS which helps analyse the threats against such\nencrypted videos. The paper also examines the attack vectors that can be used\nfor threats and the mitigation that will reduce or prevent the attack. For\nexperiments, firstly the data set is generated by applying selective encryption\non the Regions-of-interests (ROI) of the tested videos using the image\nsegmentation technique and Chacha20 cipher. Secondly, different types of\nattacks, such as inverse, lowercase, uppercase, random insertion, and\nmalleability attacks were simulated in experiments to show the effects of the\nattacks, the risk matrix, and the severity of these attacks. Our developed data\nset with the original, selective encrypted, and attacked videos are available\non git-repository(https://github.com/Ifeoluwapoo/video-datasets) for future\nresearchers.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.14833,regular,pre_llm,2022,10,"{'ai_likelihood': 3.973642985026042e-07, 'text': 'Ballot stuffing and participation privacy in pollsite voting\n\n  We study the problem of simultaneously addressing both ballot stuffing and\nparticipation privacy for pollsite voting systems. Ballot stuffing is the\nattack where fake ballots (not cast by any eligible voter) are inserted into\nthe system. Participation privacy is about hiding which eligible voters have\nactually cast their vote. So far, the combination of ballot stuffing and\nparticipation privacy has been mostly studied for internet voting, where voters\nare assumed to own trusted computing devices. Such approaches are inapplicable\nto pollsite voting where voters typically vote bare handed. We present an\neligibility audit protocol to detect ballot stuffing in pollsite voting\nprotocols. This is done while protecting participation privacy from a remote\nobserver - one who does not physically observe voters during voting. Our\nprotocol can be instantiated as an additional layer on top of most existing\npollsite E2E-V voting protocols. To achieve our guarantees, we develop an\nefficient zero-knowledge proof (ZKP), that, given a value $v$ and a set $\\Phi$\nof commitments, proves $v$ is committed by some commitment in $\\Phi$, without\nrevealing which one. We call this a ZKP of reverse set membership because of\nits relationship to the popular ZKPs of set membership. This ZKP may be of\nindependent interest.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.05226,regular,pre_llm,2022,10,"{'ai_likelihood': 1.3245476616753472e-06, 'text': 'Detecting Hidden Attackers in Photovoltaic Systems Using Machine\n  Learning\n\n  In modern smart grids, the proliferation of communication-enabled distributed\nenergy resource (DER) systems has increased the surface of possible\ncyber-physical attacks. Attacks originating from the distributed edge devices\nof DER system, such as photovoltaic (PV) system, is often difficult to detect.\nAn attacker may change the control configurations or various setpoints of the\nPV inverters to destabilize the power grid, damage devices, or for the purpose\nof economic gain. A more powerful attacker may even manipulate the PV system\nmetering data transmitted for remote monitoring, so that (s)he can remain\nhidden. In this paper, we consider a case where PV systems operating in\ndifferent control modes can be simultaneously attacked and the attacker has the\nability to manipulate individual PV bus measurements to avoid detection. We\nshow that even in such a scenario, with just the aggregated measurements (that\nthe attacker cannot manipulate), machine learning (ML) techniques are able to\ndetect the attack in a fast and accurate manner. We use a standard radial\ndistribution network, together with real smart home electricity consumption\ndata and solar power data in our experimental setup. We test the performance of\nseveral ML algorithms to detect attacks on the PV system. Our detailed\nevaluations show that the proposed intrusion detection system (IDS) is highly\neffective and efficient in detecting attacks on PV inverter control modes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.02337,review,pre_llm,2022,10,"{'ai_likelihood': 5.529986487494575e-06, 'text': 'When Physical Layer Key Generation Meets RIS: Opportunities, Challenges,\n  and Road Ahead\n\n  Physical layer key generation (PLKG) is a promising technology to obtain\nsymmetric keys between a pair of wireless communication users in a\nplug-and-play manner. The shared entropy source almost entirely comes from the\nintrinsic randomness of the radio channel, which is highly dependent on the\nwireless environments. However, in some static/block fading wireless\nenvironments, the intrinsic randomness of the wireless channel is hard to be\nguaranteed. Very recently, thanks to reconfigurable intelligent surfaces (RISs)\nwith their excellent ability on electromagnetic wave control, the wireless\nchannel environment can be customized. In this article, we overview the\nRISaided PLKG in static indoor environments, including its channel model and\nhardware architectures. Then, we propose potential application scenarios and\nanalyze the design challenges of RIS aided PLKG, including channel reciprocity,\nRIS reconfiguration speed and RIS deployment via proof-of-concept experiments\non a RIS-aided PLKG prototype system. In particular, our experimental results\nshow that the key generation rate is 15-fold higher than that without RIS in a\nstatic indoor environment. Next, we design a RIS jamming attack via a prototype\nexperiment and discuss its possible attack-defense countermeasures. Finally,\nseveral conclusions and future directions are identified.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.00581,regular,pre_llm,2022,10,"{'ai_likelihood': 4.470348358154297e-06, 'text': ""PrivTrace: Differentially Private Trajectory Synthesis by Adaptive\n  Markov Model\n\n  Publishing trajectory data (individual's movement information) is very\nuseful, but it also raises privacy concerns. To handle the privacy concern, in\nthis paper, we apply differential privacy, the standard technique for data\nprivacy, together with Markov chain model, to generate synthetic trajectories.\nWe notice that existing studies all use Markov chain model and thus propose a\nframework to analyze the usage of the Markov chain model in this problem. Based\non the analysis, we come up with an effective algorithm PrivTrace that uses the\nfirst-order and second-order Markov model adaptively. We evaluate PrivTrace and\nexisting methods on synthetic and real-world datasets to demonstrate the\nsuperiority of our method.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.04064,regular,pre_llm,2022,10,"{'ai_likelihood': 6.291601392957899e-07, 'text': 'Study and security analysis of the Spanish identity card\n\n  The National Identity Document is a fundamental piece of documentation for\nthe identification of citizens throughout the world. That is precisely the case\nof the DNI (Documento Nacional de Identidad) of Spain. Its importance has been\nenhanced in recent years with the addition of a chip for the authentication of\nusers within telematic administrative services. Thus, the document has since\nbeen called: electronic DNI or simply DNIe. Sensitive user information is\nstored in that integrated circuit, such as personal and biometric data, along\nwith signature and authentication certificates. Some of the functionalities of\nthe DNIe in its current version at the time of writing this work have been\nimplemented for years in the DNI 3.0 version launched in 2015, and therefore\nhave already been extensively studied. This work provides a theoretical and\npractical compilation study of some of the security mechanisms included in the\ncurrent DNIe and in some of the applications that require its use. It has been\ncarried out using only mobile devices and generic card readers, without having\nany type of privileged access to hardware, software or specific documentation\nfor the interception of packets between the DNIe and the destination\napplication. In other words, it is an exploratory analysis carried out with the\nintention of confirming with basic tools the level of robustness of this very\nimportant security token.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.0994,regular,pre_llm,2022,10,"{'ai_likelihood': 2.7484363979763457e-06, 'text': 'Automatic Detection of Fake Key Attacks in Secure Messaging\n\n  Popular instant messaging applications such as WhatsApp and Signal provide\nend-to-end encryption for billions of users. They rely on a centralized,\napplication-specific server to distribute public keys and relay encrypted\nmessages between the users. Therefore, they prevent passive attacks but are\nvulnerable to some active attacks. A malicious or hacked server can distribute\nfake keys to users to perform man-in-the-middle or impersonation attacks. While\ntypical secure messaging applications provide a manual method for users to\ndetect these attacks, this burdens users, and studies show it is ineffective in\npractice. This paper presents KTACA, a completely automated approach for key\nverification that is oblivious to users and easy to deploy. We motivate KTACA\nby designing two approaches to automatic key verification. One approach uses\nclient auditing (KTCA) and the second uses anonymous key monitoring (AKM). Both\nhave relatively inferior security properties, leading to KTACA, which combines\nthese approaches to provide the best of both worlds. We provide a security\nanalysis of each defense, identifying which attacks they can automatically\ndetect. We implement the active attacks to demonstrate they are possible, and\nwe also create a prototype implementation of all the defenses to measure their\nperformance and confirm their feasibility. Finally, we discuss the strengths\nand weaknesses of each defense, the overhead on clients and service providers,\nand deployment considerations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.1661,review,pre_llm,2022,10,"{'ai_likelihood': 8.940696716308594e-07, 'text': 'Optimistic and Validity Rollups: Analysis and Comparison between\n  Optimism and StarkNet\n\n  The thesis addresses the problem of scalability in decentralized blockchains\nin the context of the trade-off between transaction throughput and hardware\nrequirements to participate in the network. Rollups are presented, that is\ntechnologies to verify on-chain blocks executed off-chain by minimizing the\nassumptions of trust. The variant of the Optimistic Rollups, in particular of\nOptimism and the use of invalidity proofs through interactive binary search and\nof the Validity Rollups, in particular of StarkNet, and the use of validity\nproofs through STARKs are discussed. Finally, the two solutions are compared on\nwithdrawal time, on the cost of transactions and techniques to minimize it, on\nthe possibility of applying the technology recursively, on compatibility with\nEthereum and on the licenses used.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.09108,regular,pre_llm,2022,10,"{'ai_likelihood': 1.655684577094184e-06, 'text': 'Detect and Classify IoT Camera Traffic\n\n  Deployment of IoT cameras in an organization threatens security and privacy\npolicies, and the classification of network traffic without using IP addresses\nand port numbers has been challenging. In this paper, we have designed,\nimplemented and deployed a system called iCamInspector to classify network\ntraffic arising from IoT camera in a mixed networking environment. We have\ncollected a total of about 36GB of network traffic containing video data from\nthree different types of applications (four online audio/video conferencing\napplications, two video sharing applications and six IoT camera from different\nmanufacturers) in our IoT laboratory. We show that with the help of a limited\nnumber of flow-based features, iCamInspector achieves an average accuracy of\nmore than 98% in a 10-fold cross-validation with a false rate of about 1.5% in\ntesting phase of the system. A real deployment of our system in an unseen\nenvironment achieves a commendable performance of detecting IoT camera with an\naverage detection probability higher than 0.9.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.09269,review,pre_llm,2022,10,"{'ai_likelihood': 2.980232238769531e-07, 'text': 'Identification, Amplification and Measurement: A bridge to Gaussian\n  Differential Privacy\n\n  Gaussian differential privacy (GDP) is a single-parameter family of privacy\nnotions that provides coherent guarantees to avoid the exposure of sensitive\nindividual information. Despite the extra interpretability and tighter bounds\nunder composition GDP provides, many widely used mechanisms (e.g., the Laplace\nmechanism) inherently provide GDP guarantees but often fail to take advantage\nof this new framework because their privacy guarantees were derived under a\ndifferent background. In this paper, we study the asymptotic properties of\nprivacy profiles and develop a simple criterion to identify algorithms with GDP\nproperties. We propose an efficient method for GDP algorithms to narrow down\npossible values of an optimal privacy measurement, $\\mu$ with an arbitrarily\nsmall and quantifiable margin of error. For non GDP algorithms, we provide a\npost-processing procedure that can amplify existing privacy guarantees to meet\nthe GDP condition. As applications, we compare two single-parameter families of\nprivacy notions, $\\epsilon$-DP, and $\\mu$-GDP, and show that all $\\epsilon$-DP\nalgorithms are intrinsically also GDP. Lastly, we show that the combination of\nour measurement process and the composition theorem of GDP is a powerful and\nconvenient tool to handle compositions compared to the traditional standard and\nadvanced composition theorems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.1739,regular,pre_llm,2022,10,"{'ai_likelihood': 2.7020772298177086e-05, 'text': 'Latent Semantic Structure in Malicious Programs\n\n  Latent Semantic Analysis is a method of matrix decomposition used for\ndiscovering topics and topic weights in natural language documents. This study\nuses Latent Semantic Analysis to analyze the composition of binaries of\nmalicious programs. The semantic representation of the term frequency vector\nrepresentation yields a set of topics, each topic being a composition of terms.\nThe vectors and topics were evaluated quantitatively using a spatial\nrepresentation. This semantic analysis provides a more abstract representation\nof the program derived from its term frequency analysis. We use a metric space\nto represent a program as a collection of vectors, and a distance metric to\nevaluate their similarity within a topic. The segmentation of the vectors in\nthis dataset provides increased resolution into the program structure.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.09373,regular,pre_llm,2022,10,"{'ai_likelihood': 1.8278757731119793e-05, 'text': ""A Systematic Study of the Consistency of Two-Factor Authentication User\n  Journeys on Top-Ranked Websites (Extended Version)\n\n  Heuristics for user experience state that users will transfer their\nexpectations from one product to another. A lack of consistency between\nproducts can increase users' cognitive friction, leading to frustration and\nrejection. This paper presents the first systematic study of the external,\nfunctional consistency of two-factor authentication user journeys on top-ranked\nwebsites. We find that these websites implement only a minimal number of design\naspects consistently (e.g., naming and location of settings) but exhibit mixed\ndesign patterns for setup and usage of a second factor. Moreover, we find that\nsome of the more consistently realized aspects, such as descriptions of\ntwo-factor authentication, have been described in the literature as problematic\nand adverse to user experience. Our results advocate for more general UX\nguidelines for 2FA implementers and raise new research questions about the 2FA\nuser journeys.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.01988,regular,pre_llm,2022,10,"{'ai_likelihood': 6.622738308376736e-07, 'text': 'Bicoptor: Two-round Secure Three-party Non-linear Computation without\n  Preprocessing for Privacy-preserving Machine Learning\n\n  The overhead of non-linear functions dominates the performance of the secure\nmultiparty computation (MPC) based privacy-preserving machine learning (PPML).\nThis work introduces a family of novel secure three-party computation (3PC)\nprotocols, Bicoptor, which improve the efficiency of evaluating non-linear\nfunctions. The basis of Bicoptor is a new sign determination protocol, which\nrelies on a clever use of the truncation protocol proposed in SecureML (S\\&P\n2017). Our 3PC sign determination protocol only requires two communication\nrounds, and does not involve any preprocessing. Such sign determination\nprotocol is well-suited for computing non-linear functions in PPML, e.g. the\nactivation function ReLU, Maxpool, and their variants. We develop suitable\nprotocols for these non-linear functions, which form a family of GPU-friendly\nprotocols, Bicoptor. All Bicoptor protocols only require two communication\nrounds without preprocessing. We evaluate Bicoptor under a 3-party LAN network\nover a public cloud, and achieve more than 370,000 DReLU/ReLU or 41,000 Maxpool\n(find the maximum value of nine inputs) operations per second. Under the same\nsettings and environment, our ReLU protocol has a one or even two orders of\nmagnitude improvement to the state-of-the-art works, Falcon (PETS 2021) or\nEdabits (CRYPTO 2020), respectively without batch processing.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.10244,regular,pre_llm,2022,10,"{'ai_likelihood': 1.158979203965929e-06, 'text': 'Prove You Owned Me: One Step beyond RFID Tag/Mutual Authentication\n\n  Radio Frequency Identification (RFID) is a key technology used in many\napplications. In the past decades, plenty of secure and privacy-preserving RFID\ntag/mutual authentication protocols as well as formal frameworks for evaluating\nthem have been proposed. However, we notice that a property, namely proof of\npossession (PoP), has not been rigorously studied till now, despite it has\nsignificant value in many RFID applications. For example, in RFID-enabled\nsupply chains, PoP helps prevent dis-honest parties from publishing information\nabout products/tags that they actually have never processed.\n  We propose the first formal framework for RFID tag/mutual authentication with\nPoP after correcting deficiencies of some existing RFID formal frameworks. We\nprovide a generic construction to transform an RFID tag/mutual authentication\nprotocol to one that supports PoP using a cryptographic hash function, a\npseudorandom function (PRF) and a signature scheme. We prove that the\nconstructed protocol is secure and privacy-preserving under our framework if\nall the building blocks possess desired security properties. Finally, we show\nan RFID mutual authentication protocol with PoP. Arming tag/mutual\nauthentication protocols with PoP is an important step to strengthen\nRFID-enabled systems as it bridges the security gap between physical layer and\ndata layer, and reduces the misuses of RFID-related data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.14692,review,pre_llm,2022,10,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Identifying Threats, Cybercrime and Digital Forensic Opportunities in\n  Smart City Infrastructure via Threat Modeling\n\n  Technological advances have enabled multiple countries to consider\nimplementing Smart City Infrastructure to provide in-depth insights into\ndifferent data points and enhance the lives of citizens. Unfortunately, these\nnew technological implementations also entice adversaries and cybercriminals to\nexecute cyber-attacks and commit criminal acts on these modern infrastructures.\nGiven the borderless nature of cyber attacks, varying levels of understanding\nof smart city infrastructure and ongoing investigation workloads, law\nenforcement agencies and investigators would be hard-pressed to respond to\nthese kinds of cybercrime. Without an investigative capability by\ninvestigators, these smart infrastructures could become new targets favored by\ncybercriminals.\n  To address the challenges faced by investigators, we propose a common\ndefinition of smart city infrastructure. Based on the definition, we utilize\nthe STRIDE threat modeling methodology and the Microsoft Threat Modeling Tool\nto identify threats present in the infrastructure and create a threat model\nwhich can be further customized or extended by interested parties. Next, we map\noffences, possible evidence sources and types of threats identified to help\ninvestigators understand what crimes could have been committed and what\nevidence would be required in their investigation work. Finally, noting that\nSmart City Infrastructure investigations would be a global multi-faceted\nchallenge, we discuss technical and legal opportunities in digital forensics on\nSmart City Infrastructure.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.10294,regular,pre_llm,2022,10,"{'ai_likelihood': 1.755025651719835e-05, 'text': 'Secure and Efficient Multi-Signature Schemes for Fabric: An Enterprise\n  Blockchain Platform\n\n  Digital signature is a major component of transactions on Blockchain\nplatforms, especially in enterprise Blockchain platforms, where multiple\nsignatures from a set of peers need to be produced to endorse a transaction.\nHowever, such process is often complex and time-consuming. Multi-signature,\nwhich can improve transaction efficiency by having a set of signers cooperate\nto produce a joint signature, has attracted extensive attentions. In this work,\nwe propose two multi-signature schemes, GMS and AGMS, which are proved to be\nmore secure and efficient than state-of-the-art multi-signature schemes.\nBesides, we implement the proposed schemes in a real Enterprise Blockchain\nplatform, Fabric. Experiment results show that the proposed AGMS scheme helps\nachieve the goal of high transaction efficiency, low storage complexity, as\nwell as high robustness against rogue-key attacks and k-sum problem attacks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.04066,regular,pre_llm,2022,10,"{'ai_likelihood': 1.466936535305447e-05, 'text': 'Drowsiness detection in drivers with a smartwatch\n\n  The main objective of this work is to detect early if a driver shows symptoms\nof sleepiness that indicate that he/she is falling asleep and, in that case,\ngenerate an alert to wake him/her up. To solve this problem, an application has\nbeen designed that collects various parameters, through a smartwatch while\ndriving. First, the application detects the driving action. Then, it collects\ninformation about the most significant physiological variables of a person\nwhile driving. On the other hand, given the high level of sensitivity of the\ndata managed in the designed application, in this work special attention has\nbeen paid to the security of the implementation. The proposed solution improves\nroad safety, reducing the number of accidents caused by drowsiness while\ndriving.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.08374,regular,pre_llm,2022,10,"{'ai_likelihood': 4.3047799004448785e-07, 'text': 'Beyond the Surface: Investigating Malicious CVE Proof of Concept\n  Exploits on GitHub\n\n  Exploit proof-of-concepts (PoCs) for known vulnerabilities are widely shared\nin the security community. They help security analysts to learn from each other\nand they facilitate security assessments and red teaming tasks. In the recent\nyears, PoCs have been widely distributed, e.g., via dedicated websites and\nplatforms, and public code repositories such as GitHub. However, there is no\nguarantee that PoCs in public code repositories come from trustworthy sources\nor even that they do what they are supposed to do.\n  In this work we investigate GitHub-hosted PoCs for known vulnerabilities\ndiscovered in 2017--2021. We discovered that not all PoCs are trustworthy. Some\nproof-of-concepts are malicious, e.g., they attempt to exfiltrate data from the\nsystem they are being run on, or they try to install malware on this system,\nand in some cases they have hard-coded reverse shell listener.\n  To measure the prevalence of this threat, we propose an approach to detecting\nmalicious PoCs. Our approach relies on the maliciousness symptoms we have\nobserved in our PoC dataset: calls to malicious IP addresses, encoded malicious\ncode, and included Trojanized binaries. With this approach, we have discovered\n899 malicious repositories out of 47,285 repositories that have been downloaded\nand checked (i.e., 1.9% of the studied repositories have indicators of\nmalicious intent). This figure shows a worrying prevalence of dangerous\nmalicious PoCs among the exploit code distributed on GitHub.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2210.14067,regular,pre_llm,2022,10,"{'ai_likelihood': 0.3190104166666667, 'text': 'Reducing Information Overload: Because Even Security Experts Need to\n  Blink\n\n  Computer Emergency Response Teams (CERTs) face increasing challenges\nprocessing the growing volume of security-related information. Daily manual\nanalysis of threat reports, security advisories, and vulnerability\nannouncements leads to information overload, contributing to burnout and\nattrition among security professionals. This work evaluates 196 combinations of\nclustering algorithms and embedding models across five security-related\ndatasets to identify optimal approaches for automated information\nconsolidation. We demonstrate that clustering can reduce information processing\nrequirements by over 90% while maintaining semantic coherence, with deep\nclustering achieving homogeneity of 0.88 for security bug report (SBR) and\npartition-based clustering reaching 0.51 for advisory data. Our solution\nrequires minimal configuration, preserves all data points, and processes new\ninformation within five minutes on consumer hardware. The findings suggest that\nclustering approaches can significantly enhance CERT operational efficiency,\npotentially saving over 3.750 work hours annually per analyst while maintaining\nanalytical integrity. However, complex threat reports require careful parameter\ntuning to achieve acceptable performance, indicating areas for future\noptimization. The code is made available at\nhttps://github.com/PEASEC/reducing-information-overload.\n', 'prediction': 'Possibly AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.01,regular,pre_llm,2022,11,"{'ai_likelihood': 5.298190646701389e-07, 'text': 'SoK: Play-to-Earn Projects\n\n  Play-to-earn is one of the prospective categories of decentralized\napplications. The play-to-earn projects combine blockchain technology with\nentertaining games and finance, attracting various participants. While huge\namounts of capital have been poured into these projects, the new crypto niche\nis considered controversial, and the traditional gaming industry is hesitant to\nembrace blockchain technology. In addition, there is little systematic research\non these projects. In this paper, we delineate play-to-earn projects in terms\nof economic & governance models and implementation and analyze how blockchain\ntechnology can benefit these projects by providing system robustness,\ntransparency, composability, and decentralized governance. We begin by\nidentifying the participants and characterizing the tokens, which are products\nof composability. We then summarize the roadmap and governance model to exposit\nthere is a transition from centralized governance to decentralized governance.\nWe also classify the implementation of the play-to-earn projects with different\nextents of robustness and transparency. Finally, we discuss the security &\nsocietal challenges for future research in terms of possible attacks, the\neconomics of tokens, and governance.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.06735,regular,pre_llm,2022,11,"{'ai_likelihood': 2.1523899502224394e-06, 'text': ""CompactChain:An Efficient Stateless Chain for UTXO-model Blockchain\n\n  In this work, we propose a stateless blockchain called CompactChain, which\ncompacts the entire state of the UTXO (Unspent Transaction Output) based\nblockchain systems into two RSA accumulators. The first accumulator is called\nTransaction Output (TXO) commitment which represents the TXO set. The second\none is called Spent Transaction Output (STXO) commitment which represents the\nSTXO set. In this work, we discuss three algorithms - (i) To update the TXO and\nSTXO commitments by the miner. The miner also provides the proofs for the\ncorrectness of the updated commitments; (ii) To prove the transaction's\nvalidity by providing a membership witness in TXO commitment and non-membership\nwitness against STXO commitment for a coin being spent by a user; (iii) To\nupdate the witness for the coin that is not yet spent; The experimental results\nevaluate the performance of the CompactChain in terms of time taken by a miner\nto update the commitments and time taken by a validator to verify the\ncommitments and validate the transactions. We compare the performance of\nCompactChain with the existing state-of-art works on stateless blockchains.\nCompactChain shows a reduction in commitments update complexity and transaction\nwitness size which inturn reduces the mempool size and propagation latency\nwithout compromising the system throughput (Transactions per second (TPS)).\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.08916,review,pre_llm,2022,11,"{'ai_likelihood': 1.953707800971137e-06, 'text': 'Privacy Engineering in the Wild: Understanding the Practitioners\'\n  Mindset, Organisational Aspects, and Current Practices\n\n  Privacy engineering, as an emerging field of research and practice, comprises\nthe technical capabilities and management processes needed to implement,\ndeploy, and operate privacy features and controls in working systems. For that,\nsoftware practitioners and other stakeholders in software companies need to\nwork cooperatively toward building privacy-preserving businesses and\nengineering solutions. Significant research has been done to understand the\nsoftware practitioners\' perceptions of information privacy, but more emphasis\nshould be given to the uptake of concrete privacy engineering components. This\nresearch delves into the software practitioners\' perspectives and mindset,\norganisational aspects, and current practices on privacy and its engineering\nprocesses. A total of 30 practitioners from nine countries and backgrounds were\ninterviewed, sharing their experiences and voicing their opinions on a broad\nrange of privacy topics. The thematic analysis methodology was adopted to code\nthe interview data qualitatively and construct a rich and nuanced thematic\nframework. As a result, we identified three critical interconnected themes that\ncompose our thematic framework for privacy engineering ""in the wild"": (1)\npersonal privacy mindset and stance, categorised into practitioners\' privacy\nknowledge, attitudes and behaviours; (2) organisational privacy aspects, such\nas decision-power and positive and negative examples of privacy climate; and,\n(3) privacy engineering practices, such as procedures and controls concretely\nused in the industry. Among the main findings, this study provides many\ninsights about the state-of-the-practice of privacy engineering, pointing to a\npositive influence of privacy laws (e.g., EU General Data Protection\nRegulation) on practitioners\' behaviours and organisations\' cultures. Aspects\nsuch as organisational privacy culture and climate were also confirmed to have\n[...].\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.00128,review,pre_llm,2022,11,"{'ai_likelihood': 1.9205941094292534e-06, 'text': 'An Optimized Privacy-Utility Trade-off Framework for Differentially\n  Private Data Sharing in Blockchain-based Internet of Things\n\n  Differential private (DP) query and response mechanisms have been widely\nadopted in various applications based on Internet of Things (IoT) to leverage\nvariety of benefits through data analysis. The protection of sensitive\ninformation is achieved through the addition of noise into the query response\nwhich hides the individual records in a dataset. However, the noise addition\nnegatively impacts the accuracy which gives rise to privacy-utility trade-off.\nMoreover, the DP budget or cost $\\epsilon$ is often fixed and it accumulates\ndue to the sequential composition which limits the number of queries.\nTherefore, in this paper, we propose a framework known as optimized\nprivacy-utility trade-off framework for data sharing in IoT (OPU-TF-IoT).\nFirstly, OPU-TF-IoT uses an adaptive approach to utilize the DP budget\n$\\epsilon$ by considering a new metric of population or dataset size along with\nthe query. Secondly, our proposed heuristic search algorithm reduces the DP\nbudget accordingly whereas satisfying both data owner and data user. Thirdly,\nto make the utilization of DP budget transparent to the data owners, a\nblockchain-based verification mechanism is also proposed. Finally, the proposed\nframework is evaluated using real-world datasets and compared with the\ntraditional DP model and other related state-of-the-art works. The results\nconfirm that our proposed framework not only utilize the DP budget $\\epsilon$\nefficiently, but it also optimizes the number of queries. Furthermore, the data\nowners can effectively make sure that their data is shared accordingly through\nour blockchain-based verification mechanism which encourages them to share\ntheir data into the IoT system.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.10076,regular,pre_llm,2022,11,"{'ai_likelihood': 1.0927518208821616e-06, 'text': 'Applications of Quantum Annealing in Cryptography\n\n  This paper presents a new method to reduce the optimization of a\npseudo-Boolean function to QUBO problem which can be solved by quantum\nannealer. The new method has two aspects, one is coefficient optimization and\nthe other is variable optimization. The former is an improvement on the\nexisting algorithm in a special case. The latter is realized by means of the\nmaximal independent point set in graph theory. We apply this new method in\ninteger factorization on quantum annealers and achieve the largest integer\nfactorization (4137131) with 93 variables, the range of coefficients is\n[-1024,1024] which is much smaller than the previous results. We also focus on\nthe quantum attacks on block ciphers and present an efficient method with\nsmaller coefficients to transform Boolean equation systems into QUBO problems.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.06153,regular,pre_llm,2022,11,"{'ai_likelihood': 2.715322706434462e-06, 'text': 'SUNDEW: An Ensemble of Predictors for Case-Sensitive Detection of\n  Malware\n\n  Malware programs are diverse, with varying objectives, functionalities, and\nthreat levels ranging from mere pop-ups to financial losses. Consequently,\ntheir run-time footprints across the system differ, impacting the optimal data\nsource (Network, Operating system (OS), Hardware) and features that are\ninstrumental to malware detection. Further, the variations in threat levels of\nmalware classes affect the user requirements for detection. Thus, the optimal\ntuple of <data-source, features, user-requirements> is different for each\nmalware class, impacting the state-of-the-art detection solutions that are\nagnostic to these subtle differences.\n  This paper presents SUNDEW, a framework to detect malware classes using their\noptimal tuple of <data-source, features, user-requirements>. SUNDEW uses an\nensemble of specialized predictors, each trained with a particular data source\n(network, OS, and hardware) and tuned for features and requirements of a\nspecific class. While the specialized ensemble with a holistic view across the\nsystem improves detection, aggregating the independent conflicting inferences\nfrom the different predictors is challenging. SUNDEW resolves such conflicts\nwith a hierarchical aggregation considering the threat-level, noise in the data\nsources, and prior domain knowledge. We evaluate SUNDEW on a real-world dataset\nof over 10,000 malware samples from 8 classes. It achieves an F1-Score of one\nfor most classes, with an average of 0.93 and a limited performance overhead of\n1.5%.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.10974,regular,pre_llm,2022,11,"{'ai_likelihood': 1.1920928955078125e-06, 'text': 'Investigating the Cybersecurity of Smart Grids Based on Cyber-Physical\n  Twin Approach\n\n  While the increasing penetration of information and communication technology\ninto distribution grid brings numerous benefits, it also opens up a new threat\nlandscape, particularly through cyberattacks. To provide a basis for\ncountermeasures against such threats, this paper addresses the investigation of\nthe impact and manifestations of cyberattacks on smart grids by replicating the\npower grid in a secure, isolated, and controlled laboratory environment as a\ncyber-physical twin. Currently, detecting intrusions by unauthorized third\nparties into the central monitoring and control system of grid operators,\nespecially attacks within the grid perimeter, is a major challenge. The\ndevelopment and validation of methods to detect and prevent coordinated and\ntimed attacks on electric power systems depends not only on the availability\nand quality of data from such attack scenarios, but also on suitable realistic\ninvestigation environments. However, to create a comprehensive investigation\nenvironment, a realistic representation of the study object is required to\nthoroughly investigate critical cyberattacks on grid operations and evaluate\ntheir impact on the power grid using real data. In this paper, we demonstrate\nour cyber-physical twin approach using a microgrid in the context of a\ncyberattack case study.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.07161,review,pre_llm,2022,11,"{'ai_likelihood': 2.6490953233506946e-07, 'text': 'Is FIDO2 Passwordless Authentication a Hype or for Real?: A Position\n  Paper\n\n  Operating system and browser support that comes with the FIDO2 standard and\nthe biometric user verification options increasingly available on smart phones\nhas excited everyone, especially big tech companies, about the passwordless\nfuture. Does a dream come true, are we finally totally getting rid of\npasswords? In this position paper, we argue that although passwordless\nauthentication may be preferable in certain situations, it will be still not\npossible to eliminate passwords on the web in the foreseeable future. We defend\nour position with five main reasons, supported either by the results from the\nrecent literature or by our own technical and business experience. We believe\nour discussion could also serve as a research agenda comprising promising\nfuture work directions on (passwordless) user authentication.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.17073,review,pre_llm,2022,11,"{'ai_likelihood': 4.7021441989474825e-06, 'text': 'Risks to Zero Trust in a Federated Mission Partner Environment\n\n  Recent cybersecurity events have prompted the federal government to begin\ninvestigating strategies to transition to Zero Trust Architectures (ZTA) for\nfederal information systems. Within federated mission networks, ZTA provides\nmeasures to minimize the potential for unauthorized release and disclosure of\ninformation outside bilateral and multilateral agreements. When federating with\nmission partners, there are potential risks that may undermine the benefits of\nZero Trust. This paper explores risks associated with integrating multiple\nidentity models and proposes two potential avenues to investigate in order to\nmitigate these risks.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.1386,regular,pre_llm,2022,11,"{'ai_likelihood': 7.417466905381945e-06, 'text': 'Fast and Efficient Malware Detection with Joint Static and Dynamic\n  Features Through Transfer Learning\n\n  In malware detection, dynamic analysis extracts the runtime behavior of\nmalware samples in a controlled environment and static analysis extracts\nfeatures using reverse engineering tools. While the former faces the challenges\nof anti-virtualization and evasive behavior of malware samples, the latter\nfaces the challenges of code obfuscation. To tackle these drawbacks, prior\nworks proposed to develop detection models by aggregating dynamic and static\nfeatures, thus leveraging the advantages of both approaches. However, simply\nconcatenating dynamic and static features raises an issue of imbalanced\ncontribution due to the heterogeneous dimensions of feature vectors to the\nperformance of malware detection models. Yet, dynamic analysis is a\ntime-consuming task and requires a secure environment, leading to detection\ndelays and high costs for maintaining the analysis infrastructure. In this\npaper, we first introduce a method of constructing aggregated features via\nconcatenating latent features learned through deep learning with\nequally-contributed dimensions. We then develop a knowledge distillation\ntechnique to transfer knowledge learned from aggregated features by a teacher\nmodel to a student model trained only on static features and use the trained\nstudent model for the detection of new malware samples. We carry out extensive\nexperiments with a dataset of 86709 samples including both benign and malware\nsamples. The experimental results show that the teacher model trained on\naggregated features constructed by our method outperforms the state-of-the-art\nmodels with an improvement of up to 2.38% in detection accuracy. The distilled\nstudent model not only achieves high performance (97.81% in terms of accuracy)\nas that of the teacher model but also significantly reduces the detection time\n(from 70046.6 ms to 194.9 ms) without requiring dynamic analysis.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.15993,regular,pre_llm,2022,11,"{'ai_likelihood': 1.655684577094184e-07, 'text': 'An Empirical Study on Snapshot DAOs\n\n  Decentralized Autonomous Organization (DAO) is an organization constructed by\nautomatically executed rules such as via smart contracts, holding features of\nthe permissionless committee, transparent proposals, and fair contribution by\nstakeholders. As of Nov 2022, DAO has impacted over \\$11.2B market caps.\nHowever, there are no substantial studies focused on this emerging field. To\nfill the gap, we start from the ground truth by empirically studying the\nbreadth and depth of the DAO markets in mainstream public chain ecosystems in\nthis paper. We dive into the most widely adoptable DAO launchpad,\n\\textit{Snapshot}, which covers 95\\% in the wild DAO projects for data\ncollection and analysis. By integrating extensive enrolled DAOs and\ncorresponding data measurements, we explore statistical data from Snapshot and\ntry to demystify its undiscovered truths by delivering a series of summarised\ninsights. We also present DAO status, patterns, distribution, and trends. To\nour knowledge, this is the first empirical study putting concentration on DAO\nspaces.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.0564,review,pre_llm,2022,11,"{'ai_likelihood': 2.682209014892578e-06, 'text': 'UAV Traffic Management : A Survey On Communication Security\n\n  Unmanned Aerial Systems (UAS) have a wide variety of applications, and their\ndevelopment in terms of capabilities is continuously evolving. Many missions\nperformed by an Unmanned Aerial Vehicle (UAV) require flying in public\nairspace. This requires very high safety standards, similar to those mandatory\nin commercial civil aviation. A safe UAV Traffic Management (UTM) requires\nseveral communication links between aircraft, their pilots and UTM systems. The\nintegrity of these communication links is critical for the safety of\noperations. Several security requirements also have to be met on each of these\nlinks. Unfortunately, current cryptographic standards used over the internet\nare most often not suitable to UAS due to their limited resources and dynamic\nnature. This survey discusses the security required for every communication\nlink in order to enable a safe traffic management. Research works focusing on\nthe security of communication links using cryptographic primitives are then\npresented and discussed. Authentication protocols developed for UAVs or other\nconstrained systems are compared and evaluated as solutions for UAS security.\nSymmetrical alternatives to the AES algorithm are also presented. Works to\nsecure current UTM protocols such as ADS-B and RemoteID are discussed. The\nanalysis reveals a need for the development of a complete secure architecture\nable to provide authentication and integrity to external systems (other\naircraft, UTM systems...).\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.065,review,pre_llm,2022,11,"{'ai_likelihood': 1.655684577094184e-07, 'text': 'An investigation of security controls and MITRE ATT\\&CK techniques\n\n  Attackers utilize a plethora of adversarial techniques in cyberattacks to\ncompromise the confidentiality, integrity, and availability of the target\norganizations and systems. Information security standards such as NIST, ISO/IEC\nspecify hundreds of security controls that organizations can enforce to protect\nand defend the information systems from adversarial techniques. However,\nimplementing all the available controls at the same time can be infeasible and\nsecurity controls need to be investigated in terms of their mitigation ability\nover adversarial techniques used in cyberattacks as well. The goal of this\nresearch is to aid organizations in making informed choices on security\ncontrols to defend against cyberthreats through an investigation of adversarial\ntechniques used in current cyberattacks. In this study, we investigated the\nextent of mitigation of 298 NIST SP800-53 controls over 188 adversarial\ntechniques used in 669 cybercrime groups and malware cataloged in the MITRE\nATT\\&CK framework based upon an existing mapping between the controls and\ntechniques. We identify that, based on the mapping, only 101 out of 298 control\nare capable of mitigating adversarial techniques. However, we also identify\nthat 53 adversarial techniques cannot be mitigated by any existing controls,\nand these techniques primarily aid adversaries in bypassing system defense and\ndiscovering targeted system information. We identify a set of 20 critical\ncontrols that can mitigate 134 adversarial techniques, and on average, can\nmitigate 72\\% of all techniques used by 98\\% of the cataloged adversaries in\nMITRE ATT\\&CK. We urge organizations, that do not have any controls enforced in\nplace, to implement the top controls identified in the study.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.03776,review,pre_llm,2022,11,"{'ai_likelihood': 2.086162567138672e-06, 'text': 'Towards 5G Zero Trusted Air Interface Architecture\n\n  5G is destined to be supporting large deployment of Industrial IoT (IIoT)\nwith the characteristics of ultra-high densification and low latency. 5G\nutilizes a more intelligent architecture, with Radio Access Networks (RANs) no\nlonger constrained by base station proximity or proprietary infrastructure. The\n3rd Generation Partnership Project (3GPP) covers telecommunication technologies\nincluding RAN, core transport networks and service capabilities. Open RAN\nAlliance (O-RAN) aims to define implementation and deployment architectures,\nfocusing on open-source interfaces and functional units to further reduce the\ncost and complexity. O-RAN based 5G networks could use components from\ndifferent hardware and software vendors, promoting vendor diversity,\ninterchangeability and 5G supply chain resiliency. Both 3GPP and O-RAN 5G have\nto manage the security and privacy challenges that arose from the deployment.\nMany existing research studies have addressed the threats and vulnerabilities\nwithin each system. 5G also has the overwhelming challenges in compliance with\nprivacy regulations and requirements which mandate the user identifiable\ninformation need to be protected.\n  In this paper, we look into the 3GPP and O-RAN 5G security and privacy\ndesigns and the identified threats and vulnerabilities. We also discuss how to\nextend the Zero Trust Model to provide advanced protection over 5G air\ninterfaces and network components.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.03613,regular,pre_llm,2022,11,"{'ai_likelihood': 4.503462049696181e-06, 'text': ""Towards Devising A Fund Management System Using Blockchain\n\n  State government operations comprise a large number of transactions for\ndifferent processes that must be carried out across the state. This comprises\nnew projects, maintenance and repairs, public employee compensation, and\nagricultural schemes. Low-level corruption, which is sometimes difficult to\ntrace and hinders state growth, is a big challenge for the top administration.\nIn order to eradicate corruption and bring transparency, technology can be used\nin an efficient way. An important task to exterminate corruption is to keep\ntrack of all the financial transactions of an undergoing project. This research\nuses blockchain technology to keep track of fund management systems and assure\nthe transparency of any financial statement. This paper proposes to use a\ngateway where all transaction records are updated in the system and visible to\nall stakeholders. We find research gaps in the literature and focus on\nincluding government funds and local currency usage. The proposed model's\nmotive is to generate a funding model that attains two sub-goals: designing a\nfund management methodology in which authorized individuals can receive and\nwithdraw allocated funds in crypto currency, and evaluating a smart contract to\nincorporate the money and identify transparency and tracking. The proposed\nmodel executes every feature of our system in just 8.3786ms on average.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.16304,regular,pre_llm,2022,11,"{'ai_likelihood': 7.318125830756294e-06, 'text': 'Analysis of Anomalous Behavior in Network Systems Using Deep\n  Reinforcement Learning with CNN Architecture\n\n  In order to gain access to networks, different types of intrusion attacks\nhave been designed, and the attackers are working on improving them. Computer\nnetworks have become increasingly important in daily life due to the increasing\nreliance on them. In light of this, it is quite evident that algorithms with\nhigh detection accuracy and reliability are needed for various types of\nattacks. The purpose of this paper is to develop an intrusion detection system\nthat is based on deep reinforcement learning. Based on the Markov decision\nprocess, the proposed system can generate informative representations suitable\nfor classification tasks based on vast data. Reinforcement learning is\nconsidered from two different perspectives, deep Q learning, and double deep Q\nlearning. Different experiments have demonstrated that the proposed systems\nhave an accuracy of $99.17\\%$ over the UNSW-NB15 dataset in both approaches, an\nimprovement over previous methods based on contrastive learning and\nLSTM-Autoencoders. The performance of the model trained on UNSW-NB15 has also\nbeen evaluated on BoT-IoT datasets, resulting in competitive performance.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.13195,regular,pre_llm,2022,11,"{'ai_likelihood': 3.642506069607205e-07, 'text': ""Privacy-Preserving Application-to-Application Authentication Using\n  Dynamic Runtime Behaviors\n\n  Application authentication is typically performed using some form of secret\ncredentials such as cryptographic keys, passwords, or API keys. Since clients\nare responsible for securely storing and managing the keys, this approach is\nvulnerable to attacks on clients. Similarly a centrally managed key store is\nalso susceptible to various attacks and if compromised, can leak credentials.\nTo resolve such issues, we propose an application authentication, where we rely\non unique and distinguishable application's behavior to lock the key during a\nsetup phase and unlock it for authentication. Our system add a fuzzy-extractor\nlayer on top of current credential authentication systems. During a key\nenrollment process, the application's behavioral data collected from various\nsensors in the network are used to hide the credential key. The fuzzy extractor\nreleases the key to the server if the application's behavior during the\nauthentication matches the one collected during the enrollment, with some noise\ntolerance. We designed the system, analyzed its security, and implemented and\nevaluated it using 10 real-life applications deployed in our network. Our\nsecurity analysis shows that the system is secure against client compromise,\nvault compromise, and feature observation. The evaluation shows the scheme can\nachieve 0 percent False Accept Rate with an average False Rejection Rate 14\npercent and takes about 51 ms to successfully authenticate a client. In light\nof these promising results, we expect our system to be of practical use, since\nits deployment requires zero to minimal changes on the server.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.11608,regular,pre_llm,2022,11,"{'ai_likelihood': 1.3245476616753473e-07, 'text': 'Immersion and Invariance-based Coding for Privacy in Remote Anomaly\n  Detection\n\n  We present a framework for the design of coding mechanisms that allow\nremotely operating anomaly detectors in a privacy-preserving manner. We\nconsider the following problem setup. A remote station seeks to identify\nanomalies based on system input-output signals transmitted over communication\nnetworks. However, it is not desired to disclose true data of the system\noperation as it can be used to infer private information. To prevent\nadversaries from eavesdropping on the network or at the remote station itself\nto access private data, we propose a privacy-preserving coding scheme to\ndistort signals before transmission. As a next step, we design a new anomaly\ndetector that runs on distorted signals and produces distorted diagnostics\nsignals, and a decoding scheme that allows extracting true diagnostics data\nfrom distorted signals without error. The proposed scheme is built on the\nsynergy of matrix encryption and system Immersion and Invariance (I&I) tools\nfrom control theory. The idea is to immerse the anomaly detector into a\nhigher-dimensional system (the so-called target system). The dynamics of the\ntarget system is designed such that: the trajectories of the original anomaly\ndetector are immersed/embedded in its trajectories, it works on randomly\nencoded input-output signals, and produces an encoded version of the original\nanomaly detector alarm signals, which are decoded to extract the original alarm\nat the user side. We show that the proposed privacy-preserving scheme provides\nthe same anomaly detection performance as standard Kalman filter-based\nchi-squared anomaly detectors while revealing no information about system data.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.13546,review,pre_llm,2022,11,"{'ai_likelihood': 9.934107462565105e-07, 'text': 'Number Theoretic Transform and Its Applications in Lattice-based\n  Cryptosystems: A Survey\n\n  Number theoretic transform (NTT) is the most efficient method for multiplying\ntwo polynomials of high degree with integer coefficients, due to its series of\nadvantages in terms of algorithm and implementation, and is consequently\nwidely-used and particularly fundamental in the practical implementations of\nlattice-based cryptographic schemes. Especially, recent works have shown that\nNTT can be utilized in those schemes without NTT-friendly rings, and can\noutperform other multiplication algorithms. In this paper, we first review the\nbasic concepts of polynomial multiplication, convolution and NTT. Subsequently,\nwe systematically introduce basic radix-2 fast NTT algorithms in an algebraic\nway via Chinese Remainder Theorem. And then, we elaborate recent advances about\nthe methods to weaken restrictions on parameter conditions of NTT. Furthermore,\nwe systematically introduce how to choose appropriate strategy of NTT\nalgorithms for the various given rings. Later, we introduce the applications of\nNTT in the lattice-based cryptographic schemes of NIST post-quantum\ncryptography standardization competition. Finally, we try to present some\npossible future research directions.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2211.03138,regular,pre_llm,2022,11,"{'ai_likelihood': 2.4172994825575088e-06, 'text': ""Detection Of Insider Attacks In Block Chain Network Using The Trusted\n  Two Way Intrusion Detection System\n\n  For data privacy, system reliability, and security, Blockchain technologies\nhave become more popular in recent years. Despite its usefulness, the\nblockchain is vulnerable to cyber assaults; for example, in January 2019 a 51%\nattack on Ethereum Classic successfully exposed flaws in the platform's\nsecurity. From a statistical point of view, attacks represent a highly unusual\noccurrence that deviates significantly from the norm. Blockchain attack\ndetection may benefit from Deep Learning, a field of study whose aim is to\ndiscover insights, patterns, and anomalies within massive data repositories. In\nthis work, we define an trusted two way intrusion detection system based on a\nHierarchical weighed fuzzy algorithm and self-organized stacked network (SOSN)\ndeep learning model, that is trained exploiting aggregate information extracted\nby monitoring blockchain activities. Here initially the smart contract handles\nthe node authentication. The purpose of authenticating the node is to ensure\nthat only specific nodes can submit and retrieve the information. We implement\nHierarchical weighed fuzzy algorithm to evaluate the trust ability of the\ntransaction nodes. Then the transaction verification step ensures that all\nmalicious transactions or activities on the submitted transaction by\nself-organized stacked network deep learning model. The whole experimentation\nwas carried out under matlab environment. Extensive experimental results\nconfirm that our suggested detection method has better performance over\nimportant indicators such as Precision, Recall, F-Score, overhead.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.05462,regular,pre_llm,2022,12,"{'ai_likelihood': 1.1920928955078125e-06, 'text': 'Cryptanalysis and designing chaos-based irreversible and parallel key\n  expansion module over Galois field\n\n  From the security criteria of irreversibility, parallelizability and\nindependence, we cryptanalyzed the key expansion modules of candidate block\nciphers of AES, the results revealed that there exist some weaknesses inside,\nwhich may be explored by the attacker. Hence, we designed a more secure key\nexpansion module that the round-key can satisfy three criteria above. First, we\nconstructed a non-degenerate 2D chaotic map (2D-{\\pi}eCM) with ergodicity in\nphase space and sufficient large chaotic range. Then based on 2D-{\\pi}eCM and\npolynomial multiplication over Galois field, we designed an irreversible key\nexpansion module, which could transform the initial key of arbitrary length to\ndesired number of independent round keys in parallel. Security and statistical\nresults demonstrated the flexible and effectiveness of the proposed key\nexpansion module.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.03383,review,pre_llm,2022,12,"{'ai_likelihood': 1.4536910586886936e-05, 'text': 'Last Mile of Blockchains: RPC and Node-as-a-service\n\n  While much research focuses on different methods to secure blockchain,\ninformation on the chain needs to be accessed by end-users to be useful. This\nposition paper surveys different ways that end-users may access blockchains. We\nobserve that between the two extremes of running a full node and fully\nutilizing a trusted third-party service, many solutions regarding light nodes\nare emerging. We analyze these solutions based on three basic properties of web\ncommunication: integrity, availability and privacy. We conclude that currently,\nthe best way to access a blockchain while maintaining these three properties is\nstill to run a full node. We consider it essential that future blockchain\naccessibility services should be built while considering these three\nexpectations.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.05643,regular,pre_llm,2022,12,"{'ai_likelihood': 3.311369154188368e-07, 'text': 'Detecting Code Injections in Noisy Environments Through EM Signal\n  Analysis and SVD Denoising\n\n  The penetration of embedded devices in networks that support critical\napplications has rendered them a lucrative target for attackers and evildoers.\nHowever, traditional protection mechanisms may not be supported due to the\nmemory and computational limitations of these systems. Recently, the analysis\nof electromagnetic (EM) emanations has gathered the interest of the research\ncommunity. Thus, analogous protection systems have emerged as a viable solution\ne.g., for providing external, non-intrusive control-flow attestation for\nresource-constrained devices. Unfortunately, the majority of current work fails\nto account for the implications of real-life factors, predominantly the impact\nof environmental noise. In this work, we introduce a framework that integrates\nsingular value decomposition (SVD) along with outlier detection for discovering\nmalicious modifications of embedded software even under variable conditions of\nnoise. Our proposed framework achieves high detection accuracy i.e., above 93\\%\nAUC score for unknown attacks, even for extreme noise conditions i.e., -10 SNR.\nTo the best of our knowledge, this is the first time this realistic limiting\nfactor, i.e., environmental noise, is successfully addressed in the context of\nEM-based anomaly detection for embedded devices.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2301.03594,regular,pre_llm,2022,12,"{'ai_likelihood': 1.7550256517198352e-06, 'text': 'RingAuth: Wearable Authentication using a Smart Ring\n\n  In this paper, we show that by using inertial sensor data generated by a\nsmart ring, worn on the finger, the user can be authenticated when making\nmobile payments or when knocking on a door (for access control). The proposed\nsystem can be deployed purely in software and does not require updates to\nexisting payment terminals or infrastructure. We also demonstrate that smart\nring data can authenticate smartwatch gestures, and vice versa, allowing either\ndevice to act as an implicit second factor for the other. To validate the\nsystem, we conduct a user study (n=21) to collect inertial sensor data from\nusers as they perform gestures, and we evaluate the system against an active\nimpersonation attacker. Based on this data, we develop payment and access\ncontrol authentication models for which we achieve EERs of 0.04 and 0.02,\nrespectively.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.12309,regular,pre_llm,2022,12,"{'ai_likelihood': 0.0, 'text': 'How Cyber Criminal Use Social Engineering To Target Organizations\n\n  Social engineering is described as the art of manipulation. Cybercriminal use\nmanipulation to victims their targets using psychological principles to change\ntheir behavior to make unconscious decisions. This study identifies the attack\nand techniques used by cybercriminal to conduct social engineering attacks\nwithin an organization. This study evaluate how social engineering attacks are\ndelivered, techniques used and highlights how attackers take advantage\nCompromised systems. Lastly this study will also evaluate and provide the best\nsolutions to help mitigate social engineering attacks with an organization\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.13187,review,pre_llm,2022,12,"{'ai_likelihood': 0.00022755728827582466, 'text': ""Advancements in Biometric Technology with Artificial Intelligence\n\n  Authentication plays a significant part in dealing with security in public\nand private sectors such as healthcare systems, banking system, transportation\nsystem and law and security. Biometric technology has grown quickly recently,\nespecially in the areas of artificial intelligence and identity. Formerly,\nauthentication process has depended on security measures like passcodes,\nidentity fobs, and fingerprints. On the other hand, as just a consequence of\nthese precautions, theft has increased in frequency. In response, biometric\nsecurity was created, in which the identification of a person is based on\nfeatures derived from the physiological and behavioral traits of a human body\nusing biometric system. Biometric technology gadgets are available to the\npublic as they are embedded on computer systems, electronic devices, mobile\nphones, and other consumer electronics. As the fraudulent is increasing demand\nand use of biometric electronic devices has increased. As a consequence, it may\nbe possible to confirm a person's distinct identification. The goal of this\nstudy is to examine developments in biometric systems in the disciplines of\nmedicine and engineering. The study will present the perspectives and different\npoints of view of the secondary data, highlighting the need for more in-depth\nunderstanding and application of biometric technology to promote its\ndevelopment in the digital era. The study's findings may inspire people and\nbusinesses to more effectively incorporate biometric technologies in order to\nreduce the risks to data and identity security.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.08035,regular,pre_llm,2022,12,"{'ai_likelihood': 3.6093923780653213e-06, 'text': ""Hamming Distributions of Popular Perceptual Hashing Techniques\n\n  Content-based file matching has been widely deployed for decades, largely for\nthe detection of sources of copyright infringement, extremist materials, and\nabusive sexual media. Perceptual hashes, such as Microsoft's PhotoDNA, are one\nautomated mechanism for facilitating detection, allowing for machines to\napproximately match visual features of an image or video in a robust manner.\nHowever, there does not appear to be much public evaluation of such approaches,\nparticularly when it comes to how effective they are against content-preserving\nmodifications to media files. In this paper, we present a million-image scale\nevaluation of several perceptual hashing archetypes for popular algorithms\n(including Facebook's PDQ, Apple's Neuralhash, and the popular pHash library)\nagainst seven image variants. The focal point is the distribution of Hamming\ndistance scores between both unrelated images and image variants to better\nunderstand the problems faced by each approach.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.14296,regular,pre_llm,2022,12,"{'ai_likelihood': 7.2187847561306425e-06, 'text': 'Towards Comprehensively Understanding the Run-time Security of\n  Programmable Logic Controllers: A 3-year Empirical Study\n\n  Programmable Logic Controllers (PLCs) are the core control devices in\nIndustrial Control Systems (ICSs), which control and monitor the underlying\nphysical plants such as power grids. PLCs were initially designed to work in a\ntrusted industrial network, which however can be brittle once deployed in an\nInternet-facing (or penetrated) network. Yet, there is a lack of systematic\nempirical analysis of the run-time security of modern real-world PLCs. To close\nthis gap, we present the first large-scale measurement on 23 off-the-shelf PLCs\nacross 13 leading vendors. We find many common security issues and unexplored\nimplications that should be more carefully addressed in the design and\nimplementation. To sum up, the unsupervised logic applications can cause system\nresource/privilege abuse, which gives adversaries new means to hijack the\ncontrol flow of a runtime system remotely (without exploiting memory\nvulnerabilities); 2) the improper access control mechanisms bring many\nunauthorized access implications; 3) the proprietary or semi-proprietary\nprotocols are fragile regarding confidentiality and integrity protection of\nrun-time data. We empirically evaluated the corresponding attack vectors on\nmultiple PLCs, which demonstrates that the security implications are severe and\nbroad. Our findings were reported to the related parties responsibly, and 20\nbugs have been confirmed with 7 assigned CVEs.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.08275,review,pre_llm,2022,12,"{'ai_likelihood': 2.185503641764323e-06, 'text': ""A Survey on Anonymous Communication Systems with a Focus on Dining\n  Cryptographers Networks\n\n  Traffic analysis attacks can counteract end-to-end encryption and use leaked\ncommunication metadata to reveal information about communicating parties. With\nan ever-increasing amount of traffic by an ever-increasing number of networked\ndevices, communication privacy is undermined. Therefore, Anonymous\nCommunication Systems (ACSs) are proposed to hide the relationship between\ntransmitted messages and their senders and receivers, providing privacy\nproperties known as anonymity, unlinkability, and unobservability. This article\naims to review research in the ACSs field, focusing on Dining Cryptographers\nNetworks (DCNs). The DCN-based methods are information-theoretically secure and\nthus provide unconditional unobservability guarantees. Their adoption for\nanonymous communications was initially hindered because their computational and\ncommunication overhead was deemed significant at that time, and scalability\nproblems occurred. However, more recent contributions, such as the possibility\nto transmit messages of arbitrary length, efficient disruption handling and\noverhead improvements, have made the integration of modern DCN-based methods\nmore realistic. In addition, the literature does not follow a common definition\nfor privacy properties, making it hard to compare the approaches' gains.\nTherefore, this survey contributes to introducing a harmonized terminology for\nACS privacy properties, then presents an overview of the underlying principles\nof ACSs, in particular, DCN-based methods, and finally, investigates their\nalignment with the new harmonized privacy terminologies. Previous surveys did\nnot cover the most recent research advances in the ACS area or focus on\nDCN-based methods. Our comprehensive investigation closes this gap by providing\nvisual maps to highlight privacy properties and discussing the most promising\nideas for making DCNs applicable in resource-constrained environments.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.01537,regular,pre_llm,2022,12,"{'ai_likelihood': 1.7550256517198352e-06, 'text': 'Efficiency Boosting of Secure Cross-platform Recommender Systems over\n  Sparse Data\n\n  Fueled by its successful commercialization, the recommender system (RS) has\ngained widespread attention. However, as the training data fed into the RS\nmodels are often highly sensitive, it ultimately leads to severe privacy\nconcerns, especially when data are shared among different platforms. In this\npaper, we follow the tune of existing works to investigate the problem of\nsecure sparse matrix multiplication for cross-platform RSs. Two fundamental\nwhile critical issues are addressed: preserving the training data privacy and\nbreaking the data silo problem. Specifically, we propose two concrete\nconstructions with significantly boosted efficiency. They are designed for the\nsparse location insensitive case and location sensitive case, respectively.\nState-of-the-art cryptography building blocks including homomorphic encryption\n(HE) and private information retrieval (PIR) are fused into our protocols with\nnon-trivial optimizations. As a result, our schemes can enjoy the HE\nacceleration technique without privacy trade-offs. We give formal security\nproofs for the proposed schemes and conduct extensive experiments on both real\nand large-scale simulated datasets. Compared with state-of-the-art works, our\ntwo schemes compress the running time roughly by 10* and 2.8*. They also attain\nup to 15* and 2.3* communication reduction without accuracy loss.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.12785,regular,pre_llm,2022,12,"{'ai_likelihood': 9.271833631727431e-07, 'text': 'zkFaith: Soonami\'s Zero-Knowledge Identity Protocol\n\n  Individuals are encouraged to prove their eligibility to access specific\nservices regularly. However, providing various organizations with personal data\nspreads sensitive information and endangers people\'s privacy. Hence,\nprivacy-preserving identification systems that enable individuals to prove they\nare permitted to use specific services are required to fill the gap.\nCryptographic techniques are deployed to construct identity proofs across the\ninternet; nonetheless, they do not offer complete control over personal data or\nprevent users from forging and submitting fake data.\n  In this paper, we design a privacy-preserving identity protocol called\n""zkFaith."" A new approach to obtain a verified zero-knowledge identity unique\nto each individual. The protocol verifies the integrity of the documents\nprovided by the individuals and issues a zero-knowledge-based id without\nrevealing any information to the authenticator or verifier. The zkFaith\nleverages an aggregated version of the Camenisch-Lysyanskaya (CL) signature\nscheme to sign the user\'s commitment to the verified personal data. Then the\nusers with a zero-knowledge proof system can prove that they own the required\nattributes of the access criterion of the requested service providers. Vector\ncommitment and their position binding property enables us to, later on, update\nthe commitments based on the modification of the personal data; hence update\nthe issued zkFaith id with no requirement of initiating the protocol from\nscratch. We show that the design and implementation of the zkFaith with the\ngenerated proofs in real-world scenarios are scalable and comparable with the\nstate-of-the-art schemes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.09149,review,pre_llm,2022,12,"{'ai_likelihood': 1.5397866566975914e-05, 'text': 'From NEA and NIA to NESAS and SCAS: Demystifying the 5G Security\n  Ecosystem\n\n  Despite the numerous pompous statements regarding 5G, it is indisputable that\n5G creates a radical shift in telecommunications. The main reason is that 5G is\nan enabler of numerous applications we have long envisioned and either\nsimulated or implemented in test environments, partially or on a smaller scale.\n5G will soon unlock the potential of smart cities, industry 4.0, and IoT, to\nname a few. However, a crucial question is how much we can trust this\ntechnology. Since this technology will soon become the core infrastructure for\nall of the above, it is critical to understand the fundamental security\nmechanisms that comprise this technology and the guarantees they provide to\nassess the potential risks we are exposed to. This work follows a non-technical\nyet bottom-up approach to introduce the reader to the core security mechanisms\nand establish a baseline for the security of 5G, to demystify the principal\nnotions and processes. Based on the above, we streamline future directions and\nhighlight possible threats.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.03308,regular,pre_llm,2022,12,"{'ai_likelihood': 1.9205941094292534e-06, 'text': ""E3C: A Tool for Evaluating Communication and Computation Costs in\n  Authentication and Key Exchange Protocol\n\n  Today, with the development of blockchain and Internet of Things\ntechnologies, we need authentication protocols and key exchanges to communicate\nwith these different technologies. Symmetric and asymmetric encryption methods\nare used to design authentication and key exchange protocols, each of which has\ndifferent computation costs. In the Internet of Things systems, due to the\nlimited memory and computation power, researchers are looking the lightweight\ndesign protocols so that the pressure caused by the computation of protocols\ncan be minimized. Calculating protocols' computational and communication costs\nwas done manually until now, which was associated with human error. In this\npaper, we proposed an E3C tool that can calculate the computation and\ncommunication costs of the authentication and key exchange protocols. E3C\nprovides the ability to compare several protocols in terms of communication and\nprocessing costs and present them in separate charts. Comparing the processing\nand communication costs of classical and modern protocols manually and with the\nE3C indicate that the E3C can calculate the processing and communication costs\nof authentication and key exchange protocols with 99.99% accuracy.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.03793,regular,pre_llm,2022,12,"{'ai_likelihood': 3.311369154188368e-08, 'text': ""RADAR: A TTP-based Extensible, Explainable, and Effective System for\n  Network Traffic Analysis and Malware Detection\n\n  Network analysis and machine learning techniques have been widely applied for\nbuilding malware detection systems. Though these systems attain impressive\nresults, they often are $(i)$ not extensible, being monolithic, well tuned for\nthe specific task they have been designed for but very difficult to adapt\nand/or extend to other settings, and $(ii)$ not interpretable, being black\nboxes whose inner complexity makes it impossible to link the result of\ndetection with its root cause, making further analysis of threats a challenge.\nIn this paper we present RADAR, an extensible and explainable system that\nexploits the popular TTP (Tactics, Techniques, and Procedures) ontology of\nadversary behaviour described in the industry-standard MITRE ATT\\&CK framework\nin order to unequivocally identify and classify malicious behaviour using\nnetwork traffic. We evaluate RADAR on a very large dataset comprising of\n2,286,907 malicious and benign samples, representing a total of 84,792,452\nnetwork flows. The experimental analysis confirms that the proposed methodology\ncan be effectively exploited: RADAR's ability to detect malware is comparable\nto other state-of-the-art non-interpretable systems' capabilities. To the best\nof our knowledge, RADAR is the first TTP-based system for malware detection\nthat uses machine learning while being extensible and explainable.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.07387,review,pre_llm,2022,12,"{'ai_likelihood': 7.814831203884549e-06, 'text': 'Vulnerability Analysis of Smart Contracts\n\n  Blockchain platforms and smart contracts are vulnerable to security breaches.\nSecurity breaches of smart contracts have led to huge financial losses in terms\nof cryptocurrencies and tokens. In this paper, we present a systematic survey\nof vulnerability analysis of smart contracts. We begin by providing a brief\nabout the major types of attacks and vulnerabilities that are present in smart\ncontracts. Then we discuss existing frameworks, methods and technologies used\nfor vulnerability detection. We summarise our findings in a table which lists\neach framework and the attacks it protects against.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.11133,regular,pre_llm,2022,12,"{'ai_likelihood': 1.4106432596842449e-05, 'text': 'Device-Bind Key-Storageless Hardware AI Model IP Protection: A PUF and\n  Permute-Diffusion Encryption-Enabled Approach\n\n  Machine learning as a service (MLaaS) framework provides intelligent services\nor well-trained artificial intelligence (AI) models for local devices. However,\nin the process of model transmission and deployment, there are security issues,\ni.e. AI model leakage due to the unreliable transmission environments and\nillegal abuse at local devices without permission. Although existing works\nstudy the intellectual property (IP) protection of AI models, they mainly focus\non the watermark-based and encryption-based methods and have the following\nproblems: (i) The watermark-based methods only provide passive verification\nafterward rather than active protection. (ii) Encryption-based methods are low\nefficiency in computation and low security in key storage. (iii) The existing\nmethods are not device-bind without the ability to avoid illegal abuse of AI\nmodels. To deal with these problems, we propose a device-bind and\nkey-storageless hardware AI model IP protection mechanism. First, a physical\nunclonable function (PUF) and permute-diffusion encryption-based AI model\nprotection framework is proposed, including the PUF-based secret key generation\nand the geometric-value transformation-based weights encryption. Second, we\ndesign a PUF-based key generation protocol, where delay-based Anderson PUF is\nadopted to generate the derive-bind secret key. Besides, convolutional coding\nand convolutional interleaving technologies are combined to improve the\nstability of PUF-based key generation and reconstruction. Third, a permute and\ndiffusion-based intelligent model weights encryption/decryption method is\nproposed to achieve effective IP protection, where chaos theory is utilized to\nconvert the PUF-based secret key to encryption/decryption keys. Finally,\nexperimental evaluation demonstrates the effectiveness of the proposed\nintelligent model IP protection mechanism.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.11128,regular,pre_llm,2022,12,"{'ai_likelihood': 1.3742181989881728e-05, 'text': 'BDSP: A Fair Blockchain-enabled Framework for Privacy-Enhanced\n  Enterprise Data Sharing\n\n  Across industries, there is an ever-increasing rate of data sharing for\ncollaboration and innovation between organizations and their customers,\npartners, suppliers, and internal teams. However, many enterprises are\nrestricted from freely sharing data due to regulatory restrictions across\ndifferent regions, performance issues in moving large volume data, or\nrequirements to maintain autonomy. In such situations, the enterprise can\nbenefit from the concept of federated learning, in which machine learning\nmodels are constructed at various geographic sites. In this paper, we introduce\na general framework, namely BDSP, to share data among enterprises based on\nBlockchain and federated learning techniques. Specifically, we propose a\ntransparency contribution accounting mechanism to estimate the valuation of\ndata and implement a proof-of-concept for further evaluation. The extensive\nexperimental results show that the proposed BDSP has a competitive performance\nwith higher training accuracy, an increase of over 5%, and lower communication\noverhead, reducing 3 times, compared to baseline approaches.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.05347,review,pre_llm,2022,12,"{'ai_likelihood': 1.158979203965929e-06, 'text': ""A systematic literature review on insider threats\n\n  Insider threats is the most concerned cybersecurity problem which is poorly\naddressed by widely used security solutions. Despite the fact that there have\nbeen several scientific publications in this area, but from our innovative\nstudy classification and structural taxonomy proposals, we argue to provide the\nmore information about insider threats and defense measures used to counter\nthem. While adopting the current grounded theory method for a thorough\nliterature evaluation, our categorization's goal is to organize knowledge in\ninsider threat research. Along with an analysis of major recent studies on\ndetecting insider threats, the major goal of the study is to develop a\nclassification of current types of insiders, levels of access, motivations\nbehind it, insider profiling, security properties, and methods they use to\nattack. This includes use of machine learning algorithm, behavior analysis,\nmethods of detection and evaluation. Moreover, actual incidents related to\ninsider attacks have also been analyzed.\n"", 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.0905,regular,pre_llm,2022,12,"{'ai_likelihood': 6.622738308376736e-08, 'text': 'Determining Distributions of Security Means for WSNs based on the Model\n  of a Neighbourhood Watch\n\n  Neighbourhood watch is a concept that allows a community to distribute a\ncomplex security task in between all members. Members of the community carry\nout individual security tasks to contribute to the overall security of it. It\nreduces the workload of a particular individual while securing all members and\nallowing them to carry out a multitude of security tasks. Wireless sensor\nnetworks (WSNs) are composed of resource-constraint independent battery driven\ncomputers as nodes communicating wirelessly. Security in WSNs is essential.\nWithout sufficient security, an attacker is able to eavesdrop the\ncommunication, tamper monitoring results or deny critical nodes providing their\nservice in a way to cut off larger network parts. The resource-constraint\nnature of sensor nodes prevents them from running full-fledged security\nprotocols. Instead, it is necessary to assess the most significant security\nthreats and implement specialised protocols. A neighbourhood-watch inspired\ndistributed security scheme for WSNs has been introduced by Langend\\""orfer. Its\ngoal is to increase the variety of attacks a WSN can fend off. A framework of\nsuch complexity has to be designed in multiple steps. Here, we introduce an\napproach to determine distributions of security means on large-scale static\nhomogeneous WSNs. Therefore, we model WSNs as undirected graphs in which two\nnodes connected iff they are in transmission range. The framework aims to\npartition the graph into $n$ distinct security means resulting in the targeted\ndistribution. The underlying problems turn out to be NP hard and we attempt to\nsolve them using linear programs (LPs). To evaluate the computability of the\nLPs, we generate large numbers of random {\\lambda}-precision unit disk graphs\n(UDGs) as representation of WSNs. For this purpose, we introduce a novel\n{\\lambda}-precision UDG generator to model WSNs with a minimal distance in\nbetween nodes.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
2212.02185,regular,pre_llm,2022,12,"{'ai_likelihood': 2.4504131740993925e-06, 'text': 'Identity Management through a global Discovery System based on\n  Decentralized Identities\n\n  Digital identities today continue to be a company resource instead of\nbelonging to the actual person they represent. At the same time, the\ndigitalization of everyday services intensifies the Identity Management problem\nand leads to a constant increase of users online identities and identity\nrelated data. This paper presents DIMANDS2, a framework capable of organizing\nidentity data that allows service providers and identity issuers securely\nexchange identity related information in a privacy-enabled manner while the\nuser maintains full control over any activity related to his/her identity data.\nThe framework is format-agnostic and can accommodate any type of identifier\n(existing or new), without requiring from existing services and providers to\nimplement and adopt another new global identifier.\n', 'prediction': 'Unlikely AI', 'llm_prediction': {'GPT35': 0.0, 'GPT4': 0.0, 'CLAUDE': 0.0, 'GOOGLE': 0.0, 'OPENAI_O_SERIES': 0.0, 'DEEPSEEK': 0.0, 'GROK': 0.0, 'NOVA': 0.0, 'OTHER': 0.0, 'HUMAN': 0.0}}"
